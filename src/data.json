{"dailies":[{"items":[{"creator":"Tijdreiziger","title":"PalmOS on Raspberry Pi","link":"https://pmig96.wordpress.com/2021/04/29/palmos-on-raspberry-pi/","pubDate":"Fri, 10 Sep 2021 22:59:53 +0000","dc:creator":"Tijdreiziger","comments":"https://news.ycombinator.com/item?id=28487817","content":"\n<p>Article URL: <a href=\"https://pmig96.wordpress.com/2021/04/29/palmos-on-raspberry-pi/\">https://pmig96.wordpress.com/2021/04/29/palmos-on-raspberry-pi/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28487817\">https://news.ycombinator.com/item?id=28487817</a></p>\n<p>Points: 64</p>\n<p># Comments: 29</p>\n","contentSnippet":"Article URL: https://pmig96.wordpress.com/2021/04/29/palmos-on-raspberry-pi/\nComments URL: https://news.ycombinator.com/item?id=28487817\nPoints: 64\n# Comments: 29","guid":"https://news.ycombinator.com/item?id=28487817","isoDate":"2021-09-10T22:59:53.000Z","timestamp":"9/10/2021"},{"creator":"KangLi","title":"Indra – Hackers Behind Recent Attacks on Iran","link":"https://research.checkpoint.com/2021/indra-hackers-behind-recent-attacks-on-iran/","pubDate":"Fri, 10 Sep 2021 22:36:29 +0000","dc:creator":"KangLi","comments":"https://news.ycombinator.com/item?id=28487665","content":"\n<p>Article URL: <a href=\"https://research.checkpoint.com/2021/indra-hackers-behind-recent-attacks-on-iran/\">https://research.checkpoint.com/2021/indra-hackers-behind-recent-attacks-on-iran/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28487665\">https://news.ycombinator.com/item?id=28487665</a></p>\n<p>Points: 21</p>\n<p># Comments: 7</p>\n","contentSnippet":"Article URL: https://research.checkpoint.com/2021/indra-hackers-behind-recent-attacks-on-iran/\nComments URL: https://news.ycombinator.com/item?id=28487665\nPoints: 21\n# Comments: 7","guid":"https://news.ycombinator.com/item?id=28487665","isoDate":"2021-09-10T22:36:29.000Z","timestamp":"9/10/2021"},{"creator":"seik","title":"Show HN: LunarVim – An opinionated, extensible, and fast IDE layer for Neovim","link":"https://www.lunarvim.org","pubDate":"Fri, 10 Sep 2021 21:55:11 +0000","dc:creator":"seik","comments":"https://news.ycombinator.com/item?id=28487337","content":"\n<p>Article URL: <a href=\"https://www.lunarvim.org\">https://www.lunarvim.org</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28487337\">https://news.ycombinator.com/item?id=28487337</a></p>\n<p>Points: 33</p>\n<p># Comments: 15</p>\n","contentSnippet":"Article URL: https://www.lunarvim.org\nComments URL: https://news.ycombinator.com/item?id=28487337\nPoints: 33\n# Comments: 15","guid":"https://news.ycombinator.com/item?id=28487337","isoDate":"2021-09-10T21:55:11.000Z","timestamp":"9/10/2021"},{"creator":"Aaronn","title":"Wait, Did AS8003 just disappear?","link":"https://www.kentik.com/blog/wait-did-as8003-just-disappear/","pubDate":"Fri, 10 Sep 2021 21:49:32 +0000","dc:creator":"Aaronn","comments":"https://news.ycombinator.com/item?id=28487284","content":"\n<p>Article URL: <a href=\"https://www.kentik.com/blog/wait-did-as8003-just-disappear/\">https://www.kentik.com/blog/wait-did-as8003-just-disappear/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28487284\">https://news.ycombinator.com/item?id=28487284</a></p>\n<p>Points: 94</p>\n<p># Comments: 30</p>\n","contentSnippet":"Article URL: https://www.kentik.com/blog/wait-did-as8003-just-disappear/\nComments URL: https://news.ycombinator.com/item?id=28487284\nPoints: 94\n# Comments: 30","guid":"https://news.ycombinator.com/item?id=28487284","isoDate":"2021-09-10T21:49:32.000Z","timestamp":"9/10/2021"},{"creator":"jdkee","title":"A second hexagon in the stratosphere of Saturn","link":"https://mesonstars.com/inteteresting/they-find-a-second-hexagon-in-the-stratosphere-of-saturn/","pubDate":"Fri, 10 Sep 2021 20:41:44 +0000","dc:creator":"jdkee","comments":"https://news.ycombinator.com/item?id=28486647","content":"\n<p>Article URL: <a href=\"https://mesonstars.com/inteteresting/they-find-a-second-hexagon-in-the-stratosphere-of-saturn/\">https://mesonstars.com/inteteresting/they-find-a-second-hexagon-in-the-stratosphere-of-saturn/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28486647\">https://news.ycombinator.com/item?id=28486647</a></p>\n<p>Points: 74</p>\n<p># Comments: 25</p>\n","contentSnippet":"Article URL: https://mesonstars.com/inteteresting/they-find-a-second-hexagon-in-the-stratosphere-of-saturn/\nComments URL: https://news.ycombinator.com/item?id=28486647\nPoints: 74\n# Comments: 25","guid":"https://news.ycombinator.com/item?id=28486647","isoDate":"2021-09-10T20:41:44.000Z","timestamp":"9/10/2021"},{"creator":"petergeoghegan","title":"Index bloat reduced in PostgreSQL v14","link":"https://www.cybertec-postgresql.com/en/index-bloat-reduced-in-postgresql-v14/","pubDate":"Fri, 10 Sep 2021 20:39:08 +0000","dc:creator":"petergeoghegan","comments":"https://news.ycombinator.com/item?id=28486623","content":"\n<p>Article URL: <a href=\"https://www.cybertec-postgresql.com/en/index-bloat-reduced-in-postgresql-v14/\">https://www.cybertec-postgresql.com/en/index-bloat-reduced-in-postgresql-v14/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28486623\">https://news.ycombinator.com/item?id=28486623</a></p>\n<p>Points: 49</p>\n<p># Comments: 10</p>\n","contentSnippet":"Article URL: https://www.cybertec-postgresql.com/en/index-bloat-reduced-in-postgresql-v14/\nComments URL: https://news.ycombinator.com/item?id=28486623\nPoints: 49\n# Comments: 10","guid":"https://news.ycombinator.com/item?id=28486623","isoDate":"2021-09-10T20:39:08.000Z","timestamp":"9/10/2021"},{"creator":"kaycebasques","title":"Windy.com","link":"https://windy.com","pubDate":"Fri, 10 Sep 2021 20:15:02 +0000","dc:creator":"kaycebasques","comments":"https://news.ycombinator.com/item?id=28486389","content":"\n<p>Article URL: <a href=\"https://windy.com\">https://windy.com</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28486389\">https://news.ycombinator.com/item?id=28486389</a></p>\n<p>Points: 527</p>\n<p># Comments: 127</p>\n","contentSnippet":"Article URL: https://windy.com\nComments URL: https://news.ycombinator.com/item?id=28486389\nPoints: 527\n# Comments: 127","guid":"https://news.ycombinator.com/item?id=28486389","isoDate":"2021-09-10T20:15:02.000Z","timestamp":"9/10/2021"},{"creator":"anchpop","title":"Windows Subsystem for Linux GUI","link":"https://github.com/microsoft/wslg","pubDate":"Fri, 10 Sep 2021 19:45:49 +0000","dc:creator":"anchpop","comments":"https://news.ycombinator.com/item?id=28486133","content":"\n<p>Article URL: <a href=\"https://github.com/microsoft/wslg\">https://github.com/microsoft/wslg</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28486133\">https://news.ycombinator.com/item?id=28486133</a></p>\n<p>Points: 319</p>\n<p># Comments: 226</p>\n","contentSnippet":"Article URL: https://github.com/microsoft/wslg\nComments URL: https://news.ycombinator.com/item?id=28486133\nPoints: 319\n# Comments: 226","guid":"https://news.ycombinator.com/item?id=28486133","isoDate":"2021-09-10T19:45:49.000Z","timestamp":"9/10/2021"},{"creator":"jdkee","title":"Google illegally underpaid thousands of workers","link":"https://www.theguardian.com/technology/2021/sep/10/google-underpaid-workers-illegal-pay-disparity-documents","pubDate":"Fri, 10 Sep 2021 19:19:07 +0000","dc:creator":"jdkee","comments":"https://news.ycombinator.com/item?id=28485905","content":"\n<p>Article URL: <a href=\"https://www.theguardian.com/technology/2021/sep/10/google-underpaid-workers-illegal-pay-disparity-documents\">https://www.theguardian.com/technology/2021/sep/10/google-underpaid-workers-illegal-pay-disparity-documents</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28485905\">https://news.ycombinator.com/item?id=28485905</a></p>\n<p>Points: 398</p>\n<p># Comments: 123</p>\n","contentSnippet":"Article URL: https://www.theguardian.com/technology/2021/sep/10/google-underpaid-workers-illegal-pay-disparity-documents\nComments URL: https://news.ycombinator.com/item?id=28485905\nPoints: 398\n# Comments: 123","guid":"https://news.ycombinator.com/item?id=28485905","isoDate":"2021-09-10T19:19:07.000Z","timestamp":"9/10/2021"},{"creator":"Borrible","title":"Atomic Gardening","link":"https://www.atlasobscura.com/articles/radioactive-atomic-gardening","pubDate":"Fri, 10 Sep 2021 18:05:51 +0000","dc:creator":"Borrible","comments":"https://news.ycombinator.com/item?id=28485115","content":"\n<p>Article URL: <a href=\"https://www.atlasobscura.com/articles/radioactive-atomic-gardening\">https://www.atlasobscura.com/articles/radioactive-atomic-gardening</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28485115\">https://news.ycombinator.com/item?id=28485115</a></p>\n<p>Points: 56</p>\n<p># Comments: 18</p>\n","contentSnippet":"Article URL: https://www.atlasobscura.com/articles/radioactive-atomic-gardening\nComments URL: https://news.ycombinator.com/item?id=28485115\nPoints: 56\n# Comments: 18","guid":"https://news.ycombinator.com/item?id=28485115","isoDate":"2021-09-10T18:05:51.000Z","timestamp":"9/10/2021"},{"creator":"reikonomusha","title":"Coalton: How to Have Our (Typed) Cake and (Safely) Eat It Too, in Common Lisp","link":"https://coalton-lang.github.io/20211010-introducing-coalton/","pubDate":"Fri, 10 Sep 2021 17:42:36 +0000","dc:creator":"reikonomusha","comments":"https://news.ycombinator.com/item?id=28484850","content":"\n<p>Article URL: <a href=\"https://coalton-lang.github.io/20211010-introducing-coalton/\">https://coalton-lang.github.io/20211010-introducing-coalton/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28484850\">https://news.ycombinator.com/item?id=28484850</a></p>\n<p>Points: 114</p>\n<p># Comments: 16</p>\n","contentSnippet":"Article URL: https://coalton-lang.github.io/20211010-introducing-coalton/\nComments URL: https://news.ycombinator.com/item?id=28484850\nPoints: 114\n# Comments: 16","guid":"https://news.ycombinator.com/item?id=28484850","isoDate":"2021-09-10T17:42:36.000Z","timestamp":"9/10/2021"},{"creator":"FiloSottile","title":"WhatsApp – Security of End-to-End Encrypted Backups [pdf]","link":"https://www.whatsapp.com/security/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf","pubDate":"Fri, 10 Sep 2021 17:28:36 +0000","dc:creator":"FiloSottile","comments":"https://news.ycombinator.com/item?id=28484681","content":"\n<p>Article URL: <a href=\"https://www.whatsapp.com/security/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf\">https://www.whatsapp.com/security/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28484681\">https://news.ycombinator.com/item?id=28484681</a></p>\n<p>Points: 104</p>\n<p># Comments: 58</p>\n","contentSnippet":"Article URL: https://www.whatsapp.com/security/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf\nComments URL: https://news.ycombinator.com/item?id=28484681\nPoints: 104\n# Comments: 58","guid":"https://news.ycombinator.com/item?id=28484681","isoDate":"2021-09-10T17:28:36.000Z","timestamp":"9/10/2021"},{"creator":"T-A","title":"YOLOv5 on CPUs: Sparsifying to Achieve GPU-Level Performance","link":"https://neuralmagic.com/blog/benchmark-yolov5-on-cpus-with-deepsparse/","pubDate":"Fri, 10 Sep 2021 17:04:02 +0000","dc:creator":"T-A","comments":"https://news.ycombinator.com/item?id=28484373","content":"\n<p>Article URL: <a href=\"https://neuralmagic.com/blog/benchmark-yolov5-on-cpus-with-deepsparse/\">https://neuralmagic.com/blog/benchmark-yolov5-on-cpus-with-deepsparse/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28484373\">https://news.ycombinator.com/item?id=28484373</a></p>\n<p>Points: 90</p>\n<p># Comments: 38</p>\n","contentSnippet":"Article URL: https://neuralmagic.com/blog/benchmark-yolov5-on-cpus-with-deepsparse/\nComments URL: https://news.ycombinator.com/item?id=28484373\nPoints: 90\n# Comments: 38","guid":"https://news.ycombinator.com/item?id=28484373","isoDate":"2021-09-10T17:04:02.000Z","timestamp":"9/10/2021"},{"creator":"defaulty","title":"Write More, but Shorter","link":"https://blog.kewah.com/2021/write-more-but-shorter/","pubDate":"Fri, 10 Sep 2021 16:16:48 +0000","dc:creator":"defaulty","comments":"https://news.ycombinator.com/item?id=28483671","content":"\n<p>Article URL: <a href=\"https://blog.kewah.com/2021/write-more-but-shorter/\">https://blog.kewah.com/2021/write-more-but-shorter/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28483671\">https://news.ycombinator.com/item?id=28483671</a></p>\n<p>Points: 172</p>\n<p># Comments: 77</p>\n","contentSnippet":"Article URL: https://blog.kewah.com/2021/write-more-but-shorter/\nComments URL: https://news.ycombinator.com/item?id=28483671\nPoints: 172\n# Comments: 77","guid":"https://news.ycombinator.com/item?id=28483671","isoDate":"2021-09-10T16:16:48.000Z","timestamp":"9/10/2021"},{"creator":"freddier","title":"Court issues permanent injunction in Epic vs. Apple case","link":"https://www.theverge.com/2021/9/10/22662320/epic-apple-ruling-injunction-judge-court-app-store","pubDate":"Fri, 10 Sep 2021 15:26:35 +0000","dc:creator":"freddier","comments":"https://news.ycombinator.com/item?id=28482895","content":"\n<p>Article URL: <a href=\"https://www.theverge.com/2021/9/10/22662320/epic-apple-ruling-injunction-judge-court-app-store\">https://www.theverge.com/2021/9/10/22662320/epic-apple-ruling-injunction-judge-court-app-store</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28482895\">https://news.ycombinator.com/item?id=28482895</a></p>\n<p>Points: 1156</p>\n<p># Comments: 744</p>\n","contentSnippet":"Article URL: https://www.theverge.com/2021/9/10/22662320/epic-apple-ruling-injunction-judge-court-app-store\nComments URL: https://news.ycombinator.com/item?id=28482895\nPoints: 1156\n# Comments: 744","guid":"https://news.ycombinator.com/item?id=28482895","isoDate":"2021-09-10T15:26:35.000Z","timestamp":"9/10/2021"},{"creator":"PaulHoule","title":"Eyeway's Retina-Tracking Foveated Display","link":"https://kguttag.com/2021/09/07/eyeway-vision-part-3-analysis/","pubDate":"Fri, 10 Sep 2021 14:57:58 +0000","dc:creator":"PaulHoule","comments":"https://news.ycombinator.com/item?id=28482485","content":"\n<p>Article URL: <a href=\"https://kguttag.com/2021/09/07/eyeway-vision-part-3-analysis/\">https://kguttag.com/2021/09/07/eyeway-vision-part-3-analysis/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28482485\">https://news.ycombinator.com/item?id=28482485</a></p>\n<p>Points: 106</p>\n<p># Comments: 36</p>\n","contentSnippet":"Article URL: https://kguttag.com/2021/09/07/eyeway-vision-part-3-analysis/\nComments URL: https://news.ycombinator.com/item?id=28482485\nPoints: 106\n# Comments: 36","guid":"https://news.ycombinator.com/item?id=28482485","isoDate":"2021-09-10T14:57:58.000Z","timestamp":"9/10/2021"},{"creator":"rukshn","title":"Work on interesting problems. Not interesting tech","link":"https://ruky.me/2021/09/10/work-on-interesting-problems-not-interesting-technologies/","pubDate":"Fri, 10 Sep 2021 14:39:59 +0000","dc:creator":"rukshn","comments":"https://news.ycombinator.com/item?id=28482197","content":"\n<p>Article URL: <a href=\"https://ruky.me/2021/09/10/work-on-interesting-problems-not-interesting-technologies/\">https://ruky.me/2021/09/10/work-on-interesting-problems-not-interesting-technologies/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28482197\">https://news.ycombinator.com/item?id=28482197</a></p>\n<p>Points: 126</p>\n<p># Comments: 62</p>\n","contentSnippet":"Article URL: https://ruky.me/2021/09/10/work-on-interesting-problems-not-interesting-technologies/\nComments URL: https://news.ycombinator.com/item?id=28482197\nPoints: 126\n# Comments: 62","guid":"https://news.ycombinator.com/item?id=28482197","isoDate":"2021-09-10T14:39:59.000Z","timestamp":"9/10/2021"},{"creator":"domrdy","title":"Travel planning software: The most common bad startup idea (2012)","link":"https://blog.garrytan.com/travel-planning-software-the-most-common-bad","pubDate":"Fri, 10 Sep 2021 14:23:04 +0000","dc:creator":"domrdy","comments":"https://news.ycombinator.com/item?id=28481963","content":"\n<p>Article URL: <a href=\"https://blog.garrytan.com/travel-planning-software-the-most-common-bad\">https://blog.garrytan.com/travel-planning-software-the-most-common-bad</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28481963\">https://news.ycombinator.com/item?id=28481963</a></p>\n<p>Points: 178</p>\n<p># Comments: 125</p>\n","contentSnippet":"Article URL: https://blog.garrytan.com/travel-planning-software-the-most-common-bad\nComments URL: https://news.ycombinator.com/item?id=28481963\nPoints: 178\n# Comments: 125","guid":"https://news.ycombinator.com/item?id=28481963","isoDate":"2021-09-10T14:23:04.000Z","timestamp":"9/10/2021"},{"creator":"kordlessagain","title":"Wide-ranging SolarWinds probe sparks fear in Corporate America","link":"https://www.reuters.com/technology/exclusive-wide-ranging-solarwinds-probe-sparks-fear-corporate-america-2021-09-10/","pubDate":"Fri, 10 Sep 2021 14:20:30 +0000","dc:creator":"kordlessagain","comments":"https://news.ycombinator.com/item?id=28481925","content":"\n<p>Article URL: <a href=\"https://www.reuters.com/technology/exclusive-wide-ranging-solarwinds-probe-sparks-fear-corporate-america-2021-09-10/\">https://www.reuters.com/technology/exclusive-wide-ranging-solarwinds-probe-sparks-fear-corporate-america-2021-09-10/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28481925\">https://news.ycombinator.com/item?id=28481925</a></p>\n<p>Points: 277</p>\n<p># Comments: 131</p>\n","contentSnippet":"Article URL: https://www.reuters.com/technology/exclusive-wide-ranging-solarwinds-probe-sparks-fear-corporate-america-2021-09-10/\nComments URL: https://news.ycombinator.com/item?id=28481925\nPoints: 277\n# Comments: 131","guid":"https://news.ycombinator.com/item?id=28481925","isoDate":"2021-09-10T14:20:30.000Z","timestamp":"9/10/2021"},{"creator":"owjuhl","title":"Show HN: Medusa – Open-source alternative to Shopify","link":"https://medusa-commerce.com","pubDate":"Fri, 10 Sep 2021 14:19:28 +0000","dc:creator":"owjuhl","comments":"https://news.ycombinator.com/item?id=28481913","content":"\n<p>Article URL: <a href=\"https://medusa-commerce.com\">https://medusa-commerce.com</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=28481913\">https://news.ycombinator.com/item?id=28481913</a></p>\n<p>Points: 260</p>\n<p># Comments: 55</p>\n","contentSnippet":"Article URL: https://medusa-commerce.com\nComments URL: https://news.ycombinator.com/item?id=28481913\nPoints: 260\n# Comments: 55","guid":"https://news.ycombinator.com/item?id=28481913","isoDate":"2021-09-10T14:19:28.000Z","timestamp":"9/10/2021"}],"feedUrl":"https://hnrss.org/frontpage?points=10&comments=5","paginationLinks":{"self":"https://hnrss.org/frontpage?points=10&comments=5"},"title":"Hacker News: Front Page","description":"Hacker News RSS","generator":"hnrss v1.1-9-ge3a2bf8","link":"https://news.ycombinator.com/","lastBuildDate":"Sat, 11 Sep 2021 02:33:45 +0000","docs":"https://hnrss.org/","feed":"https://hnrss.org/frontpage?points=10&comments=5"},{"items":[{"title":"How Ayo the Clown and Sunblaze represent retro","link":"http://retronauts.com/article/1786/jumping-into-ayo-the-clown-and-sunblaze","pubDate":"Fri, 10 Sep 2021 18:50:00 -0700","content":"Two lesser-known Switch jump n' runs in the spotlight","contentSnippet":"Two lesser-known Switch jump n' runs in the spotlight","guid":"/article/1786/jumping-into-ayo-the-clown-and-sunblaze","isoDate":"2021-09-11T01:50:00.000Z","timestamp":"9/10/2021"},{"title":"Retro Re-release Roundup, week of September 9, 2021","link":"http://retronauts.com/article/1785/retro-re-release-roundup-week-of-september-9-2021","pubDate":"Thu, 09 Sep 2021 12:20:00 -0700","content":"These Colo(u)rs don't run. (The game doesn't work properly. That's the joke.)","contentSnippet":"These Colo(u)rs don't run. (The game doesn't work properly. That's the joke.)","guid":"/article/1785/retro-re-release-roundup-week-of-september-9-2021","isoDate":"2021-09-09T19:20:00.000Z","timestamp":"9/9/2021"},{"title":"Retronauts Episode 401: Kirby, Part 1","link":"http://retronauts.com/article/1784/retronauts-episode-401-kirby-part-1","pubDate":"Mon, 06 Sep 2021 16:00:00 -0700","content":"Have a pen and paper handy as you'll need to draw a lot of circles to keep up","contentSnippet":"Have a pen and paper handy as you'll need to draw a lot of circles to keep up","guid":"/article/1784/retronauts-episode-401-kirby-part-1","isoDate":"2021-09-06T23:00:00.000Z","timestamp":"9/6/2021"},{"title":"Retro Re-release Roundup, week of September 2, 2021","link":"http://retronauts.com/article/1783/retro-re-release-roundup-week-of-september-2-2021","pubDate":"Thu, 02 Sep 2021 16:02:00 -0700","content":"Everything is once again fine.","contentSnippet":"Everything is once again fine.","guid":"/article/1783/retro-re-release-roundup-week-of-september-2-2021","isoDate":"2021-09-02T23:02:00.000Z","timestamp":"9/2/2021"},{"title":"Kickstarter Kompilation: September 2021 edition","link":"http://retronauts.com/article/1782/kickstarter-kompilation-september-2021-edition","pubDate":"Wed, 01 Sep 2021 16:00:00 -0700","content":"Books about old games, videos about old games, and an actual old game are all featured this month.","contentSnippet":"Books about old games, videos about old games, and an actual old game are all featured this month.","guid":"/article/1782/kickstarter-kompilation-september-2021-edition","isoDate":"2021-09-01T23:00:00.000Z","timestamp":"9/1/2021"},{"title":"Retronauts Episode 399: Formative Gaming Memories","link":"http://retronauts.com/article/1781/retronauts-episode-399-formative-gaming-memories","pubDate":"Mon, 30 Aug 2021 16:00:00 -0700","content":"\"Recall, Recall, Recall...\"","contentSnippet":"\"Recall, Recall, Recall...\"","guid":"/article/1781/retronauts-episode-399-formative-gaming-memories","isoDate":"2021-08-30T23:00:00.000Z","timestamp":"8/30/2021"},{"title":"Retro Re-release Roundup, week of August 26, 2021","link":"http://retronauts.com/article/1780/retro-re-release-roundup-week-of-august-26-2021","pubDate":"Thu, 26 Aug 2021 14:37:00 -0700","content":"The crownless king of the rougelites returns to the handheld realm.","contentSnippet":"The crownless king of the rougelites returns to the handheld realm.","guid":"/article/1780/retro-re-release-roundup-week-of-august-26-2021","isoDate":"2021-08-26T21:37:00.000Z","timestamp":"8/26/2021"},{"title":"Retronauts Episode 398: The Super NES Launch","link":"http://retronauts.com/article/1779/retronauts-episode-398-the-super-nes-launch","pubDate":"Mon, 23 Aug 2021 16:00:00 -0700","content":"We've added four new buttons to the podcast in celebration!","contentSnippet":"We've added four new buttons to the podcast in celebration!","guid":"/article/1779/retronauts-episode-398-the-super-nes-launch","isoDate":"2021-08-23T23:00:00.000Z","timestamp":"8/23/2021"},{"title":"RIP Sonny Chiba, Japanese action star","link":"http://retronauts.com/article/1778/rip-sonny-chiba-japanese-action-star","pubDate":"Fri, 20 Aug 2021 16:30:00 -0700","content":"1939-2021","contentSnippet":"1939-2021","guid":"/article/1778/rip-sonny-chiba-japanese-action-star","isoDate":"2021-08-20T23:30:00.000Z","timestamp":"8/20/2021"},{"title":"Retro Re-release Roundup, week of August 19, 2021","link":"http://retronauts.com/article/1777/retro-re-release-roundup-week-of-august-19-2021","pubDate":"Thu, 19 Aug 2021 15:23:00 -0700","content":"Return to the Nth Dimension.","contentSnippet":"Return to the Nth Dimension.","guid":"/article/1777/retro-re-release-roundup-week-of-august-19-2021","isoDate":"2021-08-19T22:23:00.000Z","timestamp":"8/19/2021"},{"title":"Retronauts Episode 396: Battletoads","link":"http://retronauts.com/article/1776/retronauts-episode-396-battletoads","pubDate":"Mon, 16 Aug 2021 16:00:00 -0700","content":"Because \"Fighting Frogs\" must have been taken","contentSnippet":"Because \"Fighting Frogs\" must have been taken","guid":"/article/1776/retronauts-episode-396-battletoads","isoDate":"2021-08-16T23:00:00.000Z","timestamp":"8/16/2021"}],"feedUrl":"http://retronauts.com/feeds/rss/","paginationLinks":{"self":"http://retronauts.com/feeds/rss/"},"title":"Retronauts","description":"Retronauts","link":"http://retronauts.com/","feed":"https://retronauts.com/feed/rss"},{"items":[{"creator":"terry","title":"Frog Finder","link":"https://terrysfreegameoftheweek.com/frog-finder/?utm_source=rss&utm_medium=rss&utm_campaign=frog-finder","pubDate":"Fri, 10 Sep 2021 09:55:07 +0000","content:encoded":"\n<p>by <a href=\"https://poobslag.itch.io/\">Poobslag</a>.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/09/frogfinder.gif\" alt=\"\"/></figure>\n\n\n\n<p><a href=\"https://poobslag.itch.io/frog-finder\">Frog Finder</a> is an educational puzzle game, with a series of abstract puzzles about finding the frog hidden in a grid.</p>\n\n\n\n<p>I think I had an expectation going in that it was going to be somehow subversive, somehow&#8230; Frog Fractiony? But that&#8217;s not it. If anything, it&#8217;s anti-subversive, like it has a kind of charming earnestness, which is something I guess you get in kids games. It&#8217;s adorable! It made me feel like a toddler.</p>\n\n\n\n<p>It&#8217;s hard to describe &#8211; it manages to capture a nostalgia I didn&#8217;t know I had, for these alien-feeling early edutainment games that evoke a sense of wonder and joy.</p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://poobslag.itch.io/frog-finder\">[<strong>Play online (itch.io)]</strong></a></p>\n","content:encodedSnippet":"by Poobslag.\n\n\n\n\nFrog Finder is an educational puzzle game, with a series of abstract puzzles about finding the frog hidden in a grid.\nI think I had an expectation going in that it was going to be somehow subversive, somehow… Frog Fractiony? But that’s not it. If anything, it’s anti-subversive, like it has a kind of charming earnestness, which is something I guess you get in kids games. It’s adorable! It made me feel like a toddler.\nIt’s hard to describe – it manages to capture a nostalgia I didn’t know I had, for these alien-feeling early edutainment games that evoke a sense of wonder and joy.\n[Play online (itch.io)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/frog-finder/#respond","content":"by Poobslag. Frog Finder is an educational puzzle game, with a series of abstract puzzles about finding the frog hidden in a grid. I think I had an expectation going in that it was going to be somehow subversive, somehow&#8230; Frog Fractiony? But that&#8217;s not it. If anything, it&#8217;s anti-subversive, like it has a kind&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/frog-finder/\">Continue reading <span class=\"screen-reader-text\">Frog Finder</span></a>","contentSnippet":"by Poobslag. Frog Finder is an educational puzzle game, with a series of abstract puzzles about finding the frog hidden in a grid. I think I had an expectation going in that it was going to be somehow subversive, somehow… Frog Fractiony? But that’s not it. If anything, it’s anti-subversive, like it has a kind… Continue reading Frog Finder","guid":"https://terrysfreegameoftheweek.com/?p=434","categories":["Terry's Free Game of the Week"],"isoDate":"2021-09-10T09:55:07.000Z","timestamp":"9/10/2021"},{"creator":"terry","title":"BIMSY DREAMS","link":"https://terrysfreegameoftheweek.com/bimsy-dreams/?utm_source=rss&utm_medium=rss&utm_campaign=bimsy-dreams","pubDate":"Fri, 03 Sep 2021 14:57:21 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/tombdude\">Zizou</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/09/bimsydreams.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>A bootleg Warioware collection from another planet. The winner of the recent <a href=\"https://itch.io/jam/lowrezjam-2021\">2021 LOWREZJAM</a>!</p>\n\n\n\n<p>This game really nails the pacing, humour and energy that makes the Warioware series so much fun. I vibe with this.</p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://pep.itch.io/bimsy-dreams\"><strong>[Play Online (itch.io)]</strong></a></p>\n","content:encodedSnippet":"by Zizou.\n\nA bootleg Warioware collection from another planet. The winner of the recent 2021 LOWREZJAM!\nThis game really nails the pacing, humour and energy that makes the Warioware series so much fun. I vibe with this.\n[Play Online (itch.io)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/bimsy-dreams/#comments","content":"by Zizou. A bootleg Warioware collection from another planet. The winner of the recent 2021 LOWREZJAM! This game really nails the pacing, humour and energy that makes the Warioware series so much fun. I vibe with this. [Play Online (itch.io)]","contentSnippet":"by Zizou. A bootleg Warioware collection from another planet. The winner of the recent 2021 LOWREZJAM! This game really nails the pacing, humour and energy that makes the Warioware series so much fun. I vibe with this. [Play Online (itch.io)]","guid":"https://terrysfreegameoftheweek.com/?p=428","categories":["Terry's Free Game of the Week"],"isoDate":"2021-09-03T14:57:21.000Z","timestamp":"9/3/2021"},{"creator":"terry","title":"Slide in the woods","link":"https://terrysfreegameoftheweek.com/slide-in-the-woods/?utm_source=rss&utm_medium=rss&utm_campaign=slide-in-the-woods","pubDate":"Fri, 27 Aug 2021 09:42:46 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/jonnysGames\" data-type=\"URL\" data-id=\"https://twitter.com/jonnysGames\">Jonny&#8217;s Games</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/08/slideinthewoods.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>I feel like comedy and horror have a lot in common. Is this just me? A lot of it is that both genres have a lot of carefully-timed empty space where you&#8217;re waiting for something to happen (or dreading it). But it&#8217;s about set-up as well &#8211; they&#8217;re both genres where someone embarks on a plan that&#8217;s obviously a bad idea, that&#8217;s clearly going to end badly, where all you can do is put a pillow up to your face and say &#8220;I can&#8217;t watch this anymore, tell me when it&#8217;s over&#8221;. I think this is why you get so much horror that ends up being unintentionally funny.</p>\n\n\n\n<p>I really enjoyed this game. Though, while it&#8217;s all very scary, it always feels like less of a jump scare and more of a punchline. </p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://jonnys-games.itch.io/slide-in-the-woods\">[<strong>Download for Windows (itch.io)]</strong></a></p>\n","content:encodedSnippet":"by Jonny’s Games.\n\nI feel like comedy and horror have a lot in common. Is this just me? A lot of it is that both genres have a lot of carefully-timed empty space where you’re waiting for something to happen (or dreading it). But it’s about set-up as well – they’re both genres where someone embarks on a plan that’s obviously a bad idea, that’s clearly going to end badly, where all you can do is put a pillow up to your face and say “I can’t watch this anymore, tell me when it’s over”. I think this is why you get so much horror that ends up being unintentionally funny.\nI really enjoyed this game. Though, while it’s all very scary, it always feels like less of a jump scare and more of a punchline. \n[Download for Windows (itch.io)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/slide-in-the-woods/#respond","content":"by Jonny&#8217;s Games. I feel like comedy and horror have a lot in common. Is this just me? A lot of it is that both genres have a lot of carefully-timed empty space where you&#8217;re waiting for something to happen (or dreading it). But it&#8217;s about set-up as well &#8211; they&#8217;re both genres where someone&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/slide-in-the-woods/\">Continue reading <span class=\"screen-reader-text\">Slide in the woods</span></a>","contentSnippet":"by Jonny’s Games. I feel like comedy and horror have a lot in common. Is this just me? A lot of it is that both genres have a lot of carefully-timed empty space where you’re waiting for something to happen (or dreading it). But it’s about set-up as well – they’re both genres where someone… Continue reading Slide in the woods","guid":"https://terrysfreegameoftheweek.com/?p=394","categories":["Terry's Free Game of the Week"],"isoDate":"2021-08-27T09:42:46.000Z","timestamp":"8/27/2021"},{"creator":"terry","title":"Memorial Pillage","link":"https://terrysfreegameoftheweek.com/memorial-pillage/?utm_source=rss&utm_medium=rss&utm_campaign=memorial-pillage","pubDate":"Fri, 20 Aug 2021 07:42:24 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/MyMadnessWorks\">Ivan Zonotti&#8217;s MyMadnessWorks</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-full\"><img loading=\"lazy\" width=\"640\" height=\"360\" src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/08/memorial.gif\" alt=\"\" class=\"wp-image-410\"/></figure></div>\n\n\n\n<p>I just came across this really nice platformer from back in May that I missed &#8211; it&#8217;s a new game from the creator of <a href=\"https://mymadnessworks.itch.io/imscared2016\">Imscared</a> and <a href=\"https://mymadnessworks.itch.io/fireworkgame\">FIREWORK</a>. </p>\n\n\n\n<p>Memorial Pillage is a self-described &#8220;love letter to CORE&#8217;s Tomb Raider&#8221;, and focuses on the kind of weighty movement you don&#8217;t see in a lot of platformers anymore. Your movement has inertia &#8211; how far you jump depends on how fast you&#8217;re moving. Cool! </p>\n\n\n\n<p>Over the last decade or so, it feels like indie platformers have settled on a kind-of &#8220;correct&#8221; way to do things, so it&#8217;s refreshing to play something that pulls in a different direction, and takes inspiration from places less explored.</p>\n\n\n\n<p>Two quick notes for this one:</p>\n\n\n\n<ul><li>There&#8217;s an &#8220;optional&#8221; tutorial accessible from the main menu that really shouldn&#8217;t be optional, since it explains a couple of non-standard control things that are important. TLDP; you can drop through platforms by double tapping down, and if you press CTRL it slows down time.</li><li>Let me spare you some rage: you can&#8217;t walk into spikes from the side, or climb up onto a platform that has spikes on it. That place where you&#8217;re trying to do that? You can just jump right over them!</li></ul>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://mymadnessworks.itch.io/memorialpillage\"><strong>[Download for Windows (itch.io)]</strong></a></p>\n","content:encodedSnippet":"by Ivan Zonotti’s MyMadnessWorks.\n\nI just came across this really nice platformer from back in May that I missed – it’s a new game from the creator of Imscared and FIREWORK. \nMemorial Pillage is a self-described “love letter to CORE’s Tomb Raider”, and focuses on the kind of weighty movement you don’t see in a lot of platformers anymore. Your movement has inertia – how far you jump depends on how fast you’re moving. Cool! \nOver the last decade or so, it feels like indie platformers have settled on a kind-of “correct” way to do things, so it’s refreshing to play something that pulls in a different direction, and takes inspiration from places less explored.\nTwo quick notes for this one:\nThere’s an “optional” tutorial accessible from the main menu that really shouldn’t be optional, since it explains a couple of non-standard control things that are important. TLDP; you can drop through platforms by double tapping down, and if you press CTRL it slows down time.\nLet me spare you some rage: you can’t walk into spikes from the side, or climb up onto a platform that has spikes on it. That place where you’re trying to do that? You can just jump right over them!\n\n\n\n\n[Download for Windows (itch.io)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/memorial-pillage/#respond","content":"by Ivan Zonotti&#8217;s MyMadnessWorks. I just came across this really nice platformer from back in May that I missed &#8211; it&#8217;s a new game from the creator of Imscared and FIREWORK. Memorial Pillage is a self-described &#8220;love letter to CORE&#8217;s Tomb Raider&#8221;, and focuses on the kind of weighty movement you don&#8217;t see in a&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/memorial-pillage/\">Continue reading <span class=\"screen-reader-text\">Memorial Pillage</span></a>","contentSnippet":"by Ivan Zonotti’s MyMadnessWorks. I just came across this really nice platformer from back in May that I missed – it’s a new game from the creator of Imscared and FIREWORK. Memorial Pillage is a self-described “love letter to CORE’s Tomb Raider”, and focuses on the kind of weighty movement you don’t see in a… Continue reading Memorial Pillage","guid":"https://terrysfreegameoftheweek.com/?p=403","categories":["Terry's Free Game of the Week"],"isoDate":"2021-08-20T07:42:24.000Z","timestamp":"8/20/2021"},{"creator":"terry","title":"Dread the Rabbit","link":"https://terrysfreegameoftheweek.com/dread-the-rabbit/?utm_source=rss&utm_medium=rss&utm_campaign=dread-the-rabbit","pubDate":"Fri, 13 Aug 2021 00:13:11 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/GoblinGrotto\">Goblin Grotto</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/08/dread.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>Dread the Rabbit is a cleverly designed and very accessible roguelike. More than that, it&#8217;s one of those games that just <em>feels</em> really nice to play, because so much thought has gone into how it looks and sounds and feels to play from moment to moment.</p>\n\n\n\n<p><em>Cohesive</em>, is the word I&#8217;d use to describe it.</p>\n\n\n\n<p>It&#8217;s got more of a casual pace than many games in the genre &#8211; runs are long, and they can take a while to ramp up. But once they get going, they get really, really interesting. I had a lot of fun playing this!</p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://goblin-grotto.itch.io/dread-the-rabbit\"><strong>[Download for Windows (itch.io)]</strong></a></p>\n\n\n\n<p>(once again, via <a href=\"https://twitter.com/itchio/status/1414458269427408901\">@itchio</a>&#8216;s twitter account!)</p>\n","content:encodedSnippet":"by Goblin Grotto.\n\nDread the Rabbit is a cleverly designed and very accessible roguelike. More than that, it’s one of those games that just feels really nice to play, because so much thought has gone into how it looks and sounds and feels to play from moment to moment.\nCohesive, is the word I’d use to describe it.\nIt’s got more of a casual pace than many games in the genre – runs are long, and they can take a while to ramp up. But once they get going, they get really, really interesting. I had a lot of fun playing this!\n[Download for Windows (itch.io)]\n(once again, via @itchio‘s twitter account!)","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/dread-the-rabbit/#respond","content":"by Goblin Grotto. Dread the Rabbit is a cleverly designed and very accessible roguelike. More than that, it&#8217;s one of those games that just feels really nice to play, because so much thought has gone into how it looks and sounds and feels to play from moment to moment. Cohesive, is the word I&#8217;d use&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/dread-the-rabbit/\">Continue reading <span class=\"screen-reader-text\">Dread the Rabbit</span></a>","contentSnippet":"by Goblin Grotto. Dread the Rabbit is a cleverly designed and very accessible roguelike. More than that, it’s one of those games that just feels really nice to play, because so much thought has gone into how it looks and sounds and feels to play from moment to moment. Cohesive, is the word I’d use… Continue reading Dread the Rabbit","guid":"https://terrysfreegameoftheweek.com/?p=390","categories":["Terry's Free Game of the Week"],"isoDate":"2021-08-13T00:13:11.000Z","timestamp":"8/12/2021"},{"creator":"terry","title":"Security Booth","link":"https://terrysfreegameoftheweek.com/security-booth/?utm_source=rss&utm_medium=rss&utm_campaign=security-booth","pubDate":"Fri, 06 Aug 2021 09:14:26 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/KyleHorwood\">Kyle Horwood</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/08/securitybooth.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>You&#8217;re the security guard to some sort of horrifying PS1 research facility. Check people&#8217;s number plates, Papers Please style, to decide whether or not they&#8217;re allowed in. </p>\n\n\n\n<p>A playthrough takes about 10 minutes, and I promise nothing is going to jump out and scare you. I definitely said &#8220;fuck this!&#8221; out loud and tried to leave at about the 8 minute mark, though.</p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://3dkyle.itch.io/security-booth\"><strong>[Download for Windows (itch.io)]</strong></a></p>\n\n\n\n<p>(via <a href=\"https://twitter.com/itchio\">itch.io&#8217;s twitter account</a>, which has recently gotten really good at highlighting interesting new games on the site!)</p>\n","content:encodedSnippet":"by Kyle Horwood.\n\nYou’re the security guard to some sort of horrifying PS1 research facility. Check people’s number plates, Papers Please style, to decide whether or not they’re allowed in. \nA playthrough takes about 10 minutes, and I promise nothing is going to jump out and scare you. I definitely said “fuck this!” out loud and tried to leave at about the 8 minute mark, though.\n[Download for Windows (itch.io)]\n(via itch.io’s twitter account, which has recently gotten really good at highlighting interesting new games on the site!)","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/security-booth/#respond","content":"by Kyle Horwood. You&#8217;re the security guard to some sort of horrifying PS1 research facility. Check people&#8217;s number plates, Papers Please style, to decide whether or not they&#8217;re allowed in. A playthrough takes about 10 minutes, and I promise nothing is going to jump out and scare you. I definitely said &#8220;fuck this!&#8221; out loud&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/security-booth/\">Continue reading <span class=\"screen-reader-text\">Security Booth</span></a>","contentSnippet":"by Kyle Horwood. You’re the security guard to some sort of horrifying PS1 research facility. Check people’s number plates, Papers Please style, to decide whether or not they’re allowed in. A playthrough takes about 10 minutes, and I promise nothing is going to jump out and scare you. I definitely said “fuck this!” out loud… Continue reading Security Booth","guid":"https://terrysfreegameoftheweek.com/?p=386","categories":["Terry's Free Game of the Week"],"isoDate":"2021-08-06T09:14:26.000Z","timestamp":"8/6/2021"},{"creator":"terry","title":"paint everything everywhere!","link":"https://terrysfreegameoftheweek.com/paint-everything-everywhere/?utm_source=rss&utm_medium=rss&utm_campaign=paint-everything-everywhere","pubDate":"Fri, 30 Jul 2021 00:28:37 +0000","content:encoded":"\n<p>by <a href=\"https://www.increpare.com/\">increpare</a> and <a href=\"https://twitter.com/pancelor\">pancelor</a>.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/07/painteverything.gif\" alt=\"\"/></figure>\n\n\n\n<p>Here&#8217;s why a lot of people don&#8217;t like puzzle games, I think: they demand a perfect answer. The really good ones require you to sit back, stare at the screen for 10 minutes, and then finally make that single deliberate move that makes it all fall into place. Until you finally figure it out, some of these games can feel like you&#8217;re going around in circles &#8211; is this it? No? What about this? Aghh!</p>\n\n\n\n<p>I really like this game because it <em>rewards</em> that process of going around in circles &#8211; you control two slidy pieces at the same time, and you&#8217;re trying to visit every square in the level. Each level feels like it&#8217;s a dozen puzzles super-imposed on-top of each other, and you&#8217;re solving bits and pieces of different puzzles each time you move. It feels playful and satisfying in a way that&#8217;s very rare for the genre.</p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https://www.puzzlescript.net/play.html?p=6a412035f6f1999cc773ddcb071de6e6\"><strong>[Play Online (puzzlescript.net)]</strong></a></p>\n","content:encodedSnippet":"by increpare and pancelor.\n\n\n\n\nHere’s why a lot of people don’t like puzzle games, I think: they demand a perfect answer. The really good ones require you to sit back, stare at the screen for 10 minutes, and then finally make that single deliberate move that makes it all fall into place. Until you finally figure it out, some of these games can feel like you’re going around in circles – is this it? No? What about this? Aghh!\nI really like this game because it rewards that process of going around in circles – you control two slidy pieces at the same time, and you’re trying to visit every square in the level. Each level feels like it’s a dozen puzzles super-imposed on-top of each other, and you’re solving bits and pieces of different puzzles each time you move. It feels playful and satisfying in a way that’s very rare for the genre.\n[Play Online (puzzlescript.net)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/paint-everything-everywhere/#respond","content":"by increpare and pancelor. Here&#8217;s why a lot of people don&#8217;t like puzzle games, I think: they demand a perfect answer. The really good ones require you to sit back, stare at the screen for 10 minutes, and then finally make that single deliberate move that makes it all fall into place. Until you finally&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/paint-everything-everywhere/\">Continue reading <span class=\"screen-reader-text\">paint everything everywhere!</span></a>","contentSnippet":"by increpare and pancelor. Here’s why a lot of people don’t like puzzle games, I think: they demand a perfect answer. The really good ones require you to sit back, stare at the screen for 10 minutes, and then finally make that single deliberate move that makes it all fall into place. Until you finally… Continue reading paint everything everywhere!","guid":"https://terrysfreegameoftheweek.com/?p=373","categories":["Terry's Free Game of the Week"],"isoDate":"2021-07-30T00:28:37.000Z","timestamp":"7/29/2021"},{"creator":"terry","title":"Micesweeper","link":"https://terrysfreegameoftheweek.com/micesweeper/?utm_source=rss&utm_medium=rss&utm_campaign=micesweeper","pubDate":"Thu, 22 Jul 2021 07:58:16 +0000","content:encoded":"\n<p>by <a href=\"https://www.glorioustrainwrecks.com/games/*/alissa\">alissa</a>.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/07/micesweeper.gif\" alt=\"\"/></figure>\n\n\n\n<p>Find the cheese while carefully avoiding the mousetraps. A cute and cozy version of minesweeper, from the creator of the previously featured <a href=\"https://terrysfreegameoftheweek.com/worryspider-in-picnic-panic/\">Worryspider in Picnic Panic</a>.</p>\n\n\n\n<p>The changes here to the usual minesweeper rules are subtle, but really interesting! You lose the ability to just probe any arbitrary space, but to make up for it, you get more information about what&#8217;s on the board thanks to the picross style borders. It leads to some interesting little puzzles that feel very different from the usual minesweeper ones.</p>\n\n\n\n<p>It&#8217;s a small detail, but I really like how the game allows you to make mistakes &#8211; hitting a &#8220;mine&#8221; isn&#8217;t game over &#8211; you just lose a life, and then you carry on. No big deal. Sometimes that&#8217;s exactly what you want, you know?</p>\n\n\n\n<p class=\"has-text-align-center\"><strong><a href=\"https://www.glorioustrainwrecks.com/node/12097\">[Download for Windows (glorioustrainwrecks.com)]</a></strong></p>\n","content:encodedSnippet":"by alissa.\n\n\n\n\nFind the cheese while carefully avoiding the mousetraps. A cute and cozy version of minesweeper, from the creator of the previously featured Worryspider in Picnic Panic.\nThe changes here to the usual minesweeper rules are subtle, but really interesting! You lose the ability to just probe any arbitrary space, but to make up for it, you get more information about what’s on the board thanks to the picross style borders. It leads to some interesting little puzzles that feel very different from the usual minesweeper ones.\nIt’s a small detail, but I really like how the game allows you to make mistakes – hitting a “mine” isn’t game over – you just lose a life, and then you carry on. No big deal. Sometimes that’s exactly what you want, you know?\n[Download for Windows (glorioustrainwrecks.com)]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/micesweeper/#comments","content":"by alissa. Find the cheese while carefully avoiding the mousetraps. A cute and cozy version of minesweeper, from the creator of the previously featured Worryspider in Picnic Panic. The changes here to the usual minesweeper rules are subtle, but really interesting! You lose the ability to just probe any arbitrary space, but to make up&#8230; <a class=\"more-link\" href=\"https://terrysfreegameoftheweek.com/micesweeper/\">Continue reading <span class=\"screen-reader-text\">Micesweeper</span></a>","contentSnippet":"by alissa. Find the cheese while carefully avoiding the mousetraps. A cute and cozy version of minesweeper, from the creator of the previously featured Worryspider in Picnic Panic. The changes here to the usual minesweeper rules are subtle, but really interesting! You lose the ability to just probe any arbitrary space, but to make up… Continue reading Micesweeper","guid":"https://terrysfreegameoftheweek.com/?p=366","categories":["Terry's Free Game of the Week"],"isoDate":"2021-07-22T07:58:16.000Z","timestamp":"7/22/2021"},{"creator":"terry","title":"Money Man","link":"https://terrysfreegameoftheweek.com/money-man/?utm_source=rss&utm_medium=rss&utm_campaign=money-man","pubDate":"Thu, 15 Jul 2021 04:04:21 +0000","content:encoded":"\n<p>by <a href=\"https://twitter.com/8_BitAnt\">8BitAnt</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/07/moneyman.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>&#8220;Money Man&#8221; is on a quest to get all of his money back after he gambled it all away. A <a rel=\"noreferrer noopener\" href=\"https://web.archive.org/web/20100313015252/http://www.jazzuo.com/games/indexher.htm\" target=\"_blank\">Jazzuo</a> fangame.</p>\n\n\n\n<p>Really into this whole newgrounds revival that seems to be happening right now!</p>\n\n\n\n<p class=\"has-text-align-center\"><strong><a href=\"https://www.newgrounds.com/portal/view/804012\">[Play on Newgrounds.com]</a></strong></p>\n","content:encodedSnippet":"by 8BitAnt.\n\n“Money Man” is on a quest to get all of his money back after he gambled it all away. A Jazzuo fangame.\nReally into this whole newgrounds revival that seems to be happening right now!\n[Play on Newgrounds.com]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/money-man/#respond","content":"by 8BitAnt. &#8220;Money Man&#8221; is on a quest to get all of his money back after he gambled it all away. A Jazzuo fangame. Really into this whole newgrounds revival that seems to be happening right now! [Play on Newgrounds.com]","contentSnippet":"by 8BitAnt. “Money Man” is on a quest to get all of his money back after he gambled it all away. A Jazzuo fangame. Really into this whole newgrounds revival that seems to be happening right now! [Play on Newgrounds.com]","guid":"https://terrysfreegameoftheweek.com/?p=359","categories":["Terry's Free Game of the Week"],"isoDate":"2021-07-15T04:04:21.000Z","timestamp":"7/15/2021"},{"creator":"terry","title":"Neoprenanzieher","link":"https://terrysfreegameoftheweek.com/neoprenanzieher/?utm_source=rss&utm_medium=rss&utm_campaign=neoprenanzieher","pubDate":"Thu, 08 Jul 2021 11:39:53 +0000","content:encoded":"\n<p>vom <a href=\"https://www.increpare.com/\">Increpare</a>.</p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img src=\"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/07/neoprenanzieher.gif\" alt=\"\"/></figure></div>\n\n\n\n<p>Kann kaum warten in den See zu springen. Muss aber erst meinen Neoprenanzug anziehen…</p>\n\n\n\n<p class=\"has-text-align-center\"><strong><a href=\"https://www.puzzlescript.net/play.html?p=0e9a234d0e5f66d308f64f6b9e1c1fdb\">[Spiele auf puzzlescript.net]</a></strong></p>\n","content:encodedSnippet":"vom Increpare.\n\nKann kaum warten in den See zu springen. Muss aber erst meinen Neoprenanzug anziehen…\n[Spiele auf puzzlescript.net]","dc:creator":"terry","comments":"https://terrysfreegameoftheweek.com/neoprenanzieher/#respond","content":"vom Increpare. Kann kaum warten in den See zu springen. Muss aber erst meinen Neoprenanzug anziehen… [Spiele auf puzzlescript.net]","contentSnippet":"vom Increpare. Kann kaum warten in den See zu springen. Muss aber erst meinen Neoprenanzug anziehen… [Spiele auf puzzlescript.net]","guid":"https://terrysfreegameoftheweek.com/?p=354","categories":["Terry's Free Game of the Week"],"isoDate":"2021-07-08T11:39:53.000Z","timestamp":"7/8/2021"}],"feedUrl":"https://terrysfreegameoftheweek.com/feed/","image":{"link":"https://terrysfreegameoftheweek.com","url":"https://terrysfreegameoftheweek.com/wp-content/uploads/2021/03/cropped-albert-1-1-32x32.png","title":"Terry's Free Game of the Week","width":"32","height":"32"},"paginationLinks":{"self":"https://terrysfreegameoftheweek.com/feed/"},"title":"Terry's Free Game of the Week","description":"","generator":"https://wordpress.org/?v=5.8.1","link":"https://terrysfreegameoftheweek.com","language":"en-AU","lastBuildDate":"Fri, 10 Sep 2021 10:06:35 +0000","feed":"https://terrysfreegameoftheweek.com/feed/"},{"items":[{"title":"Community management","link":"https://a327ex.com/posts/community_management/","pubDate":"Tue, 27 Jul 2021 00:00:00 +0000","content":"Eventually I want to make an MMO. I&rsquo;ve already sort of described it here but that idea will probably change significantly over the years. What won&rsquo;t change is the fact that successfully running an MMO is both a massive technical and social undertaking.\nI&rsquo;m constantly working on improving the technical side of things by just programming a lot, but the social part of it is harder to practice because you actively need a community of people to manage, and until now I didn&rsquo;t have such a thing.","contentSnippet":"Eventually I want to make an MMO. I’ve already sort of described it here but that idea will probably change significantly over the years. What won’t change is the fact that successfully running an MMO is both a massive technical and social undertaking.\nI’m constantly working on improving the technical side of things by just programming a lot, but the social part of it is harder to practice because you actively need a community of people to manage, and until now I didn’t have such a thing.","guid":"https://a327ex.com/posts/community_management/","isoDate":"2021-07-27T00:00:00.000Z","timestamp":"7/26/2021"},{"title":"Auto chess formula","link":"https://a327ex.com/posts/auto_chess_formula/","pubDate":"Sun, 25 Jul 2021 00:00:00 +0000","content":"A few days ago Baumi posted a video where he reviewed SNKRX:\nIt&rsquo;s a very good video overall but the part that interested me the most was the one I linked above. It&rsquo;s a 4-5 minutes watch and there he&rsquo;s talking about how the contribution that the game made was sort of taking the auto chess formula and applying it to a different context, and how from there you could really apply it to anything because it&rsquo;s such a strong and solid formula that it should work anywhere.","contentSnippet":"A few days ago Baumi posted a video where he reviewed SNKRX:\nIt’s a very good video overall but the part that interested me the most was the one I linked above. It’s a 4-5 minutes watch and there he’s talking about how the contribution that the game made was sort of taking the auto chess formula and applying it to a different context, and how from there you could really apply it to anything because it’s such a strong and solid formula that it should work anywhere.","guid":"https://a327ex.com/posts/auto_chess_formula/","isoDate":"2021-07-25T00:00:00.000Z","timestamp":"7/24/2021"},{"title":"SNKRX's post-release log","link":"https://a327ex.com/posts/snkrx_log/","pubDate":"Sun, 30 May 2021 00:00:00 +0000","content":"<p>This article contains post-release financial results, thoughts, plans and assorted data for SNKRX.\nI&rsquo;m writing this mostly for my own future reference, especially the comparisons with BYTEPATH, since it&rsquo;s useful to see how differently\nthese games are performing despite being released under very similar conditions.</p>","contentSnippet":"This article contains post-release financial results, thoughts, plans and assorted data for SNKRX.\nI’m writing this mostly for my own future reference, especially the comparisons with BYTEPATH, since it’s useful to see how differently\nthese games are performing despite being released under very similar conditions.","guid":"https://a327ex.com/posts/snkrx_log/","isoDate":"2021-05-30T00:00:00.000Z","timestamp":"5/29/2021"},{"title":"Lessons learned from releasing my second game","link":"https://a327ex.com/posts/lessons_second_game/","pubDate":"Tue, 18 May 2021 00:00:00 +0000","content":"<p><a href=\"https://store.steampowered.com/app/915310/SNKRX/\">SNKRX</a> is the second game I&rsquo;ve released on Steam and in this post I&rsquo;ll go over my thoughts on its development and how it performed. I made this game in the past 3 months as a dev challenge to start making and releasing games more consistently.</p>","contentSnippet":"SNKRX is the second game I’ve released on Steam and in this post I’ll go over my thoughts on its development and how it performed. I made this game in the past 3 months as a dev challenge to start making and releasing games more consistently.","guid":"https://a327ex.com/posts/lessons_second_game/","isoDate":"2021-05-18T00:00:00.000Z","timestamp":"5/17/2021"}],"feedUrl":"https://a327ex.com/posts/index.xml","paginationLinks":{"self":"https://a327ex.com/posts/index.xml"},"title":"blog on adn's web page","description":"Recent content in blog on adn's web page","generator":"Hugo -- gohugo.io","link":"https://a327ex.com/posts/","language":"en-us","feed":"https://a327ex.com/posts/index.xml"},{"items":[{"title":"Understanding Rust futures by going way too deep","link":"https://fasterthanli.me/articles/understanding-rust-futures-by-going-way-too-deep","pubDate":"2021-07-25T22:00:00.000Z","summary":"\n          <p>So! Rust futures! Easy peasy lemon squeezy. Until it's not. So let's do the easy\nthing, and then instead of waiting for the hard thing to <em>sneak up on us</em>, we'll\ngo for it intentionally.</p>\n<div class=\"tip\">\n<div class=\"tip-header\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\nCool bear's hot tip\n</div>\n\n</div>\n        ","id":"https://fasterthanli.me/articles/understanding-rust-futures-by-going-way-too-deep","isoDate":"2021-07-25T22:00:00.000Z","timestamp":"7/25/2021"},{"title":"Fine, we'll relocate our own binary!","link":"https://fasterthanli.me/series/making-our-own-executable-packer/part-18","pubDate":"2021-05-01T07:30:00.000Z","summary":"\n          <p>Welcome back to the eighteenth and final part of &quot;Making our own executable\npacker&quot;.</p>\n<p>In <a href=\"/series/making-our-own-executable-packer/part-17\">the last article</a>, we had\na lot of fun. We already had a &quot;packer&quot; executable, <code>minipak</code>, which joined\ntogether <code>stage1</code> (a launcher), and a compressed version of whichever executable\nwe wanted to pack.</p>\n        ","id":"https://fasterthanli.me/series/making-our-own-executable-packer/part-18","isoDate":"2021-05-01T07:30:00.000Z","timestamp":"5/1/2021"},{"title":"What's in the box?","link":"https://fasterthanli.me/articles/whats-in-the-box","pubDate":"2021-04-18T16:30:00.000Z","summary":"\n          <p>Here's a sentence I find myself saying several times a week:</p>\n<blockquote>\n<p>...or we could just box it.</p>\n</blockquote>\n<p>There's two remarkable things about this sentence.</p>\n<p>The first, is that the advice is very rarely heeded, and instead, whoever I\njust said it to disappears for two days, emerging victorious, basking in the\nknowledge that, YES, the compiler <em>could</em> inline that, if it wanted to.</p>\n        ","id":"https://fasterthanli.me/articles/whats-in-the-box","isoDate":"2021-04-18T16:30:00.000Z","timestamp":"4/18/2021"},{"title":"Pin and suffering","link":"https://fasterthanli.me/articles/pin-and-suffering","pubDate":"2021-03-28T00:00:00.000Z","summary":"\n          <p>I'd like to think that my understanding of &quot;async Rust&quot; has increased over\nthe past year or so. I'm 100% onboard with the basic principle: I <em>would</em>\nlike to handle thousands of concurrent tasks using a handful of threads. That\nsounds great!</p>\n        ","id":"https://fasterthanli.me/articles/pin-and-suffering","isoDate":"2021-03-28T00:00:00.000Z","timestamp":"3/27/2021"},{"title":"Running a self-relocatable ELF from memory","link":"https://fasterthanli.me/series/making-our-own-executable-packer/part-17","pubDate":"2021-03-08T07:30:00.000Z","summary":"\n          <p>Welcome back!</p>\n<p>In <a href=\"/series/making-our-own-executable-packer/part-16\">the last article</a>, we\ndid foundational work on <code>minipak</code>, our ELF packer.</p>\n<p>It is now able to receive command-line arguments, environment variables, and\nauxiliary vectors. It can parse those command-line arguments into a set of\noptions. It can make an ELF file smaller using the <a href=\"https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)\">LZ4 compression\nalgorithm</a>, and pack\nit together with <code>stage1</code>, our launcher.</p>\n        ","id":"https://fasterthanli.me/series/making-our-own-executable-packer/part-17","isoDate":"2021-03-08T07:30:00.000Z","timestamp":"3/8/2021"},{"title":"Everything but ELF","link":"https://fasterthanli.me/series/making-our-own-executable-packer/part-16","pubDate":"2021-03-01T07:30:00.000Z","summary":"\n          <p>And we're back!</p>\n<p>In <a href=\"/series/making-our-own-executable-packer/part-15\">the last article</a>, we\nthanked our old code and bade it adieu, for it did not spark joy. And then we\nmade a new, solid foundation, on which we planned to actually make an\nexecutable packer.</p>\n        ","id":"https://fasterthanli.me/series/making-our-own-executable-packer/part-16","isoDate":"2021-03-01T07:30:00.000Z","timestamp":"3/1/2021"},{"title":"Between libcore and libstd","link":"https://fasterthanli.me/series/making-our-own-executable-packer/part-15","pubDate":"2021-02-21T07:30:00.000Z","summary":"\n          <p>You're still here! Fantastic.</p>\n<p>I have good news, and bad news. The <em>good</em> news is, we're actually going to make\nan executable packer now!</p>\n<div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Hurray!</p>\n</div>\n</div>\n<p>I know right? No lie, we're actually really going to start working on the\nfinal product from this point onwards.</p>\n<div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n\n</div>\n</div>\n        ","id":"https://fasterthanli.me/series/making-our-own-executable-packer/part-15","isoDate":"2021-02-21T07:30:00.000Z","timestamp":"2/21/2021"},{"title":"In the bowels of glibc","link":"https://fasterthanli.me/series/making-our-own-executable-packer/part-14","pubDate":"2021-02-08T11:29:00.000Z","summary":"\n          <p>Good morning, and welcome back to &quot;how many executables can we run with our\ncustom dynamic loader before things get <em>really</em> out of control&quot;.</p>\n<p>In <a href=\"/series/making-our-own-executable-packer/part-13\">Part 13</a>, we\n&quot;implemented&quot; thread-local storage. I'm using scare quotes because, well, we\nspent most of the article blabbering about Addressing Memory Through The\nAges, And Other Fun Tidbits.</p>\n        ","id":"https://fasterthanli.me/series/making-our-own-executable-packer/part-14","isoDate":"2021-02-08T11:29:00.000Z","timestamp":"2/8/2021"},{"title":"2020 Retrospective","link":"https://fasterthanli.me/articles/2020-retrospective","pubDate":"2020-12-31T18:25:00.000Z","summary":"\n          <p>Against all odds, it looks like the year 2020 will actually come to an end -\nin less than a day now. I know! Hard to believe for me too.</p>\n<p>A lot of things have happened for me personally, and professionally. It's\nbeen a big year in many ways, and I feel like, to get some closure, I need\nto highlight some of them.</p>\n<h2>From &quot;looking at graphs&quot; to &quot;driving to the hospital&quot;</h2>\n        ","id":"https://fasterthanli.me/articles/2020-retrospective","isoDate":"2020-12-31T18:25:00.000Z","timestamp":"12/31/2020"},{"title":"Day 14 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-14","pubDate":"2020-12-30T17:00:00.000Z","summary":"\n          <p>It's time for the <a href=\"https://adventofcode.com/2020/day/14\">Day 14 problem</a>!</p>\n<p>After the <em>hassle</em> that was Day 13, I hope this time we'll have a relatively\nchill time. And, at least for Part 1, that is true.</p>\n<p>Our input looks something like this:</p>\n<pre><div class=\"code-container\"><code>mask = XXXXXXXXXXXXXXXXXXXXXXXXXXXXX1XXXX0X\nmem[8] = 11\nmem[7] = 101\nmem[8] = 0\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-14","isoDate":"2020-12-30T17:00:00.000Z","timestamp":"12/30/2020"},{"title":"Day 13 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-13","pubDate":"2020-12-30T13:00:00.000Z","summary":"\n          <p>In the <a href=\"https://adventofcode.com/2020/day/13\">Day 13 problem</a>, we're trying to take the bus.</p>\n<p>Our input looks like this:</p>\n<pre><div class=\"code-container\"><code>939\n7,13,x,x,59,x,31,19\n</code></div></pre>\n<p>The first line indicates the earliest minute we can leave from the bus\nterminal, and the second line indicates the &quot;identifier&quot; of the buses that\nare active.</p>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-13","isoDate":"2020-12-30T13:00:00.000Z","timestamp":"12/30/2020"},{"title":"Day 12 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-12","pubDate":"2020-12-25T14:00:00.000Z","summary":"\n          <p>Time for the <a href=\"https://adventofcode.com/2020/day/12\">Day 12 problem</a>!</p>\n<p>In this problem, we have a ship. And we have navigation instructions:</p>\n<ul>\n<li>Action <code>N</code> means to move <code>north</code> by the given value.</li>\n<li>Action <code>S</code> means to move <code>south</code> by the given value.</li>\n<li>Action <code>E</code> means to move <code>east</code> by the given value.</li>\n<li>Action <code>W</code> means to move <code>west</code> by the given value.</li>\n<li>Action <code>L</code> means to turn <code>left</code> the given number of degrees.</li>\n<li>Action <code>R</code> means to turn <code>right</code> the given number of degrees.</li>\n<li>Action <code>F</code> means to move <code>forward</code> by the given value in the direction the ship is currently facing.</li>\n</ul>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-12","isoDate":"2020-12-25T14:00:00.000Z","timestamp":"12/25/2020"},{"title":"Day 11 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-11","pubDate":"2020-12-23T13:30:00.000Z","summary":"\n          <p>Another day, <a href=\"https://adventofcode.com/2020/day/11\">another problem</a>.</p>\n<p>This time the problem looks suspiciously like <a href=\"https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life\">Conway's Game of\nLife</a>, or, I guess,\nany old <a href=\"https://en.wikipedia.org/wiki/Cellular_automaton\">Cellular automaton</a>.</p>\n<p>We have a map like so:</p>\n<pre><div class=\"code-container\"><code>L.LL.LL.LL\nLLLLLLL.LL\nL.L.L..L..\nLLLL.LL.LL\nL.LL.LL.LL\nL.LLLLL.LL\n..L.L.....\nLLLLLLLLLL\nL.LLLLLL.L\nL.LLLLL.LL\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-11","isoDate":"2020-12-23T13:30:00.000Z","timestamp":"12/23/2020"},{"title":"Day 10 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-10","pubDate":"2020-12-23T08:00:00.000Z","summary":"\n          <div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Day, 10! Day, 10!</p>\n</div>\n</div>\n<p>Okay, <a href=\"https://adventofcode.com/2020/day/10\">Day 10</a>.</p>\n<p>Again, the problem statement is very confusing - but what it all boils down\nto is this. We have a list of numbers:</p>\n<pre><div class=\"code-container\"><code>16\n10\n15\n5\n1\n11\n7\n19\n6\n12\n4\n</code></div></pre>\n<p>To which we need to add <code>0</code> and whatever the maximum was, plus three:</p>\n<pre><div class=\"code-container\"><code>16\n10\n15\n5\n1\n11\n7\n19\n6\n12\n4\n0\n22\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-10","isoDate":"2020-12-23T08:00:00.000Z","timestamp":"12/23/2020"},{"title":"Day 9 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-9","pubDate":"2020-12-22T20:00:00.000Z","summary":"\n          <p>Day 9's <a href=\"https://adventofcode.com/2020/day/9\">problem statement</a> is\nconvoluted - the &quot;ah maybe that's why I don't usually do Advent of Code&quot; kind\nof convoluted, but let's give it a go anyway.</p>\n<p>So, we have a series of numbers, like so:</p>\n<pre><div class=\"code-container\"><code>35\n20\n15\n25\n47\n40\n62\n55\n65\n95\n102\n117\n150\n182\n127\n219\n299\n277\n309\n576\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-9","isoDate":"2020-12-22T20:00:00.000Z","timestamp":"12/22/2020"},{"title":"Day 8 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-8","pubDate":"2020-12-22T18:00:00.000Z","summary":"\n          <p>Time for another <a href=\"https://adventofcode.com/2020/day/8\">Advent of Code 2020 problem</a>!</p>\n<p>That one sounds like it's going to be fun. Our input is pretty much assembly, like this:</p>\n<pre><div class=\"code-container\"><code>nop +0\nacc +1\njmp +4\nacc +3\njmp -3\nacc -99\nacc +1\njmp -4\nacc +6\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-8","isoDate":"2020-12-22T18:00:00.000Z","timestamp":"12/22/2020"},{"title":"Day 7 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-7","pubDate":"2020-12-21T21:00:00.000Z","summary":"\n          <p>Another day, another <a href=\"https://adventofcode.com/2020/day/7\">Advent of Code 2020 problem</a>.</p>\n<p>That one seems fun! For some nerdy values of fun.</p>\n<p>Our input is a set of rules:</p>\n<pre><div class=\"code-container\"><code>light red bags contain 1 bright white bag, 2 muted yellow bags.\ndark orange bags contain 3 bright white bags, 4 muted yellow bags.\nbright white bags contain 1 shiny gold bag.\nmuted yellow bags contain 2 shiny gold bags, 9 faded blue bags.\nshiny gold bags contain 1 dark olive bag, 2 vibrant plum bags.\ndark olive bags contain 3 faded blue bags, 4 dotted black bags.\nvibrant plum bags contain 5 faded blue bags, 6 dotted black bags.\nfaded blue bags contain no other bags.\ndotted black bags contain no other bags.\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-7","isoDate":"2020-12-21T21:00:00.000Z","timestamp":"12/21/2020"},{"title":"Day 6 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-6","pubDate":"2020-12-20T17:30:00.000Z","summary":"\n          <p>The end of <a href=\"https://adventofcode.com/2020/\">Advent of Code 2020</a> is fast approaching,\nand we're nowhere near done. Time to do Day 6!</p>\n<p>The <a href=\"https://adventofcode.com/2020/day/6\">problem statement</a> here is a little\ncontrived, as uh, as the days that came before it, but that won't stop us.</p>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-6","isoDate":"2020-12-20T17:30:00.000Z","timestamp":"12/20/2020"},{"title":"Day 5 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-5","pubDate":"2020-12-16T21:00:00.000Z","summary":"\n          <p>Time for another day of <a href=\"https://adventofcode.com/2020/\">Advent of Code 2020</a>.</p>\n<p>For <a href=\"https://adventofcode.com/2020/day/5\">Day 5</a>, we're going to have to do...</p>\n<div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Let me guess: more parsing?</p>\n</div>\n</div>\n<div class=\"dialog amos\">\n<div class=\"dialog-head\" title=\"Amos says:\">\n    <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100\" height=\"100\" viewBox=\"0 0 26.5 26.5\"><path style=\"line-height:normal;font-variant-ligatures:normal;font-variant-position:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-alternates:normal;font-variant-east-asian:normal;font-feature-settings:normal;font-variation-settings:normal;text-indent:0;text-align:start;text-decoration-line:none;text-decoration-style:solid;text-decoration-color:#000;text-transform:none;text-orientation:mixed;white-space:normal;shape-padding:0;shape-margin:0;inline-size:0;isolation:auto;mix-blend-mode:normal;solid-color:#000;solid-opacity:1\" d=\"M14.3 3c-1.4-.2-3 .2-4 .3-1.5 0-2.9 1-3.9 2L5.3 6.6c-.3.5-.6 1.1-.5 1.8l-.5 2.8c0 1 0 2 .5 2.7h.1l.3.3.1.3c0 .3 0 .8.3 1.2 1.5 1.6 2.6 3.5 3.7 5.4l.5-.2-1-1.7c-.4-.8-1-1.5-1.2-2.2L7 14.1l-.2-.2-.1-.5.2-1c.3-.9.7-1.7.8-2.4-.1-.7 0-1.1.3-1.5a4 4 0 011.1-1c1.2-1 3.2-1.2 4.6-1 .7.2 1.4.5 1.8 1.1a10.4 10.4 0 011.1 2.7V11c.4 1.3.5 2.2.5 3.4v1.1a3.2 3.2 0 000 .4v.2h.5v-.2l.2-.3.3-.6v-.1c.2.2.3.3.3.6l.4 1.5.4 1.2.2.5.2.1h.4c.8-.7 1.6-1.5 2-2.5.5-.8.6-1.7.5-2.5l.4-1.5c0-.6 0-1.2-.2-1.8-.4-1.4-1.1-2.8-2.1-4l-1.6-1.3c-.7-.5-1.6-1-2.5-1-.6 0-.9-.2-1.2-.5l-.3-.4a.9.9 0 00-.6-.3zm0 .5l.1.2.4.4c.3.4.8.7 1.6.7.7 0 1.5.4 2.2 1L20 6.8c.9 1.2 1.6 2.4 2 3.8v.1c.2.4.2.9.1 1.4 0 .5-.2 1-.4 1.5v.1c0 .8 0 1.6-.3 2.2-.4.9-1 1.5-1.8 2.1l-.4-1.3-.4-1.5a4 4 0 00-.5-1.2H18l-.5.5v-.2c0-1.2 0-2.2-.4-3.5v-.6a10.9 10.9 0 00-1.2-2.9A3 3 0 0013.7 6a6.7 6.7 0 00-6.3 2.2c-.3.5-.5 1-.4 1.8 0 .4-.5 1.3-.7 2.2a5 5 0 00-.3 1.2c0 .4 0 .8.4 1v-.1c0 .5.3 1.3.5 2l-.8-1c-.2-.2-.2-.6-.2-1 0-.2 0-.4-.2-.6l-.4-.3c-.4-.5-.5-1.3-.4-2.2l.5-3c-.1-.5 0-.9.4-1.3l1-1.3c1-.9 2.3-1.8 3.5-1.9 1.1 0 2.7-.4 4-.3zM7 17.1z\" color=\"#000\" font-weight=\"400\" font-family=\"sans-serif\" overflow=\"visible\"/><path d=\"M11.6 19.9c.4 0 .2 0 .6-.3.2-.1.3-.6 0-.5-.3 0-1.2.2-1.4 0-.3.3.1.6.4.8zM9.2 17.6c.4-.4.7-.6 1.4-.7.8-.3 1.6-.1 2.4 0 .4.1.9 0 1.2.3l-.4.3c-.7 0-1.4.2-2 .3l-1.5.1h-1c-.3 0-.3-.2-.1-.3z\" fill=\"#000004\"/><path style=\"line-height:normal;font-variant-ligatures:normal;font-variant-position:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-alternates:normal;font-variant-east-asian:normal;font-feature-settings:normal;font-variation-settings:normal;text-indent:0;text-align:start;text-decoration-line:none;text-decoration-style:solid;text-decoration-color:#000;text-transform:none;text-orientation:mixed;white-space:normal;shape-padding:0;shape-margin:0;inline-size:0;isolation:auto;mix-blend-mode:normal;solid-color:#000;solid-opacity:1\" d=\"M18.3 6.7l-.2.2c1 .8 1.4 1.4 1.6 2l1 2.4.3-.1-1-2.4c-.3-.7-.7-1.3-1.7-2zM15.3 5.4l-.1.3c.8.3 1.4 1 2 2 .6 1 1.1 2.2 1.9 3.4l.3.7.2 1 .3 1.4h.3l-.3-1.4a15.4 15.4 0 00-.6-1.9l-1.9-3.3c-.6-1-1.2-1.8-2.1-2.2zM17.8 19c0 .6-1 1.3-1.3 1.6a11.5 11.5 0 01-1.4.8l-.1.1.3.5h.1a36 36 0 001.5-1c.3-.2 1.4-.9 1.5-2h-.6zM15 21.6z\" color=\"#000\" font-weight=\"400\" font-family=\"sans-serif\" overflow=\"visible\"/><g><path d=\"M13.9 10.7a4 4 0 00-2.8 1l-1.6.4c-.5-.2-1-.5-1.5-.5-.6 0-1.1.2-1.7.4-.3.2-1.3.3-.9.8.7-.1.3.7.6 1 .3.7.8 1.3 1.4 1.5.7.3 1.5 0 2-.6.3-.6.5-1.4.4-2.2 0-.3.7-.3 1-.3.3.2.2.8.5 1.2.3.6.8 1 1.5 1.3.9.3 2 0 2.6-.7.5-.7.7-1.5.7-2.3.2-.5 1-.2 1.2-.5 0-.2-.2-.4-.5-.3l-3-.2zm.3.5c.3 0 .5.4.2.6l-.5.4-1.3 1c-.2.4-.6.3-.7 0 0-.2.1-.3.3-.5l1.6-1.3.4-.2zm-5.8 1c.3 0 .4.3.2.4l-.4.4-1.1 1c-.1.1-.5.1-.5-.1l.1-.4 1.4-1.1.3-.2zm6 .1c.1 0 .2.2.1.3l-1 1c-.2.1-.6-.2-.4-.4l.9-.7.4-.2zm-5.7.7c.1 0 .2.2 0 .3l-.8.8c-.1.1-.4-.1-.2-.3l.7-.6.3-.2z\"/></g></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Correct!</p>\n</div>\n</div>\n<p>So there's an airline that uses binary space partitioning when referring to\nseats - there's 128 rows and 8 columns. The first 7 characters are either F\n(Front, for the lower half) and B (back, for the upper half), and the last 3\nare L (Left, for the lower half) or R (Right, for the upper half).</p>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-5","isoDate":"2020-12-16T21:00:00.000Z","timestamp":"12/16/2020"},{"title":"Day 4 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-4","pubDate":"2020-12-15T17:20:00.000Z","summary":"\n          <p>It's time for <a href=\"https://adventofcode.com/2020/day/4\">Day 4</a> of the Advent of Code 2020!</p>\n<p>Now, I've already had a look at the problem statement, at least for part 1,\nand I'm not particularly excited.</p>\n<p><em>But</em> it will allow me to underline some of the points I've <a href=\"/articles/aiming-for-correctness-with-types\">recently been\n*trying to make</a> about types\nand correctness.</p>\n<div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n\n</div>\n</div>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-4","isoDate":"2020-12-15T17:20:00.000Z","timestamp":"12/15/2020"},{"title":"Day 3 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-3","pubDate":"2020-12-14T09:40:00.000Z","summary":"\n          <p>Hello all, and welcome back to Advent of Code 2020, featuring Cool Bear.</p>\n<div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Hey y'all!</p>\n</div>\n</div>\n<p>Let's get right to it.</p>\n<p>The problem statement for <a href=\"https://adventofcode.com/2020/day/3\">Day 3</a> is as\nfollows: we're given a map, that looks like this:</p>\n<pre><div class=\"code-container\"><code>..##.......\n#...#...#..\n.#....#..#.\n..#.#...#.#\n.#...##..#.\n..#.##.....\n.#.#.#....#\n.#........#\n#.##...#...\n#...##....#\n.#..#...#.#\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-3","isoDate":"2020-12-14T09:40:00.000Z","timestamp":"12/14/2020"},{"title":"Day 2 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-2","pubDate":"2020-12-13T07:30:00.000Z","summary":"\n          <div class=\"dialog bear\">\n<div class=\"dialog-head\" title=\"Cool bear says:\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><path d=\"M21.41 41.398c.148-1.787.337-3.572.574-5.351.369-2.772 4.393-11.308 5.624-12.882l.553-.706-1.344-.449a5.772 5.772 0 0 1-3.948-5.478 5.786 5.786 0 0 1 5.779-5.78 5.768 5.768 0 0 1 5.684 4.758l.249 1.396 1.231-.704a28.845 28.845 0 0 1 14.282-3.801c4.991 0 9.93 1.314 14.282 3.801l1.231.704.249-1.396a5.766 5.766 0 0 1 5.683-4.758 5.786 5.786 0 0 1 5.779 5.78 5.772 5.772 0 0 1-3.948 5.478l-1.344.449.552.705c1.911 2.44 2.55 2.541 3.563 5.599 1.422 4.293 2.923 7.964 2.923 12.61v49.875h2V41.373c0-6.519-2.008-12.717-5.819-18.005a7.768 7.768 0 0 0 4.072-6.836c0-4.29-3.49-7.78-7.779-7.78a7.766 7.766 0 0 0-7.3 5.1 30.834 30.834 0 0 0-14.146-3.45 30.834 30.834 0 0 0-14.146 3.45 7.766 7.766 0 0 0-7.301-5.1c-4.289 0-7.779 3.49-7.779 7.78a7.766 7.766 0 0 0 4.072 6.836c-6.681 9.271-5.976 21.037-5.992 32.034-.017 11.946.656 23.895.109 35.838l2.006-.001c.67 0-.17-33.831-.156-36.912.022-4.312.148-8.631.505-12.929z\"/><path d=\"M73.854 31.271v-4.494c0-.971-.79-1.76-1.761-1.76H55.235c-.604 0-1.3.869-1.778 1.905-.015 0-.027-.008-.042-.008H46.789c-.02 0-.037.011-.057.011-.478-1.037-1.175-1.908-1.779-1.908H28.094c-.971 0-1.761.79-1.761 1.76v4.494c0 4.477 3.643 8.119 8.119 8.119h5.12c4.265 0 7.734-3.47 7.734-7.734v-2.091H52.878v2.091c0 4.265 3.47 7.734 7.734 7.734h5.121c4.479-.001 8.121-3.643 8.121-8.119zm-41.713 3.192a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm11.163-2.18l-5.75 3.597a.95.95 0 0 1-1.313-.302.952.952 0 0 1 .303-1.312l5.75-3.597a.953.953 0 0 1 1.01 1.614zm15.168 1.935a1.387 1.387 0 0 1-1.917-.442 1.392 1.392 0 0 1 .442-1.917l8.403-5.255a1.392 1.392 0 0 1 1.475 2.359l-8.403 5.255zm4.909 1.561a.953.953 0 0 1-.506-1.759l5.75-3.597a.952.952 0 1 1 1.01 1.614l-5.75 3.597a.942.942 0 0 1-.504.145z\"/><path d=\"M59.705 45.232h-2c0 1.823-1.483 3.306-3.306 3.306s-3.306-1.483-3.306-3.306v-1.439h1.06a3.294 3.294 0 0 0 3.285-3.285v-.17c0-.259-.038-.508-.095-.749a3.291 3.291 0 0 0-2.665-2.482 3.243 3.243 0 0 0-.525-.053h-4.12c-.18 0-.353.025-.525.053a3.291 3.291 0 0 0-2.665 2.482 3.255 3.255 0 0 0-.095.749v.17a3.294 3.294 0 0 0 3.285 3.285h1.06v1.439a3.31 3.31 0 0 1-3.307 3.306 3.31 3.31 0 0 1-3.306-3.306h-2a5.312 5.312 0 0 0 5.306 5.306 5.293 5.293 0 0 0 4.306-2.229 5.294 5.294 0 0 0 4.306 2.229 5.313 5.313 0 0 0 5.307-5.306zM29.742 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM43.779 58.336a.703.703 0 0 0-1.406 0v5.368a.704.704 0 0 0 1.406 0v-5.368zM57.816 58.336a.703.703 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM71.853 58.336a.704.704 0 0 0-1.407 0v5.368a.704.704 0 0 0 1.407 0v-5.368zM35.354 71.559v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-1.406 0zM49.39 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM63.427 71.559v5.369a.704.704 0 0 0 1.407 0v-5.369a.703.703 0 0 0-1.407 0zM29.038 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.703.703 0 0 0-.703-.703zM43.076 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.406 0v-5.369a.705.705 0 0 0-.703-.703zM57.113 81.364a.704.704 0 0 0-.704.703v5.369a.704.704 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.703-.703zM71.149 81.364a.703.703 0 0 0-.703.703v5.369a.703.703 0 0 0 1.407 0v-5.369a.705.705 0 0 0-.704-.703z\"/></svg>\n</div>\n<div class=\"dialog-text\">\n<p>Day 2, Day 2! Woo!</p>\n</div>\n</div>\n<p>The <a href=\"https://adventofcode.com/2020/day/2\">Advent of Code 2020, Day 2 problem</a>\ntalks about passwords. Sounds <a href=\"/articles/whats-in-a-rainbow-table\">familiar</a>.</p>\n<p>Basically, our input looks like this:</p>\n<pre><div class=\"code-container\"><code>1-3 a: abcde\n1-3 b: cdefg\n2-9 c: ccccccccc\n</code></div></pre>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-2","isoDate":"2020-12-13T07:30:00.000Z","timestamp":"12/13/2020"},{"title":"Day 1 (Advent of Code 2020)","link":"https://fasterthanli.me/series/advent-of-code-2020/part-1","pubDate":"2020-12-12T07:30:00.000Z","summary":"\n          <p>I was not planning on doing anything specific this December, but a lot of\nfolks around me (on Twitter, at work) have chosen this <a href=\"https://adventofcode.com\">Advent of\nCode</a> to pick up Rust, and I've got big\n<a href=\"https://en.wikipedia.org/wiki/Fear_of_missing_out\">FOMO</a> energy, so, let's\nsee where this goes.</p>\n        ","id":"https://fasterthanli.me/series/advent-of-code-2020/part-1","isoDate":"2020-12-12T07:30:00.000Z","timestamp":"12/12/2020"},{"title":"Aiming for correctness with types","link":"https://fasterthanli.me/articles/aiming-for-correctness-with-types","pubDate":"2020-12-12T00:30:00.000Z","summary":"\n          <p>The <a href=\"https://www.nature.com/nature-research/about\">Nature weekly journal of\nscience</a> was first published in\n1869. And after one and a half century, it has finally completed one cycle of\n<a href=\"https://en.wikipedia.org/wiki/Carcinisation\">carcinization</a>, by publishing\nan article about <a href=\"https://www.rust-lang.org/\">the Rust programming language</a>.</p>\n        ","id":"https://fasterthanli.me/articles/aiming-for-correctness-with-types","isoDate":"2020-12-12T00:30:00.000Z","timestamp":"12/11/2020"},{"title":"What's in a Rainbow table?","link":"https://fasterthanli.me/articles/whats-in-a-rainbow-table","pubDate":"2020-10-28T22:30:00.000Z","summary":"\n          <p>In <a href=\"/series/tech-as-seen-on-tv/part-1\">Veronica Mars and password hashes</a>,\nfrom my new <a href=\"/series/tech-as-seen-on-tv\">Tech As Seen On TV</a> series, we've\nexplored &quot;cracking passwords&quot; using brute-force methods, and then using\nrainbow tables, which was much, <em>much</em> faster.</p>\n        ","id":"https://fasterthanli.me/articles/whats-in-a-rainbow-table","isoDate":"2020-10-28T22:30:00.000Z","timestamp":"10/28/2020"}],"link":"https://fasterthanli.me","feedUrl":"https://fasterthanli.me/index.xml","title":"fasterthanli.me","lastBuildDate":"2021-07-25T22:00:00+00:00","feed":"https://fasterthanli.me/index.xml"},{"items":[{"title":"An introduction to typeclass metaprogramming","pubDate":"2021-03-25T00:00:00.000Z","author":"Alexis King","content":"<article><p><em>Typeclass metaprogramming</em> is a powerful technique available to Haskell programmers to automatically generate term-level code from static type information. It has been used to great effect in several popular Haskell libraries (such as the <a href=\"https://hackage.haskell.org/package/servant\">servant</a> ecosystem), and it is the core mechanism used to implement generic programming via <a href=\"https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Generics.html\">GHC generics</a>. Despite this, remarkably little material exists that explains the technique, relegating it to folk knowledge known only to advanced Haskell programmers.\n</p><p>This blog post attempts to remedy that by providing an overview of the foundational concepts behind typeclass metaprogramming. It does <em>not</em> attempt to be a complete guide to type-level programming in Haskell—such a task could easily fill a book—but it does provide explanations and illustrations of the most essential components. This is also <em>not</em> a blog post for Haskell beginners—familiarity with the essentials of the Haskell type system and several common GHC extensions is assumed—but it does not assume any prior knowledge of type-level programming.\n</p><h2><a name=\"part-1-basic-building-blocks\"></a>Part 1: Basic building blocks</h2><p>Typeclass metaprogramming is a big subject, which makes covering it in a blog post tricky. To break it into more manageable chunks, this post is divided into several parts, each of which introduces new type system features or type-level programming techniques, then presents an example of how they can be applied.\n</p><p>To start, we’ll cover the absolute foundations of typeclass metaprogramming.\n</p><h3><a name=\"typeclasses-as-functions-from-types-to-terms\"></a>Typeclasses as functions from types to terms</h3><p>As its name implies, typeclass metaprogramming (henceforth TMP<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup>) centers around Haskell’s typeclass construct. Traditionally, typeclasses are viewed as a mechanism for principled operator overloading; for example, they underpin Haskell’s polymorphic <code>==</code> operator via the <code>Eq</code> class. Though that is often the most useful way to think about typeclasses, TMP encourages a different perspective: <strong>typeclasses are functions from types to (runtime) terms</strong>.\n</p><p>What does that mean? Let’s illustrate with an example. Suppose we define a typeclass called <code>TypeOf</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span></code></pre><p>The idea is that this typeclass will accept some value and return the name of its type as a string. To illustrate, here are a couple potential instances:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"kt\">Bool</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"s\">\"Bool\"</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"kt\">Char</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"s\">\"Char\"</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">TypeOf</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">TypeOf</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"s\">\"(\"</span> <span class=\"o\">++</span> <span class=\"n\">typeOf</span> <span class=\"n\">a</span> <span class=\"o\">++</span> <span class=\"s\">\", \"</span> <span class=\"o\">++</span> <span class=\"n\">typeOf</span> <span class=\"n\">b</span> <span class=\"o\">++</span> <span class=\"s\">\")\"</span></code></pre><p>Given these instances, we can observe that they do what we expect in GHCi:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">typeOf</span> <span class=\"p\">(</span><span class=\"kt\">True</span><span class=\"p\">,</span> <span class=\"sc\">&#39;a&#39;</span><span class=\"p\">)</span>\n<span class=\"s\">\"(Bool, Char)\"</span></code></pre><p>Note that both the <code>TypeOf Bool</code> and <code>TypeOf Char</code> instances ignore the argument to <code>typeOf</code> altogether. This makes sense, as the whole point of the <code>TypeOf</code> class is to get access to <em>type</em> information, which is the same regardless of which value is provided. To make this more explicit, we can take advantage of some GHC extensions to eliminate the value-level argument altogether:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE AllowAmbiguousTypes, ScopedTypeVariables, TypeApplications #-}</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span></code></pre><p>This typeclass definition is a little unusual, as the type parameter <code>a</code> doesn’t appear anywhere in the body. To understand what it means, recall that the type of each method of a typeclass is implicitly extended with the typeclass’s constraint. For example, in the definition\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Show</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">show</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span></code></pre><p>the full type of the <code>show</code> method is implicitly extended with a <code>Show a</code> constraint to yield:\n</p><pre><code class=\"pygments\"><span class=\"nf\">show</span> <span class=\"ow\">::</span> <span class=\"kt\">Show</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span></code></pre><p>Furthermore, if we write <code>forall</code>s explicitly, each typeclass method is also implicitly quantified over the class’s type parameters, which makes the following the <em>full</em> type of <code>show</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">show</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">Show</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span></code></pre><p>In the same vein, we can write out the full type of <code>typeOf</code>, as given by our new definition of <code>TypeOf</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">typeOf</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">String</span></code></pre><p>This type is still unusual, as the <code>a</code> type parameter doesn’t appear anywhere to the right of the <code>=&gt;</code> arrow. This makes the type parameter trivially <em>ambiguous</em>, which is to say it’s impossible for GHC to infer what <code>a</code> should be at any call site. Fortunately, <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/type_applications.html\">we can use <code>TypeApplications</code></a> to pass a type for <code>a</code> directly, as we can see in the updated definition of <code>TypeOf (a, b)</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"kt\">Bool</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">=</span> <span class=\"s\">\"Bool\"</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"kt\">Char</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">=</span> <span class=\"s\">\"Char\"</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">TypeOf</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">TypeOf</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">=</span> <span class=\"s\">\"(\"</span> <span class=\"o\">++</span> <span class=\"n\">typeOf</span> <span class=\"o\">@</span><span class=\"n\">a</span> <span class=\"o\">++</span> <span class=\"s\">\", \"</span> <span class=\"o\">++</span> <span class=\"n\">typeOf</span> <span class=\"o\">@</span><span class=\"n\">b</span> <span class=\"o\">++</span> <span class=\"s\">\")\"</span></code></pre><p>Once again, we can test out our new definitions in GHCi:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">typeOf</span> <span class=\"o\">@</span><span class=\"kt\">Bool</span>\n<span class=\"s\">\"Bool\"</span>\n<span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">typeOf</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">Bool</span><span class=\"p\">,</span> <span class=\"kt\">Char</span><span class=\"p\">)</span>\n<span class=\"s\">\"(Bool, Char)\"</span></code></pre><p>This illustrates very succinctly how typeclasses can be seen as functions from types to terms. Our <code>typeOf</code> function is, quite literally, a function that accepts a single type as an argument and returns a term-level <code>String</code>. Of course, the <code>TypeOf</code> typeclass is not a particularly <em>useful</em> example of such a function, but it demonstrates how easy it is to construct.\n</p><h3><a name=\"type-level-interpreters\"></a>Type-level interpreters</h3><p>One important consequence of eliminating the value-level argument of <code>typeOf</code> is that there is no need for its argument type to actually be <em>inhabited</em>. For example, consider the <code>TypeOf</code> instance on <code>Void</code> from <code>Data.Void</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"kt\">Void</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">=</span> <span class=\"s\">\"Void\"</span></code></pre><p>This above instance is no different from the ones on <code>Bool</code> and <code>Char</code> even though <code>Void</code> is a completely uninhabited type. This is an important point: as we delve into type-level programming, it’s important to keep in mind that the language of types is mostly blind to the term-level meaning of those types. Although we usually write typeclasses that operate on values, this is not at all essential. This turns out to be quite important in practice, even in something as simple as the definition of <code>TypeOf</code> on lists:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">TypeOf</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">TypeOf</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">typeOf</span> <span class=\"ow\">=</span> <span class=\"s\">\"[\"</span> <span class=\"o\">++</span> <span class=\"n\">typeOf</span> <span class=\"o\">@</span><span class=\"n\">a</span> <span class=\"o\">++</span> <span class=\"s\">\"]\"</span></code></pre><p>If <code>typeOf</code> required a value-level argument, not just a type, our instance above would be in a pickle when given the empty list, since it would have no value of type <code>a</code> to recursively apply <code>typeOf</code> to. But since <code>typeOf</code> only accepts a type-level argument, the term-level meaning of the list type poses no obstacle.\n</p><p>A perhaps unintuitive consequence of this property is that we can use typeclasses to write interesting functions on types even if none of the types are inhabited at all. For example, consider the following pair of type definitions:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Z</span>\n<span class=\"kr\">data</span> <span class=\"kt\">S</span> <span class=\"n\">a</span></code></pre><p>It is impossible to construct any values of these types, but we can nevertheless use them to construct natural numbers at the type level:\n</p><ul><li><p><code>Z</code> is a type that represents 0.\n</p></li><li><p><code>S Z</code> is a type that represents 1.\n</p></li><li><p><code>S (S Z)</code> is a type that represents 2.\n</p></li></ul><p>And so on. These types might not seem very useful, since they aren’t inhabited by any values, but remarkably, we can still use a typeclass to distinguish them and convert them to term-level values:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">Numeric.Natural</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">ReifyNat</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">::</span> <span class=\"kt\">Natural</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">ReifyNat</span> <span class=\"kt\">Z</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">ReifyNat</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ReifyNat</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">=</span> <span class=\"mi\">1</span> <span class=\"o\">+</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"n\">a</span></code></pre><p>As its name implies, <code>reifyNat</code> reifies a type-level natural number encoded using our datatypes above into a term-level <code>Natural</code> value:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"kt\">Z</span>\n<span class=\"mi\">0</span>\n<span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">)</span>\n<span class=\"mi\">1</span>\n<span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">))</span>\n<span class=\"mi\">2</span></code></pre><p>One way to think about <code>reifyNat</code> is as an <em>interpreter</em> of a type-level language. In this case, the type-level language is very simple, only capturing natural numbers, but in general, it could be arbitrarily complex—and typeclasses can be used to give it a useful meaning, even if it has no term-level representation.\n</p><h3><a name=\"overlapping-instances\"></a>Overlapping instances</h3><p>Generally, typeclass instances aren’t supposed to overlap. That is, if you write an instance for <code>Show (Maybe a)</code>, you aren’t supposed to <em>also</em> write an instance for <code>Show (Maybe Bool)</code>, since it isn’t clear whether <code>show (Just True)</code> should use the first instance or the second. For that reason, by default, GHC rejects any form of instance overlap as soon as it detects it.\n</p><p>Usually, this is the right behavior. Due to the way Haskell’s typeclass system is designed to preserve coherency—that is, the same combination of type arguments always selects the same instance—overlapping instances can be unintuitive or even cause nonsensical behavior if orphan instances are defined. However, when doing TMP, it’s useful to make exceptions to that rule of thumb, so GHC provides the option to explicitly opt-in to overlapping instances.\n</p><p>As a simple example, suppose we wanted to write a typeclass that checks whether a given type is <code>()</code> or not:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">IsUnit</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">isUnit</span> <span class=\"ow\">::</span> <span class=\"kt\">Bool</span></code></pre><p>If we were to write an ordinary, value-level function, we could write something like this pseudo-Haskell:\n</p><pre><code class=\"pygments\"><span class=\"c1\">-- not actually valid Haskell, just an example</span>\n<span class=\"nf\">isUnit</span> <span class=\"ow\">::</span> <span class=\"o\">*</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Bool</span>\n<span class=\"nf\">isUnit</span> <span class=\"nb\">()</span> <span class=\"ow\">=</span> <span class=\"kt\">True</span>\n<span class=\"nf\">isUnit</span> <span class=\"kr\">_</span>  <span class=\"ow\">=</span> <span class=\"kt\">False</span></code></pre><p>But if we try to translate this to typeclass instances, we’ll get a problem:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">IsUnit</span> <span class=\"nb\">()</span> <span class=\"kr\">where</span>\n  <span class=\"n\">isUnit</span> <span class=\"ow\">=</span> <span class=\"kt\">True</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsUnit</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">isUnit</span> <span class=\"ow\">=</span> <span class=\"kt\">False</span></code></pre><p>The problem is that a function definition has a closed set of clauses matched from top to bottom, but typeclass instances are open and unordered.<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup> This means GHC will complain about instance overlap if we try to evaluate <code>isUnit @()</code>:\n</p><pre><code>ghci&gt; isUnit @()\n\nerror:\n    • Overlapping instances for IsUnit ()\n        arising from a use of ‘isUnit’\n      Matching instances:\n        instance IsUnit a\n        instance IsUnit ()\n</code></pre><p>To fix this, we have to explicitly mark <code>IsUnit ()</code> as overlapping:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"cm\">{-# OVERLAPPING #-}</span> <span class=\"kt\">IsUnit</span> <span class=\"nb\">()</span> <span class=\"kr\">where</span>\n  <span class=\"n\">isUnit</span> <span class=\"ow\">=</span> <span class=\"kt\">True</span></code></pre><p>Now GHC accepts the expression without complaint:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">isUnit</span> <span class=\"o\">@</span><span class=\"nb\">()</span>\n<span class=\"kt\">True</span></code></pre><p>What does the <code>{-# OVERLAPPING #-}</code> pragma do, exactly? The gory details are <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/instances.html#overlapping-instances\">spelled out in the GHC User’s Guide</a>, but the simple explanation is that <code>{-# OVERLAPPING #-}</code> relaxes the overlap checker as long as the instance is <em>strictly more specific</em> than the instance(s) it overlaps with. In this case, that is true: <code>IsUnit ()</code> is trivially more specific than <code>IsUnit a</code>, since the former only matches <code>()</code> while the latter matches anything at all. That means our overlap is well-formed, and instance resolution should behave the way we’d like.\n</p><p>Overlapping instances are a useful tool when performing TMP, as they make it possible to write piecewise functions on types in the same way it’s possible to write piecewise functions on terms. However, they must still be used with care, as without understanding how they work, they can produce unintuitive results. For an example of how things can go wrong, consider the following definition:\n</p><pre><code class=\"pygments\"><span class=\"nf\">guardUnit</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Either</span> <span class=\"kt\">String</span> <span class=\"n\">a</span>\n<span class=\"nf\">guardUnit</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">isUnit</span> <span class=\"o\">@</span><span class=\"n\">a</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">True</span>  <span class=\"ow\">-&gt;</span> <span class=\"kt\">Left</span> <span class=\"s\">\"unit is not allowed\"</span>\n  <span class=\"kt\">False</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Right</span> <span class=\"n\">x</span></code></pre><p>The intent of <code>guardUnit</code> is to use <code>isUnit</code> to detect if its argument is of type <code>()</code>, and if it is, to return an error. However, even though we marked <code>IsUnit ()</code> overlapping, we still get an overlapping instance error:\n</p><pre><code>error:\n    • Overlapping instances for IsUnit a arising from a use of ‘isUnit’\n      Matching instances:\n        instance IsUnit a\n        instance [overlapping] IsUnit ()\n    • In the expression: isUnit @a\n</code></pre><p>What gives? The problem is that GHC simply doesn’t know what type <code>a</code> is when compiling <code>guardUnit</code>. It <em>could</em> be instantiated to <code>()</code> where it’s called, but it might not be. Therefore, GHC doesn’t know which instance to pick, and an overlapping instance error is still reported.\n</p><p>This behavior is actually a very, very good thing. If GHC were to blindly pick the <code>IsUnit a</code> instance in this case, then <code>guardUnit</code> would always take the <code>False</code> branch, even when passed a value of type <code>()</code>! That would certainly not be what was intended, so it’s better to reject this program than to silently do the wrong thing. However, in more complicated situations, it can be quite surprising that GHC is complaining about instance overlap even when <code>{-# OVERLAPPING #-}</code> annotations are used, so it’s important to keep their limitations in mind.\n</p><p>As it happens, in this particular case, the error is easily remedied. We simply have to add an <code>IsUnit</code> constraint to the type signature of <code>guardUnit</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">guardUnit</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">IsUnit</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Either</span> <span class=\"kt\">String</span> <span class=\"n\">a</span>\n<span class=\"nf\">guardUnit</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">isUnit</span> <span class=\"o\">@</span><span class=\"n\">a</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">True</span>  <span class=\"ow\">-&gt;</span> <span class=\"kt\">Left</span> <span class=\"s\">\"unit is not allowed\"</span>\n  <span class=\"kt\">False</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Right</span> <span class=\"n\">x</span></code></pre><p>Now picking the right <code>IsUnit</code> instance is deferred to the place where <code>guardUnit</code> is used, and the definition is accepted.<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup>\n</p><h3><a name=\"type-families-are-functions-from-types-to-types\"></a>Type families are functions from types to types</h3><p>In the previous section, we discussed how typeclasses are functions from types to terms, but what about functions from types to types? For example, suppose we wanted to sum two type-level natural numbers and get a new type-level natural number as a result? For that, we can use a type family:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE TypeFamilies #-}</span>\n\n<span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">Sum</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">Sum</span> <span class=\"kt\">Z</span>     <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">b</span>\n  <span class=\"kt\">Sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">Sum</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span></code></pre><p>The above is a <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/type_families.html#closed-type-families\">closed type family</a>, which works quite a lot like an ordinary Haskell function definition, just at the type level instead of at the value level. For comparison, the equivalent value-level definition of <code>Sum</code> would look like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Nat</span> <span class=\"ow\">=</span> <span class=\"kt\">Z</span> <span class=\"o\">|</span> <span class=\"kt\">S</span> <span class=\"kt\">Nat</span>\n\n<span class=\"nf\">sum</span> <span class=\"ow\">::</span> <span class=\"kt\">Nat</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Nat</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Nat</span>\n<span class=\"nf\">sum</span> <span class=\"kt\">Z</span>     <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">b</span>\n<span class=\"nf\">sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"n\">sum</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span></code></pre><p>As you can see, the two are quite similar. Both are defined via a pair of pattern-matching clauses, and though it doesn’t matter here, both closed type families and ordinary functions evaluate their clauses top to bottom.\n</p><p>To test our definition of <code>Sum</code> in GHCi, we can use <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/ghci.html#ghci-cmd-:kind\">the <code>:kind!</code> command</a>, which prints out a type and its kind after reducing it as much as possible:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">:</span><span class=\"n\">kind</span><span class=\"o\">!</span> <span class=\"kt\">Sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">))</span>\n<span class=\"kt\">Sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">))</span> <span class=\"ow\">::</span> <span class=\"o\">*</span>\n<span class=\"ow\">=</span> <span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">))</span></code></pre><p>We can also combine <code>Sum</code> with our <code>ReifyNat</code> class from earlier:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">Sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"kt\">Z</span><span class=\"p\">)))</span>\n<span class=\"mi\">3</span></code></pre><p>Type families are a useful complement to typeclasses when performing type-level programming. They allow computation to occur entirely at the type-level, which is necessarily computation that occurs entirely at compile-time, and the result can then be passed to a typeclass method to produce a term-level value from the result.\n</p><h3><a name=\"example-1-generalized-concat\"></a>Example 1: Generalized <code>concat</code></h3><p>Finally, using what we’ve discussed so far, we can do our first bit of practical TMP. Specifically, we’re going to define a <code>flatten</code> function similar to like-named functions provided by many dynamically-typed languages. In those languages, <code>flatten</code> is like <code>concat</code>, but it works on a list of arbitrary depth. For example, we might use it like this:\n</p><pre><code class=\"pygments\"><span class=\"o\">&gt;</span> <span class=\"n\">flatten</span> <span class=\"p\">[[[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">]],</span> <span class=\"p\">[[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">]]]</span>\n<span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">]</span></code></pre><p>In Haskell, lists of different depths have different types, so multiple levels of <code>concat</code> have to be applied explicitly. But using TMP, we can write a generic <code>flatten</code> function that operates on lists of any depth!\n</p><p>Since this is <em>typeclass</em> metaprogramming, we’ll unsurprisingly begin with a typeclass:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Flatten</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"o\">???</span><span class=\"p\">]</span></code></pre><p>Our first challenge is writing the return type of <code>flatten</code>. Since the argument could be a list of any depth, there’s no direct way to obtain its element type. Fortunately, we can define a type family that does precisely that:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">ElementOf</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">ElementOf</span> <span class=\"p\">[[</span><span class=\"n\">a</span><span class=\"p\">]]</span> <span class=\"ow\">=</span> <span class=\"kt\">ElementOf</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>\n  <span class=\"kt\">ElementOf</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>   <span class=\"ow\">=</span> <span class=\"n\">a</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">Flatten</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"kt\">ElementOf</span> <span class=\"n\">a</span><span class=\"p\">]</span></code></pre><p>Now we can write our <code>Flatten</code> instances. The base case is when the type is a list of depth 1, in which case we don’t have any flattening to do:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>The inductive case is when the type is a nested list, in which case we want to apply <code>concat</code> and recur:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"cm\">{-# OVERLAPPING #-}</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[[</span><span class=\"n\">a</span><span class=\"p\">]]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">flatten</span> <span class=\"p\">(</span><span class=\"n\">concat</span> <span class=\"n\">x</span><span class=\"p\">)</span></code></pre><p>Sadly, if we try to compile these definitions, GHC will reject our <code>Flatten [a]</code> instance:\n</p><pre><code>error:\n    • Couldn't match type ‘a’ with ‘ElementOf [a]’\n      ‘a’ is a rigid type variable bound by\n        the instance declaration\n      Expected type: [ElementOf [a]]\n        Actual type: [a]\n    • In the expression: x\n      In an equation for ‘flatten’: flatten x = x\n      In the instance declaration for ‘Flatten [a]’\n   |\n   |   flatten x = x\n   |               ^\n</code></pre><p>At first blush, this error looks very confusing. Why doesn’t GHC think <code>a</code> and <code>ElementOf [a]</code> are the same type? Well, consider what would happen if we picked a type like <code>[Int]</code> for <code>a</code>. Then <code>[a]</code> would be <code>[[Int]]</code>, a nested list, so the first case of <code>ElementOf</code> would apply. Therefore, GHC refuses to pick the second equation of <code>ElementOf</code> so hastily.\n</p><p>In this particular case, we might think that’s rather silly. After all, if <code>a</code> were <code>[Int]</code>, then GHC wouldn’t have picked the <code>Flatten [a]</code> instance to begin with, it would pick the more specific <code>Flatten [[a]]</code> instance defined below. Therefore, the hypothetical situation above could never happen. Unfortunately, GHC does not realize this, so we find ourselves at an impasse.\n</p><p>Fortunately, we can soothe GHC’s anxiety by adding an extra constraint to our <code>Flatten [a]</code> instance:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">ElementOf</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"o\">~</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>This is a <em>type equality constraint</em>. Type equality constraints are written with the syntax <code>a ~ b</code>, and they state that <code>a</code> must be the same type as <code>b</code>. Type equality constraints are mostly useful when type families are involved, since they can be used (as in this case) to require a type family reduce to a certain type. In this case, we’re asserting that <code>ElementOf [a]</code> must always be <code>a</code>, which allows the instance to typecheck.\n</p><p>Note that this doesn’t let us completely wriggle out of our obligation, as the type equality constraint must <em>eventually</em> be checked when the instance is actually used, so initially this might seem like we’ve only deferred the problem to later. But in this case, that’s exactly what we need: by the time the <code>Flatten [a]</code> instance is selected, GHC will know that <code>a</code> is <em>not</em> a list type, and it will be able to reduce <code>ElementOf [a]</code> to <code>a</code> without difficulty. Indeed, we can see this for ourselves by using <code>flatten</code> in GHCi:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">flatten</span> <span class=\"p\">[[[</span><span class=\"mi\">1</span> <span class=\"ow\">::</span> <span class=\"kt\">Integer</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">]],</span> <span class=\"p\">[[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">]]]</span>\n<span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">7</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">]</span></code></pre><p>It works! But why do we need the type annotation on <code>1</code>? If we leave it out, we get a rather hairy type error:\n</p><pre><code>error:\n    • Couldn't match type ‘ElementOf [a0]’ with ‘ElementOf [a]’\n      Expected type: [ElementOf [a]]\n        Actual type: [ElementOf [a0]]\n      NB: ‘ElementOf’ is a non-injective type family\n      The type variable ‘a0’ is ambiguous\n</code></pre><p>The issue here stems from the polymorphic nature of Haskell number literals. Theoretically, someone could define a <code>Num [a]</code> instance, in which case <code>1</code> could actually have a list type, and either case of <code>ElementOf</code> could match depending on the choice of <code>Num</code> instance. Of course, no such <code>Num</code> instance exists, nor should it, but the possibility of it being defined means GHC can’t be certain of the depth of the argument list.\n</p><p>This issue happens to come up a lot in simple examples of TMP, since polymorphic number literals introduce a level of ambiguity. In real programs, this is much less of an issue, since there’s no reason to call <code>flatten</code> on a completely hardcoded list! However, it’s still important to understand what these type errors mean and why they occur.\n</p><p>That wrinkle aside, <code>flatten</code> is a functioning example of what useful TMP can look like. We’ve written a single, generic definition that flattens lists of any depth, taking advantage of static type information to choose what to do at runtime.\n</p><h4><a name=\"typeclasses-as-compile-time-code-generation\"></a>Typeclasses as compile-time code generation</h4><p>Presented with the above definition of <code>Flatten</code>, it might not be immediately obvious how to think about <code>Flatten</code> as a function from types to terms. After all, it looks a lot more like an “ordinary” typeclass (like, say, <code>Eq</code> or <code>Show</code>) than the <code>TypeOf</code> and <code>ReifyNat</code> classes we defined above.\n</p><p>One useful way to shift our perspective is to consider equivalent <code>Flatten</code> instances written using point-free style:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">ElementOf</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"o\">~</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"ow\">=</span> <span class=\"n\">id</span>\n\n<span class=\"kr\">instance</span> <span class=\"cm\">{-# OVERLAPPING #-}</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Flatten</span> <span class=\"p\">[[</span><span class=\"n\">a</span><span class=\"p\">]]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">flatten</span> <span class=\"ow\">=</span> <span class=\"n\">flatten</span> <span class=\"o\">.</span> <span class=\"n\">concat</span></code></pre><p>These definitions of <code>flatten</code> no longer (syntactically) depend on term-level arguments, just like our definitions of <code>typeOf</code> and <code>reifyNat</code> didn’t accept any term-level arguments above. This allows us to consider what <code>flatten</code> might “expand to” given a type argument alone:\n</p><ul><li><p><code>flatten @[Int]</code> is just <code>id</code>, since the <code>Flatten [a]</code> instance is selected.\n</p></li><li><p><code>flatten @[[Int]]</code> is <code>flatten @[Int] . concat</code>, since the <code>Flatten [[a]]</code> instance is selected. That then becomes <code>id . concat</code>, which can be further simplified to just <code>concat</code>.\n</p></li><li><p><code>flatten @[[[Int]]]</code> is <code>flatten @[[Int]] . concat</code>, which simplifies to <code>concat . concat</code> by the same reasoning above.\n</p></li><li><p><code>flatten @[[[[Int]]]]</code> is then <code>concat . concat . concat</code>, and so on.\n</p></li></ul><p>This meshes quite naturally with our intuition of typeclasses as functions from types to terms. Each application of <code>flatten</code> takes a type as an argument and produces some number of composed <code>concat</code>s as a result. From this perspective, <code>Flatten</code> is performing a kind of compile-time code generation, synthesizing an expression to do the concatenation on the fly by inspecting the type information.\n</p><p>This framing is one of the key ideas that makes TMP so powerful, and indeed, it explains how it’s worthy of the name <em>metaprogramming</em>. As we continue to more sophisticated examples of TMP, try to keep this perspective in mind.\n</p><h2><a name=\"part-2-generic-programming\"></a>Part 2: Generic programming</h2><p>Part 1 of this blog post established the foundational techniques used in TMP, all of which are useful on their own. If you’ve read up to this point, you now know enough to start applying TMP yourself, and the remainder of this blog post will simply continue to build upon what you already know.\n</p><p>In the previous section, we discussed how to use TMP to write a generic <code>flatten</code> operation. In this section, we’ll aim a bit higher: totally generic functions that operate on <em>arbitrary</em> datatypes.\n</p><h3><a name=\"open-type-families-and-associated-types\"></a>Open type families and associated types</h3><p>Before we can dive into examples, we need to revisit type families. In the previous sections, we discussed closed type families, but we did not cover their counterpart, <em>open type families</em>. Like closed type families, open type families are effectively functions from types to types, but unlike closed type families, they are not defined with a predefined set of equations. Instead, new equations are added separately using <code>type instance</code> declarations. For example, we could define our <code>Sum</code> family from above like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">Sum</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n<span class=\"kr\">type</span> <span class=\"kr\">instance</span> <span class=\"kt\">Sum</span> <span class=\"kt\">Z</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">b</span>\n<span class=\"kr\">type</span> <span class=\"kr\">instance</span> <span class=\"kt\">Sum</span> <span class=\"p\">(</span><span class=\"kt\">S</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kt\">S</span> <span class=\"p\">(</span><span class=\"kt\">Sum</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span></code></pre><p>In the case of <code>Sum</code>, this would not be very useful, and indeed, <code>Sum</code> is much better expressed as a closed type family than an open one. But the advantage of open type families is similar to the advantage of typeclasses: new equations can be added at any time, even in modules other than the one that declares the open type family.\n</p><p>This extensibility means open type families are used less for type-level computation and more for type-level maps that associate types with other types. For example, one might define a <code>Key</code> open type family that relates types to the types used to index them:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">Key</span> <span class=\"n\">a</span>\n<span class=\"kr\">type</span> <span class=\"kr\">instance</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Vector</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Int</span>\n<span class=\"kr\">type</span> <span class=\"kr\">instance</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Map</span> <span class=\"n\">k</span> <span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">k</span>\n<span class=\"kr\">type</span> <span class=\"kr\">instance</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Trie</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">ByteString</span></code></pre><p>This can be combined with a typeclass to provide a generic way to see if a data structure contains a given key:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">HasKey</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">::</span> <span class=\"kt\">Key</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Bool</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Vector</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">hasKey</span> <span class=\"n\">i</span> <span class=\"n\">vec</span> <span class=\"ow\">=</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">0</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Vector</span><span class=\"o\">.</span><span class=\"n\">length</span> <span class=\"n\">vec</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Map</span> <span class=\"n\">k</span> <span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">=</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Map</span><span class=\"o\">.</span><span class=\"n\">member</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Trie</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">=</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Trie</span><span class=\"o\">.</span><span class=\"n\">member</span></code></pre><p>In this case, anyone could define their own data structure, define instances of <code>Key</code> and <code>HasKey</code> for their data structure, and use <code>hasKey</code> to see if it contains a given key, regardless of the structure of those keys. In fact, it’s so common for open type families and typeclasses to cooperate in this way that GHC provides the option to make the connection explicit by defining them together:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">HasKey</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Key</span> <span class=\"n\">a</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">::</span> <span class=\"kt\">Key</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Bool</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Vector</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Vector</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Int</span>\n  <span class=\"n\">hasKey</span> <span class=\"n\">i</span> <span class=\"n\">vec</span> <span class=\"ow\">=</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">0</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">i</span> <span class=\"o\">&lt;</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Vector</span><span class=\"o\">.</span><span class=\"n\">length</span> <span class=\"n\">vec</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Map</span> <span class=\"n\">k</span> <span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Map</span> <span class=\"n\">k</span> <span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">k</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">=</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Map</span><span class=\"o\">.</span><span class=\"n\">member</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">HasKey</span> <span class=\"p\">(</span><span class=\"kt\">Trie</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Key</span> <span class=\"p\">(</span><span class=\"kt\">Trie</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">ByteString</span>\n  <span class=\"n\">hasKey</span> <span class=\"ow\">=</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Trie</span><span class=\"o\">.</span><span class=\"n\">member</span></code></pre><p>An open family declared inside a typeclass like this is called an <em>associated type</em>. It works exactly the same way as the separate definitions of <code>Key</code> and <code>HasKey</code>, it just uses a different syntax. Note that although the <code>family</code> and <code>instance</code> keywords have disappeared from the declarations, that is only an abbreviation; the keywords are simply implicitly added (and explicitly writing them is still allowed, though most people do not).\n</p><p>Open type families and associated types are extremely useful for abstracting over similar types with slightly different structure, and libraries like <a href=\"https://hackage.haskell.org/package/mono-traversable\"><code>mono-traversable</code></a> are examples of how they can be used to that end for their full effect. However, those use cases can’t really be classified as TMP, just using typeclasses for their traditional purpose of operation overloading.\n</p><p>However, that doesn’t mean open type families aren’t useful for TMP. In fact, one use case of TMP makes <em>heavy</em> use of open type families: datatype-generic programming.\n</p><h3><a name=\"example-2-datatype-generic-programming\"></a>Example 2: Datatype-generic programming</h3><p><em>Datatype-generic programming</em> refers to a class of techniques for writing generic functions that operate on arbitrary data structures. Some useful applications of datatype-generic programming include\n</p><ul><li><p>equality, comparison, and hashing,\n</p></li><li><p>recursive traversal of self-similar data structures, and\n</p></li><li><p>serialization and deserialization,\n</p></li></ul><p>among other things. The idea is that by exploiting the structure of datatype definitions themselves, it’s possible for a datatype-generic function to provide implementations of functionality like the above on <em>any</em> datatype.\n</p><p>In Haskell, the most popular approach to datatype-generic programming leverages GHC generics, which is quite sophisticated. The <a href=\"https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Generics.html\">module documentation for <code>GHC.Generics</code></a> already includes a fairly lengthy explanation of how it works, so I will not regurgitate it here (that could fill a blog post of its own!), but I will show how to construct a simplified version of the system that highlights the key role of TMP.\n</p><h4><a name=\"generic-datatype-representations\"></a>Generic datatype representations</h4><p>At the heart of the <code>Generic</code> class is a simple concept: all non-GADT Haskell datatypes can be represented as sums of products. For example, if we have\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Authentication</span>\n  <span class=\"ow\">=</span> <span class=\"kt\">AuthBasic</span> <span class=\"kt\">Username</span> <span class=\"kt\">Password</span>\n  <span class=\"o\">|</span> <span class=\"kt\">AuthSSH</span> <span class=\"kt\">PublicKey</span></code></pre><p>then we have a type that is essentially equivalent to this one:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">Authentication</span> <span class=\"ow\">=</span> <span class=\"kt\">Either</span> <span class=\"p\">(</span><span class=\"kt\">Username</span><span class=\"p\">,</span> <span class=\"kt\">Password</span><span class=\"p\">)</span> <span class=\"kt\">PublicKey</span></code></pre><p>If we know how to define a function on a nested tree built out of <code>Either</code>s and pairs, then we know how to define it on <em>any</em> such datatype! This is where TMP comes in: recall the way we viewed <code>Flatten</code> as a mechanism for compile-time code generation based on type information. Could we use the same technique to generate implementations of equality, comparison, hashing, etc. from statically-known information about the structure of a datatype?\n</p><p>The answer to that question is <em>yes</em>. To start, let’s consider a particularly simple example: suppose we want to write a generic function that counts the number of fields stored in an arbitrary constructor. For example, <code>numFields (AuthBasic \"alyssa\" \"pass1234\")</code> would return <code>2</code>, while <code>numFields (AuthSSH \"&lt;key&gt;\")</code> would return <code>1</code>. Not a very useful function, admittedly, but it’s a simple example of what generic programming can do.\n</p><p>We’ll start by using TMP to implement a “generic” version of <code>numFields</code> that operates on trees of <code>Either</code>s and pairs as described above:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Natural</span>\n\n<span class=\"c1\">-- base case: leaf value</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"mi\">1</span>\n\n<span class=\"kr\">instance</span> <span class=\"cm\">{-# OVERLAPPING #-}</span> <span class=\"p\">(</span><span class=\"kt\">GNumFields</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">a</span> <span class=\"o\">+</span> <span class=\"n\">gnumFields</span> <span class=\"n\">b</span>\n\n<span class=\"kr\">instance</span> <span class=\"cm\">{-# OVERLAPPING #-}</span> <span class=\"p\">(</span><span class=\"kt\">GNumFields</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"kt\">Left</span> <span class=\"n\">a</span><span class=\"p\">)</span>  <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">a</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"kt\">Right</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">b</span></code></pre><p>Just like our <code>Flatten</code> class from earlier, <code>GNumFields</code> uses the type-level structure of its argument to choose what to do:\n</p><ul><li><p>If we find a pair, that corresponds to a product, so we recur into both sides and sum the results.\n</p></li><li><p>If we find <code>Left</code> or <code>Right</code>, that corresponds to the “spine” differentiating different constructors, so we simply recur into the contained value.\n</p></li><li><p>In the case of any other value, we’re at a “leaf” in the tree of <code>Either</code>s and pairs, which corresponds to a single field, so we just return <code>1</code>.\n</p></li></ul><p>Now if we call <code>gnumFields (Left (\"alyssa\", \"pass1234\"))</code>, we’ll get <code>2</code>, and if we call <code>gnumFields (Right \"&lt;key&gt;\")</code>, we’ll get <code>1</code>. All that’s left to do is write a bit of code that converts our <code>Authentication</code> type to a tree of <code>Either</code>s and pairs:\n</p><pre><code class=\"pygments\"><span class=\"nf\">genericizeAuthentication</span> <span class=\"ow\">::</span> <span class=\"kt\">Authentication</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Either</span> <span class=\"p\">(</span><span class=\"kt\">Username</span><span class=\"p\">,</span> <span class=\"kt\">Password</span><span class=\"p\">)</span> <span class=\"kt\">PublicKey</span>\n<span class=\"nf\">genericizeAuthentication</span> <span class=\"p\">(</span><span class=\"kt\">AuthBasic</span> <span class=\"n\">user</span> <span class=\"n\">pass</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">,</span> <span class=\"n\">pass</span><span class=\"p\">)</span>\n<span class=\"nf\">genericizeAuthentication</span> <span class=\"p\">(</span><span class=\"kt\">AuthSSH</span> <span class=\"n\">key</span><span class=\"p\">)</span>         <span class=\"ow\">=</span> <span class=\"kt\">Right</span> <span class=\"n\">key</span>\n\n<span class=\"nf\">numFieldsAuthentication</span> <span class=\"ow\">::</span> <span class=\"kt\">Authentication</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Natural</span>\n<span class=\"nf\">numFieldsAuthentication</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"o\">.</span> <span class=\"n\">genericizeAuthentication</span></code></pre><p>Now we get the results we want on our <code>Authentication</code> type using <code>numFieldsAuthentication</code>, but we’re not done yet, since it only works on <code>Authentication</code> values. Is there a way to define a generic <code>numFields</code> function that works on arbitrary datatypes that implement this conversion to sums-of-products? Yes, with another typeclass:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Generic</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Rep</span> <span class=\"n\">a</span>\n  <span class=\"n\">genericize</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Rep</span> <span class=\"n\">a</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Generic</span> <span class=\"kt\">Authentication</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Rep</span> <span class=\"kt\">Authentication</span> <span class=\"ow\">=</span> <span class=\"kt\">Either</span> <span class=\"p\">(</span><span class=\"kt\">Username</span><span class=\"p\">,</span> <span class=\"kt\">Password</span><span class=\"p\">)</span> <span class=\"kt\">PublicKey</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">AuthBasic</span> <span class=\"n\">user</span> <span class=\"n\">pass</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"n\">user</span><span class=\"p\">,</span> <span class=\"n\">pass</span><span class=\"p\">)</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">AuthSSH</span> <span class=\"n\">key</span><span class=\"p\">)</span>         <span class=\"ow\">=</span> <span class=\"kt\">Right</span> <span class=\"n\">key</span>\n\n<span class=\"nf\">numFields</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">Generic</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"kt\">Rep</span> <span class=\"n\">a</span><span class=\"p\">))</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Natural</span>\n<span class=\"nf\">numFields</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"o\">.</span> <span class=\"n\">genericize</span></code></pre><p>Now <code>numFields (AuthBasic \"alyssa\" \"pass1234\")</code> returns <code>2</code>, as desired, and it will <em>also</em> work with any datatype that provides a <code>Generic</code> instance. If the above code makes your head spin, don’t worry: this is by far the most complicated piece of code in this blog post up to this point. Let’s break down how it works piece by piece:\n</p><ul><li><p>First, we define the <code>Generic</code> class, comprised of two parts:\n</p><ol><li><p>The <code>Rep a</code> associated type maps a type <code>a</code> onto its generic, sums-of-products representation, i.e. one built out of combinations of <code>Either</code> and pairs.\n</p></li><li><p>The <code>genericize</code> method converts an actual <em>value</em> of type <code>a</code> to the equivalent value using the sums-of-products representation.\n</p></li></ol></li><li><p>Next, we define a <code>Generic</code> instance for <code>Authentication</code>. <code>Rep Authentication</code> is the sums-of-products representation we described above, and <code>genericize</code> is likewise <code>genericizeAuthentication</code> from above.\n</p></li><li><p>Finally, we define <code>numFields</code> as a function with a <code>GNumFields (Rep a)</code> constraint. This is where all the magic happens:\n</p><ul><li><p>When we apply <code>numFields</code> to a datatype, <code>Rep</code> retrieves its generic, sums-of-products representation type.\n</p></li><li><p>The <code>GNumFields</code> class then uses various TMP techniques we’ve already described so far in this blog post to generate a <code>numFields</code> implementation on the fly from the structure of <code>Rep a</code>.\n</p></li><li><p>Finally, that generated <code>numFields</code> implementation is applied to the genericized term-level value, and the result is produced.\n</p></li></ul></li></ul><p>After all that, I suspect you might think this seems like a very convoluted way to define the (rather unhelpful) <code>numFields</code> operation. Surely just defining <code>numFields</code> on each type directly would be far easier? Indeed, if we were just considering <code>numFields</code>, you’d be right, but in fact we get much more than that. Using the same machinery, we can continue to define other generic operations—equality, comparison, etc.—the same way we defined <code>numFields</code>, and all of them would automatically work on <code>Authentication</code> because they all leverage the same <code>Generic</code> instance!\n</p><p>This is the basic value proposition of generic programming: we can do a little work up front to normalize our datatype to a generic representation <em>once</em>, then get a whole buffet of generic operations on it for free. In Haskell, the code generation capabilities of TMP is a key piece of that puzzle.\n</p><h4><a name=\"improving-our-definition-of-generic\"></a>Improving our definition of <code>Generic</code></h4><p>You may note that the definition of <code>Generic</code> provided above does not match the one in <code>GHC.Generic</code>. Indeed, our naïve approach suffers from several flaws that the real version does not. This is not a <code>GHC.Generics</code> tutorial, so I will not discuss every detail of the full implementation, but I will highlight a few improvements relevant to the broader theme of TMP.\n</p><h5><a name=\"distinguishing-leaves-from-the-spine\"></a>Distinguishing leaves from the spine</h5><p>One problem with our version of <code>Generic</code> is that it provides no way to distinguish an <code>Either</code> or pair that should be considered a “leaf”, as in a type like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Foo</span> <span class=\"ow\">=</span> <span class=\"kt\">A</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">Int</span> <span class=\"kt\">String</span><span class=\"p\">)</span> <span class=\"o\">|</span> <span class=\"kt\">B</span> <span class=\"p\">(</span><span class=\"kt\">Char</span><span class=\"p\">,</span> <span class=\"kt\">Bool</span><span class=\"p\">)</span></code></pre><p>Given this type, <code>Rep Foo</code> should be <code>Either (Either Int String) (Char, Bool)</code>, and <code>numFields (Right ('a', True))</code> will erroneously return <code>2</code> rather than <code>1</code>. To fix this, we can introduce a simple wrapper newtype that distinguishes leaves specifically:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Leaf</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Leaf</span> <span class=\"p\">{</span> <span class=\"n\">getLeaf</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"p\">}</span></code></pre><p>Now our <code>Generic</code> instances look like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">Generic</span> <span class=\"kt\">Authentication</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Rep</span> <span class=\"kt\">Authentication</span> <span class=\"ow\">=</span> <span class=\"kt\">Either</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"kt\">Username</span><span class=\"p\">,</span> <span class=\"kt\">Leaf</span> <span class=\"kt\">Password</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"kt\">PublicKey</span><span class=\"p\">)</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">AuthBasic</span> <span class=\"n\">user</span> <span class=\"n\">pass</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"n\">user</span><span class=\"p\">,</span> <span class=\"kt\">Leaf</span> <span class=\"n\">pass</span><span class=\"p\">)</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">AuthSSH</span> <span class=\"n\">key</span><span class=\"p\">)</span>         <span class=\"ow\">=</span> <span class=\"kt\">Right</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"n\">key</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Generic</span> <span class=\"kt\">Foo</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Rep</span> <span class=\"kt\">Foo</span> <span class=\"ow\">=</span> <span class=\"kt\">Either</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">Int</span> <span class=\"kt\">String</span><span class=\"p\">))</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"p\">(</span><span class=\"kt\">Char</span><span class=\"p\">,</span> <span class=\"kt\">Bool</span><span class=\"p\">))</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">A</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n  <span class=\"n\">genericize</span> <span class=\"p\">(</span><span class=\"kt\">B</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Right</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"n\">x</span><span class=\"p\">)</span></code></pre><p>Since the <code>Leaf</code> constructor now distinguishes a leaf, rather than the absence of an <code>Either</code> or <code>(,)</code> constructor, we’ll have to update our <code>GNumFields</code> instances as well. However, this has the additional pleasant effect of eliminating the need for overlapping instances:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"kt\">Leaf</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>  \n  <span class=\"n\">gnumFields</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"mi\">1</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">GNumFields</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">a</span> <span class=\"o\">+</span> <span class=\"n\">gnumFields</span> <span class=\"n\">b</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">GNumFields</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">GNumFields</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GNumFields</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"kt\">Left</span> <span class=\"n\">a</span><span class=\"p\">)</span>  <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">a</span>\n  <span class=\"n\">gnumFields</span> <span class=\"p\">(</span><span class=\"kt\">Right</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">gnumFields</span> <span class=\"n\">b</span></code></pre><p>This is a good example of why overlapping instances can be so seductive, but they often have unintended consequences. Even when doing TMP, explicit tags are almost always preferable.\n</p><h5><a name=\"handling-empty-constructors\"></a>Handling empty constructors</h5><p>Suppose we have a type with nullary data constructors, like the standard <code>Bool</code> type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Bool</span> <span class=\"ow\">=</span> <span class=\"kt\">False</span> <span class=\"o\">|</span> <span class=\"kt\">True</span></code></pre><p>How do we write a <code>Generic</code> instance for <code>Bool</code>? Using just <code>Either</code>, <code>(,)</code>, and <code>Leaf</code>, we can’t, but if we are willing to add a case for <code>()</code>, we can use it to denote nullary constructors:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">GNumFields</span> <span class=\"nb\">()</span> <span class=\"kr\">where</span>\n  <span class=\"n\">gnumFields</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Generic</span> <span class=\"kt\">Bool</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">Rep</span> <span class=\"kt\">Bool</span> <span class=\"ow\">=</span> <span class=\"kt\">Either</span> <span class=\"nb\">()</span> <span class=\"nb\">()</span>\n  <span class=\"n\">genericize</span> <span class=\"kt\">False</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span> <span class=\"nb\">()</span>\n  <span class=\"n\">genericize</span> <span class=\"kt\">True</span>  <span class=\"ow\">=</span> <span class=\"kt\">Right</span> <span class=\"nb\">()</span></code></pre><p>In a similar vein, we could use <code>Void</code> to represent datatypes that don’t have any constructors at all.\n</p><h4><a name=\"continuing-from-here\"></a>Continuing from here</h4><p>The full version of <code>Generic</code> has a variety of further improvements useful for generic programming, including:\n</p><ul><li><p>Support for converting from <code>Rep a</code> to <code>a</code>.\n</p></li><li><p>Special indication of self-recursive datatypes, making generic tree traversals possible.\n</p></li><li><p>Type-level information about datatype constructor and record accessor names, allowing them to be used in serialization.\n</p></li><li><p>Fully automatic generation of <code>Generic</code> instances via <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/generics.html#extension-DeriveGeneric\">the <code>DeriveGeneric</code> extension</a>, which reduces the per-type boilerplate to essentially nothing.\n</p></li></ul><p>The <a href=\"https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Generics.html\">module documentation for <code>GHC.Generics</code></a> discusses the full system in detail, and it provides an additional example that uses the same essential TMP techniques discussed here.\n</p><h2><a name=\"part-3-dependent-typing\"></a>Part 3: Dependent typing</h2><p>It’s time for the third and final part of this blog post: an introduction to dependently typed programming in Haskell. A full treatment of dependently typed programming is far, far too vast to be contained in a single blog post, so I will not attempt to do so here. Rather, I will cover some basic idioms for doing dependent programming and highlight how TMP can be valuable when doing so.\n</p><h3><a name=\"datatype-promotion\"></a>Datatype promotion</h3><p>In part 1, we used uninhabited datatypes like <code>Z</code> and <code>S a</code> to define new type-level constants. This works, but it is awkward. Imagine for a moment that we wanted to work with type-level booleans. Using our previous approach, we could define two empty datatypes, <code>True</code> and <code>False</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">True</span>\n<span class=\"kr\">data</span> <span class=\"kt\">False</span></code></pre><p>Now we could define type families to provide operations on these types, such as <code>Not</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">Not</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">Not</span> <span class=\"kt\">True</span>  <span class=\"ow\">=</span> <span class=\"kt\">False</span>\n  <span class=\"kt\">Not</span> <span class=\"kt\">False</span> <span class=\"ow\">=</span> <span class=\"kt\">True</span></code></pre><p>However, this has some frustrating downsides:\n</p><ul><li><p>First, it’s simply inconvenient that we have to define these new <code>True</code> and <code>False</code> “dummy” types, which are completely distinct from the <code>Bool</code> type provided by the prelude.\n</p></li><li><p>More significantly, it means <code>Not</code> has a very unhelpful kind:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">:</span><span class=\"n\">kind</span> <span class=\"kt\">Not</span>\n<span class=\"kt\">Not</span> <span class=\"ow\">::</span> <span class=\"o\">*</span> <span class=\"ow\">-&gt;</span> <span class=\"o\">*</span></code></pre><p>Even though <code>Not</code> is only <em>supposed</em> to be applied to <code>True</code> or <code>False</code>, its kind allows it to be applied to any type at all. You can see this in practice if you try to evaluate something like <code>Not Char</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">:</span><span class=\"n\">kind</span><span class=\"o\">!</span> <span class=\"kt\">Not</span> <span class=\"kt\">Char</span>\n<span class=\"kt\">Not</span> <span class=\"kt\">Char</span> <span class=\"ow\">::</span> <span class=\"o\">*</span>\n<span class=\"ow\">=</span> <span class=\"kt\">Not</span> <span class=\"kt\">Char</span></code></pre><p>Rather than getting an error, GHC simply spits <code>Not Char</code> back at us. This is a somewhat unintuitive property of closed type families: if none of the clauses match, the type family just gets “stuck,” not reducing any further. This can lead to very confusing type errors later in the typechecking process.\n</p></li></ul><p>One way to think about <code>Not</code> is that it is largely <em>dynamically kinded</em> in the same way some languages are dynamically typed. That isn’t entirely true, as we technically <em>will</em> get a kind error if we try to apply <code>Not</code> to a type constructor rather than a type, such as <code>Maybe</code>:\n</p><pre><code>ghci&gt; :kind! Not Maybe\n\n&lt;interactive&gt;:1:5: error:\n    • Expecting one more argument to ‘Maybe’\n      Expected a type, but ‘Maybe’ has kind ‘* -&gt; *’\n</code></pre><p>…but <code>*</code> is still a very big kind, much bigger than we would like to permit for <code>Not</code>.\n</p><p>To help with both these problems, GHC provides <em>datatype promotion</em> via <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/data_kinds.html\">the <code>DataKinds</code> language extension</a>. The idea is that for each normal, non-GADT type definition like\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Bool</span> <span class=\"ow\">=</span> <span class=\"kt\">False</span> <span class=\"o\">|</span> <span class=\"kt\">True</span></code></pre><p>then in addition to the normal type constructor and value constructors, GHC also defines several <em>promoted</em> constructors:\n</p><ul><li><p><code>Bool</code> is allowed as both a type and a kind.\n</p></li><li><p><code>'True</code> and <code>'False</code> are defined as new types of kind <code>Bool</code>.\n</p></li></ul><p>We can see this in action if we remove our <code>data True</code> and <code>data False</code> declarations and adjust our definition of <code>Not</code> to use promoted constructors:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE DataKinds #-}</span>\n\n<span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">Not</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">Not</span> <span class=\"kt\">&#39;True</span>  <span class=\"ow\">=</span> <span class=\"kt\">&#39;False</span>\n  <span class=\"kt\">Not</span> <span class=\"kt\">&#39;False</span> <span class=\"ow\">=</span> <span class=\"kt\">&#39;True</span></code></pre><p>Now the inferred kind of <code>Not</code> is no longer <code>* -&gt; *</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">:</span><span class=\"n\">kind</span> <span class=\"kt\">Not</span>\n<span class=\"kt\">Not</span> <span class=\"ow\">::</span> <span class=\"kt\">Bool</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Bool</span></code></pre><p>Consequently, we will now get a kind error if we attempt to apply <code>Not</code> to anything other than <code>'True</code> or <code>'False</code>:\n</p><pre><code>ghci&gt; :kind! Not Char\n\n&lt;interactive&gt;:1:5: error:\n    • Expected kind ‘Bool’, but ‘Char’ has kind ‘*’\n</code></pre><p>This is a nice improvement. We can make a similar change to our definitions involving type-level natural numbers:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Nat</span> <span class=\"ow\">=</span> <span class=\"kt\">Z</span> <span class=\"o\">|</span> <span class=\"kt\">S</span> <span class=\"kt\">Nat</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">ReifyNat</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"ow\">::</span> <span class=\"kt\">Nat</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">::</span> <span class=\"kt\">Natural</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">ReifyNat</span> <span class=\"kt\">&#39;Z</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">=</span> <span class=\"mi\">0</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">ReifyNat</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ReifyNat</span> <span class=\"p\">(</span><span class=\"kt\">&#39;S</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">reifyNat</span> <span class=\"ow\">=</span> <span class=\"mi\">1</span> <span class=\"o\">+</span> <span class=\"n\">reifyNat</span> <span class=\"o\">@</span><span class=\"n\">a</span></code></pre><p>Note that we need to add an explicit kind signature on the definition of the <code>ReifyNat</code> typeclass, since otherwise GHC will assume <code>a</code> has kind <code>*</code>, since nothing in the types of the typeclass methods suggests otherwise. In addition to making it clearer that <code>Z</code> and <code>S</code> are related, this prevents someone from coming along and defining a nonsensical instance like <code>ReifyNat Char</code>, which previously would have been allowed but will now be rejected with a kind error.\n</p><p>Datatype promotion is not strictly required to do TMP, but makes the process significantly less painful. It makes Haskell’s kind language extensible in the same way its type language is, which allows type-level programming to enjoy static typechecking (or more accurately, static kindchecking) in the same way term-level programming does.\n</p><h3><a name=\"gadts-and-proof-terms\"></a>GADTs and proof terms</h3><p>So far in this blog post, we have discussed several different function-like things:\n</p><ul><li><p>Ordinary Haskell functions are functions from terms to terms.\n</p></li><li><p>Type families are functions from types to types.\n</p></li><li><p>Typeclasses are functions from types to terms.\n</p></li></ul><p>A curious reader may wonder about the existence of a fourth class of function:\n</p><ul><li><p><em>???</em> are functions from terms to types.\n</p></li></ul><p>To reason about what could go in the <em>???</em> above, we must consider what “a function from terms to types” would even mean. Functions from terms to terms and types to types are straightforward enough. Functions from types to terms are a little trickier, but they make intuitive sense: we use information known at compile-time to generate runtime behavior. But how could information possibly flow in the other direction? How could we possibly turn runtime information into compile-time information without being able to predict the future?\n</p><p>In general, we cannot. However, one feature of Haskell allows a restricted form of seemingly doing the impossible—turning runtime information into compile-time information—and that’s GADTs.\n</p><p>GADTs<sup><a id=\"footnote-ref-4-1\" href=\"#footnote-4\">4</a></sup> are <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/exts/gadt.html\">described in detail in the GHC User’s Guide</a>, but the key idea for our purposes is that <em>pattern-matching on a GADT constructor can refine type information</em>. Here’s a simple, silly example:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">WhatIsIt</span> <span class=\"n\">a</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">ABool</span> <span class=\"ow\">::</span> <span class=\"kt\">WhatIsIt</span> <span class=\"kt\">Bool</span>\n  <span class=\"kt\">AnInt</span> <span class=\"ow\">::</span> <span class=\"kt\">WhatIsIt</span> <span class=\"kt\">Int</span>\n\n<span class=\"nf\">doSomething</span> <span class=\"ow\">::</span> <span class=\"kt\">WhatIsIt</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">doSomething</span> <span class=\"kt\">ABool</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">not</span> <span class=\"n\">x</span>\n<span class=\"nf\">doSomething</span> <span class=\"kt\">AnInt</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"mi\">1</span></code></pre><p>Here, <code>WhatIsIt</code> is a datatype with two nullary constructors, <code>ABool</code> and <code>AnInt</code>, similar to a normal, non-GADT datatype like this one:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">WhatIsIt</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">ABool</span> <span class=\"o\">|</span> <span class=\"kt\">AnInt</span></code></pre><p>What’s special about GADTs is that each constructor is given an explicit type signature. With the plain ADT definition above, <code>ABool</code> and <code>AnInt</code> would both have the type <code>forall a. WhatIsIt a</code>, but in the GADT definition, we explicitly fix <code>a</code> to <code>Bool</code> in the type of <code>ABool</code> and to <code>Int</code> in the type of <code>AnInt</code>.\n</p><p>This simple feature allows us to do very interesting things. The <code>doSomething</code> function is polymorphic in <code>a</code>, but on the right-hand side of the first equation, <code>x</code> has type <code>Bool</code>, while on the right-hand side of the second equation, <code>x</code> has type <code>Int</code>. This is because the <code>WhatIsIt a</code> argument effectively constrains the type of <code>a</code>, as we can see by experimenting with <code>doSomething</code> in GHCi:\n</p><pre><code>ghci&gt; doSomething ABool True\nFalse\nghci&gt; doSomething AnInt 10\n11\nghci&gt; doSomething AnInt True\n\nerror:\n    • Couldn't match expected type ‘Int’ with actual type ‘Bool’\n    • In the second argument of ‘doSomething’, namely ‘True’\n      In the expression: doSomething AnInt True\n      In an equation for ‘it’: it = doSomething AnInt True\n</code></pre><p>One way to think about GADTs is as “proofs” or “witnesses” of type equalities. The <code>ABool</code> constructor is a proof of <code>a ~ Bool</code>, while the <code>AnInt</code> constructor is a proof of <code>a ~ Int</code>. When you construct <code>ABool</code> or <code>AnInt</code>, you must be able to satisfy the equality, and it is in a sense “packed into” the constructor value. When code pattern-matches on the constructor, the equality is “unpacked from” the value, and the equality becomes available on the right-hand side of the pattern match.\n</p><p>GADTs can be much more sophisticated than our simple <code>WhatIsIt</code> type above. Just like normal ADTs, GADT constructors can have parameters, which makes it possible to write inductive datatypes that carry type equality proofs with them:\n</p><pre><code class=\"pygments\"><span class=\"kr\">infixr</span> <span class=\"mi\">5</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span>\n\n<span class=\"kr\">data</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">HNil</span>  <span class=\"ow\">::</span> <span class=\"kt\">HList</span> <span class=\"kt\">&#39;[]</span>\n  <span class=\"kt\">HCons</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as)</span></code></pre><p>This type is a <em>heterogenous list</em>, a list that can contain elements of different types:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">:</span><span class=\"n\">t</span> <span class=\"kt\">True</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"s\">\"hello\"</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"mi\">42</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span>\n<span class=\"kt\">True</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"s\">\"hello\"</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"mi\">42</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span>\n  <span class=\"ow\">::</span> <span class=\"kt\">Num</span> <span class=\"n\">a</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">HList</span> <span class=\"kt\">&#39;[Bool, [Char]</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"p\">]</span></code></pre><p>An <code>HList</code> is parameterized by a type-level list that keeps track of the types of its elements, which allows us to highlight another interesting property of GADTs: if we restrict that type information, the GHC pattern exhaustiveness checker will take the restriction into account. For example, we can write a completely total <code>head</code> function on <code>HList</code>s like this:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) -&gt; a</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kr\">_</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>Remarkably, GHC does not complain that this definition of <code>head</code> is non-exhaustive. Since we specified that the argument must be of type <code>HList (a ': as)</code> in the type signature for <code>head</code>, GHC knows that the argument <em>cannot</em> be <code>HNil</code> (which would have the type <code>HList '[]</code>), so it doesn’t ask us to handle that case.\n</p><p>These examples illustrate the way GADTs serve as a general-purpose construct for relating type- and term-level information. Information flows bidirectionally: type information refines the set of type constructors that can be matched on, and matching on type constructors exposes new type equalities.\n</p><h4><a name=\"proofs-that-work-together\"></a>Proofs that work together</h4><p>This interplay is wonderfully compositional. Suppose we wanted to write a function that accepts an <code>HList</code> of exactly 1, 2, or 3 elements. There’s no easy way to express that in the type signature the way we did with <code>head</code>, so it might seem like all we can do is write an entirely new container datatype that has three constructors, one for each case.\n</p><p>However, a more interesting solution exists that takes advantage of the bidirectional nature of GADTs. We can start by writing a <em>proof term</em> that contains no values, it just encapsulates type equalities on a type-level list:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">OneToThree</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">One</span>   <span class=\"ow\">::</span> <span class=\"kt\">OneToThree</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"kt\">&#39;[a]</span>\n  <span class=\"kt\">Two</span>   <span class=\"ow\">::</span> <span class=\"kt\">OneToThree</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"kt\">&#39;[a, b]</span>\n  <span class=\"kt\">Three</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToThree</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"kt\">&#39;[a, b, c]</span></code></pre><p>We call it a proof term because a value of type <code>OneToThree a b c as</code> constitutes a <em>proof</em> that <code>as</code> has exactly 1, 2, or 3 elements. Using <code>OneToThree</code>, we can write a function that accepts an <code>HList</code> accompanied by a proof term:\n</p><pre><code class=\"pygments\"><span class=\"nf\">sumUpToThree</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToThree</span> <span class=\"kt\">Int</span> <span class=\"kt\">Int</span> <span class=\"kt\">Int</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Int</span>\n<span class=\"nf\">sumUpToThree</span> <span class=\"kt\">One</span>   <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span>                     <span class=\"ow\">=</span> <span class=\"n\">x</span>\n<span class=\"nf\">sumUpToThree</span> <span class=\"kt\">Two</span>   <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">y</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span>           <span class=\"ow\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span>\n<span class=\"nf\">sumUpToThree</span> <span class=\"kt\">Three</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">y</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">z</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">z</span></code></pre><p>As with <code>head</code>, this function is completely exhaustive, in this case because we take full advantage of the bidirectional nature of GADTs:\n</p><ul><li><p>When we match on the <code>OneToThree</code> proof term, information flows from the term level to the type level, refining the type of <code>as</code> in that branch.\n</p></li><li><p>The refined type of <code>as</code> then flows back down to the term level, restricting the shape the <code>HList</code> can take and refinine the set of patterns we have to match.\n</p></li></ul><p>Of course, this example is not especially useful, but in general proof terms can encode any number of useful properties. For example, we can write a proof term that ensures an <code>HList</code> has an even number of elements:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">EvenNil</span>  <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"kt\">&#39;[]</span>\n  <span class=\"kt\">EvenCons</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Even</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: b</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span></code></pre><p>This is a proof which itself has inductive structure: <code>EvenCons</code> takes a proof that <code>as</code> has an even number of elements and produces a proof that adding two more elements preserves the evenness. We can combine this with a type family to write a function that “pairs up” elements in an <code>HList</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">PairUp</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">PairUp</span> <span class=\"kt\">&#39;[]</span>            <span class=\"ow\">=</span> <span class=\"kt\">&#39;[]</span>\n  <span class=\"kt\">PairUp</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: b</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"sc\">&#39;</span><span class=\"err\">: PairUp as</span>\n\n<span class=\"nf\">pairUp</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"kt\">PairUp</span> <span class=\"n\">as</span><span class=\"p\">)</span>\n<span class=\"nf\">pairUp</span> <span class=\"kt\">EvenNil</span>         <span class=\"kt\">HNil</span>                     <span class=\"ow\">=</span> <span class=\"kt\">HNil</span>\n<span class=\"nf\">pairUp</span> <span class=\"p\">(</span><span class=\"kt\">EvenCons</span> <span class=\"n\">even</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">y</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">xs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">pairUp</span> <span class=\"n\">even</span> <span class=\"n\">xs</span></code></pre><p>Once again, this definition is completely exhaustive, and we can show that it works in GHCi:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">pairUp</span> <span class=\"p\">(</span><span class=\"kt\">EvenCons</span> <span class=\"o\">$</span> <span class=\"kt\">EvenCons</span> <span class=\"kt\">EvenNil</span><span class=\"p\">)</span>\n             <span class=\"p\">(</span><span class=\"kt\">True</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"sc\">&#39;a&#39;</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"s\">\"foo\"</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"kt\">True</span><span class=\"p\">,</span><span class=\"sc\">&#39;a&#39;</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"nb\">()</span><span class=\"p\">,</span><span class=\"s\">\"foo\"</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span></code></pre><p>This ability to capture properties of a type using auxiliary proof terms, rather than having to define an entirely new type, is one of the things that makes dependently typed programming so powerful.\n</p><h4><a name=\"proof-inference\"></a>Proof inference</h4><p>While our definition of <code>pairUp</code> is interesting, you may be skeptical of its practical utility. It’s fiddly and inconvenient to have to pass the <code>Even</code> proof term explicitly, since it must be updated every time the length of the list changes. Fortunately, this is where TMP comes in.\n</p><p>Remember that typeclasses are functions from types to terms. As its happens, a value of type <code>Even as</code> can be mechanically produced from the structure of the type <code>as</code>. This suggests that we could use TMP to automatically generate <code>Even</code> proofs, and indeed, we can. In fact, it’s not at all complicated:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">IsEven</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsEven</span> <span class=\"kt\">&#39;[]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenNil</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsEven</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">IsEven</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: b</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenCons</span> <span class=\"n\">evenProof</span></code></pre><p>We can now adjust our <code>pairUp</code> function to use <code>IsEven</code> instead of an explicit <code>Even</code> argument:\n</p><pre><code class=\"pygments\"><span class=\"nf\">pairUp</span> <span class=\"ow\">::</span> <span class=\"kt\">IsEven</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"kt\">PairUp</span> <span class=\"n\">as</span><span class=\"p\">)</span>\n<span class=\"nf\">pairUp</span> <span class=\"ow\">=</span> <span class=\"n\">go</span> <span class=\"n\">evenProof</span> <span class=\"kr\">where</span>\n  <span class=\"n\">go</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"kt\">PairUp</span> <span class=\"n\">as</span><span class=\"p\">)</span>\n  <span class=\"n\">go</span> <span class=\"kt\">EvenNil</span>         <span class=\"kt\">HNil</span>                     <span class=\"ow\">=</span> <span class=\"kt\">HNil</span>\n  <span class=\"n\">go</span> <span class=\"p\">(</span><span class=\"kt\">EvenCons</span> <span class=\"n\">even</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">y</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">xs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">go</span> <span class=\"n\">even</span> <span class=\"n\">xs</span></code></pre><p>This is essentially identical to its old definition, but by acquiring the proof via <code>IsEven</code> rather than passing it explicitly, we can call <code>pairUp</code> without having to construct a proof manually:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">pairUp</span> <span class=\"p\">(</span><span class=\"kt\">True</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"sc\">&#39;a&#39;</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"s\">\"foo\"</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"kt\">True</span><span class=\"p\">,</span><span class=\"sc\">&#39;a&#39;</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"nb\">()</span><span class=\"p\">,</span><span class=\"s\">\"foo\"</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span></code></pre><p>This is rather remarkable. Using TMP, we are able to get GHC to <em>automatically construct a proof that a list is even</em>, with no programmer guidance beyond writing the <code>IsEven</code> typeclass. This relies once more on the perspective that typeclasses are functions that accept types and generate term-level code: <code>IsEven</code> is a function that accepts a type-level list and generates an <code>Even</code> proof term.\n</p><p>From this perspective, <strong>typeclasses are a way of specifying a proof search algorithm</strong> to the compiler. In the case of <code>IsEven</code>, the proofs being generated are rather simple, so the proof search algorithm is quite mechanical. But in general, typeclasses can be used to perform proof search of significant complexity, given a sufficiently clever encoding into the type system.\n</p><h3><a name=\"aside-gadts-versus-type-families\"></a>Aside: GADTs versus type families</h3><p>Before moving on, I want to explicitly call attention to the relationship between GADTs and type families. Though at first glance they may seem markedly different, there are some similarities between the two, and sometimes they may be used to accomplish similar things.\n</p><p>Consider again the type of the <code>pairUp</code> function above (without the typeclass for simplicity):\n</p><pre><code class=\"pygments\"><span class=\"nf\">pairUp</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"kt\">PairUp</span> <span class=\"n\">as</span><span class=\"p\">)</span></code></pre><p>We used both a GADT, <code>Even</code>, and a type family, <code>PairUp</code>. But we could have, in theory, used <em>only</em> a GADT and eliminated the type family altogether. Consider this variation on the <code>Even</code> proof term:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">EvenPairs</span> <span class=\"n\">as</span> <span class=\"n\">bs</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">EvenNil</span>  <span class=\"ow\">::</span> <span class=\"kt\">EvenPairs</span> <span class=\"kt\">&#39;[]</span> <span class=\"kt\">&#39;[]</span>\n  <span class=\"kt\">EvenCons</span> <span class=\"ow\">::</span> <span class=\"kt\">EvenPairs</span> <span class=\"n\">as</span> <span class=\"n\">bs</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">EvenPairs</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: b</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"p\">((</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"sc\">&#39;</span><span class=\"err\">: bs)</span></code></pre><p>This type has two type parameters rather than one, and though there’s no distinction between the two from GHC’s point of view, it can be useful to think of <code>as</code> as an “input” parameter and <code>bs</code> as an “output” parameter. The idea is that any <code>EvenPairs</code> proof relates both an even-length list type and its paired up equivalent:\n</p><ul><li><p><code>EvenNil</code> has type <code>EvenPairs '[] '[]</code>,\n</p></li><li><p><code>EvenCons EvenNil</code> has type <code>EvenPairs '[a, b] '[(a, b)]</code>,\n</p></li><li><p><code>EvenCons (EvenCons EvenNil)</code> has type <code>EvenPairs '[a, b, c, d] '[(a, b), (c, d)]</code>,\n</p></li><li><p>…and so on.\n</p></li></ul><p>This allows us to reformulate our <code>pairUp</code> type signature this way:\n</p><pre><code class=\"pygments\"><span class=\"nf\">pairUp</span> <span class=\"ow\">::</span> <span class=\"kt\">EvenPairs</span> <span class=\"n\">as</span> <span class=\"n\">bs</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">bs</span></code></pre><p>The definition is otherwise unchanged. The <code>PairUp</code> type family is completely gone, because now <code>EvenPairs</code> itself defines the relation. In this way, GADTs can be used like type-level functions!\n</p><p>The inverse, however, is not true, at least not directly: we cannot eliminate the GADT altogether and exclusively use type families. One way to attempt doing so would be to define a type family that returns a constraint rather than a type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">Data.Kind</span> <span class=\"p\">(</span><span class=\"kt\">Constraint</span><span class=\"p\">)</span>\n\n<span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">IsEvenTF</span> <span class=\"n\">as</span> <span class=\"ow\">::</span> <span class=\"kt\">Constraint</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">IsEvenTF</span> <span class=\"kt\">&#39;[]</span>            <span class=\"ow\">=</span> <span class=\"nb\">()</span>\n  <span class=\"kt\">IsEvenTF</span> <span class=\"p\">(</span><span class=\"kr\">_</span> <span class=\"sc\">&#39;</span><span class=\"err\">: _</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">IsEvenTF</span> <span class=\"n\">as</span></code></pre><p>The idea here is that <code>IsEvenTF as</code> produces a constraint can only be satisfied if <code>as</code> has an even number of elements, since that’s the only way it will eventually reduce to <code>()</code>, which in this case means the empty set of constraints, not the unit type (yes, the syntax for that is confusing). And in fact, it’s true that putting <code>IsEvenTF as =&gt;</code> in a type signature successfully restricts <code>as</code> to be an even-length list, but it doesn’t allow us to write <code>pairUp</code>. To see why, we can try the following definition:\n</p><pre><code class=\"pygments\"><span class=\"nf\">pairUp</span> <span class=\"ow\">::</span> <span class=\"kt\">IsEvenTF</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">HList</span> <span class=\"p\">(</span><span class=\"kt\">PairUp</span> <span class=\"n\">as</span><span class=\"p\">)</span>\n<span class=\"nf\">pairUp</span> <span class=\"kt\">HNil</span>                     <span class=\"ow\">=</span> <span class=\"kt\">HNil</span>\n<span class=\"nf\">pairUp</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">y</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">xs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">pairUp</span> <span class=\"n\">xs</span></code></pre><p>Unlike the version using the GADT, this version of <code>pairUp</code> is not considered exhaustive:\n</p><pre><code>warning: [-Wincomplete-patterns]\n    Pattern match(es) are non-exhaustive\n    In an equation for ‘pairUp’: Patterns not matched: HCons _ HNil\n</code></pre><p>This is because type families don’t provide the same bidirectional flow of information that GADTs do, they’re only type-level functions. The constraint generated by <code>IsEvenTF</code> provides no term-level evidence about the shape of <code>as</code>, so we can’t branch on it the way we can branch on the <code>Even</code> GADT.<sup><a id=\"footnote-ref-5-1\" href=\"#footnote-5\">5</a></sup> (In a sense, <code>IsEvenTF</code> is doing <a href=\"/blog/2019/11/05/parse-don-t-validate/\">validation, not parsing</a>.)\n</p><p>For this reason, I caution against overuse of type families. Their simplicity is seductive, but all too often you pay for that simplicity with inflexibility. GADTs combined with TMP for proof inference can provide the best of both worlds: complete control over the term-level proof that gets generated while still letting the compiler do most of the work for you.\n</p><h3><a name=\"guiding-type-inference\"></a>Guiding type inference</h3><p>So far, this blog post has given relatively little attention to type inference. That is in some part a testament to the robustness of GHC’s type inference algorithm: even when fairly sophisticated TMP is involved, GHC often manages to propagate enough type information that type annotations are rarely needed.\n</p><p>However, when doing TMP, it would be irresponsible to not at least consider the type inference properties of programs. Type inference is what drives the whole typeclass resolution process to begin with, so poor type inference can easily make your fancy TMP construction next to useless. To take advantage of GHC to the fullest extent, programs should proactively guide the typechecker to help it infer as much as possible as often as possible.\n</p><p>To illustrate what that can look like, suppose we want to use TMP to generate an <code>HList</code> full of <code>()</code> values of an arbitrary length:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">UnitList</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"n\">unitList</span> <span class=\"ow\">::</span> <span class=\"kt\">HList</span> <span class=\"n\">as</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">UnitList</span> <span class=\"kt\">&#39;[]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">unitList</span> <span class=\"ow\">=</span> <span class=\"kt\">HNil</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">UnitList</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">UnitList</span> <span class=\"p\">(</span><span class=\"nb\">()</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) where</span>\n  <span class=\"n\">unitList</span> <span class=\"ow\">=</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">unitList</span></code></pre><p>Testing in GHCi, we can see it behaves as desired:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">unitList</span> <span class=\"ow\">::</span> <span class=\"kt\">HList</span> <span class=\"kt\">&#39;[(), (), ()]</span>\n<span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span></code></pre><p>Now suppose we write a function that accepts a list containing exactly one element and returns it:\n</p><pre><code class=\"pygments\"><span class=\"nf\">unsingleton</span> <span class=\"ow\">::</span> <span class=\"kt\">HList</span> <span class=\"kt\">&#39;[a]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">unsingleton</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"kt\">HNil</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>Naturally, we would expect these to compose without a hitch. If we write <code>unsingleton unitList</code>, our TMP should generate a list of length 1, and we should get back <code>()</code>. However, it may surprise you to learn that <em>isn’t</em>, in fact, what happens:<sup><a id=\"footnote-ref-6-1\" href=\"#footnote-6\">6</a></sup>\n</p><pre><code>ghci&gt; unsingleton unitList\n\nerror:\n    • Ambiguous type variable ‘a0’ arising from a use of ‘unitList’\n      prevents the constraint ‘(UnitList '[a0])’ from being solved.\n      Probable fix: use a type annotation to specify what ‘a0’ should be.\n      These potential instances exist:\n        instance UnitList as =&gt; UnitList (() : as)\n</code></pre><p>What went wrong? The type error says that <code>a0</code> is ambiguous, but it only lists a single matching <code>UnitList</code> instance—the one we want—so how can it be ambiguous which one to select?\n</p><p>The problem stems from the way we defined <code>UnitList</code>. When we wrote the instance\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">UnitList</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">UnitList</span> <span class=\"p\">(</span><span class=\"nb\">()</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) where</span></code></pre><p>we said the first element of the type-level list must be <code>()</code>, so there’s nothing stopping someone from coming along and defining another instance:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">UnitList</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">UnitList</span> <span class=\"p\">(</span><span class=\"kt\">Int</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) where</span>\n  <span class=\"n\">unitList</span> <span class=\"ow\">=</span> <span class=\"mi\">0</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">unitList</span></code></pre><p>In that case, GHC would have no way to know which instance to pick. Nothing in the type of <code>unsingleton</code> forces the element in the list to have type <code>()</code>, so both instances are equally valid. To hedge against this future possibility, GHC rejects the program as ambiguous from the start.\n</p><p>Of course, this isn’t what we want. The <code>UnitList</code> class is supposed to <em>always</em> return a list of <code>()</code> values, so how can we force GHC to pick our instance anyway? The answer is to play a trick:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">~</span> <span class=\"nb\">()</span><span class=\"p\">,</span> <span class=\"kt\">UnitList</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">UnitList</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) where</span>\n  <span class=\"n\">unitList</span> <span class=\"ow\">=</span> <span class=\"nb\">()</span> <span class=\"p\">`</span><span class=\"kt\">HCons</span><span class=\"p\">`</span> <span class=\"n\">unitList</span></code></pre><p>Here we’ve changed the instance so that it has the shape <code>UnitList (a ': as)</code>, with a type variable in place of the <code>()</code>, but we also added an equality constraint that forces <code>a</code> to be <code>()</code>. Intuitively, you might think these two instances are completely identical, but in fact they are not! As proof, our example now typechecks:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">unsingleton</span> <span class=\"n\">unitList</span>\n<span class=\"nb\">()</span></code></pre><p>To understand why, it’s important to understand how GHC’s typeclass resolution algorithm works. Let’s start by establishing some terminology. Note that every instance declaration has the following shape:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"o\">&lt;</span><span class=\"n\">constraints</span><span class=\"o\">&gt;</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">C</span> <span class=\"o\">&lt;</span><span class=\"n\">types</span><span class=\"o\">&gt;</span></code></pre><p>The part to the left of the <code>=&gt;</code> is known as the <em>instance context</em>, while the part to the right is known as the <em>instance head</em>. Now for the important bit: when GHC attempts to pick which typeclass instance to use to solve a typeclass constraint, <strong>only the instance head matters, and the instance context is completely ignored</strong>. Once GHC picks an instance, it commits to its choice, and only then does it consider the instance context.\n</p><p>This explains why our two <code>UnitList</code> instances behave differently:\n</p><ul><li><p>Given the instance head <code>UnitList (() ': as)</code>, GHC won’t select the instance unless it knows the first element of the list is <code>()</code>.\n</p></li><li><p>But given the instance head <code>UnitList (a ': as)</code>, GHC will pick the instance regardless of the type of the first element. All that matters is that the list is at least one element long.\n</p></li></ul><p>After the <code>UnitList (a ': as)</code> instance is selected, GHC attempts to solve the constraints in the instance context, including the <code>a ~ ()</code> constraint. This <em>forces</em> <code>a</code> to be <code>()</code>, resolving the ambiguity and allowing type inference to proceed.\n</p><p>This distinction might seem excessively subtle, but in practice it is enormously useful. It means you, the programmer, have direct control over the type inference process:\n</p><ul><li><p>If you put a type in the instance head, you’re asking GHC to figure out how to make the types match up by some other means. Sometimes that’s very useful, since perhaps you want that type to inform which instance to pick.\n</p></li><li><p>But if you put an equality constraint in the instance context, the roles are reversed: you’re saying to the compiler “you don’t tell me, I’ll tell <em>you</em> what type this is,” effectively giving you a role in type inference itself.\n</p></li></ul><p>From this perspective, typeclass instances with equality constraints make GHC’s type inference algorithm extensible. You get to pick which decisions are made and when, and crucially, you can use knowledge of your own program structure to expose more information to the typechecker.\n</p><p>Given all of the above, consider again the definition of <code>IsEven</code> from earlier:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">IsEven</span> <span class=\"n\">as</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">::</span> <span class=\"kt\">Even</span> <span class=\"n\">as</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsEven</span> <span class=\"kt\">&#39;[]</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenNil</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsEven</span> <span class=\"n\">as</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">IsEven</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: b</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenCons</span> <span class=\"n\">evenProof</span></code></pre><p>Though it didn’t cause any problems in the examples we tried, this definition isn’t optimized for type inference. If GHC needed to solve an <code>IsEven (a ': b0)</code> constraint, where <code>b0</code> is an ambiguous type variable, it would get stuck, since it doesn’t know that someone won’t come along and define an <code>IsEven '[a]</code> instance in the future.\n</p><p>To fix this, we can apply the same trick we used for <code>UnitList</code>, just in a slightly different way:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"n\">as</span> <span class=\"o\">~</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"sc\">&#39;</span><span class=\"err\">: bs), IsEven bs) =&gt; IsEven (a</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">as</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">evenProof</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenCons</span> <span class=\"n\">evenProof</span></code></pre><p>Again, the idea is to move the type information we <em>learn</em> from picking this instance into the instance context, allowing it to guide type inference rather than making type inference figure it out from some other source. Consistently applying this transformation can <strong>dramatically</strong> improve type inference in programs that make heavy use of TMP.\n</p><h3><a name=\"example-3-subtyping-constraints\"></a>Example 3: Subtyping constraints</h3><p>At last, we have reached the final example of this blog post. For this one, I have the pleasure of providing a real-world example from a production Haskell codebase: while I was working at <a href=\"https://hasura.io/\">Hasura</a>, I had the opportunity to design an internal parser combinator library that captures aspects of the <a href=\"https://graphql.org/\">GraphQL</a> type system. One such aspect of that type system is a form of subtyping; GraphQL essentially has two “kinds” of types—input types and output types—but some types can be used as both.\n</p><p>Haskell has no built-in support for subtyping, so most Haskell programs do their best to get away with parametric polymorphism instead. However, in our case, we actually need to distinguish (at runtime) types in the “both” category from those that are exclusively input or exclusively output types. Consequently, our <code>GQLKind</code> datatype has three cases:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">GQLKind</span>\n  <span class=\"ow\">=</span> <span class=\"kt\">Both</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Input</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Output</span></code></pre><p>We use <code>DataKind</code>-promoted versions of this <code>GQLKind</code> type as a parameter to a <code>GQLType</code> GADT:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">GQLType</span> <span class=\"n\">k</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">TScalar</span>      <span class=\"ow\">::</span> <span class=\"kt\">GQLType</span> <span class=\"kt\">&#39;Both</span>\n  <span class=\"kt\">TInputObject</span> <span class=\"ow\">::</span> <span class=\"kt\">InputObjectInfo</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">GQLType</span> <span class=\"kt\">&#39;Input</span>\n  <span class=\"kt\">TIObject</span>     <span class=\"ow\">::</span> <span class=\"kt\">ObjectInfo</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">GQLType</span> <span class=\"kt\">&#39;Output</span>\n  <span class=\"c1\">-- ...and so on...</span></code></pre><p>This allows us to write functions that only accept input types or only accept output types, which is a wonderful property to be able to guarantee at compile-time! But there’s a problem: if we write a function that only accepts values of type <code>GQLType 'Input</code>, we can’t pass a <code>GQLType 'Both</code>, even though we really ought to be able to.\n</p><p>To fix this, we can use a little dependently typed programming. First, we’ll define a type to represent proof terms that witness a subkinding relationship:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">SubKind</span> <span class=\"n\">k1</span> <span class=\"n\">k2</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">KRefl</span> <span class=\"ow\">::</span> <span class=\"kt\">SubKind</span> <span class=\"n\">k</span> <span class=\"n\">k</span>\n  <span class=\"kt\">KBoth</span> <span class=\"ow\">::</span> <span class=\"kt\">SubKind</span> <span class=\"kt\">&#39;Both</span> <span class=\"n\">k</span></code></pre><p>The first case, <code>KRefl</code>, states that every kind is trivially a subkind of itself. The second case, <code>KBoth</code>, states that <code>Both</code> is a subkind of any kind at all. (This is a particularly literal example of <a href=\"/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/\">using a type to define axioms</a>.) The next step is to use TMP to implement proof inference:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">IsSubKind</span> <span class=\"n\">k1</span> <span class=\"n\">k2</span> <span class=\"kr\">where</span>\n  <span class=\"n\">subKindProof</span> <span class=\"ow\">::</span> <span class=\"kt\">SubKind</span> <span class=\"n\">k1</span> <span class=\"n\">k2</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">IsSubKind</span> <span class=\"kt\">&#39;Both</span> <span class=\"n\">k</span> <span class=\"kr\">where</span>\n  <span class=\"n\">subKindProof</span> <span class=\"ow\">=</span> <span class=\"kt\">KBoth</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"n\">k</span> <span class=\"o\">~</span> <span class=\"kt\">&#39;Input</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">IsSubKind</span> <span class=\"kt\">&#39;Input</span> <span class=\"n\">k</span> <span class=\"kr\">where</span>\n  <span class=\"n\">subKindProof</span> <span class=\"ow\">=</span> <span class=\"kt\">KRefl</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"n\">k</span> <span class=\"o\">~</span> <span class=\"kt\">&#39;Output</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">IsSubKind</span> <span class=\"kt\">&#39;Output</span> <span class=\"n\">k</span> <span class=\"kr\">where</span>\n  <span class=\"n\">subKindProof</span> <span class=\"ow\">=</span> <span class=\"kt\">KRefl</span></code></pre><p>These instances use the type equality trick described in the previous section to guide type inference, ensuring that if we ever need to prove that <code>k</code> is a superkind of <code>'Input</code> or <code>'Output</code>, type inference will force them to be equal.\n</p><p>Using <code>IsSubKind</code>, we can easily resolve the problem described above. Rather than write a function with a type like this:\n</p><pre><code class=\"pygments\"><span class=\"nf\">nullable</span> <span class=\"ow\">::</span> <span class=\"kt\">GQLParser</span> <span class=\"kt\">&#39;Input</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">GQLParser</span> <span class=\"kt\">&#39;Input</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>…we simply use an <code>IsSubKind</code> constraint, instead:\n</p><pre><code class=\"pygments\"><span class=\"nf\">nullable</span> <span class=\"ow\">::</span> <span class=\"kt\">IsSubKind</span> <span class=\"n\">k</span> <span class=\"kt\">&#39;Input</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GQLParser</span> <span class=\"n\">k</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">GQLParser</span> <span class=\"n\">k</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>Now both <code>'Input</code> and <code>'Both</code> kinds are accepted. In my experience, this caused no trouble at all for callers of these functions; everything worked completely automatically. <em>Consuming</em> the <code>SubKind</code> proofs was slightly more involved, but only ever so slightly. For example, we have a type family that looks like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">ParserInput</span> <span class=\"n\">k</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">ParserInput</span> <span class=\"kt\">&#39;Both</span>   <span class=\"ow\">=</span> <span class=\"kt\">InputValue</span>\n  <span class=\"kt\">ParserInput</span> <span class=\"kt\">&#39;Input</span>  <span class=\"ow\">=</span> <span class=\"kt\">InputValue</span>\n  <span class=\"kt\">ParserInput</span> <span class=\"kt\">&#39;Output</span> <span class=\"ow\">=</span> <span class=\"kt\">SelectionSet</span></code></pre><p>This type family is used to determine what a <code>GQLParser k a</code> actually consumes as input, based on the kind of the GraphQL type it corresponds to. In some functions, we need to prove to GHC that <code>IsSubKind k 'Input</code> implies <code>ParserInput k ~ InputValue</code>.\n</p><p>Fortunately, that is very easy to do using <a href=\"https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-Type-Equality.html\">the <code>(:~:)</code> type from <code>Data.Type.Equality</code> in <code>base</code></a> to capture a term-level witness of a type equality. It’s an ordinary Haskell GADT that happens to have an infix type constructor, and this is its definition:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"n\">a</span> <span class=\"kt\">:~:</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">Refl</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"kt\">:~:</span> <span class=\"n\">a</span></code></pre><p>Just as with any other GADT, <code>(:~:)</code> can be used to pack up type equalities and unpack them later; <code>a :~: b</code> just happens to be the GADT that corresponds precisely to the equality <code>a ~ b</code>. Using <code>(:~:)</code>, we can write a reusable proof that <code>IsSubKind k 'Input</code> implies <code>ParserInput k ~ InputValue</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">inputParserInput</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">k</span><span class=\"o\">.</span> <span class=\"kt\">IsSubKind</span> <span class=\"n\">k</span> <span class=\"kt\">&#39;Input</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ParserInput</span> <span class=\"n\">k</span> <span class=\"kt\">:~:</span> <span class=\"kt\">InputValue</span>\n<span class=\"nf\">inputParserInput</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">subKindProof</span> <span class=\"o\">@</span><span class=\"n\">k</span> <span class=\"o\">@</span><span class=\"kt\">&#39;Input</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">KRefl</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Refl</span>\n  <span class=\"kt\">KBoth</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Refl</span></code></pre><p>This function is a very simple proof by cases, where <code>Refl</code> can be read as “Q.E.D.”:\n</p><ul><li><p>In the first case, matching on <code>KRefl</code> refines <code>k</code> to <code>'Input</code>, and <code>ParserInput 'Input</code> is <code>InputValue</code> by definition of <code>ParserInput</code>.\n</p></li><li><p>Likewise, in the second case, matching on <code>KBoth</code> refines <code>k</code> to <code>'Both</code>, and <code>ParserInput 'Both</code> is also <code>InputValue</code> by definition of <code>ParserInput</code>.\n</p></li></ul><p>This <code>inputParserInput</code> helper allows functions like <code>nullable</code>, which internally need <code>ParserInput k ~ InputValue</code>, to take the form\n</p><pre><code class=\"pygments\"><span class=\"nf\">nullable</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">k</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">IsSubKind</span> <span class=\"n\">k</span> <span class=\"kt\">&#39;Input</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">GQLParser</span> <span class=\"n\">k</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">GQLParser</span> <span class=\"n\">k</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"nf\">nullable</span> <span class=\"n\">parser</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">inputParserInput</span> <span class=\"o\">@</span><span class=\"n\">k</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">Refl</span> <span class=\"ow\">-&gt;</span> <span class=\"cm\">{- ...implementation goes here... -}</span></code></pre><p>Overall, this burden is quite minimal, so the additional type safety is more than worth the effort. The same could not be said without <code>IsSubKind</code> doing work to infer the proofs at each use site, so in this case, TMP has certainly paid its weight!\n</p><h2><a name=\"wrapping-up-and-closing-thoughts\"></a>Wrapping up and closing thoughts</h2><p>So concludes my introduction to Haskell TMP. As seems to happen all too often with my blog posts, this one has grown rather long, so allow me to provide a summary of the most important points:\n</p><ul><li><p>Typeclass metaprogramming is a powerful technique for performing type-directed code generation, making it a form of “value inference” that infers values from types.\n</p></li><li><p>Unlike most other metaprogramming mechanisms, TMP has a wonderful synergy with type inference, which allows it to take advantage of information the programmer may not have even written explicitly.\n</p></li><li><p>Though I’ve called the technique “<em>typeclass</em> metaprogramming,” TMP really leverages the entirety of the modern GHC type system. Type families, GADTs, promoted types, and more all have their place in usefully applying type-level programming.\n</p></li><li><p>Finally, since TMP relies so heavily on type inference to do its job, it’s crucial to be thoughtful about how you design type-level code to give the typechecker as many opportunities to succeed as you possibly can.\n</p></li></ul><p>The individual applications of TMP covered in this blog post—type-level computation, generic programming, and dependent typing—are all useful in their own right, and this post does not linger on any of them long enough to do any of them justice. That is, perhaps, the cost one pays when trying to discuss such an abstract, general technique. However, I hope that readers can see the forest for the trees and understand how TMP can be a set of techniques in their own right, applicable to the topics described above and more.\n</p><p>Readers may note that this blog post targets a slightly different audience than my other recent writing has been. That is a conscious choice: there is an unfortunate dearth of resources to help intermediate Haskell programmers become advanced Haskell programmers, in part because it’s hard to write them. The lack of resources makes tackling topics like this rather difficult, as too often it feels as though an entire web of concepts must be explained all at once, with no obvious incremental path that provides sufficient motivation every step of the way.\n</p><p>It remains to be seen whether my stab at the problem will be successful. But on the chance that it is, I suspect some readers will be curious about where to go next. Here are some ideas:\n</p><ul><li><p>As mentioned earlier in this blog post, <a href=\"https://hackage.haskell.org/package/base-4.14.1.0/docs/GHC-Generics.html\">the <code>GHC.Generics</code> module documentation</a> is a great resource if you want to explore generic programming further, and generic programming is a great way to put TMP to practical use.\n</p></li><li><p>I have long believed that <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/\">the GHC User’s Guide</a> is a criminally under-read and underappreciated piece of documentation. It is a treasure trove of knowledge, and I highly recommend reading through the sections on type-related language extensions if you want to get a better grasp of the mechanics of the Haskell type system.\n</p></li><li><p>Finally, if dependently typed programming in Haskell intrigues you, and you don’t mind staring into the sun, the <a href=\"https://hackage.haskell.org/package/singletons\">singletons</a> library provides abstractions and design patterns that can considerably cut down on the boilerplate. (Also, <a href=\"https://cs.brynmawr.edu/~rae/papers/2012/singletons/paper.pdf\">the accompanying paper</a> is definitely worth a read if you’d like to go down that route.)\n</p></li></ul><p>Even if you don’t decide to pursue type-level programming in Haskell, I hope this blog post helps make some of the concepts involved less mystical and intimidating. I, for one, think this stuff is worth the effort involved in understanding. After all, you never know when it might come in handy.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Not to be confused with C++’s <a href=\"https://en.wikipedia.org/wiki/Template_metaprogramming\"><em>template</em> metaprogramming</a>, though there are significant similarities between the two techniques.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>There have been proposals to introduce ordered instances, known in the literature as <a href=\"https://homepage.cs.uiowa.edu/~jgmorrs/pubs/morris-icfp2010-instances.pdf\"><em>instance chains</em></a>, but as of this writing, GHC does not implement them.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>Note that this also preserves an important property of the Haskell type system, parametricity. A function like <code>id :: a -&gt; a</code> shouldn’t be allowed to do different things depending on which type is chosen for <code>a</code>, which our first version of <code>guardUnit</code> tried to violate. Typeclasses, being functions on types, can naturally do different things given different types, so a typeclass constraint is precisely what gives us the power to violate parametricity.\n <a href=\"#footnote-ref-3-1\">↩</a></p></li><li id=\"footnote-4\"><p>Short for <em>generalized algebraic datatypes</em>, which is a rather unhelpful name for actually understanding what they are or what they’re for.\n <a href=\"#footnote-ref-4-1\">↩</a></p></li><li id=\"footnote-5\"><p>If GHC allowed lightweight existential quantification, we could make that term-level evidence available with a sufficiently clever definition for <code>IsEvenTF</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">family</span> <span class=\"kt\">IsEvenTF</span> <span class=\"n\">as</span> <span class=\"ow\">::</span> <span class=\"kt\">Constraint</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">IsEvenTF</span> <span class=\"kt\">&#39;[]</span>       <span class=\"ow\">=</span> <span class=\"nb\">()</span>\n  <span class=\"kt\">IsEvenTF</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"sc\">&#39;</span><span class=\"err\">: as) = exists b a</span><span class=\"sc\">s&#39;</span><span class=\"o\">.</span> <span class=\"p\">(</span><span class=\"n\">as</span> <span class=\"o\">~</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"sc\">&#39;</span><span class=\"err\">: a</span><span class=\"sc\">s&#39;</span><span class=\"p\">),</span> <span class=\"kt\">IsEvenTF</span> <span class=\"n\">as&#39;</span><span class=\"p\">)</span></code></pre><p>The type refinement provided by matching on <code>HCons</code> would be enough for the second case of <code>IsEvenTF</code> to be selected, which would provide an equality proof that <code>as</code> has at least two elements. Sadly, GHC does not support anything of this sort, and it’s unclear if it would be tractable to implement at all.\n <a href=\"#footnote-ref-5-1\">↩</a></p></li><li id=\"footnote-6\"><p>Actually, I’ve cheated a little bit here, because <code>unsingleton unitList</code> really does typecheck in GHCi under normal circumstances. That’s because <a href=\"https://downloads.haskell.org/ghc/9.0.1/docs/html/users_guide/ghci.html#extension-ExtendedDefaultRules\">the <code>ExtendedDefaultRules</code> extension</a> is enabled in GHCi by default, which defaults ambiguous type variables to <code>()</code>, which happens to be exactly what’s needed to make this contrived example typecheck. However, that doesn’t say anything very useful, since the same expression really would fail to typecheck inside a Haskell module, so I’ve turned <code>ExtendedDefaultRules</code> off to illustrate the problem.\n <a href=\"#footnote-ref-6-1\">↩</a></p></li></ol></article>","contentSnippet":"Typeclass metaprogramming is a powerful technique available to Haskell programmers to automatically generate term-level code from static type information. It has been used to great effect in several popular Haskell libraries (such as the servant ecosystem), and it is the core mechanism used to implement generic programming via GHC generics. Despite this, remarkably little material exists that explains the technique, relegating it to folk knowledge known only to advanced Haskell programmers.\n\nThis blog post attempts to remedy that by providing an overview of the foundational concepts behind typeclass metaprogramming. It does not attempt to be a complete guide to type-level programming in Haskell—such a task could easily fill a book—but it does provide explanations and illustrations of the most essential components. This is also not a blog post for Haskell beginners—familiarity with the essentials of the Haskell type system and several common GHC extensions is assumed—but it does not assume any prior knowledge of type-level programming.\n\nPart 1: Basic building blocks\nTypeclass metaprogramming is a big subject, which makes covering it in a blog post tricky. To break it into more manageable chunks, this post is divided into several parts, each of which introduces new type system features or type-level programming techniques, then presents an example of how they can be applied.\n\nTo start, we’ll cover the absolute foundations of typeclass metaprogramming.\n\nTypeclasses as functions from types to terms\nAs its name implies, typeclass metaprogramming (henceforth TMP1) centers around Haskell’s typeclass construct. Traditionally, typeclasses are viewed as a mechanism for principled operator overloading; for example, they underpin Haskell’s polymorphic == operator via the Eq class. Though that is often the most useful way to think about typeclasses, TMP encourages a different perspective: typeclasses are functions from types to (runtime) terms.\n\nWhat does that mean? Let’s illustrate with an example. Suppose we define a typeclass called TypeOf:\n\nclass TypeOf a where\n  typeOf :: a -> String\nThe idea is that this typeclass will accept some value and return the name of its type as a string. To illustrate, here are a couple potential instances:\n\ninstance TypeOf Bool where\n  typeOf _ = \"Bool\"\n\ninstance TypeOf Char where\n  typeOf _ = \"Char\"\n\ninstance (TypeOf a, TypeOf b) => TypeOf (a, b) where\n  typeOf (a, b) = \"(\" ++ typeOf a ++ \", \" ++ typeOf b ++ \")\"\nGiven these instances, we can observe that they do what we expect in GHCi:\n\nghci> typeOf (True, 'a')\n\"(Bool, Char)\"\nNote that both the TypeOf Bool and TypeOf Char instances ignore the argument to typeOf altogether. This makes sense, as the whole point of the TypeOf class is to get access to type information, which is the same regardless of which value is provided. To make this more explicit, we can take advantage of some GHC extensions to eliminate the value-level argument altogether:\n\n{-# LANGUAGE AllowAmbiguousTypes, ScopedTypeVariables, TypeApplications #-}\n\nclass TypeOf a where\n  typeOf :: String\nThis typeclass definition is a little unusual, as the type parameter a doesn’t appear anywhere in the body. To understand what it means, recall that the type of each method of a typeclass is implicitly extended with the typeclass’s constraint. For example, in the definition\n\nclass Show a where\n  show :: a -> String\nthe full type of the show method is implicitly extended with a Show a constraint to yield:\n\nshow :: Show a => a -> String\nFurthermore, if we write foralls explicitly, each typeclass method is also implicitly quantified over the class’s type parameters, which makes the following the full type of show:\n\nshow :: forall a. Show a => a -> String\nIn the same vein, we can write out the full type of typeOf, as given by our new definition of TypeOf:\n\ntypeOf :: forall a. TypeOf a => String\nThis type is still unusual, as the a type parameter doesn’t appear anywhere to the right of the => arrow. This makes the type parameter trivially ambiguous, which is to say it’s impossible for GHC to infer what a should be at any call site. Fortunately, we can use TypeApplications to pass a type for a directly, as we can see in the updated definition of TypeOf (a, b):\n\ninstance TypeOf Bool where\n  typeOf = \"Bool\"\n\ninstance TypeOf Char where\n  typeOf = \"Char\"\n\ninstance (TypeOf a, TypeOf b) => TypeOf (a, b) where\n  typeOf = \"(\" ++ typeOf @a ++ \", \" ++ typeOf @b ++ \")\"\nOnce again, we can test out our new definitions in GHCi:\n\nghci> typeOf @Bool\n\"Bool\"\nghci> typeOf @(Bool, Char)\n\"(Bool, Char)\"\nThis illustrates very succinctly how typeclasses can be seen as functions from types to terms. Our typeOf function is, quite literally, a function that accepts a single type as an argument and returns a term-level String. Of course, the TypeOf typeclass is not a particularly useful example of such a function, but it demonstrates how easy it is to construct.\n\nType-level interpreters\nOne important consequence of eliminating the value-level argument of typeOf is that there is no need for its argument type to actually be inhabited. For example, consider the TypeOf instance on Void from Data.Void:\n\ninstance TypeOf Void where\n  typeOf = \"Void\"\nThis above instance is no different from the ones on Bool and Char even though Void is a completely uninhabited type. This is an important point: as we delve into type-level programming, it’s important to keep in mind that the language of types is mostly blind to the term-level meaning of those types. Although we usually write typeclasses that operate on values, this is not at all essential. This turns out to be quite important in practice, even in something as simple as the definition of TypeOf on lists:\n\ninstance TypeOf a => TypeOf [a] where\n  typeOf = \"[\" ++ typeOf @a ++ \"]\"\nIf typeOf required a value-level argument, not just a type, our instance above would be in a pickle when given the empty list, since it would have no value of type a to recursively apply typeOf to. But since typeOf only accepts a type-level argument, the term-level meaning of the list type poses no obstacle.\n\nA perhaps unintuitive consequence of this property is that we can use typeclasses to write interesting functions on types even if none of the types are inhabited at all. For example, consider the following pair of type definitions:\n\ndata Z\ndata S a\nIt is impossible to construct any values of these types, but we can nevertheless use them to construct natural numbers at the type level:\n\n\nZ is a type that represents 0.\n\n\nS Z is a type that represents 1.\n\n\nS (S Z) is a type that represents 2.\n\n\nAnd so on. These types might not seem very useful, since they aren’t inhabited by any values, but remarkably, we can still use a typeclass to distinguish them and convert them to term-level values:\n\nimport Numeric.Natural\n\nclass ReifyNat a where\n  reifyNat :: Natural\n\ninstance ReifyNat Z where\n  reifyNat = 0\n\ninstance ReifyNat a => ReifyNat (S a) where\n  reifyNat = 1 + reifyNat @a\nAs its name implies, reifyNat reifies a type-level natural number encoded using our datatypes above into a term-level Natural value:\n\nghci> reifyNat @Z\n0\nghci> reifyNat @(S Z)\n1\nghci> reifyNat @(S (S Z))\n2\nOne way to think about reifyNat is as an interpreter of a type-level language. In this case, the type-level language is very simple, only capturing natural numbers, but in general, it could be arbitrarily complex—and typeclasses can be used to give it a useful meaning, even if it has no term-level representation.\n\nOverlapping instances\nGenerally, typeclass instances aren’t supposed to overlap. That is, if you write an instance for Show (Maybe a), you aren’t supposed to also write an instance for Show (Maybe Bool), since it isn’t clear whether show (Just True) should use the first instance or the second. For that reason, by default, GHC rejects any form of instance overlap as soon as it detects it.\n\nUsually, this is the right behavior. Due to the way Haskell’s typeclass system is designed to preserve coherency—that is, the same combination of type arguments always selects the same instance—overlapping instances can be unintuitive or even cause nonsensical behavior if orphan instances are defined. However, when doing TMP, it’s useful to make exceptions to that rule of thumb, so GHC provides the option to explicitly opt-in to overlapping instances.\n\nAs a simple example, suppose we wanted to write a typeclass that checks whether a given type is () or not:\n\nclass IsUnit a where\n  isUnit :: Bool\nIf we were to write an ordinary, value-level function, we could write something like this pseudo-Haskell:\n\n-- not actually valid Haskell, just an example\nisUnit :: * -> Bool\nisUnit () = True\nisUnit _  = False\nBut if we try to translate this to typeclass instances, we’ll get a problem:\n\ninstance IsUnit () where\n  isUnit = True\n\ninstance IsUnit a where\n  isUnit = False\nThe problem is that a function definition has a closed set of clauses matched from top to bottom, but typeclass instances are open and unordered.2 This means GHC will complain about instance overlap if we try to evaluate isUnit @():\n\nghci> isUnit @()\n\nerror:\n    • Overlapping instances for IsUnit ()\n        arising from a use of ‘isUnit’\n      Matching instances:\n        instance IsUnit a\n        instance IsUnit ()\n\nTo fix this, we have to explicitly mark IsUnit () as overlapping:\n\ninstance {-# OVERLAPPING #-} IsUnit () where\n  isUnit = True\nNow GHC accepts the expression without complaint:\n\nghci> isUnit @()\nTrue\nWhat does the {-# OVERLAPPING #-} pragma do, exactly? The gory details are spelled out in the GHC User’s Guide, but the simple explanation is that {-# OVERLAPPING #-} relaxes the overlap checker as long as the instance is strictly more specific than the instance(s) it overlaps with. In this case, that is true: IsUnit () is trivially more specific than IsUnit a, since the former only matches () while the latter matches anything at all. That means our overlap is well-formed, and instance resolution should behave the way we’d like.\n\nOverlapping instances are a useful tool when performing TMP, as they make it possible to write piecewise functions on types in the same way it’s possible to write piecewise functions on terms. However, they must still be used with care, as without understanding how they work, they can produce unintuitive results. For an example of how things can go wrong, consider the following definition:\n\nguardUnit :: forall a. a -> Either String a\nguardUnit x = case isUnit @a of\n  True  -> Left \"unit is not allowed\"\n  False -> Right x\nThe intent of guardUnit is to use isUnit to detect if its argument is of type (), and if it is, to return an error. However, even though we marked IsUnit () overlapping, we still get an overlapping instance error:\n\nerror:\n    • Overlapping instances for IsUnit a arising from a use of ‘isUnit’\n      Matching instances:\n        instance IsUnit a\n        instance [overlapping] IsUnit ()\n    • In the expression: isUnit @a\n\nWhat gives? The problem is that GHC simply doesn’t know what type a is when compiling guardUnit. It could be instantiated to () where it’s called, but it might not be. Therefore, GHC doesn’t know which instance to pick, and an overlapping instance error is still reported.\n\nThis behavior is actually a very, very good thing. If GHC were to blindly pick the IsUnit a instance in this case, then guardUnit would always take the False branch, even when passed a value of type ()! That would certainly not be what was intended, so it’s better to reject this program than to silently do the wrong thing. However, in more complicated situations, it can be quite surprising that GHC is complaining about instance overlap even when {-# OVERLAPPING #-} annotations are used, so it’s important to keep their limitations in mind.\n\nAs it happens, in this particular case, the error is easily remedied. We simply have to add an IsUnit constraint to the type signature of guardUnit:\n\nguardUnit :: forall a. IsUnit a => a -> Either String a\nguardUnit x = case isUnit @a of\n  True  -> Left \"unit is not allowed\"\n  False -> Right x\nNow picking the right IsUnit instance is deferred to the place where guardUnit is used, and the definition is accepted.3\n\nType families are functions from types to types\nIn the previous section, we discussed how typeclasses are functions from types to terms, but what about functions from types to types? For example, suppose we wanted to sum two type-level natural numbers and get a new type-level natural number as a result? For that, we can use a type family:\n\n{-# LANGUAGE TypeFamilies #-}\n\ntype family Sum a b where\n  Sum Z     b = b\n  Sum (S a) b = S (Sum a b)\nThe above is a closed type family, which works quite a lot like an ordinary Haskell function definition, just at the type level instead of at the value level. For comparison, the equivalent value-level definition of Sum would look like this:\n\ndata Nat = Z | S Nat\n\nsum :: Nat -> Nat -> Nat\nsum Z     b = b\nsum (S a) b = S (sum a b)\nAs you can see, the two are quite similar. Both are defined via a pair of pattern-matching clauses, and though it doesn’t matter here, both closed type families and ordinary functions evaluate their clauses top to bottom.\n\nTo test our definition of Sum in GHCi, we can use the :kind! command, which prints out a type and its kind after reducing it as much as possible:\n\nghci> :kind! Sum (S Z) (S (S Z))\nSum (S Z) (S (S Z)) :: *\n= S (S (S Z))\nWe can also combine Sum with our ReifyNat class from earlier:\n\nghci> reifyNat @(Sum (S Z) (S (S Z)))\n3\nType families are a useful complement to typeclasses when performing type-level programming. They allow computation to occur entirely at the type-level, which is necessarily computation that occurs entirely at compile-time, and the result can then be passed to a typeclass method to produce a term-level value from the result.\n\nExample 1: Generalized concat\nFinally, using what we’ve discussed so far, we can do our first bit of practical TMP. Specifically, we’re going to define a flatten function similar to like-named functions provided by many dynamically-typed languages. In those languages, flatten is like concat, but it works on a list of arbitrary depth. For example, we might use it like this:\n\n> flatten [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n[1, 2, 3, 4, 5, 6, 7, 8]\nIn Haskell, lists of different depths have different types, so multiple levels of concat have to be applied explicitly. But using TMP, we can write a generic flatten function that operates on lists of any depth!\n\nSince this is typeclass metaprogramming, we’ll unsurprisingly begin with a typeclass:\n\nclass Flatten a where\n  flatten :: a -> [???]\nOur first challenge is writing the return type of flatten. Since the argument could be a list of any depth, there’s no direct way to obtain its element type. Fortunately, we can define a type family that does precisely that:\n\ntype family ElementOf a where\n  ElementOf [[a]] = ElementOf [a]\n  ElementOf [a]   = a\n\nclass Flatten a where\n  flatten :: a -> [ElementOf a]\nNow we can write our Flatten instances. The base case is when the type is a list of depth 1, in which case we don’t have any flattening to do:\n\ninstance Flatten [a] where\n  flatten x = x\nThe inductive case is when the type is a nested list, in which case we want to apply concat and recur:\n\ninstance {-# OVERLAPPING #-} Flatten [a] => Flatten [[a]] where\n  flatten x = flatten (concat x)\nSadly, if we try to compile these definitions, GHC will reject our Flatten [a] instance:\n\nerror:\n    • Couldn't match type ‘a’ with ‘ElementOf [a]’\n      ‘a’ is a rigid type variable bound by\n        the instance declaration\n      Expected type: [ElementOf [a]]\n        Actual type: [a]\n    • In the expression: x\n      In an equation for ‘flatten’: flatten x = x\n      In the instance declaration for ‘Flatten [a]’\n   |\n   |   flatten x = x\n   |               ^\n\nAt first blush, this error looks very confusing. Why doesn’t GHC think a and ElementOf [a] are the same type? Well, consider what would happen if we picked a type like [Int] for a. Then [a] would be [[Int]], a nested list, so the first case of ElementOf would apply. Therefore, GHC refuses to pick the second equation of ElementOf so hastily.\n\nIn this particular case, we might think that’s rather silly. After all, if a were [Int], then GHC wouldn’t have picked the Flatten [a] instance to begin with, it would pick the more specific Flatten [[a]] instance defined below. Therefore, the hypothetical situation above could never happen. Unfortunately, GHC does not realize this, so we find ourselves at an impasse.\n\nFortunately, we can soothe GHC’s anxiety by adding an extra constraint to our Flatten [a] instance:\n\ninstance (ElementOf [a] ~ a) => Flatten [a] where\n  flatten x = x\nThis is a type equality constraint. Type equality constraints are written with the syntax a ~ b, and they state that a must be the same type as b. Type equality constraints are mostly useful when type families are involved, since they can be used (as in this case) to require a type family reduce to a certain type. In this case, we’re asserting that ElementOf [a] must always be a, which allows the instance to typecheck.\n\nNote that this doesn’t let us completely wriggle out of our obligation, as the type equality constraint must eventually be checked when the instance is actually used, so initially this might seem like we’ve only deferred the problem to later. But in this case, that’s exactly what we need: by the time the Flatten [a] instance is selected, GHC will know that a is not a list type, and it will be able to reduce ElementOf [a] to a without difficulty. Indeed, we can see this for ourselves by using flatten in GHCi:\n\nghci> flatten [[[1 :: Integer, 2], [3, 4]], [[5, 6], [7, 8]]]\n[1,2,3,4,5,6,7,8]\nIt works! But why do we need the type annotation on 1? If we leave it out, we get a rather hairy type error:\n\nerror:\n    • Couldn't match type ‘ElementOf [a0]’ with ‘ElementOf [a]’\n      Expected type: [ElementOf [a]]\n        Actual type: [ElementOf [a0]]\n      NB: ‘ElementOf’ is a non-injective type family\n      The type variable ‘a0’ is ambiguous\n\nThe issue here stems from the polymorphic nature of Haskell number literals. Theoretically, someone could define a Num [a] instance, in which case 1 could actually have a list type, and either case of ElementOf could match depending on the choice of Num instance. Of course, no such Num instance exists, nor should it, but the possibility of it being defined means GHC can’t be certain of the depth of the argument list.\n\nThis issue happens to come up a lot in simple examples of TMP, since polymorphic number literals introduce a level of ambiguity. In real programs, this is much less of an issue, since there’s no reason to call flatten on a completely hardcoded list! However, it’s still important to understand what these type errors mean and why they occur.\n\nThat wrinkle aside, flatten is a functioning example of what useful TMP can look like. We’ve written a single, generic definition that flattens lists of any depth, taking advantage of static type information to choose what to do at runtime.\n\nTypeclasses as compile-time code generation\nPresented with the above definition of Flatten, it might not be immediately obvious how to think about Flatten as a function from types to terms. After all, it looks a lot more like an “ordinary” typeclass (like, say, Eq or Show) than the TypeOf and ReifyNat classes we defined above.\n\nOne useful way to shift our perspective is to consider equivalent Flatten instances written using point-free style:\n\ninstance (ElementOf [a] ~ a) => Flatten [a] where\n  flatten = id\n\ninstance {-# OVERLAPPING #-} Flatten [a] => Flatten [[a]] where\n  flatten = flatten . concat\nThese definitions of flatten no longer (syntactically) depend on term-level arguments, just like our definitions of typeOf and reifyNat didn’t accept any term-level arguments above. This allows us to consider what flatten might “expand to” given a type argument alone:\n\n\nflatten @[Int] is just id, since the Flatten [a] instance is selected.\n\n\nflatten @[[Int]] is flatten @[Int] . concat, since the Flatten [[a]] instance is selected. That then becomes id . concat, which can be further simplified to just concat.\n\n\nflatten @[[[Int]]] is flatten @[[Int]] . concat, which simplifies to concat . concat by the same reasoning above.\n\n\nflatten @[[[[Int]]]] is then concat . concat . concat, and so on.\n\n\nThis meshes quite naturally with our intuition of typeclasses as functions from types to terms. Each application of flatten takes a type as an argument and produces some number of composed concats as a result. From this perspective, Flatten is performing a kind of compile-time code generation, synthesizing an expression to do the concatenation on the fly by inspecting the type information.\n\nThis framing is one of the key ideas that makes TMP so powerful, and indeed, it explains how it’s worthy of the name metaprogramming. As we continue to more sophisticated examples of TMP, try to keep this perspective in mind.\n\nPart 2: Generic programming\nPart 1 of this blog post established the foundational techniques used in TMP, all of which are useful on their own. If you’ve read up to this point, you now know enough to start applying TMP yourself, and the remainder of this blog post will simply continue to build upon what you already know.\n\nIn the previous section, we discussed how to use TMP to write a generic flatten operation. In this section, we’ll aim a bit higher: totally generic functions that operate on arbitrary datatypes.\n\nOpen type families and associated types\nBefore we can dive into examples, we need to revisit type families. In the previous sections, we discussed closed type families, but we did not cover their counterpart, open type families. Like closed type families, open type families are effectively functions from types to types, but unlike closed type families, they are not defined with a predefined set of equations. Instead, new equations are added separately using type instance declarations. For example, we could define our Sum family from above like this:\n\ntype family Sum a b\ntype instance Sum Z b = b\ntype instance Sum (S a) b = S (Sum a b)\nIn the case of Sum, this would not be very useful, and indeed, Sum is much better expressed as a closed type family than an open one. But the advantage of open type families is similar to the advantage of typeclasses: new equations can be added at any time, even in modules other than the one that declares the open type family.\n\nThis extensibility means open type families are used less for type-level computation and more for type-level maps that associate types with other types. For example, one might define a Key open type family that relates types to the types used to index them:\n\ntype family Key a\ntype instance Key (Vector a) = Int\ntype instance Key (Map k v) = k\ntype instance Key (Trie a) = ByteString\nThis can be combined with a typeclass to provide a generic way to see if a data structure contains a given key:\n\nclass HasKey a where\n  hasKey :: Key a -> a -> Bool\n\ninstance HasKey (Vector a) where\n  hasKey i vec = i >= 0 && i < Data.Vector.length vec\n\ninstance HasKey (Map k v) where\n  hasKey = Data.Map.member\n\ninstance HasKey (Trie a) where\n  hasKey = Data.Trie.member\nIn this case, anyone could define their own data structure, define instances of Key and HasKey for their data structure, and use hasKey to see if it contains a given key, regardless of the structure of those keys. In fact, it’s so common for open type families and typeclasses to cooperate in this way that GHC provides the option to make the connection explicit by defining them together:\n\nclass HasKey a where\n  type Key a\n  hasKey :: Key a -> a -> Bool\n\ninstance HasKey (Vector a) where\n  type Key (Vector a) = Int\n  hasKey i vec = i >= 0 && i < Data.Vector.length vec\n\ninstance HasKey (Map k v) where\n  type Key (Map k v) = k\n  hasKey = Data.Map.member\n\ninstance HasKey (Trie a) where\n  type Key (Trie a) = ByteString\n  hasKey = Data.Trie.member\nAn open family declared inside a typeclass like this is called an associated type. It works exactly the same way as the separate definitions of Key and HasKey, it just uses a different syntax. Note that although the family and instance keywords have disappeared from the declarations, that is only an abbreviation; the keywords are simply implicitly added (and explicitly writing them is still allowed, though most people do not).\n\nOpen type families and associated types are extremely useful for abstracting over similar types with slightly different structure, and libraries like mono-traversable are examples of how they can be used to that end for their full effect. However, those use cases can’t really be classified as TMP, just using typeclasses for their traditional purpose of operation overloading.\n\nHowever, that doesn’t mean open type families aren’t useful for TMP. In fact, one use case of TMP makes heavy use of open type families: datatype-generic programming.\n\nExample 2: Datatype-generic programming\nDatatype-generic programming refers to a class of techniques for writing generic functions that operate on arbitrary data structures. Some useful applications of datatype-generic programming include\n\n\nequality, comparison, and hashing,\n\n\nrecursive traversal of self-similar data structures, and\n\n\nserialization and deserialization,\n\n\namong other things. The idea is that by exploiting the structure of datatype definitions themselves, it’s possible for a datatype-generic function to provide implementations of functionality like the above on any datatype.\n\nIn Haskell, the most popular approach to datatype-generic programming leverages GHC generics, which is quite sophisticated. The module documentation for GHC.Generics already includes a fairly lengthy explanation of how it works, so I will not regurgitate it here (that could fill a blog post of its own!), but I will show how to construct a simplified version of the system that highlights the key role of TMP.\n\nGeneric datatype representations\nAt the heart of the Generic class is a simple concept: all non-GADT Haskell datatypes can be represented as sums of products. For example, if we have\n\ndata Authentication\n  = AuthBasic Username Password\n  | AuthSSH PublicKey\nthen we have a type that is essentially equivalent to this one:\n\ntype Authentication = Either (Username, Password) PublicKey\nIf we know how to define a function on a nested tree built out of Eithers and pairs, then we know how to define it on any such datatype! This is where TMP comes in: recall the way we viewed Flatten as a mechanism for compile-time code generation based on type information. Could we use the same technique to generate implementations of equality, comparison, hashing, etc. from statically-known information about the structure of a datatype?\n\nThe answer to that question is yes. To start, let’s consider a particularly simple example: suppose we want to write a generic function that counts the number of fields stored in an arbitrary constructor. For example, numFields (AuthBasic \"alyssa\" \"pass1234\") would return 2, while numFields (AuthSSH \"<key>\") would return 1. Not a very useful function, admittedly, but it’s a simple example of what generic programming can do.\n\nWe’ll start by using TMP to implement a “generic” version of numFields that operates on trees of Eithers and pairs as described above:\n\nclass GNumFields a where\n  gnumFields :: a -> Natural\n\n-- base case: leaf value\ninstance GNumFields a where\n  gnumFields _ = 1\n\ninstance {-# OVERLAPPING #-} (GNumFields a, GNumFields b) => GNumFields (a, b) where\n  gnumFields (a, b) = gnumFields a + gnumFields b\n\ninstance {-# OVERLAPPING #-} (GNumFields a, GNumFields b) => GNumFields (Either a b) where\n  gnumFields (Left a)  = gnumFields a\n  gnumFields (Right b) = gnumFields b\nJust like our Flatten class from earlier, GNumFields uses the type-level structure of its argument to choose what to do:\n\n\nIf we find a pair, that corresponds to a product, so we recur into both sides and sum the results.\n\n\nIf we find Left or Right, that corresponds to the “spine” differentiating different constructors, so we simply recur into the contained value.\n\n\nIn the case of any other value, we’re at a “leaf” in the tree of Eithers and pairs, which corresponds to a single field, so we just return 1.\n\n\nNow if we call gnumFields (Left (\"alyssa\", \"pass1234\")), we’ll get 2, and if we call gnumFields (Right \"<key>\"), we’ll get 1. All that’s left to do is write a bit of code that converts our Authentication type to a tree of Eithers and pairs:\n\ngenericizeAuthentication :: Authentication -> Either (Username, Password) PublicKey\ngenericizeAuthentication (AuthBasic user pass) = Left (user, pass)\ngenericizeAuthentication (AuthSSH key)         = Right key\n\nnumFieldsAuthentication :: Authentication -> Natural\nnumFieldsAuthentication = gnumFields . genericizeAuthentication\nNow we get the results we want on our Authentication type using numFieldsAuthentication, but we’re not done yet, since it only works on Authentication values. Is there a way to define a generic numFields function that works on arbitrary datatypes that implement this conversion to sums-of-products? Yes, with another typeclass:\n\nclass Generic a where\n  type Rep a\n  genericize :: a -> Rep a\n\ninstance Generic Authentication where\n  type Rep Authentication = Either (Username, Password) PublicKey\n  genericize (AuthBasic user pass) = Left (user, pass)\n  genericize (AuthSSH key)         = Right key\n\nnumFields :: (Generic a, GNumFields (Rep a)) => a -> Natural\nnumFields = gnumFields . genericize\nNow numFields (AuthBasic \"alyssa\" \"pass1234\") returns 2, as desired, and it will also work with any datatype that provides a Generic instance. If the above code makes your head spin, don’t worry: this is by far the most complicated piece of code in this blog post up to this point. Let’s break down how it works piece by piece:\n\n\nFirst, we define the Generic class, comprised of two parts:\n\n\nThe Rep a associated type maps a type a onto its generic, sums-of-products representation, i.e. one built out of combinations of Either and pairs.\n\n\nThe genericize method converts an actual value of type a to the equivalent value using the sums-of-products representation.\n\n\n\nNext, we define a Generic instance for Authentication. Rep Authentication is the sums-of-products representation we described above, and genericize is likewise genericizeAuthentication from above.\n\n\nFinally, we define numFields as a function with a GNumFields (Rep a) constraint. This is where all the magic happens:\n\n\nWhen we apply numFields to a datatype, Rep retrieves its generic, sums-of-products representation type.\n\n\nThe GNumFields class then uses various TMP techniques we’ve already described so far in this blog post to generate a numFields implementation on the fly from the structure of Rep a.\n\n\nFinally, that generated numFields implementation is applied to the genericized term-level value, and the result is produced.\n\n\n\nAfter all that, I suspect you might think this seems like a very convoluted way to define the (rather unhelpful) numFields operation. Surely just defining numFields on each type directly would be far easier? Indeed, if we were just considering numFields, you’d be right, but in fact we get much more than that. Using the same machinery, we can continue to define other generic operations—equality, comparison, etc.—the same way we defined numFields, and all of them would automatically work on Authentication because they all leverage the same Generic instance!\n\nThis is the basic value proposition of generic programming: we can do a little work up front to normalize our datatype to a generic representation once, then get a whole buffet of generic operations on it for free. In Haskell, the code generation capabilities of TMP is a key piece of that puzzle.\n\nImproving our definition of Generic\nYou may note that the definition of Generic provided above does not match the one in GHC.Generic. Indeed, our naïve approach suffers from several flaws that the real version does not. This is not a GHC.Generics tutorial, so I will not discuss every detail of the full implementation, but I will highlight a few improvements relevant to the broader theme of TMP.\n\nDistinguishing leaves from the spine\nOne problem with our version of Generic is that it provides no way to distinguish an Either or pair that should be considered a “leaf”, as in a type like this:\n\ndata Foo = A (Either Int String) | B (Char, Bool)\nGiven this type, Rep Foo should be Either (Either Int String) (Char, Bool), and numFields (Right ('a', True)) will erroneously return 2 rather than 1. To fix this, we can introduce a simple wrapper newtype that distinguishes leaves specifically:\n\nnewtype Leaf a = Leaf { getLeaf :: a }\nNow our Generic instances look like this:\n\ninstance Generic Authentication where\n  type Rep Authentication = Either (Leaf Username, Leaf Password) (Leaf PublicKey)\n  genericize (AuthBasic user pass) = Left (Leaf user, Leaf pass)\n  genericize (AuthSSH key)         = Right (Leaf key)\n\ninstance Generic Foo where\n  type Rep Foo = Either (Leaf (Either Int String)) (Leaf (Char, Bool))\n  genericize (A x) = Left (Leaf x)\n  genericize (B x) = Right (Leaf x)\nSince the Leaf constructor now distinguishes a leaf, rather than the absence of an Either or (,) constructor, we’ll have to update our GNumFields instances as well. However, this has the additional pleasant effect of eliminating the need for overlapping instances:\n\ninstance GNumFields (Leaf a) where  \n  gnumFields _ = 1\n\ninstance (GNumFields a, GNumFields b) => GNumFields (a, b) where\n  gnumFields (a, b) = gnumFields a + gnumFields b\n\ninstance (GNumFields a, GNumFields b) => GNumFields (Either a b) where\n  gnumFields (Left a)  = gnumFields a\n  gnumFields (Right b) = gnumFields b\nThis is a good example of why overlapping instances can be so seductive, but they often have unintended consequences. Even when doing TMP, explicit tags are almost always preferable.\n\nHandling empty constructors\nSuppose we have a type with nullary data constructors, like the standard Bool type:\n\ndata Bool = False | True\nHow do we write a Generic instance for Bool? Using just Either, (,), and Leaf, we can’t, but if we are willing to add a case for (), we can use it to denote nullary constructors:\n\ninstance GNumFields () where\n  gnumFields _ = 0\n\ninstance Generic Bool where\n  type Rep Bool = Either () ()\n  genericize False = Left ()\n  genericize True  = Right ()\nIn a similar vein, we could use Void to represent datatypes that don’t have any constructors at all.\n\nContinuing from here\nThe full version of Generic has a variety of further improvements useful for generic programming, including:\n\n\nSupport for converting from Rep a to a.\n\n\nSpecial indication of self-recursive datatypes, making generic tree traversals possible.\n\n\nType-level information about datatype constructor and record accessor names, allowing them to be used in serialization.\n\n\nFully automatic generation of Generic instances via the DeriveGeneric extension, which reduces the per-type boilerplate to essentially nothing.\n\n\nThe module documentation for GHC.Generics discusses the full system in detail, and it provides an additional example that uses the same essential TMP techniques discussed here.\n\nPart 3: Dependent typing\nIt’s time for the third and final part of this blog post: an introduction to dependently typed programming in Haskell. A full treatment of dependently typed programming is far, far too vast to be contained in a single blog post, so I will not attempt to do so here. Rather, I will cover some basic idioms for doing dependent programming and highlight how TMP can be valuable when doing so.\n\nDatatype promotion\nIn part 1, we used uninhabited datatypes like Z and S a to define new type-level constants. This works, but it is awkward. Imagine for a moment that we wanted to work with type-level booleans. Using our previous approach, we could define two empty datatypes, True and False:\n\ndata True\ndata False\nNow we could define type families to provide operations on these types, such as Not:\n\ntype family Not a where\n  Not True  = False\n  Not False = True\nHowever, this has some frustrating downsides:\n\n\nFirst, it’s simply inconvenient that we have to define these new True and False “dummy” types, which are completely distinct from the Bool type provided by the prelude.\n\n\nMore significantly, it means Not has a very unhelpful kind:\n\nghci> :kind Not\nNot :: * -> *\nEven though Not is only supposed to be applied to True or False, its kind allows it to be applied to any type at all. You can see this in practice if you try to evaluate something like Not Char:\n\nghci> :kind! Not Char\nNot Char :: *\n= Not Char\nRather than getting an error, GHC simply spits Not Char back at us. This is a somewhat unintuitive property of closed type families: if none of the clauses match, the type family just gets “stuck,” not reducing any further. This can lead to very confusing type errors later in the typechecking process.\n\n\nOne way to think about Not is that it is largely dynamically kinded in the same way some languages are dynamically typed. That isn’t entirely true, as we technically will get a kind error if we try to apply Not to a type constructor rather than a type, such as Maybe:\n\nghci> :kind! Not Maybe\n\n<interactive>:1:5: error:\n    • Expecting one more argument to ‘Maybe’\n      Expected a type, but ‘Maybe’ has kind ‘* -> *’\n\n…but * is still a very big kind, much bigger than we would like to permit for Not.\n\nTo help with both these problems, GHC provides datatype promotion via the DataKinds language extension. The idea is that for each normal, non-GADT type definition like\n\ndata Bool = False | True\nthen in addition to the normal type constructor and value constructors, GHC also defines several promoted constructors:\n\n\nBool is allowed as both a type and a kind.\n\n\n'True and 'False are defined as new types of kind Bool.\n\n\nWe can see this in action if we remove our data True and data False declarations and adjust our definition of Not to use promoted constructors:\n\n{-# LANGUAGE DataKinds #-}\n\ntype family Not a where\n  Not 'True  = 'False\n  Not 'False = 'True\nNow the inferred kind of Not is no longer * -> *:\n\nghci> :kind Not\nNot :: Bool -> Bool\nConsequently, we will now get a kind error if we attempt to apply Not to anything other than 'True or 'False:\n\nghci> :kind! Not Char\n\n<interactive>:1:5: error:\n    • Expected kind ‘Bool’, but ‘Char’ has kind ‘*’\n\nThis is a nice improvement. We can make a similar change to our definitions involving type-level natural numbers:\n\ndata Nat = Z | S Nat\n\nclass ReifyNat (a :: Nat) where\n  reifyNat :: Natural\n\ninstance ReifyNat 'Z where\n  reifyNat = 0\n\ninstance ReifyNat a => ReifyNat ('S a) where\n  reifyNat = 1 + reifyNat @a\nNote that we need to add an explicit kind signature on the definition of the ReifyNat typeclass, since otherwise GHC will assume a has kind *, since nothing in the types of the typeclass methods suggests otherwise. In addition to making it clearer that Z and S are related, this prevents someone from coming along and defining a nonsensical instance like ReifyNat Char, which previously would have been allowed but will now be rejected with a kind error.\n\nDatatype promotion is not strictly required to do TMP, but makes the process significantly less painful. It makes Haskell’s kind language extensible in the same way its type language is, which allows type-level programming to enjoy static typechecking (or more accurately, static kindchecking) in the same way term-level programming does.\n\nGADTs and proof terms\nSo far in this blog post, we have discussed several different function-like things:\n\n\nOrdinary Haskell functions are functions from terms to terms.\n\n\nType families are functions from types to types.\n\n\nTypeclasses are functions from types to terms.\n\n\nA curious reader may wonder about the existence of a fourth class of function:\n\n\n??? are functions from terms to types.\n\n\nTo reason about what could go in the ??? above, we must consider what “a function from terms to types” would even mean. Functions from terms to terms and types to types are straightforward enough. Functions from types to terms are a little trickier, but they make intuitive sense: we use information known at compile-time to generate runtime behavior. But how could information possibly flow in the other direction? How could we possibly turn runtime information into compile-time information without being able to predict the future?\n\nIn general, we cannot. However, one feature of Haskell allows a restricted form of seemingly doing the impossible—turning runtime information into compile-time information—and that’s GADTs.\n\nGADTs4 are described in detail in the GHC User’s Guide, but the key idea for our purposes is that pattern-matching on a GADT constructor can refine type information. Here’s a simple, silly example:\n\ndata WhatIsIt a where\n  ABool :: WhatIsIt Bool\n  AnInt :: WhatIsIt Int\n\ndoSomething :: WhatIsIt a -> a -> a\ndoSomething ABool x = not x\ndoSomething AnInt x = x + 1\nHere, WhatIsIt is a datatype with two nullary constructors, ABool and AnInt, similar to a normal, non-GADT datatype like this one:\n\ndata WhatIsIt a = ABool | AnInt\nWhat’s special about GADTs is that each constructor is given an explicit type signature. With the plain ADT definition above, ABool and AnInt would both have the type forall a. WhatIsIt a, but in the GADT definition, we explicitly fix a to Bool in the type of ABool and to Int in the type of AnInt.\n\nThis simple feature allows us to do very interesting things. The doSomething function is polymorphic in a, but on the right-hand side of the first equation, x has type Bool, while on the right-hand side of the second equation, x has type Int. This is because the WhatIsIt a argument effectively constrains the type of a, as we can see by experimenting with doSomething in GHCi:\n\nghci> doSomething ABool True\nFalse\nghci> doSomething AnInt 10\n11\nghci> doSomething AnInt True\n\nerror:\n    • Couldn't match expected type ‘Int’ with actual type ‘Bool’\n    • In the second argument of ‘doSomething’, namely ‘True’\n      In the expression: doSomething AnInt True\n      In an equation for ‘it’: it = doSomething AnInt True\n\nOne way to think about GADTs is as “proofs” or “witnesses” of type equalities. The ABool constructor is a proof of a ~ Bool, while the AnInt constructor is a proof of a ~ Int. When you construct ABool or AnInt, you must be able to satisfy the equality, and it is in a sense “packed into” the constructor value. When code pattern-matches on the constructor, the equality is “unpacked from” the value, and the equality becomes available on the right-hand side of the pattern match.\n\nGADTs can be much more sophisticated than our simple WhatIsIt type above. Just like normal ADTs, GADT constructors can have parameters, which makes it possible to write inductive datatypes that carry type equality proofs with them:\n\ninfixr 5 `HCons`\n\ndata HList as where\n  HNil  :: HList '[]\n  HCons :: a -> HList as -> HList (a ': as)\nThis type is a heterogenous list, a list that can contain elements of different types:\n\nghci> :t True `HCons` \"hello\" `HCons` 42 `HCons` HNil\nTrue `HCons` \"hello\" `HCons` 42 `HCons` HNil\n  :: Num a => HList '[Bool, [Char], a]\nAn HList is parameterized by a type-level list that keeps track of the types of its elements, which allows us to highlight another interesting property of GADTs: if we restrict that type information, the GHC pattern exhaustiveness checker will take the restriction into account. For example, we can write a completely total head function on HLists like this:\n\nhead :: HList (a ': as) -> a\nhead (x `HCons` _) = x\nRemarkably, GHC does not complain that this definition of head is non-exhaustive. Since we specified that the argument must be of type HList (a ': as) in the type signature for head, GHC knows that the argument cannot be HNil (which would have the type HList '[]), so it doesn’t ask us to handle that case.\n\nThese examples illustrate the way GADTs serve as a general-purpose construct for relating type- and term-level information. Information flows bidirectionally: type information refines the set of type constructors that can be matched on, and matching on type constructors exposes new type equalities.\n\nProofs that work together\nThis interplay is wonderfully compositional. Suppose we wanted to write a function that accepts an HList of exactly 1, 2, or 3 elements. There’s no easy way to express that in the type signature the way we did with head, so it might seem like all we can do is write an entirely new container datatype that has three constructors, one for each case.\n\nHowever, a more interesting solution exists that takes advantage of the bidirectional nature of GADTs. We can start by writing a proof term that contains no values, it just encapsulates type equalities on a type-level list:\n\ndata OneToThree a b c as where\n  One   :: OneToThree a b c '[a]\n  Two   :: OneToThree a b c '[a, b]\n  Three :: OneToThree a b c '[a, b, c]\nWe call it a proof term because a value of type OneToThree a b c as constitutes a proof that as has exactly 1, 2, or 3 elements. Using OneToThree, we can write a function that accepts an HList accompanied by a proof term:\n\nsumUpToThree :: OneToThree Int Int Int as -> HList as -> Int\nsumUpToThree One   (x `HCons` HNil)                     = x\nsumUpToThree Two   (x `HCons` y `HCons` HNil)           = x + y\nsumUpToThree Three (x `HCons` y `HCons` z `HCons` HNil) = x + y + z\nAs with head, this function is completely exhaustive, in this case because we take full advantage of the bidirectional nature of GADTs:\n\n\nWhen we match on the OneToThree proof term, information flows from the term level to the type level, refining the type of as in that branch.\n\n\nThe refined type of as then flows back down to the term level, restricting the shape the HList can take and refinine the set of patterns we have to match.\n\n\nOf course, this example is not especially useful, but in general proof terms can encode any number of useful properties. For example, we can write a proof term that ensures an HList has an even number of elements:\n\ndata Even as where\n  EvenNil  :: Even '[]\n  EvenCons :: Even as -> Even (a ': b ': as)\nThis is a proof which itself has inductive structure: EvenCons takes a proof that as has an even number of elements and produces a proof that adding two more elements preserves the evenness. We can combine this with a type family to write a function that “pairs up” elements in an HList:\n\ntype family PairUp as where\n  PairUp '[]            = '[]\n  PairUp (a ': b ': as) = (a, b) ': PairUp as\n\npairUp :: Even as -> HList as -> HList (PairUp as)\npairUp EvenNil         HNil                     = HNil\npairUp (EvenCons even) (x `HCons` y `HCons` xs) = (x, y) `HCons` pairUp even xs\nOnce again, this definition is completely exhaustive, and we can show that it works in GHCi:\n\nghci> pairUp (EvenCons $ EvenCons EvenNil)\n             (True `HCons` 'a' `HCons` () `HCons` \"foo\" `HCons` HNil)\n(True,'a') `HCons` ((),\"foo\") `HCons` HNil\nThis ability to capture properties of a type using auxiliary proof terms, rather than having to define an entirely new type, is one of the things that makes dependently typed programming so powerful.\n\nProof inference\nWhile our definition of pairUp is interesting, you may be skeptical of its practical utility. It’s fiddly and inconvenient to have to pass the Even proof term explicitly, since it must be updated every time the length of the list changes. Fortunately, this is where TMP comes in.\n\nRemember that typeclasses are functions from types to terms. As its happens, a value of type Even as can be mechanically produced from the structure of the type as. This suggests that we could use TMP to automatically generate Even proofs, and indeed, we can. In fact, it’s not at all complicated:\n\nclass IsEven as where\n  evenProof :: Even as\n\ninstance IsEven '[] where\n  evenProof = EvenNil\n\ninstance IsEven as => IsEven (a ': b ': as) where\n  evenProof = EvenCons evenProof\nWe can now adjust our pairUp function to use IsEven instead of an explicit Even argument:\n\npairUp :: IsEven as => HList as -> HList (PairUp as)\npairUp = go evenProof where\n  go :: Even as -> HList as -> HList (PairUp as)\n  go EvenNil         HNil                     = HNil\n  go (EvenCons even) (x `HCons` y `HCons` xs) = (x, y) `HCons` go even xs\nThis is essentially identical to its old definition, but by acquiring the proof via IsEven rather than passing it explicitly, we can call pairUp without having to construct a proof manually:\n\nghci> pairUp (True `HCons` 'a' `HCons` () `HCons` \"foo\" `HCons` HNil)\n(True,'a') `HCons` ((),\"foo\") `HCons` HNil\nThis is rather remarkable. Using TMP, we are able to get GHC to automatically construct a proof that a list is even, with no programmer guidance beyond writing the IsEven typeclass. This relies once more on the perspective that typeclasses are functions that accept types and generate term-level code: IsEven is a function that accepts a type-level list and generates an Even proof term.\n\nFrom this perspective, typeclasses are a way of specifying a proof search algorithm to the compiler. In the case of IsEven, the proofs being generated are rather simple, so the proof search algorithm is quite mechanical. But in general, typeclasses can be used to perform proof search of significant complexity, given a sufficiently clever encoding into the type system.\n\nAside: GADTs versus type families\nBefore moving on, I want to explicitly call attention to the relationship between GADTs and type families. Though at first glance they may seem markedly different, there are some similarities between the two, and sometimes they may be used to accomplish similar things.\n\nConsider again the type of the pairUp function above (without the typeclass for simplicity):\n\npairUp :: Even as -> HList as -> HList (PairUp as)\nWe used both a GADT, Even, and a type family, PairUp. But we could have, in theory, used only a GADT and eliminated the type family altogether. Consider this variation on the Even proof term:\n\ndata EvenPairs as bs where\n  EvenNil  :: EvenPairs '[] '[]\n  EvenCons :: EvenPairs as bs -> EvenPairs (a ': b ': as) ((a, b) ': bs)\nThis type has two type parameters rather than one, and though there’s no distinction between the two from GHC’s point of view, it can be useful to think of as as an “input” parameter and bs as an “output” parameter. The idea is that any EvenPairs proof relates both an even-length list type and its paired up equivalent:\n\n\nEvenNil has type EvenPairs '[] '[],\n\n\nEvenCons EvenNil has type EvenPairs '[a, b] '[(a, b)],\n\n\nEvenCons (EvenCons EvenNil) has type EvenPairs '[a, b, c, d] '[(a, b), (c, d)],\n\n\n…and so on.\n\n\nThis allows us to reformulate our pairUp type signature this way:\n\npairUp :: EvenPairs as bs -> HList as -> HList bs\nThe definition is otherwise unchanged. The PairUp type family is completely gone, because now EvenPairs itself defines the relation. In this way, GADTs can be used like type-level functions!\n\nThe inverse, however, is not true, at least not directly: we cannot eliminate the GADT altogether and exclusively use type families. One way to attempt doing so would be to define a type family that returns a constraint rather than a type:\n\nimport Data.Kind (Constraint)\n\ntype family IsEvenTF as :: Constraint where\n  IsEvenTF '[]            = ()\n  IsEvenTF (_ ': _ ': as) = IsEvenTF as\nThe idea here is that IsEvenTF as produces a constraint can only be satisfied if as has an even number of elements, since that’s the only way it will eventually reduce to (), which in this case means the empty set of constraints, not the unit type (yes, the syntax for that is confusing). And in fact, it’s true that putting IsEvenTF as => in a type signature successfully restricts as to be an even-length list, but it doesn’t allow us to write pairUp. To see why, we can try the following definition:\n\npairUp :: IsEvenTF as => HList as -> HList (PairUp as)\npairUp HNil                     = HNil\npairUp (x `HCons` y `HCons` xs) = (x, y) `HCons` pairUp xs\nUnlike the version using the GADT, this version of pairUp is not considered exhaustive:\n\nwarning: [-Wincomplete-patterns]\n    Pattern match(es) are non-exhaustive\n    In an equation for ‘pairUp’: Patterns not matched: HCons _ HNil\n\nThis is because type families don’t provide the same bidirectional flow of information that GADTs do, they’re only type-level functions. The constraint generated by IsEvenTF provides no term-level evidence about the shape of as, so we can’t branch on it the way we can branch on the Even GADT.5 (In a sense, IsEvenTF is doing validation, not parsing.)\n\nFor this reason, I caution against overuse of type families. Their simplicity is seductive, but all too often you pay for that simplicity with inflexibility. GADTs combined with TMP for proof inference can provide the best of both worlds: complete control over the term-level proof that gets generated while still letting the compiler do most of the work for you.\n\nGuiding type inference\nSo far, this blog post has given relatively little attention to type inference. That is in some part a testament to the robustness of GHC’s type inference algorithm: even when fairly sophisticated TMP is involved, GHC often manages to propagate enough type information that type annotations are rarely needed.\n\nHowever, when doing TMP, it would be irresponsible to not at least consider the type inference properties of programs. Type inference is what drives the whole typeclass resolution process to begin with, so poor type inference can easily make your fancy TMP construction next to useless. To take advantage of GHC to the fullest extent, programs should proactively guide the typechecker to help it infer as much as possible as often as possible.\n\nTo illustrate what that can look like, suppose we want to use TMP to generate an HList full of () values of an arbitrary length:\n\nclass UnitList as where\n  unitList :: HList as\n\ninstance UnitList '[] where\n  unitList = HNil\n\ninstance UnitList as => UnitList (() ': as) where\n  unitList = () `HCons` unitList\nTesting in GHCi, we can see it behaves as desired:\n\nghci> unitList :: HList '[(), (), ()]\n() `HCons` () `HCons` () `HCons` HNil\nNow suppose we write a function that accepts a list containing exactly one element and returns it:\n\nunsingleton :: HList '[a] -> a\nunsingleton (x `HCons` HNil) = x\nNaturally, we would expect these to compose without a hitch. If we write unsingleton unitList, our TMP should generate a list of length 1, and we should get back (). However, it may surprise you to learn that isn’t, in fact, what happens:6\n\nghci> unsingleton unitList\n\nerror:\n    • Ambiguous type variable ‘a0’ arising from a use of ‘unitList’\n      prevents the constraint ‘(UnitList '[a0])’ from being solved.\n      Probable fix: use a type annotation to specify what ‘a0’ should be.\n      These potential instances exist:\n        instance UnitList as => UnitList (() : as)\n\nWhat went wrong? The type error says that a0 is ambiguous, but it only lists a single matching UnitList instance—the one we want—so how can it be ambiguous which one to select?\n\nThe problem stems from the way we defined UnitList. When we wrote the instance\n\ninstance UnitList as => UnitList (() ': as) where\nwe said the first element of the type-level list must be (), so there’s nothing stopping someone from coming along and defining another instance:\n\ninstance UnitList as => UnitList (Int ': as) where\n  unitList = 0 `HCons` unitList\nIn that case, GHC would have no way to know which instance to pick. Nothing in the type of unsingleton forces the element in the list to have type (), so both instances are equally valid. To hedge against this future possibility, GHC rejects the program as ambiguous from the start.\n\nOf course, this isn’t what we want. The UnitList class is supposed to always return a list of () values, so how can we force GHC to pick our instance anyway? The answer is to play a trick:\n\ninstance (a ~ (), UnitList as) => UnitList (a ': as) where\n  unitList = () `HCons` unitList\nHere we’ve changed the instance so that it has the shape UnitList (a ': as), with a type variable in place of the (), but we also added an equality constraint that forces a to be (). Intuitively, you might think these two instances are completely identical, but in fact they are not! As proof, our example now typechecks:\n\nghci> unsingleton unitList\n()\nTo understand why, it’s important to understand how GHC’s typeclass resolution algorithm works. Let’s start by establishing some terminology. Note that every instance declaration has the following shape:\n\ninstance <constraints> => C <types>\nThe part to the left of the => is known as the instance context, while the part to the right is known as the instance head. Now for the important bit: when GHC attempts to pick which typeclass instance to use to solve a typeclass constraint, only the instance head matters, and the instance context is completely ignored. Once GHC picks an instance, it commits to its choice, and only then does it consider the instance context.\n\nThis explains why our two UnitList instances behave differently:\n\n\nGiven the instance head UnitList (() ': as), GHC won’t select the instance unless it knows the first element of the list is ().\n\n\nBut given the instance head UnitList (a ': as), GHC will pick the instance regardless of the type of the first element. All that matters is that the list is at least one element long.\n\n\nAfter the UnitList (a ': as) instance is selected, GHC attempts to solve the constraints in the instance context, including the a ~ () constraint. This forces a to be (), resolving the ambiguity and allowing type inference to proceed.\n\nThis distinction might seem excessively subtle, but in practice it is enormously useful. It means you, the programmer, have direct control over the type inference process:\n\n\nIf you put a type in the instance head, you’re asking GHC to figure out how to make the types match up by some other means. Sometimes that’s very useful, since perhaps you want that type to inform which instance to pick.\n\n\nBut if you put an equality constraint in the instance context, the roles are reversed: you’re saying to the compiler “you don’t tell me, I’ll tell you what type this is,” effectively giving you a role in type inference itself.\n\n\nFrom this perspective, typeclass instances with equality constraints make GHC’s type inference algorithm extensible. You get to pick which decisions are made and when, and crucially, you can use knowledge of your own program structure to expose more information to the typechecker.\n\nGiven all of the above, consider again the definition of IsEven from earlier:\n\nclass IsEven as where\n  evenProof :: Even as\n\ninstance IsEven '[] where\n  evenProof = EvenNil\n\ninstance IsEven as => IsEven (a ': b ': as) where\n  evenProof = EvenCons evenProof\nThough it didn’t cause any problems in the examples we tried, this definition isn’t optimized for type inference. If GHC needed to solve an IsEven (a ': b0) constraint, where b0 is an ambiguous type variable, it would get stuck, since it doesn’t know that someone won’t come along and define an IsEven '[a] instance in the future.\n\nTo fix this, we can apply the same trick we used for UnitList, just in a slightly different way:\n\ninstance (as ~ (b ': bs), IsEven bs) => IsEven (a ': as) where\n  evenProof = EvenCons evenProof\nAgain, the idea is to move the type information we learn from picking this instance into the instance context, allowing it to guide type inference rather than making type inference figure it out from some other source. Consistently applying this transformation can dramatically improve type inference in programs that make heavy use of TMP.\n\nExample 3: Subtyping constraints\nAt last, we have reached the final example of this blog post. For this one, I have the pleasure of providing a real-world example from a production Haskell codebase: while I was working at Hasura, I had the opportunity to design an internal parser combinator library that captures aspects of the GraphQL type system. One such aspect of that type system is a form of subtyping; GraphQL essentially has two “kinds” of types—input types and output types—but some types can be used as both.\n\nHaskell has no built-in support for subtyping, so most Haskell programs do their best to get away with parametric polymorphism instead. However, in our case, we actually need to distinguish (at runtime) types in the “both” category from those that are exclusively input or exclusively output types. Consequently, our GQLKind datatype has three cases:\n\ndata GQLKind\n  = Both\n  | Input\n  | Output\nWe use DataKind-promoted versions of this GQLKind type as a parameter to a GQLType GADT:\n\ndata GQLType k where\n  TScalar      :: GQLType 'Both\n  TInputObject :: InputObjectInfo -> GQLType 'Input\n  TIObject     :: ObjectInfo -> GQLType 'Output\n  -- ...and so on...\nThis allows us to write functions that only accept input types or only accept output types, which is a wonderful property to be able to guarantee at compile-time! But there’s a problem: if we write a function that only accepts values of type GQLType 'Input, we can’t pass a GQLType 'Both, even though we really ought to be able to.\n\nTo fix this, we can use a little dependently typed programming. First, we’ll define a type to represent proof terms that witness a subkinding relationship:\n\ndata SubKind k1 k2 where\n  KRefl :: SubKind k k\n  KBoth :: SubKind 'Both k\nThe first case, KRefl, states that every kind is trivially a subkind of itself. The second case, KBoth, states that Both is a subkind of any kind at all. (This is a particularly literal example of using a type to define axioms.) The next step is to use TMP to implement proof inference:\n\nclass IsSubKind k1 k2 where\n  subKindProof :: SubKind k1 k2\n\ninstance IsSubKind 'Both k where\n  subKindProof = KBoth\n\ninstance (k ~ 'Input) => IsSubKind 'Input k where\n  subKindProof = KRefl\n\ninstance (k ~ 'Output) => IsSubKind 'Output k where\n  subKindProof = KRefl\nThese instances use the type equality trick described in the previous section to guide type inference, ensuring that if we ever need to prove that k is a superkind of 'Input or 'Output, type inference will force them to be equal.\n\nUsing IsSubKind, we can easily resolve the problem described above. Rather than write a function with a type like this:\n\nnullable :: GQLParser 'Input a -> GQLParser 'Input (Maybe a)\n…we simply use an IsSubKind constraint, instead:\n\nnullable :: IsSubKind k 'Input => GQLParser k a -> GQLParser k (Maybe a)\nNow both 'Input and 'Both kinds are accepted. In my experience, this caused no trouble at all for callers of these functions; everything worked completely automatically. Consuming the SubKind proofs was slightly more involved, but only ever so slightly. For example, we have a type family that looks like this:\n\ntype family ParserInput k where\n  ParserInput 'Both   = InputValue\n  ParserInput 'Input  = InputValue\n  ParserInput 'Output = SelectionSet\nThis type family is used to determine what a GQLParser k a actually consumes as input, based on the kind of the GraphQL type it corresponds to. In some functions, we need to prove to GHC that IsSubKind k 'Input implies ParserInput k ~ InputValue.\n\nFortunately, that is very easy to do using the (:~:) type from Data.Type.Equality in base to capture a term-level witness of a type equality. It’s an ordinary Haskell GADT that happens to have an infix type constructor, and this is its definition:\n\ndata a :~: b where\n  Refl :: a :~: a\nJust as with any other GADT, (:~:) can be used to pack up type equalities and unpack them later; a :~: b just happens to be the GADT that corresponds precisely to the equality a ~ b. Using (:~:), we can write a reusable proof that IsSubKind k 'Input implies ParserInput k ~ InputValue:\n\ninputParserInput :: forall k. IsSubKind k 'Input => ParserInput k :~: InputValue\ninputParserInput = case subKindProof @k @'Input of\n  KRefl -> Refl\n  KBoth -> Refl\nThis function is a very simple proof by cases, where Refl can be read as “Q.E.D.”:\n\n\nIn the first case, matching on KRefl refines k to 'Input, and ParserInput 'Input is InputValue by definition of ParserInput.\n\n\nLikewise, in the second case, matching on KBoth refines k to 'Both, and ParserInput 'Both is also InputValue by definition of ParserInput.\n\n\nThis inputParserInput helper allows functions like nullable, which internally need ParserInput k ~ InputValue, to take the form\n\nnullable :: forall k a. IsSubKind k 'Input => GQLParser k a -> GQLParser k (Maybe a)\nnullable parser = case inputParserInput @k of\n  Refl -> {- ...implementation goes here... -}\nOverall, this burden is quite minimal, so the additional type safety is more than worth the effort. The same could not be said without IsSubKind doing work to infer the proofs at each use site, so in this case, TMP has certainly paid its weight!\n\nWrapping up and closing thoughts\nSo concludes my introduction to Haskell TMP. As seems to happen all too often with my blog posts, this one has grown rather long, so allow me to provide a summary of the most important points:\n\n\nTypeclass metaprogramming is a powerful technique for performing type-directed code generation, making it a form of “value inference” that infers values from types.\n\n\nUnlike most other metaprogramming mechanisms, TMP has a wonderful synergy with type inference, which allows it to take advantage of information the programmer may not have even written explicitly.\n\n\nThough I’ve called the technique “typeclass metaprogramming,” TMP really leverages the entirety of the modern GHC type system. Type families, GADTs, promoted types, and more all have their place in usefully applying type-level programming.\n\n\nFinally, since TMP relies so heavily on type inference to do its job, it’s crucial to be thoughtful about how you design type-level code to give the typechecker as many opportunities to succeed as you possibly can.\n\n\nThe individual applications of TMP covered in this blog post—type-level computation, generic programming, and dependent typing—are all useful in their own right, and this post does not linger on any of them long enough to do any of them justice. That is, perhaps, the cost one pays when trying to discuss such an abstract, general technique. However, I hope that readers can see the forest for the trees and understand how TMP can be a set of techniques in their own right, applicable to the topics described above and more.\n\nReaders may note that this blog post targets a slightly different audience than my other recent writing has been. That is a conscious choice: there is an unfortunate dearth of resources to help intermediate Haskell programmers become advanced Haskell programmers, in part because it’s hard to write them. The lack of resources makes tackling topics like this rather difficult, as too often it feels as though an entire web of concepts must be explained all at once, with no obvious incremental path that provides sufficient motivation every step of the way.\n\nIt remains to be seen whether my stab at the problem will be successful. But on the chance that it is, I suspect some readers will be curious about where to go next. Here are some ideas:\n\n\nAs mentioned earlier in this blog post, the GHC.Generics module documentation is a great resource if you want to explore generic programming further, and generic programming is a great way to put TMP to practical use.\n\n\nI have long believed that the GHC User’s Guide is a criminally under-read and underappreciated piece of documentation. It is a treasure trove of knowledge, and I highly recommend reading through the sections on type-related language extensions if you want to get a better grasp of the mechanics of the Haskell type system.\n\n\nFinally, if dependently typed programming in Haskell intrigues you, and you don’t mind staring into the sun, the singletons library provides abstractions and design patterns that can considerably cut down on the boilerplate. (Also, the accompanying paper is definitely worth a read if you’d like to go down that route.)\n\n\nEven if you don’t decide to pursue type-level programming in Haskell, I hope this blog post helps make some of the concepts involved less mystical and intimidating. I, for one, think this stuff is worth the effort involved in understanding. After all, you never know when it might come in handy.\n\n\nNot to be confused with C++’s template metaprogramming, though there are significant similarities between the two techniques.\n ↩\n\nThere have been proposals to introduce ordered instances, known in the literature as instance chains, but as of this writing, GHC does not implement them.\n ↩\n\nNote that this also preserves an important property of the Haskell type system, parametricity. A function like id :: a -> a shouldn’t be allowed to do different things depending on which type is chosen for a, which our first version of guardUnit tried to violate. Typeclasses, being functions on types, can naturally do different things given different types, so a typeclass constraint is precisely what gives us the power to violate parametricity.\n ↩\n\nShort for generalized algebraic datatypes, which is a rather unhelpful name for actually understanding what they are or what they’re for.\n ↩\n\nIf GHC allowed lightweight existential quantification, we could make that term-level evidence available with a sufficiently clever definition for IsEvenTF:\n\ntype family IsEvenTF as :: Constraint where\n  IsEvenTF '[]       = ()\n  IsEvenTF (a ': as) = exists b as'. (as ~ (b ': as'), IsEvenTF as')\nThe type refinement provided by matching on HCons would be enough for the second case of IsEvenTF to be selected, which would provide an equality proof that as has at least two elements. Sadly, GHC does not support anything of this sort, and it’s unclear if it would be tractable to implement at all.\n ↩\n\nActually, I’ve cheated a little bit here, because unsingleton unitList really does typecheck in GHCi under normal circumstances. That’s because the ExtendedDefaultRules extension is enabled in GHCi by default, which defaults ambiguous type variables to (), which happens to be exactly what’s needed to make this contrived example typecheck. However, that doesn’t say anything very useful, since the same expression really would fail to typecheck inside a Haskell module, so I’ve turned ExtendedDefaultRules off to illustrate the problem.\n ↩","isoDate":"2021-03-25T00:00:00.000Z","timestamp":"3/24/2021"},{"title":"Names are not type safety","pubDate":"2020-11-01T00:00:00.000Z","author":"Alexis King","content":"<article><p>Haskell programmers spend a lot of time talking about <em>type safety</em>. The Haskell school of program construction advocates “capturing invariants in the type system” and “making illegal states unrepresentable,” both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published <a href=\"/blog/2019/11/05/parse-don-t-validate/\">Parse, Don’t Validate</a> as an initial stab towards bridging that gap.\n</p><p>The ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell’s <code>newtype</code> construct. The idea is simple enough—the <code>newtype</code> keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps—and on the surface this <em>sounds</em> like a simple and straightforward path to type safety. For example, one might consider using a <code>newtype</code> declaration to define a type for an email address:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">EmailAddress</span> <span class=\"ow\">=</span> <span class=\"kt\">EmailAddress</span> <span class=\"kt\">Text</span></code></pre><p>This technique can provide <em>some</em> value, and when coupled with a smart constructor and an encapsulation boundary, it can even provide some safety. But it is a meaningfully distinct <em>kind</em> of type safety from the one I highlighted a year ago, one that is far weaker. On its own, a newtype is just a name.\n</p><p>And names are not type safety.\n</p><h2><a name=\"intrinsic-and-extrinsic-safety\"></a>Intrinsic and extrinsic safety</h2><p>To illustrate the difference between constructive data modeling (discussed at length in my <a href=\"/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/\">previous blog post</a>) and newtype wrappers, let’s consider an example. Suppose we want a type for “an integer between 1 and 5, inclusive.” The natural constructive modeling would be an enumeration with five cases:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">OneToFive</span>\n  <span class=\"ow\">=</span> <span class=\"kt\">One</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Two</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Three</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Four</span>\n  <span class=\"o\">|</span> <span class=\"kt\">Five</span></code></pre><p>We could then write some functions to convert between <code>Int</code> and our <code>OneToFive</code> type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">toOneToFive</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"kt\">OneToFive</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"mi\">1</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"kt\">One</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"mi\">2</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"kt\">Two</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"mi\">3</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"kt\">Three</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"mi\">4</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"kt\">Four</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"mi\">5</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"kt\">Five</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"kt\">Nothing</span>\n\n<span class=\"nf\">fromOneToFive</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToFive</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Int</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"kt\">One</span>   <span class=\"ow\">=</span> <span class=\"mi\">1</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"kt\">Two</span>   <span class=\"ow\">=</span> <span class=\"mi\">2</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"kt\">Three</span> <span class=\"ow\">=</span> <span class=\"mi\">3</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"kt\">Four</span>  <span class=\"ow\">=</span> <span class=\"mi\">4</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"kt\">Five</span>  <span class=\"ow\">=</span> <span class=\"mi\">5</span></code></pre><p>This would be perfectly sufficient for achieving our stated goal, but you’d be forgiven for finding it odd: it would be rather awkward to work with in practice. Because we’ve invented an entirely new type, we can’t reuse any of the usual numeric functions Haskell provides. Consequently, many programmers would gravitate towards a newtype wrapper, instead:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">OneToFive</span> <span class=\"ow\">=</span> <span class=\"kt\">OneToFive</span> <span class=\"kt\">Int</span></code></pre><p>Just as before, we can provide <code>toOneToFive</code> and <code>fromOneToFive</code> functions, with identical types:\n</p><pre><code class=\"pygments\"><span class=\"nf\">toOneToFive</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"kt\">OneToFive</span>\n<span class=\"nf\">toOneToFive</span> <span class=\"n\">n</span>\n  <span class=\"o\">|</span> <span class=\"n\">n</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">1</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">n</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">5</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"o\">$</span> <span class=\"kt\">OneToFive</span> <span class=\"n\">n</span>\n  <span class=\"o\">|</span> <span class=\"n\">otherwise</span>        <span class=\"ow\">=</span> <span class=\"kt\">Nothing</span>\n\n<span class=\"nf\">fromOneToFive</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToFive</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Int</span>\n<span class=\"nf\">fromOneToFive</span> <span class=\"p\">(</span><span class=\"kt\">OneToFive</span> <span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">n</span></code></pre><p>If we put these declarations in their own module and choose not to export the <code>OneToFive</code> constructor, these APIs might appear entirely interchangeable. Naïvely, it seems that the newtype version is both simpler and equally type-safe. However—perhaps surprisingly—this is not actually true.\n</p><p>To see why, suppose we write a function that consumes a <code>OneToFive</code> value as an argument. Under the constructive modeling, such a function need only pattern-match against each of the five constructors, and GHC will accept the definition as exhaustive:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ordinal</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToFive</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Text</span>\n<span class=\"nf\">ordinal</span> <span class=\"kt\">One</span>   <span class=\"ow\">=</span> <span class=\"s\">\"first\"</span>\n<span class=\"nf\">ordinal</span> <span class=\"kt\">Two</span>   <span class=\"ow\">=</span> <span class=\"s\">\"second\"</span>\n<span class=\"nf\">ordinal</span> <span class=\"kt\">Three</span> <span class=\"ow\">=</span> <span class=\"s\">\"third\"</span>\n<span class=\"nf\">ordinal</span> <span class=\"kt\">Four</span>  <span class=\"ow\">=</span> <span class=\"s\">\"fourth\"</span>\n<span class=\"nf\">ordinal</span> <span class=\"kt\">Five</span>  <span class=\"ow\">=</span> <span class=\"s\">\"fifth\"</span></code></pre><p>The same is not true given the newtype encoding. The newtype is opaque, so the only way to observe it is to convert it back to an <code>Int</code>—after all, it <em>is</em> an <code>Int</code>. An <code>Int</code> can of course contain many other values besides <code>1</code> through <code>5</code>, so we are forced to add an error case to satisfy the exhaustiveness checker:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ordinal</span> <span class=\"ow\">::</span> <span class=\"kt\">OneToFive</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Text</span>\n<span class=\"nf\">ordinal</span> <span class=\"n\">n</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">fromOneToFive</span> <span class=\"n\">n</span> <span class=\"kr\">of</span>\n  <span class=\"mi\">1</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"first\"</span>\n  <span class=\"mi\">2</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"second\"</span>\n  <span class=\"mi\">3</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"third\"</span>\n  <span class=\"mi\">4</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"fourth\"</span>\n  <span class=\"mi\">5</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"fifth\"</span>\n  <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"ne\">error</span> <span class=\"s\">\"impossible: bad OneToFive value\"</span></code></pre><p>In this highly contrived example, this may not seem like much of a problem to you. But it nonetheless illustrates a key difference in the guarantees afforded by the two approaches:\n</p><ul><li><p>The constructive datatype captures its invariants in such a way that they are <em>accessible</em> to downstream consumers. This frees our <code>ordinal</code> function from worrying about handling illegal values, as they have been made unutterable.\n</p></li><li><p>The newtype wrapper provides a smart constructor that <em>validates</em> the value, but the boolean result of that check is used only for control flow; it is not preserved in the function’s result. Accordingly, downstream consumers cannot take advantage of the restricted domain; they are functionally accepting <code>Int</code>s.\n</p></li></ul><p>Losing exhaustiveness checking might seem like small potatoes, but it absolutely is not: our use of <code>error</code> has punched a hole right through our type system. If we were to add another constructor to our <code>OneToFive</code> datatype,<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup> the version of <code>ordinal</code> that consumes a constructive datatype would be immediately detected non-exhaustive at compile-time, while the version that consumes a newtype wrapper would continue to compile yet fail at runtime, dropping through to the “impossible” case.\n</p><p>All of this is a consequence of the fact that the constructive modeling is <em>intrinsically</em> type-safe; that is, the safety properties are enforced by the type declaration itself. Illegal values truly are unrepresentable: there is simply no way to represent <code>6</code> using any of the five constructors. The same is not true of the newtype declaration, which has no intrinsic semantic distinction from that of an <code>Int</code>; its meaning is specified extrinsically via the <code>toOneToFive</code> smart constructor. Any semantic distinction intended by a newtype is thoroughly invisible to the type system; it exists only in the programmer’s mind.\n</p><h3><a name=\"revisiting-non-empty-lists\"></a>Revisiting non-empty lists</h3><p>Our <code>OneToFive</code> datatype is rather artificial, but identical reasoning applies to other datatypes that are significantly more practical. Consider the <code>NonEmpty</code> datatype I’ve repeatedly highlighted in recent blog posts:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">a</span> <span class=\"kt\">:|</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span></code></pre><p>It may be illustrative to imagine a version of <code>NonEmpty</code> represented as a newtype over ordinary lists. We can use the usual smart constructor strategy to enforce the desired non-emptiness property:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">NonEmpty</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>\n\n<span class=\"nf\">nonEmpty</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"nf\">nonEmpty</span> <span class=\"kt\">[]</span> <span class=\"ow\">=</span> <span class=\"kt\">Nothing</span>\n<span class=\"nf\">nonEmpty</span> <span class=\"n\">xs</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"o\">$</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">xs</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Foldable</span> <span class=\"kt\">NonEmpty</span> <span class=\"kr\">where</span>\n  <span class=\"n\">toList</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"n\">xs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">xs</span></code></pre><p>Just as with <code>OneToFive</code>, we quickly discover the consequences of failing to preserve this information in the type system. Our motivating use case for <code>NonEmpty</code> was the ability to write a safe version of <code>head</code>, but the newtype version requires another assertion:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">head</span> <span class=\"n\">xs</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">toList</span> <span class=\"n\">xs</span> <span class=\"kr\">of</span>\n  <span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">x</span>\n  <span class=\"kt\">[]</span>  <span class=\"ow\">-&gt;</span> <span class=\"ne\">error</span> <span class=\"s\">\"impossible: empty NonEmpty value\"</span></code></pre><p>This might not seem like a big deal, since it seems unlikely such a case would ever happen. But that reasoning hinges entirely on trusting the correctness of the module that defines <code>NonEmpty</code>, while the constructive definition only requires trusting the GHC typechecker. As we generally trust that the typechecker works correctly, the latter is a much more compelling proof.\n</p><h2><a name=\"newtypes-as-tokens\"></a>Newtypes as tokens</h2><p>If you are fond of newtypes, this whole argument may seem a bit troubling. It may seem like I’m implying newtypes are scarcely better than comments, albeit comments that happen to be meaningful to the typechecker. Fortunately, the situation is not quite that grim—newtypes <em>can</em> provide a sort of safety, just a weaker one.\n</p><p>The primary safety benefit of newtypes is derived from abstraction boundaries. If a newtype’s constructor is not exported, it becomes opaque to other modules. The module that defines the newtype—its “home module”—can take advantage of this to create a <em>trust boundary</em> where internal invariants are enforced by restricting clients to a safe API.\n</p><p>We can use the <code>NonEmpty</code> example from above to illustrate how this works. We refrain from exporting the <code>NonEmpty</code> constructor, and we provide <code>head</code> and <code>tail</code> operations that we trust to never actually fail:\n</p><pre><code class=\"pygments\"><span class=\"kr\">module</span> <span class=\"nn\">Data.List.NonEmpty.Newtype</span>\n  <span class=\"p\">(</span> <span class=\"kt\">NonEmpty</span>\n  <span class=\"p\">,</span> <span class=\"nf\">cons</span>\n  <span class=\"p\">,</span> <span class=\"nf\">nonEmpty</span>\n  <span class=\"p\">,</span> <span class=\"nf\">head</span>\n  <span class=\"p\">,</span> <span class=\"nf\">tail</span>\n  <span class=\"p\">)</span> <span class=\"kr\">where</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">NonEmpty</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>\n\n<span class=\"nf\">cons</span> <span class=\"ow\">::</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span>\n<span class=\"nf\">cons</span> <span class=\"n\">x</span> <span class=\"n\">xs</span> <span class=\"ow\">=</span> <span class=\"kt\">NonEmpty</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"n\">xs</span><span class=\"p\">)</span>\n\n<span class=\"nf\">nonEmpty</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"nf\">nonEmpty</span> <span class=\"kt\">[]</span> <span class=\"ow\">=</span> <span class=\"kt\">Nothing</span>\n<span class=\"nf\">nonEmpty</span> <span class=\"n\">xs</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"o\">$</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">xs</span>\n\n<span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"kr\">_</span><span class=\"p\">))</span> <span class=\"ow\">=</span> <span class=\"n\">x</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"kt\">[]</span><span class=\"p\">)</span>    <span class=\"ow\">=</span> <span class=\"ne\">error</span> <span class=\"s\">\"impossible: empty NonEmpty value\"</span>\n\n<span class=\"nf\">tail</span> <span class=\"ow\">::</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>\n<span class=\"nf\">tail</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"p\">(</span><span class=\"kr\">_</span><span class=\"kt\">:</span><span class=\"n\">xs</span><span class=\"p\">))</span> <span class=\"ow\">=</span> <span class=\"n\">xs</span>\n<span class=\"nf\">tail</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"kt\">[]</span><span class=\"p\">)</span>     <span class=\"ow\">=</span> <span class=\"ne\">error</span> <span class=\"s\">\"impossible: empty NonEmpty value\"</span></code></pre><p>Since the only way to construct or consume <code>NonEmpty</code> values is to use the functions in <code>Data.List.NonEmpty.Newtype</code>’s exported API, the above implementation makes it impossible for clients to violate the non-emptiness invariant. In a sense, values of opaque newtypes are like <em>tokens</em>: the implementing module issues tokens via its constructor functions, and those tokens have no intrinsic value. The only way to do anything useful with them is to “redeem” them to the issuing module’s accessor functions, in this case <code>head</code> and <code>tail</code>, to obtain the values contained within.\n</p><p>This approach is significantly weaker than using a constructive datatype, since it is theoretically possible to screw up and accidentally provide a means to construct an invalid <code>NonEmpty []</code> value. For this reason, the newtype approach to type safety does not on its own constitute a <em>proof</em> that a desired invariant holds. However, it restricts the “surface area” where an invariant violation can occur to the defining module, so reasonable confidence the invariant really does hold can be achieved by thoroughly testing the module’s API using fuzzing or property-based testing techniques.<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup>\n</p><p>This tradeoff may not seem all that bad, and indeed, it is often a very good one! Guaranteeing invariants using constructive data modeling can, in general, be quite difficult, which often makes it impractical. However, it is easy to dramatically underestimate the care needed to avoid accidentally providing a mechanism that permits violating the invariant. For example, the programmer may choose to take advantage of GHC’s convenient typeclass deriving to derive a <code>Generic</code> instance for <code>NonEmpty</code>:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE DeriveGeneric #-}</span>\n\n<span class=\"kr\">import</span> <span class=\"nn\">GHC.Generics</span> <span class=\"p\">(</span><span class=\"kt\">Generic</span><span class=\"p\">)</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">NonEmpty</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Generic</span><span class=\"p\">)</span></code></pre><p>However, this innocuous line provides a trivial mechanism to circumvent the abstraction boundary:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"kt\">GHC</span><span class=\"o\">.</span><span class=\"kt\">Generics</span><span class=\"o\">.</span><span class=\"n\">to</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"nb\">()</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">M1</span> <span class=\"o\">$</span> <span class=\"kt\">M1</span> <span class=\"o\">$</span> <span class=\"kt\">M1</span> <span class=\"o\">$</span> <span class=\"kt\">K1</span> <span class=\"kt\">[]</span><span class=\"p\">)</span>\n<span class=\"kt\">NonEmpty</span> <span class=\"kt\">[]</span></code></pre><p>This is a particularly extreme example, since derived <code>Generic</code> instances are fundamentally abstraction-breaking, but this problem can crop up in less obvious ways, too. The same problem occurs with a derived <code>Read</code> instance:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">read</span> <span class=\"o\">@</span><span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"nb\">()</span><span class=\"p\">)</span> <span class=\"s\">\"NonEmpty []\"</span>\n<span class=\"kt\">NonEmpty</span> <span class=\"kt\">[]</span></code></pre><p>To some readers, these pitfalls may seem obvious, but safety holes of this sort are remarkably common in practice. This is especially true for datatypes with more sophisticated invariants, as it may not be easy to determine whether the invariants are actually upheld by the module’s implementation. Proper use of this technique demands caution and care:\n</p><ul><li><p>All invariants must be made clear to maintainers of the trusted module. For simple types, such as <code>NonEmpty</code>, the invariant is self-evident, but for more sophisticated types, comments are not optional.\n</p></li><li><p>Every change to the trusted module must be carefully audited to ensure it does not somehow weaken the desired invariants.\n</p></li><li><p>Discipline is needed to resist the temptation to add unsafe trapdoors that allow compromising the invariants if used incorrectly.\n</p></li><li><p>Periodic refactoring may be needed to ensure the trusted surface area remains small. It is all too easy for the responsibility of the trusted module to accumulate over time, dramatically increasing the likelihood of some subtle interaction causing an invariant violation.\n</p></li></ul><p>In contrast, datatypes that are correct by construction suffer none of these problems. The invariant cannot be violated without changing the datatype definition itself, which has rippling effects throughout the rest of the program to make the consequences immediately clear. Discipline on the part of the programmer is unnecessary, as the typechecker enforces the invariants automatically. There is no “trusted code” for such datatypes, since all parts of the program are equally beholden to the datatype-mandated constraints.\n</p><p>In libraries, the newtype-afforded notion of safety via encapsulation is useful, as libraries often provide the building blocks used to construct more complicated data structures. Such libraries generally receive more scrutiny and care than application code does, especially given they change far less frequently. In application code, these techniques are still useful, but the churn of a production codebase tends to weaken encapsulation boundaries over time, so correctness by construction should be preferred whenever practical.\n</p><h2><a name=\"other-newtype-use-abuse-and-misuse\"></a>Other newtype use, abuse, and misuse</h2><p>The previous section covers the primary means by which newtypes are useful. However, in practice, newtypes are routinely used in ways that do not fit the above pattern. Some such uses are reasonable:\n</p><ul><li><p>Haskell’s notion of typeclass coherency limits each type to a single instance of any given class. For types that permit more than one useful instance, newtypes are the traditional solution, and this can be used to good effect. For example, the <code>Sum</code> and <code>Product</code> newtypes from <code>Data.Monoid</code> provide useful <code>Monoid</code> instances for numeric types.\n</p></li><li><p>In a similar vein, newtypes can be useful for introducing or rearranging type parameters. The <code>Flip</code> newtype from <code>Data.Bifunctor.Flip</code> is a simple example, flipping the arguments of a <code>Bifunctor</code> so the <code>Functor</code> instance may operate on the other side:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Flip</span> <span class=\"n\">p</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kt\">Flip</span> <span class=\"p\">{</span> <span class=\"n\">runFlip</span> <span class=\"ow\">::</span> <span class=\"n\">p</span> <span class=\"n\">b</span> <span class=\"n\">a</span> <span class=\"p\">}</span></code></pre><p>Newtypes are needed to do this sort of juggling, as Haskell does not (yet) support type-level lambdas.\n</p></li><li><p>More simply, transparent newtypes can be useful to discourage misuse when the value needs to be passed between distant parts of the program and the intermediate code has no reason to inspect the value. For example, a <code>ByteString</code> containing a secret key may be wrapped in a newtype (with a <code>Show</code> instance omitted) to discourage code from accidentally logging or otherwise exposing it.\n</p></li></ul><p>All of these applications are good ones, but they have little to do with <em>type safety.</em> The last bullet in particular is often confused for safety, and to be fair, it does in fact take advantage of the type system to help avoid logical mistakes. However, it would be a mischaracterization to claim such usage actually <em>prevents</em> misuse; any part of the program may inspect the value at any time.\n</p><p>Too often, this illusion of safety leads to outright newtype abuse. For example, here’s a definition from the very codebase I work on for a living:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">ArgumentName</span> <span class=\"ow\">=</span> <span class=\"kt\">ArgumentName</span> <span class=\"p\">{</span> <span class=\"n\">unArgumentName</span> <span class=\"ow\">::</span> <span class=\"kt\">GraphQL</span><span class=\"o\">.</span><span class=\"kt\">Name</span> <span class=\"p\">}</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span> <span class=\"kt\">Show</span><span class=\"p\">,</span> <span class=\"kt\">Eq</span><span class=\"p\">,</span> <span class=\"kt\">FromJSON</span><span class=\"p\">,</span> <span class=\"kt\">ToJSON</span><span class=\"p\">,</span> <span class=\"kt\">FromJSONKey</span><span class=\"p\">,</span> <span class=\"kt\">ToJSONKey</span>\n           <span class=\"p\">,</span> <span class=\"kt\">Hashable</span><span class=\"p\">,</span> <span class=\"kt\">ToTxt</span><span class=\"p\">,</span> <span class=\"kt\">Lift</span><span class=\"p\">,</span> <span class=\"kt\">Generic</span><span class=\"p\">,</span> <span class=\"kt\">NFData</span><span class=\"p\">,</span> <span class=\"kt\">Cacheable</span> <span class=\"p\">)</span></code></pre><p>This newtype is useless noise. Functionally, it is completely interchangeable with its underlying <code>Name</code> type, so much so that it derives a dozen typeclasses! In every location it’s used, it’s immediately unwrapped the instant it’s extracted from its enclosing record, so there is no type safety benefit whatsoever. Worse, there isn’t even any clarity added by labeling it an <code>ArgumentName</code>, since the enclosing field name already makes its role clear.\n</p><p>Newtypes like these seem to arise from a desire to use the type system as a taxonomy of the external world. An “argument name” is a more specific concept than a generic “name,” so surely it ought to have its own type. This makes some intuitive sense, but it’s rather misguided: taxonomies are useful for documenting a domain of interest, but not necessarily helpful for modeling it. When programming, we use types for a different end:\n</p><ul><li><p>Primarily, types distinguish <em>functional</em> differences between values. A value of type <code>NonEmpty a</code> is <em>functionally</em> distinct from a value of type <code>[a]</code>, since it is fundamentally structurally different and permits additional operations. In this sense, types are <em>structural</em>; they describe what values <em>are</em> in the internal world of the programming language.\n</p></li><li><p>Secondarily, we sometimes use types to help ourselves avoid making logical mistakes. We might use separate <code>Distance</code> and <code>Duration</code> types to avoid accidentally doing something nonsensical like adding them together, even though they’re both representationally real numbers.\n</p></li></ul><p>Note that both these uses are <em>pragmatic</em>; they look at the type system as a tool. This is a rather natural perspective to take, seeing as a static type system <em>is</em> a tool in a literal sense. Nevertheless, that perspective seems surprisingly unusual, even though the use of types to classify the world routinely yields unhelpful noise like <code>ArgumentName</code>.\n</p><p>If a newtype is completely transparent, and it is routinely wrapped and unwrapped at will, it is likely not very helpful. In this particular case, I would eliminate the distinction altogether and use <code>Name</code>, but in situations where the different label adds genuine clarity, one can always use a type alias:<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">ArgumentName</span> <span class=\"ow\">=</span> <span class=\"kt\">GraphQL</span><span class=\"o\">.</span><span class=\"kt\">Name</span></code></pre><p>Newtypes like these are security blankets. Forcing programmers to jump through a few hoops is not type safety—trust me when I say they will happily jump through them without a second thought.\n</p><h2><a name=\"final-thoughts-and-related-reading\"></a>Final thoughts and related reading</h2><p>I’ve been wanting to write this blog post for a long time. Ostensibly, it’s a very specific critique of Haskell newtypes, and I’ve chosen to frame things this way because I write Haskell for a living and this is the way I encounter this problem in practice. Really, though, the core idea is much bigger than that.\n</p><p>Newtypes are one particular mechanism of defining <em>wrapper types</em>, a concept that exists in almost any language, even those that are dynamically typed. Even if you don’t write Haskell, much of the reasoning in this blog post is likely still relevant in your language of choice. More broadly, this is a continuation of a theme I’ve been trying to convey from different angles over the past year: type systems are tools, and we should be more conscious and intentional about what they actually do and how to use them effectively.\n</p><p>The catalyst that got me to finally sit down and write this was the recently-published <a href=\"https://tech.freckle.com/2020/10/26/tagged-is-not-a-newtype/\">Tagged is not a Newtype</a>. It’s a good blog post, and I wholeheartedly agree with its general thrust, but I thought it was a missed opportunity to make a larger point. Indeed, <code>Tagged</code> <em>is</em> a newtype, definitionally, so the title of the blog post is something of a misdirection. The real problem is a little deeper.\n</p><p>Newtypes are useful when carefully applied, but their safety is not intrinsic, no more than the safety of a traffic cone is somehow contained within the plastic it’s made of. What matters is being placed in the right context—without that, newtypes are just a labeling scheme, a way of giving something a name.\n</p><p>And a name is not type safety.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Admittedly rather unlikely given its name, but bear with me through the contrived example.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>In theory, it is still possible to thoroughly prove the invariant holds using external verification techniques, such as by writing a pen-and-paper proof or by using program extraction in combination with a proof assistant/theorem prover. However, these techniques are extremely uncommon in general programming practice.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>As it happens, I think type aliases are often also more harmful than helpful, so I would caution against overusing them, too, but that is outside the scope of this blog post.\n <a href=\"#footnote-ref-3-1\">↩</a></p></li></ol></article>","contentSnippet":"Haskell programmers spend a lot of time talking about type safety. The Haskell school of program construction advocates “capturing invariants in the type system” and “making illegal states unrepresentable,” both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published Parse, Don’t Validate as an initial stab towards bridging that gap.\n\nThe ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell’s newtype construct. The idea is simple enough—the newtype keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps—and on the surface this sounds like a simple and straightforward path to type safety. For example, one might consider using a newtype declaration to define a type for an email address:\n\nnewtype EmailAddress = EmailAddress Text\nThis technique can provide some value, and when coupled with a smart constructor and an encapsulation boundary, it can even provide some safety. But it is a meaningfully distinct kind of type safety from the one I highlighted a year ago, one that is far weaker. On its own, a newtype is just a name.\n\nAnd names are not type safety.\n\nIntrinsic and extrinsic safety\nTo illustrate the difference between constructive data modeling (discussed at length in my previous blog post) and newtype wrappers, let’s consider an example. Suppose we want a type for “an integer between 1 and 5, inclusive.” The natural constructive modeling would be an enumeration with five cases:\n\ndata OneToFive\n  = One\n  | Two\n  | Three\n  | Four\n  | Five\nWe could then write some functions to convert between Int and our OneToFive type:\n\ntoOneToFive :: Int -> Maybe OneToFive\ntoOneToFive 1 = Just One\ntoOneToFive 2 = Just Two\ntoOneToFive 3 = Just Three\ntoOneToFive 4 = Just Four\ntoOneToFive 5 = Just Five\ntoOneToFive _ = Nothing\n\nfromOneToFive :: OneToFive -> Int\nfromOneToFive One   = 1\nfromOneToFive Two   = 2\nfromOneToFive Three = 3\nfromOneToFive Four  = 4\nfromOneToFive Five  = 5\nThis would be perfectly sufficient for achieving our stated goal, but you’d be forgiven for finding it odd: it would be rather awkward to work with in practice. Because we’ve invented an entirely new type, we can’t reuse any of the usual numeric functions Haskell provides. Consequently, many programmers would gravitate towards a newtype wrapper, instead:\n\nnewtype OneToFive = OneToFive Int\nJust as before, we can provide toOneToFive and fromOneToFive functions, with identical types:\n\ntoOneToFive :: Int -> Maybe OneToFive\ntoOneToFive n\n  | n >= 1 && n <= 5 = Just $ OneToFive n\n  | otherwise        = Nothing\n\nfromOneToFive :: OneToFive -> Int\nfromOneToFive (OneToFive n) = n\nIf we put these declarations in their own module and choose not to export the OneToFive constructor, these APIs might appear entirely interchangeable. Naïvely, it seems that the newtype version is both simpler and equally type-safe. However—perhaps surprisingly—this is not actually true.\n\nTo see why, suppose we write a function that consumes a OneToFive value as an argument. Under the constructive modeling, such a function need only pattern-match against each of the five constructors, and GHC will accept the definition as exhaustive:\n\nordinal :: OneToFive -> Text\nordinal One   = \"first\"\nordinal Two   = \"second\"\nordinal Three = \"third\"\nordinal Four  = \"fourth\"\nordinal Five  = \"fifth\"\nThe same is not true given the newtype encoding. The newtype is opaque, so the only way to observe it is to convert it back to an Int—after all, it is an Int. An Int can of course contain many other values besides 1 through 5, so we are forced to add an error case to satisfy the exhaustiveness checker:\n\nordinal :: OneToFive -> Text\nordinal n = case fromOneToFive n of\n  1 -> \"first\"\n  2 -> \"second\"\n  3 -> \"third\"\n  4 -> \"fourth\"\n  5 -> \"fifth\"\n  _ -> error \"impossible: bad OneToFive value\"\nIn this highly contrived example, this may not seem like much of a problem to you. But it nonetheless illustrates a key difference in the guarantees afforded by the two approaches:\n\n\nThe constructive datatype captures its invariants in such a way that they are accessible to downstream consumers. This frees our ordinal function from worrying about handling illegal values, as they have been made unutterable.\n\n\nThe newtype wrapper provides a smart constructor that validates the value, but the boolean result of that check is used only for control flow; it is not preserved in the function’s result. Accordingly, downstream consumers cannot take advantage of the restricted domain; they are functionally accepting Ints.\n\n\nLosing exhaustiveness checking might seem like small potatoes, but it absolutely is not: our use of error has punched a hole right through our type system. If we were to add another constructor to our OneToFive datatype,1 the version of ordinal that consumes a constructive datatype would be immediately detected non-exhaustive at compile-time, while the version that consumes a newtype wrapper would continue to compile yet fail at runtime, dropping through to the “impossible” case.\n\nAll of this is a consequence of the fact that the constructive modeling is intrinsically type-safe; that is, the safety properties are enforced by the type declaration itself. Illegal values truly are unrepresentable: there is simply no way to represent 6 using any of the five constructors. The same is not true of the newtype declaration, which has no intrinsic semantic distinction from that of an Int; its meaning is specified extrinsically via the toOneToFive smart constructor. Any semantic distinction intended by a newtype is thoroughly invisible to the type system; it exists only in the programmer’s mind.\n\nRevisiting non-empty lists\nOur OneToFive datatype is rather artificial, but identical reasoning applies to other datatypes that are significantly more practical. Consider the NonEmpty datatype I’ve repeatedly highlighted in recent blog posts:\n\ndata NonEmpty a = a :| [a]\nIt may be illustrative to imagine a version of NonEmpty represented as a newtype over ordinary lists. We can use the usual smart constructor strategy to enforce the desired non-emptiness property:\n\nnewtype NonEmpty a = NonEmpty [a]\n\nnonEmpty :: [a] -> Maybe (NonEmpty a)\nnonEmpty [] = Nothing\nnonEmpty xs = Just $ NonEmpty xs\n\ninstance Foldable NonEmpty where\n  toList (NonEmpty xs) = xs\nJust as with OneToFive, we quickly discover the consequences of failing to preserve this information in the type system. Our motivating use case for NonEmpty was the ability to write a safe version of head, but the newtype version requires another assertion:\n\nhead :: NonEmpty a -> a\nhead xs = case toList xs of\n  x:_ -> x\n  []  -> error \"impossible: empty NonEmpty value\"\nThis might not seem like a big deal, since it seems unlikely such a case would ever happen. But that reasoning hinges entirely on trusting the correctness of the module that defines NonEmpty, while the constructive definition only requires trusting the GHC typechecker. As we generally trust that the typechecker works correctly, the latter is a much more compelling proof.\n\nNewtypes as tokens\nIf you are fond of newtypes, this whole argument may seem a bit troubling. It may seem like I’m implying newtypes are scarcely better than comments, albeit comments that happen to be meaningful to the typechecker. Fortunately, the situation is not quite that grim—newtypes can provide a sort of safety, just a weaker one.\n\nThe primary safety benefit of newtypes is derived from abstraction boundaries. If a newtype’s constructor is not exported, it becomes opaque to other modules. The module that defines the newtype—its “home module”—can take advantage of this to create a trust boundary where internal invariants are enforced by restricting clients to a safe API.\n\nWe can use the NonEmpty example from above to illustrate how this works. We refrain from exporting the NonEmpty constructor, and we provide head and tail operations that we trust to never actually fail:\n\nmodule Data.List.NonEmpty.Newtype\n  ( NonEmpty\n  , cons\n  , nonEmpty\n  , head\n  , tail\n  ) where\n\nnewtype NonEmpty a = NonEmpty [a]\n\ncons :: a -> [a] -> NonEmpty a\ncons x xs = NonEmpty (x:xs)\n\nnonEmpty :: [a] -> Maybe (NonEmpty a)\nnonEmpty [] = Nothing\nnonEmpty xs = Just $ NonEmpty xs\n\nhead :: NonEmpty a -> a\nhead (NonEmpty (x:_)) = x\nhead (NonEmpty [])    = error \"impossible: empty NonEmpty value\"\n\ntail :: NonEmpty a -> [a]\ntail (NonEmpty (_:xs)) = xs\ntail (NonEmpty [])     = error \"impossible: empty NonEmpty value\"\nSince the only way to construct or consume NonEmpty values is to use the functions in Data.List.NonEmpty.Newtype’s exported API, the above implementation makes it impossible for clients to violate the non-emptiness invariant. In a sense, values of opaque newtypes are like tokens: the implementing module issues tokens via its constructor functions, and those tokens have no intrinsic value. The only way to do anything useful with them is to “redeem” them to the issuing module’s accessor functions, in this case head and tail, to obtain the values contained within.\n\nThis approach is significantly weaker than using a constructive datatype, since it is theoretically possible to screw up and accidentally provide a means to construct an invalid NonEmpty [] value. For this reason, the newtype approach to type safety does not on its own constitute a proof that a desired invariant holds. However, it restricts the “surface area” where an invariant violation can occur to the defining module, so reasonable confidence the invariant really does hold can be achieved by thoroughly testing the module’s API using fuzzing or property-based testing techniques.2\n\nThis tradeoff may not seem all that bad, and indeed, it is often a very good one! Guaranteeing invariants using constructive data modeling can, in general, be quite difficult, which often makes it impractical. However, it is easy to dramatically underestimate the care needed to avoid accidentally providing a mechanism that permits violating the invariant. For example, the programmer may choose to take advantage of GHC’s convenient typeclass deriving to derive a Generic instance for NonEmpty:\n\n{-# LANGUAGE DeriveGeneric #-}\n\nimport GHC.Generics (Generic)\n\nnewtype NonEmpty a = NonEmpty [a]\n  deriving (Generic)\nHowever, this innocuous line provides a trivial mechanism to circumvent the abstraction boundary:\n\nghci> GHC.Generics.to @(NonEmpty ()) (M1 $ M1 $ M1 $ K1 [])\nNonEmpty []\nThis is a particularly extreme example, since derived Generic instances are fundamentally abstraction-breaking, but this problem can crop up in less obvious ways, too. The same problem occurs with a derived Read instance:\n\nghci> read @(NonEmpty ()) \"NonEmpty []\"\nNonEmpty []\nTo some readers, these pitfalls may seem obvious, but safety holes of this sort are remarkably common in practice. This is especially true for datatypes with more sophisticated invariants, as it may not be easy to determine whether the invariants are actually upheld by the module’s implementation. Proper use of this technique demands caution and care:\n\n\nAll invariants must be made clear to maintainers of the trusted module. For simple types, such as NonEmpty, the invariant is self-evident, but for more sophisticated types, comments are not optional.\n\n\nEvery change to the trusted module must be carefully audited to ensure it does not somehow weaken the desired invariants.\n\n\nDiscipline is needed to resist the temptation to add unsafe trapdoors that allow compromising the invariants if used incorrectly.\n\n\nPeriodic refactoring may be needed to ensure the trusted surface area remains small. It is all too easy for the responsibility of the trusted module to accumulate over time, dramatically increasing the likelihood of some subtle interaction causing an invariant violation.\n\n\nIn contrast, datatypes that are correct by construction suffer none of these problems. The invariant cannot be violated without changing the datatype definition itself, which has rippling effects throughout the rest of the program to make the consequences immediately clear. Discipline on the part of the programmer is unnecessary, as the typechecker enforces the invariants automatically. There is no “trusted code” for such datatypes, since all parts of the program are equally beholden to the datatype-mandated constraints.\n\nIn libraries, the newtype-afforded notion of safety via encapsulation is useful, as libraries often provide the building blocks used to construct more complicated data structures. Such libraries generally receive more scrutiny and care than application code does, especially given they change far less frequently. In application code, these techniques are still useful, but the churn of a production codebase tends to weaken encapsulation boundaries over time, so correctness by construction should be preferred whenever practical.\n\nOther newtype use, abuse, and misuse\nThe previous section covers the primary means by which newtypes are useful. However, in practice, newtypes are routinely used in ways that do not fit the above pattern. Some such uses are reasonable:\n\n\nHaskell’s notion of typeclass coherency limits each type to a single instance of any given class. For types that permit more than one useful instance, newtypes are the traditional solution, and this can be used to good effect. For example, the Sum and Product newtypes from Data.Monoid provide useful Monoid instances for numeric types.\n\n\nIn a similar vein, newtypes can be useful for introducing or rearranging type parameters. The Flip newtype from Data.Bifunctor.Flip is a simple example, flipping the arguments of a Bifunctor so the Functor instance may operate on the other side:\n\nnewtype Flip p a b = Flip { runFlip :: p b a }\nNewtypes are needed to do this sort of juggling, as Haskell does not (yet) support type-level lambdas.\n\n\nMore simply, transparent newtypes can be useful to discourage misuse when the value needs to be passed between distant parts of the program and the intermediate code has no reason to inspect the value. For example, a ByteString containing a secret key may be wrapped in a newtype (with a Show instance omitted) to discourage code from accidentally logging or otherwise exposing it.\n\n\nAll of these applications are good ones, but they have little to do with type safety. The last bullet in particular is often confused for safety, and to be fair, it does in fact take advantage of the type system to help avoid logical mistakes. However, it would be a mischaracterization to claim such usage actually prevents misuse; any part of the program may inspect the value at any time.\n\nToo often, this illusion of safety leads to outright newtype abuse. For example, here’s a definition from the very codebase I work on for a living:\n\nnewtype ArgumentName = ArgumentName { unArgumentName :: GraphQL.Name }\n  deriving ( Show, Eq, FromJSON, ToJSON, FromJSONKey, ToJSONKey\n           , Hashable, ToTxt, Lift, Generic, NFData, Cacheable )\nThis newtype is useless noise. Functionally, it is completely interchangeable with its underlying Name type, so much so that it derives a dozen typeclasses! In every location it’s used, it’s immediately unwrapped the instant it’s extracted from its enclosing record, so there is no type safety benefit whatsoever. Worse, there isn’t even any clarity added by labeling it an ArgumentName, since the enclosing field name already makes its role clear.\n\nNewtypes like these seem to arise from a desire to use the type system as a taxonomy of the external world. An “argument name” is a more specific concept than a generic “name,” so surely it ought to have its own type. This makes some intuitive sense, but it’s rather misguided: taxonomies are useful for documenting a domain of interest, but not necessarily helpful for modeling it. When programming, we use types for a different end:\n\n\nPrimarily, types distinguish functional differences between values. A value of type NonEmpty a is functionally distinct from a value of type [a], since it is fundamentally structurally different and permits additional operations. In this sense, types are structural; they describe what values are in the internal world of the programming language.\n\n\nSecondarily, we sometimes use types to help ourselves avoid making logical mistakes. We might use separate Distance and Duration types to avoid accidentally doing something nonsensical like adding them together, even though they’re both representationally real numbers.\n\n\nNote that both these uses are pragmatic; they look at the type system as a tool. This is a rather natural perspective to take, seeing as a static type system is a tool in a literal sense. Nevertheless, that perspective seems surprisingly unusual, even though the use of types to classify the world routinely yields unhelpful noise like ArgumentName.\n\nIf a newtype is completely transparent, and it is routinely wrapped and unwrapped at will, it is likely not very helpful. In this particular case, I would eliminate the distinction altogether and use Name, but in situations where the different label adds genuine clarity, one can always use a type alias:3\n\ntype ArgumentName = GraphQL.Name\nNewtypes like these are security blankets. Forcing programmers to jump through a few hoops is not type safety—trust me when I say they will happily jump through them without a second thought.\n\nFinal thoughts and related reading\nI’ve been wanting to write this blog post for a long time. Ostensibly, it’s a very specific critique of Haskell newtypes, and I’ve chosen to frame things this way because I write Haskell for a living and this is the way I encounter this problem in practice. Really, though, the core idea is much bigger than that.\n\nNewtypes are one particular mechanism of defining wrapper types, a concept that exists in almost any language, even those that are dynamically typed. Even if you don’t write Haskell, much of the reasoning in this blog post is likely still relevant in your language of choice. More broadly, this is a continuation of a theme I’ve been trying to convey from different angles over the past year: type systems are tools, and we should be more conscious and intentional about what they actually do and how to use them effectively.\n\nThe catalyst that got me to finally sit down and write this was the recently-published Tagged is not a Newtype. It’s a good blog post, and I wholeheartedly agree with its general thrust, but I thought it was a missed opportunity to make a larger point. Indeed, Tagged is a newtype, definitionally, so the title of the blog post is something of a misdirection. The real problem is a little deeper.\n\nNewtypes are useful when carefully applied, but their safety is not intrinsic, no more than the safety of a traffic cone is somehow contained within the plastic it’s made of. What matters is being placed in the right context—without that, newtypes are just a labeling scheme, a way of giving something a name.\n\nAnd a name is not type safety.\n\n\nAdmittedly rather unlikely given its name, but bear with me through the contrived example.\n ↩\n\nIn theory, it is still possible to thoroughly prove the invariant holds using external verification techniques, such as by writing a pen-and-paper proof or by using program extraction in combination with a proof assistant/theorem prover. However, these techniques are extremely uncommon in general programming practice.\n ↩\n\nAs it happens, I think type aliases are often also more harmful than helpful, so I would caution against overusing them, too, but that is outside the scope of this blog post.\n ↩","isoDate":"2020-11-01T00:00:00.000Z","timestamp":"10/31/2020"},{"title":"Types as axioms, or: playing god with static types","pubDate":"2020-08-13T00:00:00.000Z","author":"Alexis King","content":"<article><p>Just what exactly <em>is</em> a type?\n</p><p>A common perspective is that types are <em>restrictions</em>. Static types restrict the set of values a variable may contain, capturing some subset of the space of “all possible values.” Under this worldview, a typechecker is sort of like an oracle, predicting which values will end up where when the program runs and making sure they satisfy the constraints the programmer wrote down in the type annotations. Of course, the typechecker can’t <em>really</em> predict the future, so when the typechecker gets it wrong—it can’t “figure out” what a value will be—static types can feel like self-inflicted shackles.\n</p><p>But that is not the <em>only</em> perspective. There is another way—a way that puts you, the programmer, back in the driver’s seat. You make the rules, you call the shots, you set the objectives. You need not be limited any longer by what the designers of your programming language decided the typechecker can and cannot prove. You do not serve the typechecker; the typechecker serves <em>you.</em>\n</p><p>…no, I’m not trying to sell you a dubious self-help book for programmers who feel like they’ve lost control of their lives. If the above sounds too good to be true, well… I won’t pretend it’s all actually as easy as I make it sound. Nevertheless, it’s well within the reach of the working programmer, and most remarkably, all it takes is a change in perspective.\n</p><h2><a name=\"seeing-the-types-half-empty\"></a>Seeing the types half-empty</h2><p>Let’s talk a little about TypeScript.\n</p><p>TypeScript is a <em>gradually-typed</em> language, which means it’s possible to mix statically- and dynamically-typed code. The original intended use case of gradual typing was to <em>gradually</em> add static types to an existing dynamically-typed codebase, which imposes some interesting design constraints. For one, a valid JavaScript program must also be a valid TypeScript program; for another, TypeScript must be accommodating of traditional JavaScript idioms.\n</p><p>Gradually typed languages like TypeScript are particularly good illustrations of the way type annotations can be viewed as constraints. A function with no explicit type declarations<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup> can accept <em>any</em> JavaScript value, so adding a type annotation fundamentally restricts the set of legal values.\n</p><p>Furthermore, languages like TypeScript tend to have subtyping. This makes it easy to classify certain types as “more restrictive” than others. For example, a type like <code>string | number</code> clearly includes more values than just <code>number</code>, so <code>number</code> is a more restrictive type—a <em>subtype</em>.\n</p><p>An exceptionally concrete way to illustrate this “types are restrictions” mentality is to write a function with an unnecessarily specific type. Here’s a TypeScript function that returns the first element in an array of numbers:\n</p><pre><code class=\"pygments\"><span class=\"kd\">function</span> <span class=\"nx\">getFirst</span><span class=\"p\">(</span><span class=\"nx\">arr</span>: <span class=\"kt\">number</span><span class=\"p\">[])</span><span class=\"o\">:</span> <span class=\"kt\">number</span> <span class=\"o\">|</span> <span class=\"kc\">undefined</span> <span class=\"p\">{</span>\n  <span class=\"k\">return</span> <span class=\"nx\">arr</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">];</span>\n<span class=\"p\">}</span></code></pre><p>If we ignore the type annotations and consider only the dynamic semantics of JavaScript, this function would work perfectly well given a list of strings. However, if we write <code>getFirst([\"hello\", \"world\"])</code>, the typechecker will complain. In this example, the restriction is thoroughly self-imposed—it would be easy to give this function a more generic type—but it’s not always that easy. For example, suppose we wrote a function where the return type depends upon the type of the argument:\n</p><pre><code class=\"pygments\"><span class=\"kd\">function</span> <span class=\"nx\">emptyLike</span><span class=\"p\">(</span><span class=\"nx\">val</span>: <span class=\"kt\">number</span> <span class=\"o\">|</span> <span class=\"kt\">string</span><span class=\"p\">)</span><span class=\"o\">:</span> <span class=\"kt\">number</span> <span class=\"o\">|</span> <span class=\"kt\">string</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"k\">typeof</span> <span class=\"nx\">val</span> <span class=\"o\">===</span> <span class=\"s2\">\"number\"</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"s2\">\"\"</span><span class=\"p\">;</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre><p>Now if we write <code>emptyLike(42) * 10</code>, the typechecker will once again complain, claiming the result might be a string—it can’t “figure out” that when we pass a number, we always get a number back.\n</p><p>When type systems are approached from this perspective, the result is often frustration. The programmer knows that the equivalent untyped JavaScript is perfectly well-behaved, so the typechecker comes off as being the highly unfortunate combination of stubborn yet dim-witted. What’s more, the programmer likely has little mental model of the typechecker’s internal operation, so when types like the above are inferred (not explicitly written), it can be unclear what solutions exist to make the error go away.\n</p><p>At this point, the programmer may give up. “Stupid typechecker,” they grumble, changing the return type of <code>emptyLike</code> to <code>any</code>. “If it can’t even figure this out, can it <em>really</em> be all that useful?”\n</p><p>Sadly, this relationship with the typechecker is all too common, and gradually-typed languages in particular tend to create a vicious cycle of frustration:\n</p><ul><li><p>Gradual type systems are intentionally designed to “just work” on idiomatic code as much as possible, so programmers may not think much about the types except when they get type errors.\n</p></li><li><p>Furthermore, many programmers using gradually-typed languages are already adept at programming in the underlying dynamically-typed language, so they have working mental models of program operation in terms of the dynamic semantics alone. They are much less likely to develop a rich mental model of the static semantics of the type system because they are used to reasoning without one.\n</p></li><li><p>Gradually typed languages must support idioms from their dynamically-typed heritage, so they often include ad-hoc special cases (such as, for example, special treatment of <code>typeof</code> checks) that obscure the rules the typechecker follows and make them seem semi-magical.\n</p></li><li><p>Builtin types are deeply blessed in the type system, strongly encouraging programmers to embrace their full flexibility, but leaving little recourse when they run up against their limits.\n</p></li><li><p>All this frustration breeds a readiness to override the typechecker using casts or <code>any</code>, which ultimately creates a self-fulfilling prophecy in which the typechecker rarely catches any interesting mistakes because it has been so routinely disabled.\n</p></li></ul><p>The end result of all of this is a defeatist attitude that views the typechecker as a minor tooling convenience at best (i.e. a fancy autocomplete provider) or an active impediment at worst. Who can really blame them? The type system has (unintentionally of course) been designed in such a way so as to lead them into this dead end. The public perception of type systems settles into that of a strikingly literal nitpicker we endure rather than as a tool we actively leverage.\n</p><h2><a name=\"taking-back-types\"></a>Taking back types</h2><p>After everything I said above, it may be hard to imagine seeing types any other way. Indeed, through the lens of TypeScript, the “types are restrictions” mentality is incredibly natural, so much so that it seems self-evident. But let’s move away from TypeScript for a moment and focus on a different language, Haskell, which encourages a somewhat different perspective. If you aren’t familiar with Haskell, that’s alright—I’m going to try to keep the examples in this blog post as accessible as possible whether you’ve written any Haskell or not.\n</p><p>Though Haskell and TypeScript are both statically-typed—and both of their type systems are fairly sophisticated—Haskell’s type system is almost completely different philosophically:\n</p><ul><li><p>Haskell does not have subtyping,<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup> which means that every value belongs to exactly one type.\n</p></li><li><p>While JavaScript is built around a small handful of flexible builtin datatypes (booleans, numbers, strings, arrays, and objects), Haskell has essentially no blessed, built-in datatypes other than numbers. Key types such as booleans, lists, and tuples are ordinary datatypes defined in the standard library, no different from types users could define.<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup>\n</p></li><li><p>In particular, Haskell is built around the idea that datatypes can be defined with multiple <em>cases</em>, and branching is done via pattern-matching (more on this shortly).\n</p></li></ul><p>Let’s look at a basic Haskell datatype declaration. Suppose we want to define a type that represents a season:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Season</span> <span class=\"ow\">=</span> <span class=\"kt\">Spring</span> <span class=\"o\">|</span> <span class=\"kt\">Summer</span> <span class=\"o\">|</span> <span class=\"kt\">Fall</span> <span class=\"o\">|</span> <span class=\"kt\">Winter</span></code></pre><p>If you are familiar with TypeScript, this may look rather similar to a union type; if you’re familiar with a C-family language, this may remind you more of an enum. Both are on the right track: this defines a new type named <code>Season</code> with four possible values, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>.\n</p><p>But what exactly <em>are</em> those values?\n</p><ul><li><p>In TypeScript, we’d represent this type with a union of strings, like this:\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">Season</span> <span class=\"o\">=</span> <span class=\"s2\">\"spring\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"summer\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"fall\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"winter\"</span><span class=\"p\">;</span></code></pre><p>Here, <code>Season</code> is a type that can be one of those four strings, but nothing else.\n</p></li><li><p>In C, we’d represent this type with an enum, like this:\n</p><pre><code class=\"pygments\"><span class=\"k\">enum</span> <span class=\"n\">season</span> <span class=\"p\">{</span> <span class=\"n\">SPRING</span><span class=\"p\">,</span> <span class=\"n\">SUMMER</span><span class=\"p\">,</span> <span class=\"n\">FALL</span><span class=\"p\">,</span> <span class=\"n\">WINTER</span> <span class=\"p\">};</span></code></pre><p>Here, <code>SPRING</code>, <code>SUMMER</code>, <code>FALL</code>, and <code>WINTER</code> are essentially defined to be global aliases for the integers <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>, and the type <code>enum season</code> is essentially an alias for <code>int</code>.\n</p></li></ul><p>So in TypeScript, the values are strings, and in C, the values are numbers. What are they in Haskell? Well… they simply <em>are</em>.\n</p><p>The Haskell declaration invents four completely new constants out of thin air, <code>Spring</code>, <code>Summer</code>, <code>Fall</code>, and <code>Winter</code>. They aren’t aliases for numbers, nor are they symbols or strings. The compiler doesn’t expose anything about how it chooses to represent these values at runtime; that’s an implementation detail. In Haskell, <code>Spring</code> is now a value <em>distinct from all other values</em>, even if someone in a different module were to also use the name <code>Spring</code>. Haskell type declarations let us play god, creating something from nothing.\n</p><p>Since these values are totally unique, abstract constants, what can we actually do with them? The answer is one thing and <em>exactly</em> one thing: we can branch on them. For example, we can write a function that takes a <code>Season</code> as an argument and returns whether or not Christmas occurs during it:\n</p><pre><code class=\"pygments\"><span class=\"nf\">containsChristmas</span> <span class=\"ow\">::</span> <span class=\"kt\">Season</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Bool</span>\n<span class=\"nf\">containsChristmas</span> <span class=\"n\">season</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">season</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">Spring</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">False</span>\n  <span class=\"kt\">Summer</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">True</span>  <span class=\"c1\">-- southern hemisphere</span>\n  <span class=\"kt\">Fall</span>   <span class=\"ow\">-&gt;</span> <span class=\"kt\">False</span>\n  <span class=\"kt\">Winter</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">True</span>  <span class=\"c1\">-- northern hemisphere</span></code></pre><p><code>case</code> expressions are, to a first approximation, a lot like C-style <code>switch</code> statements (though they can do a lot more than this simple example suggests). Using <code>case</code>, we can also define conversions from our totally unique <code>Season</code> constants to other types, if we want:\n</p><pre><code class=\"pygments\"><span class=\"nf\">seasonToString</span> <span class=\"ow\">::</span> <span class=\"kt\">Season</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span>\n<span class=\"nf\">seasonToString</span> <span class=\"n\">season</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">season</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">Spring</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"spring\"</span>\n  <span class=\"kt\">Summer</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"summer\"</span>\n  <span class=\"kt\">Fall</span>   <span class=\"ow\">-&gt;</span> <span class=\"s\">\"fall\"</span>\n  <span class=\"kt\">Winter</span> <span class=\"ow\">-&gt;</span> <span class=\"s\">\"winter\"</span></code></pre><p>We can also go the other way around, converting a <code>String</code> to a <code>Season</code>, but if we try, we run into a problem: what do we return for a string like, say, <code>\"cheesecake\"</code>? In other languages, we might throw an error or return <code>null</code>, but Haskell does not have <code>null</code>, and errors are generally reserved for truly catastrophic failures. What can we do instead?\n</p><p>A particularly naïve solution would be to create a type called <code>MaybeASeason</code> that has two cases—it can be a valid <code>Season</code>, or it can be <code>NotASeason</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">MaybeASeason</span> <span class=\"ow\">=</span> <span class=\"kt\">IsASeason</span> <span class=\"kt\">Season</span> <span class=\"o\">|</span> <span class=\"kt\">NotASeason</span>\n\n<span class=\"nf\">stringToSeason</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">MaybeASeason</span>\n<span class=\"nf\">stringToSeason</span> <span class=\"n\">seasonString</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">seasonString</span> <span class=\"kr\">of</span>\n  <span class=\"s\">\"spring\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IsASeason</span> <span class=\"kt\">Spring</span>\n  <span class=\"s\">\"summer\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IsASeason</span> <span class=\"kt\">Summer</span>\n  <span class=\"s\">\"fall\"</span>   <span class=\"ow\">-&gt;</span> <span class=\"kt\">IsASeason</span> <span class=\"kt\">Fall</span>\n  <span class=\"s\">\"winter\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IsASeason</span> <span class=\"kt\">Winter</span>\n  <span class=\"kr\">_</span>        <span class=\"ow\">-&gt;</span> <span class=\"kt\">NotASeason</span></code></pre><p>This shows a feature of Haskell datatypes that C-style enums do <em>not</em> have: they aren’t just constants, they can contain other values. A <code>MaybeASeason</code> can be one of five different values: <code>IsASeason Spring</code>, <code>IsASeason Summer</code>, <code>IsASeason Fall</code>, <code>IsASeason Winter</code>, or <code>NotASeason</code>.\n</p><p>In TypeScript, we’d write <code>MaybeASeason</code> more like this:\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">MaybeASeason</span> <span class=\"o\">=</span> <span class=\"nx\">Season</span> <span class=\"o\">|</span> <span class=\"s2\">\"not-a-season\"</span><span class=\"p\">;</span></code></pre><p>This is kind of nice, because we don’t have to wrap all our <code>Season</code> values with <code>IsASeason</code> like we have to do in Haskell. But remember that Haskell doesn’t have subtyping—every value must belong to exactly one type—so the Haskell code needs the <code>IsASeason</code> wrapper to distinguish the value as a <code>MaybeASeason</code> rather than a <code>Season</code>.\n</p><p>Now, you may rightly point out that having to invent a type like <code>MaybeASeason</code> every time we need to create a variant of a type with a failure case is absurd, so fortunately we can define a type like <code>MaybeASeason</code> that works for <em>any</em> underlying type. In Haskell, it looks like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Maybe</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"kt\">Nothing</span></code></pre><p>This defines a generic type, where the <code>a</code> in <code>Maybe a</code> is a stand-in for some other type, much like the <code>T</code> in <code>Array&lt;T&gt;</code> in other languages. We can change our <code>stringToSeason</code> function to use <code>Maybe</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">stringToSeason</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"kt\">Season</span>\n<span class=\"nf\">stringToSeason</span> <span class=\"n\">seasonString</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">seasonString</span> <span class=\"kr\">of</span>\n  <span class=\"s\">\"spring\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Just</span> <span class=\"kt\">Spring</span>\n  <span class=\"s\">\"summer\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Just</span> <span class=\"kt\">Summer</span>\n  <span class=\"s\">\"fall\"</span>   <span class=\"ow\">-&gt;</span> <span class=\"kt\">Just</span> <span class=\"kt\">Fall</span>\n  <span class=\"s\">\"winter\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Just</span> <span class=\"kt\">Winter</span>\n  <span class=\"kr\">_</span>        <span class=\"ow\">-&gt;</span> <span class=\"kt\">Nothing</span></code></pre><p><code>Maybe</code> gets us something a lot like nullable types, but it isn’t built into the type system, it’s just an ordinary type defined in the standard library.\n</p><h3><a name=\"positive-versus-negative-space\"></a>Positive versus negative space</h3><p>At this point, you may be wondering to yourself why I am talking about all of this, seeing as everything in the previous section is information you could find in a basic Haskell tutorial. But the point of this blog post is not to teach you Haskell, it’s to focus on a particular philosophical approach to modeling data.\n</p><p>In TypeScript, when we write a type declaration like\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">Season</span> <span class=\"o\">=</span> <span class=\"s2\">\"summer\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"spring\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"fall\"</span> <span class=\"o\">|</span> <span class=\"s2\">\"winter\"</span><span class=\"p\">;</span></code></pre><p>we are defining a type that can be one of those four strings <em>and nothing else</em>. All the other strings that <em>aren’t</em> one of those four make up <code>Season</code>’s “negative space”—values that exist, but that we have intentionally excluded. In contrast, the Haskell type does not really have any “negative space” because we pulled four new values out of thin air.\n</p><p>Of course, I suspect you don’t really buy this argument. What makes a string like <code>\"cheesecake\"</code> “negative space” in TypeScript but not in Haskell? Well… nothing, really. The distinction I’m drawing here doesn’t really exist, it’s just a different perspective, and arguably a totally contrived and arbitrary one. But now that I’ve explained the premise and set up some context, let me provide a more compelling example.\n</p><p>Suppose you are writing a TypeScript program, and you want a function that only accepts <em>non-empty</em> arrays. What can you do? Your first instinct is that you need a way to somehow further restrict the function’s input type to exclude empty arrays. And indeed, there <em>is</em> a trick for doing that:\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">NonEmptyArray</span><span class=\"o\">&lt;</span><span class=\"nx\">T</span><span class=\"o\">&gt;</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"nx\">T</span><span class=\"p\">,</span> <span class=\"p\">...</span><span class=\"nx\">T</span><span class=\"p\">[]];</span></code></pre><p>Great! But what if the constraint was more complicated: what if you needed an array containing an even number of elements? Unfortunately, there isn’t really a trick for that one. At this point, you might start wishing the type system had support for something really fancy, like refinement types, so you could write something like this:\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">EvenArray</span><span class=\"o\">&lt;</span><span class=\"nx\">T</span><span class=\"o\">&gt;</span> <span class=\"o\">=</span> <span class=\"nx\">T</span><span class=\"p\">[]</span> <span class=\"nx\">satisfies</span> <span class=\"p\">(</span><span class=\"nx\">arr</span> <span class=\"o\">=&gt;</span> <span class=\"nx\">arr</span><span class=\"p\">.</span><span class=\"nx\">length</span> <span class=\"o\">%</span> <span class=\"mi\">2</span> <span class=\"o\">===</span> <span class=\"mi\">0</span><span class=\"p\">);</span></code></pre><p>But TypeScript doesn’t support anything like that, so for now you’re stuck. You need a way to restrict the function’s domain in a way the type system does not have any special support for, so your conclusion might be “I guess the type system just can’t do this.” People tend to call this “running up against the limits of the type system.”\n</p><p>But what if we took a different perspective? Recall that in Haskell, lists aren’t built-in datatypes, they’re just ordinary datatypes defined in the standard library:<sup><a id=\"footnote-ref-4-1\" href=\"#footnote-4\">4</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">List</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Nil</span> <span class=\"o\">|</span> <span class=\"kt\">Cons</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"kt\">List</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>This type might be a bit confusing at first if you have not written any Haskell, since it’s <em>recursive</em>. All of these are valid values of type <code>List Int</code>:\n</p><ul><li><p><code>Nil</code>\n</p></li><li><p><code>Cons 1 Nil</code>\n</p></li><li><p><code>Cons 1 (Cons 2 Nil)</code>\n</p></li><li><p><code>Cons 1 (Cons 2 (Cons 3 Nil))</code>\n</p></li></ul><p>The recursive nature of <code>Cons</code> is what gives our user-defined datatype the ability to hold any number of values: we can have any number of nested <code>Cons</code>es we want before we terminate the list with a final <code>Nil</code>.\n</p><p>If we wanted to define an <code>EvenList</code> type in Haskell, we might end up thinking along the same lines we did before, that we need some fancy type system extension so we can restrict <code>List</code> to exclude lists with odd numbers of elements. But that’s focusing on the negative space of things we want to exclude… what if instead, we focused on the <em>positive</em> space of things we want to <em>include?</em>\n</p><p>What do I mean by that? Well, we could define an entirely new type that’s just like <code>List</code>, but we make it <em>impossible</em> to ever include an odd number of elements:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">EvenList</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenNil</span> <span class=\"o\">|</span> <span class=\"kt\">EvenCons</span> <span class=\"n\">a</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"kt\">EvenList</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>Here are some valid values of type <code>EvenList Int</code>:\n</p><ul><li><p><code>EvenNil</code>\n</p></li><li><p><code>EvenCons 1 2 EvenNil</code>\n</p></li><li><p><code>EvenCons 1 2 (EvenCons 3 4 EvenNil)</code>\n</p></li></ul><p>Lo and behold, a datatype that can only ever include even numbers of elements!\n</p><p>Now, at this point you might realize that this is kind of silly. We don’t need to invent an entirely new datatype for this! We could just create a list of pairs:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">EvenList</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">List</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>Now values like <code>Cons (1, 2) (Cons (3, 4) Nil)</code> would be valid values of type <code>EvenList Int</code>, and we wouldn’t have to reinvent lists. But again, this is an approach based on thinking not on which values we want to exclude, but rather how to structure our data such that those illegal values aren’t even <em>constructible.</em>\n</p><p><strong>This is the essence of the Haskeller’s mantra, “Make illegal states unrepresentable,”</strong> and sadly it is often misinterpreted. It’s much easier to think “hm, I want to make these states illegal, how can I add some post-hoc restrictions to rule them out?” And indeed, this is why refinement types really <em>are</em> awesome, and when they’re available, by all means use them! But checking totally arbitrary properties at the type level is not tractable in general, and sometimes you need to think a little more outside the box.\n</p><h3><a name=\"types-as-axiom-schemas\"></a>Types as axiom schemas</h3><p>So far in this blog post, I’ve repeatedly touched upon a handful of different ideas in a few different ways:\n</p><ul><li><p>Instead of thinking about how to <em>restrict</em>, it can be useful to think about how to <em>correctly construct</em>.\n</p></li><li><p>In Haskell, datatype declarations invent new values out of thin air.\n</p></li><li><p>We can represent a <em>lot</em> of different data structures using the incredibly simple framework of “datatypes with several possibilities.”\n</p></li></ul><p>Independently, those ideas might not seem deeply related, but in fact, they’re all essential to the Haskell school of data modeling. I want to now explore how we can unify them into a single framework that makes this seem less magical and more like an iterative design process.\n</p><p>In Haskell, when you define a datatype, you’re really defining a new, self-contained set of <em>axioms</em> and <em>inference rules.</em> That is rather abstract, so let’s make it more concrete. Consider the <code>List</code> type again:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">List</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Nil</span> <span class=\"o\">|</span> <span class=\"kt\">Cons</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"kt\">List</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>Viewed as an axiom schema, this type has one axiom and one inference rule:\n</p><ul><li><p>The empty list is a list.\n</p></li><li><p>If you have a list, and you add an element to the beginning, the result is also a list.\n</p></li></ul><p>The axiom is <code>Nil</code>, and the inference rule is <code>Cons</code>. Every list<sup><a id=\"footnote-ref-5-1\" href=\"#footnote-5\">5</a></sup> is constructed by starting with the axiom, <code>Nil</code>, followed by some number of applications of the inference rule, <code>Cons</code>.\n</p><p>We can take a similar approach when designing the <code>EvenList</code> type. The axiom is the same:\n</p><ul><li><p>The empty list is a list with an even number of elements.\n</p></li></ul><p>But our inference rule must preserve the invariant that the list always contains an even number of elements. We can do this by always adding two elements at a time:\n</p><ul><li><p>If you have a list with an even number of elements, and you add two elements to the beginning, the result is also a list with an even number of elements.\n</p></li></ul><p>This corresponds precisely to our <code>EvenList</code> declaration:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">EvenList</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">EvenNil</span> <span class=\"o\">|</span> <span class=\"kt\">EvenCons</span> <span class=\"n\">a</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"kt\">EvenList</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>We can also go through this same reasoning process to come up with a type that represents non-empty lists. That type has just one inference rule:\n</p><ul><li><p>If you have a list, and you add an element to the beginning, the result is a non-empty list.\n</p></li></ul><p>That inference rule corresponds to the following datatype:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">NonEmptyList</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">NonEmptyCons</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"kt\">List</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>Of course, it’s possible to do this with much more than just lists. A particularly classic example is the constructive definition of natural numbers:\n</p><ul><li><p>Zero is a natural number.\n</p></li><li><p>If you have a natural number, its successor (i.e. that number plus one) is also a natural number.\n</p></li></ul><p>These are two of the <a href=\"https://en.wikipedia.org/wiki/Peano_axioms\">Peano axioms</a>, which can be represented in Haskell as the following datatype:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Natural</span> <span class=\"ow\">=</span> <span class=\"kt\">Zero</span> <span class=\"o\">|</span> <span class=\"kt\">Succ</span> <span class=\"kt\">Natural</span></code></pre><p>Using this type, <code>Zero</code> represents 0, <code>Succ Zero</code> represents 1, <code>Succ (Succ Zero)</code> represents 2, and so on. Just as <code>EvenList</code> allowed us to represent any list with an even number of elements but made other values impossible to even express, this <code>Natural</code> type allows us to represent all natural numbers, while other numbers (such as, for example, negative integers) are impossible to express.\n</p><p>Now, of course, all this hinges on our interpretation of the values we’ve invented! We have chosen to interpret <code>Zero</code> as <code>0</code> and <code>Succ n</code> as <code>n + 1</code>, but that interpretation is not inherent to <code>Natural</code>’s definition—it’s all in our heads! We could choose to interpret <code>Succ n</code> as <code>n - 1</code> instead, in which case we would only be able to represent non-positive integers, or we could interpret <code>Zero</code> as <code>1</code> and <code>Succ n</code> as <code>n * 2</code>, in which case we could only represent powers of two.\n</p><p>I find that people sometimes find this approach troubling, or at least counterintuitive. Is <code>Succ (Succ Zero)</code> <em>really</em> 2? It certainly doesn’t look like a number we’re used to writing. When someone thinks “I need a datatype for a number greater than or equal to zero,” they’re going to reach for the type in their programming language called <code>number</code> or <code>int</code>, not think to invent a recursive datatype. And admittedly, the <code>Natural</code> type defined here is not very practical: it’s an incredibly inefficient representation of natural numbers.\n</p><p>But in less contrived situations, this approach <em>is</em> practical, and in fact it’s highly useful! The quibble that an <code>EvenList Int</code> isn’t “really” a <code>List Int</code> is rather meaningless, seeing as our definition of <code>List</code> was just as arbitrary. A great deal of our jobs as programmers is imbuing arbitrary symbols with meaning; at some point someone decided that the number 65 would correspond to the capital letter A, and it was no less arbitrary then.\n</p><p>So when you have a property you want to capture in your types, take a step back and think about it for a little bit. Is there a way you can structure your data so that, no matter how you build it, the result is always a valid value? In other words, don’t try to add post-hoc restrictions to exclude bad values, <strong>make your datatypes correct by construction</strong>.\n</p><h2><a name=\"but-what-if-i-don-t-write-haskell-and-other-closing-thoughts\"></a>“But what if I don’t write Haskell?” And other closing thoughts</h2><p>I write Haskell for a living, and I wrote this blog post with both my coworkers and the broader Haskell community in mind, but if I had <em>only</em> written it with those people in mind, it wouldn’t make sense to have spent so much time explaining basic Haskell. These techniques can be used in almost any statically typed programming language, though it’s certainly easier in some than others.\n</p><p>I don’t want people to come away from this blog post with an impression that I think TypeScript is a bad language, or that I’m claiming Haskell can do things TypeScript can’t. In fact, TypeScript <em>can</em> do all the things I’ve talked about in this blog post! As proof, here are TypeScript definitions of both <code>EvenList</code> and <code>Natural</code>:\n</p><pre><code class=\"pygments\"><span class=\"nx\">type</span> <span class=\"nx\">EvenList</span><span class=\"o\">&lt;</span><span class=\"nx\">T</span><span class=\"o\">&gt;</span> <span class=\"o\">=</span> <span class=\"p\">[]</span> <span class=\"o\">|</span> <span class=\"p\">[</span><span class=\"nx\">T</span><span class=\"p\">,</span> <span class=\"nx\">T</span><span class=\"p\">,</span> <span class=\"nx\">EvenList</span><span class=\"o\">&lt;</span><span class=\"nx\">T</span><span class=\"o\">&gt;</span><span class=\"p\">];</span>\n<span class=\"nx\">type</span> <span class=\"nx\">Natural</span> <span class=\"o\">=</span> <span class=\"s2\">\"zero\"</span> <span class=\"o\">|</span> <span class=\"p\">{</span> <span class=\"nx\">succ</span>: <span class=\"kt\">Natural</span> <span class=\"p\">};</span></code></pre><p>If anything, <strong>the real point of this blog post is that a type system does not have a well-defined list of things it “can prove” and “can’t prove.”</strong> Languages like TypeScript don’t really encourage this approach to data modeling, where you restructure your values in a certain way so as to guarantee certain properties. Rather, they prefer to add increasingly sophisticated constraints and type system features that can capture the properties people want to capture without having to change their data representation.\n</p><p>And in general, <em>that’s great!</em>\n</p><p>Being able to reuse the same data representation is <em>hugely</em> beneficial. Functions like <code>map</code> and <code>filter</code> already exist for ordinary lists/arrays, but a home-grown <code>EvenList</code> type needs its own versions. Passing an <code>EvenList</code> to a function that expects a list requires explicitly converting between the two. All these things have both code complexity and performance costs, and type system features that make these issues just invisibly disappear are <em>obviously</em> a good thing.\n</p><p>But the danger of treating the type system this way is that it means you may find yourself unsure what to do when suddenly you have a new requirement that the type system doesn’t provide built-in support for. What then? Do you start punching holes through your type system? The more you do that, the less useful the type system becomes: type systems are great at detecting how changes in one part of a codebase can impact seemingly-unrelated areas in surprising ways, but every unsafe cast or use of <code>any</code> is a hard stop, a point past which the typechecker cannot propagate information. Do that once or twice in a leaf function, it’s okay, but do that even just a half dozen times in your application’s connective tissue, and your type system might not be able to catch those things anymore.\n</p><p>Even if it isn’t a technique you use every day, it’s worth getting comfortable tweaking your data representation to preserve those guarantees. It’s a magical experience having the typechecker teach you things about your domain you hadn’t even considered simply because you got a type error and started thinking through why. Yes, it’s extra work, but trust me: it’s a lot more pleasant to work for your typechecker when you know exactly how much your typechecker is working for you.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Sort of. TypeScript will try to infer type annotations based on how variables and functions are used, but by default, it falls back on the dynamic, unchecked <code>any</code> type if it can’t find a solution that makes the program typecheck. That behavior can be changed via a configuration option, but that isn’t relevant here: I’m just trying to illustrate a perspective, not make any kind of value judgment about TypeScript specifically.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>Sort of. Haskell does have a limited notion of subtyping when polymorphism is involved; for example, the type <code>forall a. a -&gt; a</code> is a subtype of the type <code>Int -&gt; Int</code>. But Haskell does not have anything resembling inheritance (e.g. there is no common <code>Number</code> supertype that includes both <code>Int</code> and <code>Double</code>) nor does it have untagged unions (e.g. the argument to a function cannot be something like <code>Int | String</code>, you must define a wrapper type like <code>data IntOrString = AnInt Int | AString String</code>).\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>Lists, tuples, and strings do technically have special <em>syntax</em>, which is built into the compiler, but there is truly nothing special about their semantics. They would work exactly the same way without the syntax, the code would just look less pretty.\n <a href=\"#footnote-ref-3-1\">↩</a></p></li><li id=\"footnote-4\"><p>Haskell programmers will notice that this is not actually the definition of the list type, since the real list type uses special syntax, but I wanted to keep things as simple as possible for this blog post.\n <a href=\"#footnote-ref-4-1\">↩</a></p></li><li id=\"footnote-5\"><p>Ignoring infinite lists, but the fact that infinite lists are representable in Haskell is outside the scope of this blog post.\n <a href=\"#footnote-ref-5-1\">↩</a></p></li></ol></article>","contentSnippet":"Just what exactly is a type?\n\nA common perspective is that types are restrictions. Static types restrict the set of values a variable may contain, capturing some subset of the space of “all possible values.” Under this worldview, a typechecker is sort of like an oracle, predicting which values will end up where when the program runs and making sure they satisfy the constraints the programmer wrote down in the type annotations. Of course, the typechecker can’t really predict the future, so when the typechecker gets it wrong—it can’t “figure out” what a value will be—static types can feel like self-inflicted shackles.\n\nBut that is not the only perspective. There is another way—a way that puts you, the programmer, back in the driver’s seat. You make the rules, you call the shots, you set the objectives. You need not be limited any longer by what the designers of your programming language decided the typechecker can and cannot prove. You do not serve the typechecker; the typechecker serves you.\n\n…no, I’m not trying to sell you a dubious self-help book for programmers who feel like they’ve lost control of their lives. If the above sounds too good to be true, well… I won’t pretend it’s all actually as easy as I make it sound. Nevertheless, it’s well within the reach of the working programmer, and most remarkably, all it takes is a change in perspective.\n\nSeeing the types half-empty\nLet’s talk a little about TypeScript.\n\nTypeScript is a gradually-typed language, which means it’s possible to mix statically- and dynamically-typed code. The original intended use case of gradual typing was to gradually add static types to an existing dynamically-typed codebase, which imposes some interesting design constraints. For one, a valid JavaScript program must also be a valid TypeScript program; for another, TypeScript must be accommodating of traditional JavaScript idioms.\n\nGradually typed languages like TypeScript are particularly good illustrations of the way type annotations can be viewed as constraints. A function with no explicit type declarations1 can accept any JavaScript value, so adding a type annotation fundamentally restricts the set of legal values.\n\nFurthermore, languages like TypeScript tend to have subtyping. This makes it easy to classify certain types as “more restrictive” than others. For example, a type like string | number clearly includes more values than just number, so number is a more restrictive type—a subtype.\n\nAn exceptionally concrete way to illustrate this “types are restrictions” mentality is to write a function with an unnecessarily specific type. Here’s a TypeScript function that returns the first element in an array of numbers:\n\nfunction getFirst(arr: number[]): number | undefined {\n  return arr[0];\n}\nIf we ignore the type annotations and consider only the dynamic semantics of JavaScript, this function would work perfectly well given a list of strings. However, if we write getFirst([\"hello\", \"world\"]), the typechecker will complain. In this example, the restriction is thoroughly self-imposed—it would be easy to give this function a more generic type—but it’s not always that easy. For example, suppose we wrote a function where the return type depends upon the type of the argument:\n\nfunction emptyLike(val: number | string): number | string {\n  if (typeof val === \"number\") {\n    return 0;\n  } else {\n    return \"\";\n  }\n}\nNow if we write emptyLike(42) * 10, the typechecker will once again complain, claiming the result might be a string—it can’t “figure out” that when we pass a number, we always get a number back.\n\nWhen type systems are approached from this perspective, the result is often frustration. The programmer knows that the equivalent untyped JavaScript is perfectly well-behaved, so the typechecker comes off as being the highly unfortunate combination of stubborn yet dim-witted. What’s more, the programmer likely has little mental model of the typechecker’s internal operation, so when types like the above are inferred (not explicitly written), it can be unclear what solutions exist to make the error go away.\n\nAt this point, the programmer may give up. “Stupid typechecker,” they grumble, changing the return type of emptyLike to any. “If it can’t even figure this out, can it really be all that useful?”\n\nSadly, this relationship with the typechecker is all too common, and gradually-typed languages in particular tend to create a vicious cycle of frustration:\n\n\nGradual type systems are intentionally designed to “just work” on idiomatic code as much as possible, so programmers may not think much about the types except when they get type errors.\n\n\nFurthermore, many programmers using gradually-typed languages are already adept at programming in the underlying dynamically-typed language, so they have working mental models of program operation in terms of the dynamic semantics alone. They are much less likely to develop a rich mental model of the static semantics of the type system because they are used to reasoning without one.\n\n\nGradually typed languages must support idioms from their dynamically-typed heritage, so they often include ad-hoc special cases (such as, for example, special treatment of typeof checks) that obscure the rules the typechecker follows and make them seem semi-magical.\n\n\nBuiltin types are deeply blessed in the type system, strongly encouraging programmers to embrace their full flexibility, but leaving little recourse when they run up against their limits.\n\n\nAll this frustration breeds a readiness to override the typechecker using casts or any, which ultimately creates a self-fulfilling prophecy in which the typechecker rarely catches any interesting mistakes because it has been so routinely disabled.\n\n\nThe end result of all of this is a defeatist attitude that views the typechecker as a minor tooling convenience at best (i.e. a fancy autocomplete provider) or an active impediment at worst. Who can really blame them? The type system has (unintentionally of course) been designed in such a way so as to lead them into this dead end. The public perception of type systems settles into that of a strikingly literal nitpicker we endure rather than as a tool we actively leverage.\n\nTaking back types\nAfter everything I said above, it may be hard to imagine seeing types any other way. Indeed, through the lens of TypeScript, the “types are restrictions” mentality is incredibly natural, so much so that it seems self-evident. But let’s move away from TypeScript for a moment and focus on a different language, Haskell, which encourages a somewhat different perspective. If you aren’t familiar with Haskell, that’s alright—I’m going to try to keep the examples in this blog post as accessible as possible whether you’ve written any Haskell or not.\n\nThough Haskell and TypeScript are both statically-typed—and both of their type systems are fairly sophisticated—Haskell’s type system is almost completely different philosophically:\n\n\nHaskell does not have subtyping,2 which means that every value belongs to exactly one type.\n\n\nWhile JavaScript is built around a small handful of flexible builtin datatypes (booleans, numbers, strings, arrays, and objects), Haskell has essentially no blessed, built-in datatypes other than numbers. Key types such as booleans, lists, and tuples are ordinary datatypes defined in the standard library, no different from types users could define.3\n\n\nIn particular, Haskell is built around the idea that datatypes can be defined with multiple cases, and branching is done via pattern-matching (more on this shortly).\n\n\nLet’s look at a basic Haskell datatype declaration. Suppose we want to define a type that represents a season:\n\ndata Season = Spring | Summer | Fall | Winter\nIf you are familiar with TypeScript, this may look rather similar to a union type; if you’re familiar with a C-family language, this may remind you more of an enum. Both are on the right track: this defines a new type named Season with four possible values, Spring, Summer, Fall, and Winter.\n\nBut what exactly are those values?\n\n\nIn TypeScript, we’d represent this type with a union of strings, like this:\n\ntype Season = \"spring\" | \"summer\" | \"fall\" | \"winter\";\nHere, Season is a type that can be one of those four strings, but nothing else.\n\n\nIn C, we’d represent this type with an enum, like this:\n\nenum season { SPRING, SUMMER, FALL, WINTER };\nHere, SPRING, SUMMER, FALL, and WINTER are essentially defined to be global aliases for the integers 0, 1, 2, and 3, and the type enum season is essentially an alias for int.\n\n\nSo in TypeScript, the values are strings, and in C, the values are numbers. What are they in Haskell? Well… they simply are.\n\nThe Haskell declaration invents four completely new constants out of thin air, Spring, Summer, Fall, and Winter. They aren’t aliases for numbers, nor are they symbols or strings. The compiler doesn’t expose anything about how it chooses to represent these values at runtime; that’s an implementation detail. In Haskell, Spring is now a value distinct from all other values, even if someone in a different module were to also use the name Spring. Haskell type declarations let us play god, creating something from nothing.\n\nSince these values are totally unique, abstract constants, what can we actually do with them? The answer is one thing and exactly one thing: we can branch on them. For example, we can write a function that takes a Season as an argument and returns whether or not Christmas occurs during it:\n\ncontainsChristmas :: Season -> Bool\ncontainsChristmas season = case season of\n  Spring -> False\n  Summer -> True  -- southern hemisphere\n  Fall   -> False\n  Winter -> True  -- northern hemisphere\ncase expressions are, to a first approximation, a lot like C-style switch statements (though they can do a lot more than this simple example suggests). Using case, we can also define conversions from our totally unique Season constants to other types, if we want:\n\nseasonToString :: Season -> String\nseasonToString season = case season of\n  Spring -> \"spring\"\n  Summer -> \"summer\"\n  Fall   -> \"fall\"\n  Winter -> \"winter\"\nWe can also go the other way around, converting a String to a Season, but if we try, we run into a problem: what do we return for a string like, say, \"cheesecake\"? In other languages, we might throw an error or return null, but Haskell does not have null, and errors are generally reserved for truly catastrophic failures. What can we do instead?\n\nA particularly naïve solution would be to create a type called MaybeASeason that has two cases—it can be a valid Season, or it can be NotASeason:\n\ndata MaybeASeason = IsASeason Season | NotASeason\n\nstringToSeason :: String -> MaybeASeason\nstringToSeason seasonString = case seasonString of\n  \"spring\" -> IsASeason Spring\n  \"summer\" -> IsASeason Summer\n  \"fall\"   -> IsASeason Fall\n  \"winter\" -> IsASeason Winter\n  _        -> NotASeason\nThis shows a feature of Haskell datatypes that C-style enums do not have: they aren’t just constants, they can contain other values. A MaybeASeason can be one of five different values: IsASeason Spring, IsASeason Summer, IsASeason Fall, IsASeason Winter, or NotASeason.\n\nIn TypeScript, we’d write MaybeASeason more like this:\n\ntype MaybeASeason = Season | \"not-a-season\";\nThis is kind of nice, because we don’t have to wrap all our Season values with IsASeason like we have to do in Haskell. But remember that Haskell doesn’t have subtyping—every value must belong to exactly one type—so the Haskell code needs the IsASeason wrapper to distinguish the value as a MaybeASeason rather than a Season.\n\nNow, you may rightly point out that having to invent a type like MaybeASeason every time we need to create a variant of a type with a failure case is absurd, so fortunately we can define a type like MaybeASeason that works for any underlying type. In Haskell, it looks like this:\n\ndata Maybe a = Just a | Nothing\nThis defines a generic type, where the a in Maybe a is a stand-in for some other type, much like the T in Array<T> in other languages. We can change our stringToSeason function to use Maybe:\n\nstringToSeason :: String -> Maybe Season\nstringToSeason seasonString = case seasonString of\n  \"spring\" -> Just Spring\n  \"summer\" -> Just Summer\n  \"fall\"   -> Just Fall\n  \"winter\" -> Just Winter\n  _        -> Nothing\nMaybe gets us something a lot like nullable types, but it isn’t built into the type system, it’s just an ordinary type defined in the standard library.\n\nPositive versus negative space\nAt this point, you may be wondering to yourself why I am talking about all of this, seeing as everything in the previous section is information you could find in a basic Haskell tutorial. But the point of this blog post is not to teach you Haskell, it’s to focus on a particular philosophical approach to modeling data.\n\nIn TypeScript, when we write a type declaration like\n\ntype Season = \"summer\" | \"spring\" | \"fall\" | \"winter\";\nwe are defining a type that can be one of those four strings and nothing else. All the other strings that aren’t one of those four make up Season’s “negative space”—values that exist, but that we have intentionally excluded. In contrast, the Haskell type does not really have any “negative space” because we pulled four new values out of thin air.\n\nOf course, I suspect you don’t really buy this argument. What makes a string like \"cheesecake\" “negative space” in TypeScript but not in Haskell? Well… nothing, really. The distinction I’m drawing here doesn’t really exist, it’s just a different perspective, and arguably a totally contrived and arbitrary one. But now that I’ve explained the premise and set up some context, let me provide a more compelling example.\n\nSuppose you are writing a TypeScript program, and you want a function that only accepts non-empty arrays. What can you do? Your first instinct is that you need a way to somehow further restrict the function’s input type to exclude empty arrays. And indeed, there is a trick for doing that:\n\ntype NonEmptyArray<T> = [T, ...T[]];\nGreat! But what if the constraint was more complicated: what if you needed an array containing an even number of elements? Unfortunately, there isn’t really a trick for that one. At this point, you might start wishing the type system had support for something really fancy, like refinement types, so you could write something like this:\n\ntype EvenArray<T> = T[] satisfies (arr => arr.length % 2 === 0);\nBut TypeScript doesn’t support anything like that, so for now you’re stuck. You need a way to restrict the function’s domain in a way the type system does not have any special support for, so your conclusion might be “I guess the type system just can’t do this.” People tend to call this “running up against the limits of the type system.”\n\nBut what if we took a different perspective? Recall that in Haskell, lists aren’t built-in datatypes, they’re just ordinary datatypes defined in the standard library:4\n\ndata List a = Nil | Cons a (List a)\nThis type might be a bit confusing at first if you have not written any Haskell, since it’s recursive. All of these are valid values of type List Int:\n\n\nNil\n\n\nCons 1 Nil\n\n\nCons 1 (Cons 2 Nil)\n\n\nCons 1 (Cons 2 (Cons 3 Nil))\n\n\nThe recursive nature of Cons is what gives our user-defined datatype the ability to hold any number of values: we can have any number of nested Conses we want before we terminate the list with a final Nil.\n\nIf we wanted to define an EvenList type in Haskell, we might end up thinking along the same lines we did before, that we need some fancy type system extension so we can restrict List to exclude lists with odd numbers of elements. But that’s focusing on the negative space of things we want to exclude… what if instead, we focused on the positive space of things we want to include?\n\nWhat do I mean by that? Well, we could define an entirely new type that’s just like List, but we make it impossible to ever include an odd number of elements:\n\ndata EvenList a = EvenNil | EvenCons a a (EvenList a)\nHere are some valid values of type EvenList Int:\n\n\nEvenNil\n\n\nEvenCons 1 2 EvenNil\n\n\nEvenCons 1 2 (EvenCons 3 4 EvenNil)\n\n\nLo and behold, a datatype that can only ever include even numbers of elements!\n\nNow, at this point you might realize that this is kind of silly. We don’t need to invent an entirely new datatype for this! We could just create a list of pairs:\n\ntype EvenList a = List (a, a)\nNow values like Cons (1, 2) (Cons (3, 4) Nil) would be valid values of type EvenList Int, and we wouldn’t have to reinvent lists. But again, this is an approach based on thinking not on which values we want to exclude, but rather how to structure our data such that those illegal values aren’t even constructible.\n\nThis is the essence of the Haskeller’s mantra, “Make illegal states unrepresentable,” and sadly it is often misinterpreted. It’s much easier to think “hm, I want to make these states illegal, how can I add some post-hoc restrictions to rule them out?” And indeed, this is why refinement types really are awesome, and when they’re available, by all means use them! But checking totally arbitrary properties at the type level is not tractable in general, and sometimes you need to think a little more outside the box.\n\nTypes as axiom schemas\nSo far in this blog post, I’ve repeatedly touched upon a handful of different ideas in a few different ways:\n\n\nInstead of thinking about how to restrict, it can be useful to think about how to correctly construct.\n\n\nIn Haskell, datatype declarations invent new values out of thin air.\n\n\nWe can represent a lot of different data structures using the incredibly simple framework of “datatypes with several possibilities.”\n\n\nIndependently, those ideas might not seem deeply related, but in fact, they’re all essential to the Haskell school of data modeling. I want to now explore how we can unify them into a single framework that makes this seem less magical and more like an iterative design process.\n\nIn Haskell, when you define a datatype, you’re really defining a new, self-contained set of axioms and inference rules. That is rather abstract, so let’s make it more concrete. Consider the List type again:\n\ndata List a = Nil | Cons a (List a)\nViewed as an axiom schema, this type has one axiom and one inference rule:\n\n\nThe empty list is a list.\n\n\nIf you have a list, and you add an element to the beginning, the result is also a list.\n\n\nThe axiom is Nil, and the inference rule is Cons. Every list5 is constructed by starting with the axiom, Nil, followed by some number of applications of the inference rule, Cons.\n\nWe can take a similar approach when designing the EvenList type. The axiom is the same:\n\n\nThe empty list is a list with an even number of elements.\n\n\nBut our inference rule must preserve the invariant that the list always contains an even number of elements. We can do this by always adding two elements at a time:\n\n\nIf you have a list with an even number of elements, and you add two elements to the beginning, the result is also a list with an even number of elements.\n\n\nThis corresponds precisely to our EvenList declaration:\n\ndata EvenList a = EvenNil | EvenCons a a (EvenList a)\nWe can also go through this same reasoning process to come up with a type that represents non-empty lists. That type has just one inference rule:\n\n\nIf you have a list, and you add an element to the beginning, the result is a non-empty list.\n\n\nThat inference rule corresponds to the following datatype:\n\ndata NonEmptyList a = NonEmptyCons a (List a)\nOf course, it’s possible to do this with much more than just lists. A particularly classic example is the constructive definition of natural numbers:\n\n\nZero is a natural number.\n\n\nIf you have a natural number, its successor (i.e. that number plus one) is also a natural number.\n\n\nThese are two of the Peano axioms, which can be represented in Haskell as the following datatype:\n\ndata Natural = Zero | Succ Natural\nUsing this type, Zero represents 0, Succ Zero represents 1, Succ (Succ Zero) represents 2, and so on. Just as EvenList allowed us to represent any list with an even number of elements but made other values impossible to even express, this Natural type allows us to represent all natural numbers, while other numbers (such as, for example, negative integers) are impossible to express.\n\nNow, of course, all this hinges on our interpretation of the values we’ve invented! We have chosen to interpret Zero as 0 and Succ n as n + 1, but that interpretation is not inherent to Natural’s definition—it’s all in our heads! We could choose to interpret Succ n as n - 1 instead, in which case we would only be able to represent non-positive integers, or we could interpret Zero as 1 and Succ n as n * 2, in which case we could only represent powers of two.\n\nI find that people sometimes find this approach troubling, or at least counterintuitive. Is Succ (Succ Zero) really 2? It certainly doesn’t look like a number we’re used to writing. When someone thinks “I need a datatype for a number greater than or equal to zero,” they’re going to reach for the type in their programming language called number or int, not think to invent a recursive datatype. And admittedly, the Natural type defined here is not very practical: it’s an incredibly inefficient representation of natural numbers.\n\nBut in less contrived situations, this approach is practical, and in fact it’s highly useful! The quibble that an EvenList Int isn’t “really” a List Int is rather meaningless, seeing as our definition of List was just as arbitrary. A great deal of our jobs as programmers is imbuing arbitrary symbols with meaning; at some point someone decided that the number 65 would correspond to the capital letter A, and it was no less arbitrary then.\n\nSo when you have a property you want to capture in your types, take a step back and think about it for a little bit. Is there a way you can structure your data so that, no matter how you build it, the result is always a valid value? In other words, don’t try to add post-hoc restrictions to exclude bad values, make your datatypes correct by construction.\n\n“But what if I don’t write Haskell?” And other closing thoughts\nI write Haskell for a living, and I wrote this blog post with both my coworkers and the broader Haskell community in mind, but if I had only written it with those people in mind, it wouldn’t make sense to have spent so much time explaining basic Haskell. These techniques can be used in almost any statically typed programming language, though it’s certainly easier in some than others.\n\nI don’t want people to come away from this blog post with an impression that I think TypeScript is a bad language, or that I’m claiming Haskell can do things TypeScript can’t. In fact, TypeScript can do all the things I’ve talked about in this blog post! As proof, here are TypeScript definitions of both EvenList and Natural:\n\ntype EvenList<T> = [] | [T, T, EvenList<T>];\ntype Natural = \"zero\" | { succ: Natural };\nIf anything, the real point of this blog post is that a type system does not have a well-defined list of things it “can prove” and “can’t prove.” Languages like TypeScript don’t really encourage this approach to data modeling, where you restructure your values in a certain way so as to guarantee certain properties. Rather, they prefer to add increasingly sophisticated constraints and type system features that can capture the properties people want to capture without having to change their data representation.\n\nAnd in general, that’s great!\n\nBeing able to reuse the same data representation is hugely beneficial. Functions like map and filter already exist for ordinary lists/arrays, but a home-grown EvenList type needs its own versions. Passing an EvenList to a function that expects a list requires explicitly converting between the two. All these things have both code complexity and performance costs, and type system features that make these issues just invisibly disappear are obviously a good thing.\n\nBut the danger of treating the type system this way is that it means you may find yourself unsure what to do when suddenly you have a new requirement that the type system doesn’t provide built-in support for. What then? Do you start punching holes through your type system? The more you do that, the less useful the type system becomes: type systems are great at detecting how changes in one part of a codebase can impact seemingly-unrelated areas in surprising ways, but every unsafe cast or use of any is a hard stop, a point past which the typechecker cannot propagate information. Do that once or twice in a leaf function, it’s okay, but do that even just a half dozen times in your application’s connective tissue, and your type system might not be able to catch those things anymore.\n\nEven if it isn’t a technique you use every day, it’s worth getting comfortable tweaking your data representation to preserve those guarantees. It’s a magical experience having the typechecker teach you things about your domain you hadn’t even considered simply because you got a type error and started thinking through why. Yes, it’s extra work, but trust me: it’s a lot more pleasant to work for your typechecker when you know exactly how much your typechecker is working for you.\n\n\nSort of. TypeScript will try to infer type annotations based on how variables and functions are used, but by default, it falls back on the dynamic, unchecked any type if it can’t find a solution that makes the program typecheck. That behavior can be changed via a configuration option, but that isn’t relevant here: I’m just trying to illustrate a perspective, not make any kind of value judgment about TypeScript specifically.\n ↩\n\nSort of. Haskell does have a limited notion of subtyping when polymorphism is involved; for example, the type forall a. a -> a is a subtype of the type Int -> Int. But Haskell does not have anything resembling inheritance (e.g. there is no common Number supertype that includes both Int and Double) nor does it have untagged unions (e.g. the argument to a function cannot be something like Int | String, you must define a wrapper type like data IntOrString = AnInt Int | AString String).\n ↩\n\nLists, tuples, and strings do technically have special syntax, which is built into the compiler, but there is truly nothing special about their semantics. They would work exactly the same way without the syntax, the code would just look less pretty.\n ↩\n\nHaskell programmers will notice that this is not actually the definition of the list type, since the real list type uses special syntax, but I wanted to keep things as simple as possible for this blog post.\n ↩\n\nIgnoring infinite lists, but the fact that infinite lists are representable in Haskell is outside the scope of this blog post.\n ↩","isoDate":"2020-08-13T00:00:00.000Z","timestamp":"8/12/2020"},{"title":"No, dynamic type systems are not inherently more open","pubDate":"2020-01-19T00:00:00.000Z","author":"Alexis King","content":"<article><p>Internet debates about typing disciplines continue to be plagued by a pervasive myth that dynamic type systems are inherently better at modeling “open world” domains. The argument usually goes like this: the goal of static typing is to pin everything down as much as possible, but in the real world, that just isn’t practical. Real systems should be loosely coupled and worry about data representation as little as possible, so dynamic types lead to a more robust system in the large.\n</p><p>This story sounds compelling, but it isn’t true. The flaw is in the premise: static types are <em>not</em> about “classifying the world” or pinning down the structure of every value in a system. The reality is that static type systems allow specifying exactly how much a component needs to know about the structure of its inputs, and conversely, how much it doesn’t. Indeed, in practice static type systems excel at processing data with only a partially-known structure, as they can be used to ensure application logic doesn’t accidentally assume too much.\n</p><h2><a name=\"two-typing-fallacies\"></a>Two typing fallacies</h2><p>I’ve wanted to write this blog post for a while, but what finally made me decide to do it were misinformed comments responding to <a href=\"/blog/2019/11/05/parse-don-t-validate/\">my previous blog post</a>. Two comments in particular caught my eye, <a href=\"https://www.reddit.com/r/programming/comments/dt0w63/parse_dont_validate/f6ulpsy/\">the first of which was posted on /r/programming</a>:\n</p><blockquote><p>Strongly disagree with the post […] it promotes a fundamentally entangled and static view of the world. It assumes that we can or should theorize about what is \"valid\" input at the edge between the program and the world, thus introducing a strong sense of coupling through the entire software, where failure to conform to some schema will automatically crash the program.\n</p><p>This is touted as a feature here but imagine if the internet worked like this. A server changes their JSON output, and we need to recompile and reprogram the entire internet. This is the static view that is promoted as a feature here. […] The \"parser mentality\" is fundamentally rigid and global, whereas robust system design should be decentralised and leave interpretation of data to the receiver.\n</p></blockquote><p>Given the argument being made in the blog post—that you should use precise types whenever possible—one can see where this misinterpretation comes from. How could a proxy server possibly be written in such a style, since it cannot anticipate the structure of its payloads? The commenter’s conclusion is that strict static typing is at odds with programs that don’t know the structure of their inputs ahead of time.\n</p><p><a href=\"https://news.ycombinator.com/item?id=21479933\">The second comment was left on Hacker News</a>, and it is significantly shorter than the first one:\n</p><blockquote><p>What would be the type signature of, say, Python's <code>pickle.load()</code>?\n</p></blockquote><p>This is a different kind of argument, one that relies on the fact that the types of reflective operations may depend on runtime values, which makes them challenging to capture with static types. This argument suggests that static types limit expressiveness because they forbid such operations outright.\n</p><p>Both these arguments are fallacious, but in order to show why, we have to make explicit an implicit claim. The two comments focus primarily on illustrating how static type systems can’t process data of an unknown shape, but they simultaneously advance an implicit belief: that dynamically typed languages <em>can</em> process data of an unknown shape. As we’ll see, this belief is misguided; programs are not capable of processing data of a truly unknown shape regardless of typing discipline, and static type systems only make already-present assumptions explicit.\n</p><h2><a name=\"you-can-t-process-what-you-don-t-know\"></a>You can’t process what you don’t know</h2><p>The claim is simple: in a static type system, you must declare the shape of data ahead of time, but in a dynamic type system, the type can be, well, dynamic! It sounds self-evident, so much so that Rich Hickey has practically built a speaking career upon its emotional appeal. The only problem is it isn’t true.\n</p><p>The hypothetical scenario usually goes like this. Say you have a distributed system, and services in the system emit events that can be consumed by any other service that might need them. Each event is accompanied by a payload, which listening services can use to inform further action. The payload itself is minimally-structured, schemaless data encoded using a generic interchange format such as JSON or <a href=\"https://github.com/edn-format/edn\">EDN</a>.\n</p><p>As a simple example, a login service might emit an event like this one whenever a new user signs up:\n</p><pre><code class=\"pygments\"><span class=\"p\">{</span>\n  <span class=\"nt\">\"event_type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"signup\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"timestamp\"</span><span class=\"p\">:</span> <span class=\"s2\">\"2020-01-19T05:37:09Z\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"data\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"user\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"nt\">\"id\"</span><span class=\"p\">:</span> <span class=\"mi\">42</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Alyssa\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"email\"</span><span class=\"p\">:</span> <span class=\"s2\">\"alyssa@example.com\"</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre><p>Some downstream services might listen for these <code>signup</code> events and take further action whenever they are emitted. For example, a transactional email service might send a welcome email whenever a new user signs up. If the service were written in JavaScript, the handler might look something like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">const</span> <span class=\"nx\">handleEvent</span> <span class=\"o\">=</span> <span class=\"p\">({</span> <span class=\"nx\">event_type</span><span class=\"p\">,</span> <span class=\"nx\">data</span> <span class=\"p\">})</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">switch</span> <span class=\"p\">(</span><span class=\"nx\">event_type</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">case</span> <span class=\"s1\">&#39;login&#39;</span><span class=\"o\">:</span>\n      <span class=\"cm\">/* ... */</span>\n      <span class=\"k\">break</span>\n    <span class=\"k\">case</span> <span class=\"s1\">&#39;signup&#39;</span><span class=\"o\">:</span>\n      <span class=\"nx\">sendEmail</span><span class=\"p\">(</span><span class=\"nx\">data</span><span class=\"p\">.</span><span class=\"nx\">user</span><span class=\"p\">.</span><span class=\"nx\">email</span><span class=\"p\">,</span> <span class=\"sb\">`Welcome to Blockchain Emporium, </span><span class=\"si\">${</span><span class=\"nx\">data</span><span class=\"p\">.</span><span class=\"nx\">user</span><span class=\"p\">.</span><span class=\"nx\">name</span><span class=\"si\">}</span><span class=\"sb\">!`</span><span class=\"p\">)</span>\n      <span class=\"k\">break</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre><p>But what if this service were written in Haskell instead? Being good, reality-fearing Haskell programmers who <a href=\"/blog/2019/11/05/parse-don-t-validate/\">parse, not validate</a>, the Haskell code might look something like this, instead:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Event</span> <span class=\"ow\">=</span> <span class=\"kt\">Login</span> <span class=\"kt\">LoginPayload</span> <span class=\"o\">|</span> <span class=\"kt\">Signup</span> <span class=\"kt\">SignupPayload</span>\n<span class=\"kr\">data</span> <span class=\"kt\">LoginPayload</span> <span class=\"ow\">=</span> <span class=\"kt\">LoginPayload</span> <span class=\"p\">{</span> <span class=\"n\">userId</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span> <span class=\"p\">}</span>\n<span class=\"kr\">data</span> <span class=\"kt\">SignupPayload</span> <span class=\"ow\">=</span> <span class=\"kt\">SignupPayload</span>\n  <span class=\"p\">{</span> <span class=\"n\">userId</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span>\n  <span class=\"p\">,</span> <span class=\"n\">userName</span> <span class=\"ow\">::</span> <span class=\"kt\">Text</span>\n  <span class=\"p\">,</span> <span class=\"n\">userEmail</span> <span class=\"ow\">::</span> <span class=\"kt\">Text</span> <span class=\"p\">}</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">FromJSON</span> <span class=\"kt\">Event</span> <span class=\"kr\">where</span>\n  <span class=\"n\">parseJSON</span> <span class=\"ow\">=</span> <span class=\"n\">withObject</span> <span class=\"s\">\"Event\"</span> <span class=\"nf\">\\</span><span class=\"n\">obj</span> <span class=\"ow\">-&gt;</span> <span class=\"kr\">do</span>\n    <span class=\"n\">eventType</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">obj</span> <span class=\"o\">.:</span> <span class=\"s\">\"event_type\"</span>\n    <span class=\"kr\">case</span> <span class=\"n\">eventType</span> <span class=\"kr\">of</span>\n      <span class=\"s\">\"login\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Login</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"p\">(</span><span class=\"n\">obj</span> <span class=\"o\">.:</span> <span class=\"s\">\"data\"</span><span class=\"p\">)</span>\n      <span class=\"s\">\"signup\"</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Signup</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"p\">(</span><span class=\"n\">obj</span> <span class=\"o\">.:</span> <span class=\"s\">\"signup\"</span><span class=\"p\">)</span>\n      <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">fail</span> <span class=\"o\">$</span> <span class=\"s\">\"unknown event_type: \"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">eventType</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">FromJSON</span> <span class=\"kt\">LoginPayload</span> <span class=\"kr\">where</span> <span class=\"p\">{</span> <span class=\"o\">...</span> <span class=\"p\">}</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">FromJSON</span> <span class=\"kt\">SignupPayload</span> <span class=\"kr\">where</span> <span class=\"p\">{</span> <span class=\"o\">...</span> <span class=\"p\">}</span>\n\n<span class=\"nf\">handleEvent</span> <span class=\"ow\">::</span> <span class=\"kt\">JSON</span><span class=\"o\">.</span><span class=\"kt\">Value</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">handleEvent</span> <span class=\"n\">payload</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">fromJSON</span> <span class=\"n\">payload</span> <span class=\"kr\">of</span>\n  <span class=\"kt\">Success</span> <span class=\"p\">(</span><span class=\"kt\">Login</span> <span class=\"kt\">LoginPayload</span> <span class=\"p\">{</span> <span class=\"n\">userId</span> <span class=\"p\">})</span> <span class=\"ow\">-&gt;</span> <span class=\"cm\">{- ... -}</span>\n  <span class=\"kt\">Success</span> <span class=\"p\">(</span><span class=\"kt\">Signup</span> <span class=\"kt\">SignupPayload</span> <span class=\"p\">{</span> <span class=\"n\">userName</span><span class=\"p\">,</span> <span class=\"n\">userEmail</span> <span class=\"p\">})</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">sendEmail</span> <span class=\"n\">userEmail</span> <span class=\"o\">$</span> <span class=\"s\">\"Welcome to Blockchain Emporium, \"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">userName</span> <span class=\"o\">&lt;&gt;</span> <span class=\"s\">\"!\"</span>\n  <span class=\"kt\">Error</span> <span class=\"n\">message</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">fail</span> <span class=\"o\">$</span> <span class=\"s\">\"could not parse event: \"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">message</span></code></pre><p>It’s definitely more boilerplate, but some extra overhead for type definitions is to be expected (and is greatly exaggerated in such tiny examples), and the arguments we’re discussing aren’t about boilerplate, anyway. The <em>real</em> problem with this version of the code, according to the Reddit comment from earlier, is that the Haskell code has to be updated whenever a service adds a new event type! A new case has to be added to the <code>Event</code> datatype, and it must be given new parsing logic. And what about when new fields get added to the payload? What a maintenance nightmare.\n</p><p>In comparison, the JavaScript code is much more permissive. If a new event type is added, it will just fall through the <code>switch</code> and do nothing. If extra fields are added to the payload, the JavaScript code will just ignore them. Seems like a win for dynamic typing.\n</p><p>Except that no, it isn’t. The only reason the statically typed program fails if we don’t update the <code>Event</code> type is that we wrote <code>handleEvent</code> that way. We could just have easily done the same thing in the JavaScript code, adding a default case that rejects unknown event types:\n</p><pre><code class=\"pygments\"><span class=\"kr\">const</span> <span class=\"nx\">handleEvent</span> <span class=\"o\">=</span> <span class=\"p\">({</span> <span class=\"nx\">event_type</span><span class=\"p\">,</span> <span class=\"nx\">data</span> <span class=\"p\">})</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">switch</span> <span class=\"p\">(</span><span class=\"nx\">event_type</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"cm\">/* ... */</span>\n    <span class=\"k\">default</span><span class=\"o\">:</span>\n      <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nb\">Error</span><span class=\"p\">(</span><span class=\"sb\">`unknown event_type: </span><span class=\"si\">${</span><span class=\"nx\">event_type</span><span class=\"si\">}</span><span class=\"sb\">`</span><span class=\"p\">)</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span></code></pre><p>We didn’t do that, since in this case it would clearly be silly. If a service receives an event it doesn’t know about, it should just ignore it. This is a case where being permissive is clearly the correct behavior, and we can easily implement that in the Haskell code too:\n</p><pre><code class=\"pygments\"><span class=\"nf\">handleEvent</span> <span class=\"ow\">::</span> <span class=\"kt\">JSON</span><span class=\"o\">.</span><span class=\"kt\">Value</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">handleEvent</span> <span class=\"n\">payload</span> <span class=\"ow\">=</span> <span class=\"kr\">case</span> <span class=\"n\">fromJSON</span> <span class=\"n\">payload</span> <span class=\"kr\">of</span>\n  <span class=\"cm\">{- ... -}</span>\n  <span class=\"kt\">Error</span> <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span></code></pre><p>This is still in the spirit of “parse, don’t validate” because we’re still parsing the values we <em>do</em> care about as early as possible, so we don’t fall into the double-validation trap. At no point do we take a code path that depends on a value being well-formed without first ensuring (with the help of the type system) that it is, in fact, actually well-formed. We don’t have to respond to an ill-formed value by raising an error! We just have to be explicit about ignoring it.\n</p><p>This illustrates an important point: the <code>Event</code> type in this Haskell code doesn’t describe “all possible events,” it describes all the events that the application cares about. Likewise, the code that parses those events’ payloads only worries about the fields the application needs, and it ignores extraneous ones. A static type system doesn’t require you eagerly write a schema for the whole universe, it simply requires you to be up front about the things you need.\n</p><p>This turns out to have a lot of pleasant benefits even though knowledge about inputs is limited:\n</p><ul><li><p>It’s easy to discover the assumptions of the Haskell program just by looking at the type definitions. We know, for example, that this application doesn’t care about the <code>timestamp</code> field, since it never appears in any of the payload types. In the dynamically-typed program, we’d have to audit every code path to see whether or not it inspects that field, which would be a lot of error-prone work!\n</p></li><li><p>What’s more, it turns out the Haskell code doesn’t actually <em>use</em> the <code>userId</code> field inside the <code>SignupPayload</code> type, so that type is overly conservative. If we want to ensure it isn’t actually needed (since, for example, maybe we’re phasing out providing the user ID in that payload entirely), we need only delete that record field; if the code typechecks, we can be confident it really doesn’t depend on that field.\n</p></li><li><p>Finally, we neatly avoid all the gotchas related to shotgun parsing <a href=\"/blog/2019/11/05/parse-don-t-validate/#the-danger-of-validation\">mentioned in the previous blog post</a>, since we still haven’t compromised on any of those principles.\n</p></li></ul><p>We’ve already invalidated the first half of the claim: that statically typed languages can’t deal with data where the structure isn’t completely known. Let’s now look at the other half, which states that dynamically typed languages can process data where the structure isn’t known at all. Maybe that still sounds right, but if you slow down and think about it more carefully, you’ll find it can’t be.\n</p><p>The above JavaScript code makes all the same assumptions our Haskell code does: it assumes event payloads are JSON objects with an <code>event_type</code> field, and it assumes <code>signup</code> payloads include <code>data.user.name</code> and <code>data.user.email</code> fields. It certainly can’t do anything useful with truly unknown input! If a new event payload is added, our JavaScript code can’t magically adapt to handle it simply because it is dynamically typed. Dynamic typing just means the types of values are carried alongside them at runtime and checked as the program executes; the types are still there, and this program still implicitly relies on them being particular things.\n</p><h2><a name=\"keeping-opaque-data-opaque\"></a>Keeping opaque data opaque</h2><p>In the previous section, we debunked the idea that statically typed systems can’t process partially-known data, but if you have been paying close attention, you may have noticed it did not fully refute the original claim.\n</p><p>Although we were able to handle unknown data, we always simply discarded it, which would not fly if we were trying to implement some sort of proxying. For example, suppose we have a forwarding service that broadcasts events over a public network, attaching a signature to each payload to ensure it can’t be spoofed. We might implement this in JavaScript this way:\n</p><pre><code class=\"pygments\"><span class=\"kr\">const</span> <span class=\"nx\">handleEvent</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nx\">payload</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"kr\">const</span> <span class=\"nx\">signedPayload</span> <span class=\"o\">=</span> <span class=\"p\">{</span> <span class=\"p\">...</span><span class=\"nx\">payload</span><span class=\"p\">,</span> <span class=\"nx\">signature</span><span class=\"o\">:</span> <span class=\"nx\">signature</span><span class=\"p\">(</span><span class=\"nx\">payload</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n  <span class=\"nx\">retransmitEvent</span><span class=\"p\">(</span><span class=\"nx\">signedPayload</span><span class=\"p\">)</span>\n<span class=\"p\">}</span></code></pre><p>In this case, we don’t care about the structure of the payload at all (the <code>signature</code> function just works on any valid JSON object), but we still have to preserve all the information. How could we do that in a statically typed language, since a statically-typed language would have to assign the payload a precise type?\n</p><p>Once again, the answer involves rejecting the premise: there’s no need to give data a type that’s any more precise than the application needs. The same logic could be written in a straightforward way in Haskell:\n</p><pre><code class=\"pygments\"><span class=\"nf\">handleEvent</span> <span class=\"ow\">::</span> <span class=\"kt\">JSON</span><span class=\"o\">.</span><span class=\"kt\">Value</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">handleEvent</span> <span class=\"p\">(</span><span class=\"kt\">Object</span> <span class=\"n\">payload</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"kr\">let</span> <span class=\"n\">signedPayload</span> <span class=\"ow\">=</span> <span class=\"kt\">Map</span><span class=\"o\">.</span><span class=\"n\">insert</span> <span class=\"s\">\"signature\"</span> <span class=\"p\">(</span><span class=\"n\">signature</span> <span class=\"n\">payload</span><span class=\"p\">)</span> <span class=\"n\">payload</span>\n  <span class=\"n\">retransmitEvent</span> <span class=\"n\">signedPayload</span>\n<span class=\"nf\">handleEvent</span> <span class=\"n\">payload</span> <span class=\"ow\">=</span> <span class=\"n\">fail</span> <span class=\"o\">$</span> <span class=\"s\">\"event payload was not an object \"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">show</span> <span class=\"n\">payload</span></code></pre><p>In this case, since we don’t care about the structure of the payload, we manipulate a value of type <code>JSON.Value</code> directly. This type is extremely imprecise compared to our <code>Event</code> type from earlier—it can hold any legal JSON value, of any shape—but in this case, we <em>want</em> it to be imprecise.\n</p><p>Thanks to that imprecision, the type system helped us here: it caught the fact that we’re assuming the payload is a JSON object, not some other JSON value, and it made us handle the non-object cases explicitly. In this case we chose to raise an error, but of course, as before, you could choose some other form of recovery if you wanted to. You just have to be explicit about it.\n</p><p>Once more, note that the assumption we were forced to make explicit in Haskell is <em>also</em> made by the JavaScript code! If our JavaScript <code>handleEvent</code> function were called with a string rather than an object, it’s unlikely the behavior would be desirable, since an object spread on a string results in the following surprise:\n</p><pre><code class=\"pygments\"><span class=\"o\">&gt;</span> <span class=\"p\">{</span> <span class=\"p\">...</span><span class=\"s2\">\"payload\"</span><span class=\"p\">,</span> <span class=\"nx\">signature</span><span class=\"o\">:</span> <span class=\"s2\">\"sig\"</span> <span class=\"p\">}</span>\n<span class=\"p\">{</span><span class=\"mi\">0</span><span class=\"o\">:</span> <span class=\"s2\">\"p\"</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"o\">:</span> <span class=\"s2\">\"a\"</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"o\">:</span> <span class=\"s2\">\"y\"</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"o\">:</span> <span class=\"s2\">\"l\"</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"o\">:</span> <span class=\"s2\">\"o\"</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"o\">:</span> <span class=\"s2\">\"a\"</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"o\">:</span> <span class=\"s2\">\"d\"</span><span class=\"p\">,</span> <span class=\"nx\">signature</span><span class=\"o\">:</span> <span class=\"s2\">\"sig\"</span><span class=\"p\">}</span></code></pre><p>Oops. Once again, the parsing style of programming has helped us out, since if we didn’t “parse” the JSON value into an object by matching on the <code>Object</code> case explicitly, our code would not compile, and if we left off the fallthrough case, we’d get a warning about inexhaustive patterns.\n</p><hr/><p>Let’s look at one more example of this phenomenon before moving on. Suppose we’re consuming an API that returns user IDs, and suppose those IDs happen to be UUIDs. A straightforward interpretation of “parse, don’t validate” might suggest we represent user IDs in our Haskell API client using a <code>UUID</code> type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">UserId</span> <span class=\"ow\">=</span> <span class=\"kt\">UUID</span></code></pre><p>However, our Reddit commenter would likely take umbrage with this! Unless the API contract explicitly states that all user IDs will be UUIDs, this representation is overstepping our bounds. Although user IDs might be UUIDs today, perhaps they won’t be tomorrow, and then our code would break for no reason! Is this the fault of static type systems?\n</p><p>Again, the answer is no. This is a case of improper data modeling, but the static type system is not at fault—it has simply been misused. The appropriate way to represent a <code>UserId</code> is to define a new, opaque type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">UserId</span> <span class=\"ow\">=</span> <span class=\"kt\">UserId</span> <span class=\"kt\">Text</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Eq</span><span class=\"p\">,</span> <span class=\"kt\">FromJSON</span><span class=\"p\">,</span> <span class=\"kt\">ToJSON</span><span class=\"p\">)</span></code></pre><p>Unlike the type alias defined above which simply creates a new name for the existing <code>UUID</code> type, this declaration creates a totally new <code>UserId</code> type that is distinct from all other types, including <code>Text</code>. If we keep the datatype’s constructor private (that is, we don’t export it from the module that defines this type), then the <em>only</em> way to produce a <code>UserId</code> will be to go through its <code>FromJSON</code> parser. Dually, the only things you can do with a <code>UserId</code> are compare it with other <code>UserId</code>s for equality or serialize it using the <code>ToJSON</code> instance. Nothing else is permitted: the type system will prevent you from depending on the remote service’s internal representation of user IDs.\n</p><p>This illustrates another way that static type systems can provide strong, useful guarantees when manipulating completely opaque data. The runtime representation of a <code>UserId</code> is really just a string, but the type system does not allow you to accidentally use it like it’s a string, nor does it allow you to forge a new <code>UserId</code> out of thin air from an arbitrary string.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup>\n</p><p>The type system is not a ball and chain forcing you to describe the representation of every value that enters and leaves your program in exquisite detail. Rather, it’s a tool that you can use in whatever way best suits your needs.\n</p><h2><a name=\"reflection-is-not-special\"></a>Reflection is not special</h2><p>We’ve now thoroughly debunked the claims made by the first commenter, but the question posed by the second commenter may still seem like a loophole in our logic. What <em>is</em> the type of Python’s <code>pickle.load()</code>? For those unfamiliar, <a href=\"https://docs.python.org/3/library/pickle.html\">Python’s cutely-named <code>pickle</code> library</a> allows serializing and deserializing entire Python object graphs. Any object can be serialized and stored in a file using <code>pickle.dump()</code>, and it can be deserialized at a later point in time using <code>pickle.load()</code>.\n</p><p>What makes this appear challenging to our static type system is that the type of value produced by <code>pickle.load()</code> is difficult to predict—it depends entirely on whatever happened to be written to that file using <code>pickle.dump()</code>. This seems inherently dynamic, since we cannot possibly know what type of value it will produce at compile-time. At first blush, this is something a dynamically typed system can pull off, but a statically-typed one just can’t.\n</p><p>However, it turns out this situation is actually identical to the previous examples using JSON, and the fact that Python’s pickling serializes native Python objects directly does not change things. Why? Well, consider what happens <em>after</em> a program calls <code>pickle.load()</code>. Say you write the following function:\n</p><pre><code class=\"pygments\"><span class=\"k\">def</span> <span class=\"nf\">load_value</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">):</span>\n  <span class=\"n\">val</span> <span class=\"o\">=</span> <span class=\"n\">pickle</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n  <span class=\"c1\"># do something with `val`</span></code></pre><p>The trouble is that <code>val</code> can now be of <em>any</em> type, and just as you can’t do anything useful with truly unknown, unstructured input, you can’t do anything with a value unless you know at least something about it. If you call any method or access any field on the result, then you’ve already made an assumption about what sort of thing <code>pickle.load(f)</code> returned—and it turns out those assumptions <em>are</em> <code>val</code>’s type!\n</p><p>For example, imagine the only thing you do with <code>val</code> is call the <code>val.foo()</code> method and return its result, which is expected to be a string. If we were writing Java, then the expected type of <code>val</code> would be quite straightforward—we’d expect it to be an instance of the following interface:\n</p><pre><code class=\"pygments\"><span class=\"kd\">interface</span> <span class=\"nc\">Foo</span> <span class=\"kd\">extends</span> <span class=\"n\">Serializable</span> <span class=\"o\">{</span>\n  <span class=\"n\">String</span> <span class=\"nf\">foo</span><span class=\"o\">();</span>\n<span class=\"o\">}</span></code></pre><p>And indeed, it turns out a <code>pickle.load()</code>-like function can be given a perfectly reasonable type in Java:\n</p><pre><code class=\"pygments\"><span class=\"kd\">static</span> <span class=\"o\">&lt;</span><span class=\"n\">T</span> <span class=\"kd\">extends</span> <span class=\"n\">Serializable</span><span class=\"o\">&gt;</span> <span class=\"n\">Optional</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"o\">&gt;</span> <span class=\"nf\">load</span><span class=\"o\">(</span><span class=\"n\">InputStream</span> <span class=\"n\">in</span><span class=\"o\">,</span> <span class=\"n\">Class</span><span class=\"o\">&lt;?</span> <span class=\"kd\">extends</span> <span class=\"n\">T</span><span class=\"o\">&gt;</span> <span class=\"n\">cls</span><span class=\"o\">);</span></code></pre><p>Nitpickers will complain that this isn’t the same as <code>pickle.load()</code>, since you have to pass a <code>Class&lt;T&gt;</code> token to choose what type of thing you want ahead of time. However, nothing is stopping you from passing <code>Serializable.class</code> and branching on the type later, after the object has been loaded. And that’s the key point: the instant you do <em>anything</em> with the object, you must know something about its type, even in a dynamically typed language! The statically-typed language just forces you to be more explicit about it, just as it did when we were talking about JSON payloads.\n</p><hr/><p>Can we do this in Haskell, too? Absolutely—we can use <a href=\"https://hackage.haskell.org/package/serialise\">the <code>serialise</code> library</a>, which has a similar API to the Java one mentioned above. It also happens to have a very similar interface to <a href=\"https://hackage.haskell.org/package/aeson\">the Haskell JSON library, aeson</a>, as it turns out the problem of dealing with unknown JSON data is not terribly different from dealing with an unknown Haskell value—at some point, you have to do a little bit of parsing to do anything with the value.\n</p><p>That said, while you <em>can</em> emulate the dynamic typing of <code>pickle.load()</code> if you really want to by deferring the type check until the last possible moment, the reality is that doing so is almost never actually useful. At some point, you have to make assumptions about the structure of the value in order to use it, and you know what those assumptions are because <em>you wrote the code</em>. While there are extremely rare exceptions to this that require true dynamic code loading (such as, say, implementing a REPL for your programming language), they do not occur in day-to-day programming, and programmers in statically-typed languages are perfectly happy to supply their assumptions up front.\n</p><p>This is one of the fundamental disconnects between the static typing camp and the dynamic typing camp. Programmers working in statically-typed languages are perplexed when a programmer suggests they can do something in a dynamically typed language that a statically-typed language “fundamentally” prevents, since a programmer in a statically-typed language may reply the value has simply not been given a sufficiently precise type. From the perspective of a programmer working in a dynamically-typed language, the type system restricts the space of legal behaviors, but from the perspective of a programmer working in a statically-typed language, the set of legal behaviors <em>is</em> a value’s type.\n</p><p>Neither of these perspectives are actually inaccurate, from the appropriate point of view. Static type systems <em>do</em> impose restrictions on program structure, as it is provably impossible to reject <em>all</em> bad programs in a Turing-complete language without also rejecting some good ones (this is <a href=\"https://en.wikipedia.org/wiki/Rice's_theorem\">Rice’s theorem</a>). But it is simultaneously true that the impossibility of solving the general problem does not preclude solving a slightly more restricted version of the problem in a useful way, and a lot of the so-called “fundamental” inabilities of static type systems are not fundamental at all.\n</p><h2><a name=\"appendix-the-reality-behind-the-myths\"></a>Appendix: the reality behind the myths</h2><p>The key thesis of this blog post has now been delivered: static type systems are not fundamentally worse than dynamic type systems at processing data with an open or partially-known structure. The sorts of claims made in the comments cited at the beginning of this blog post are not accurate depictions of what statically-typed program construction is like, and they misunderstand the limitations of static typing disciplines while exaggerating the capabilities of dynamically typed disciplines.\n</p><p>However, although greatly exaggerated, these myths do have some basis in reality. They appear to have developed at least in part from a misunderstanding about the differences between structural and nominal typing. This difference is unfortunately too big to address in this blog post, as it could likely fill several blog posts of its own. About six months ago I attempted to write a blog post on the subject, but I didn’t think it came out very compelling, so I scrapped it. Maybe someday I’ll find a better way to communicate the ideas.\n</p><p>Although I can’t give it the full treatment it deserves right now, I’d still like to touch on the idea briefly so that interested readers may be able to find other resources on the subject should they wish to do so. The key idea is that many dynamically typed languages idiomatically reuse simple data structures like hashmaps to represent what in statically-typed languages are often represented by bespoke datatypes (usually defined as classes or structs).\n</p><p>These two styles facilitate very different flavors of programming. A JavaScript or Clojure program may represent a record as a hashmap from string or symbol keys to values, written using object or hash literals and manipulated using ordinary functions from the standard library that manipulate keys and values in a generic way. This makes it straightforward to take two records and union their fields or to take an arbitrary (or even dynamic) subselection of fields from an existing record.\n</p><p>In contrast, most static type systems do not allow such free-form manipulation of records because records are not maps at all but unique types distinct from all other types. These types are uniquely identified by their (fully-qualified) name, hence the term <em>nominal typing</em>. If you wish to take a subselection of a struct’s fields, you must define an entirely new struct; doing this often creates an explosion of awkward boilerplate.\n</p><p>This is one of the main ideas that Rich Hickey has discussed in many of his talks that criticize static typing. He has advanced the idea that this ability to fluidly merge, separate, and transform records makes dynamic typing particularly suited to the domain of distributed, open systems. Unfortunately, this rhetoric has two significant flaws:\n</p><ol><li><p>It skirts too close to calling this a fundamental limitation of type systems, suggesting that it is not simply inconvenient but <em>impossible</em> to model such systems in a nominal, static type system. Not only is this not true (as this blog post has demonstrated), it misdirects people away from the point of his that actually has value: the practical, pragmatic advantage of a more structural approach to data modeling.\n</p></li><li><p>It confuses the structural/nominal distinction with the dynamic/static distinction, incorrectly creating the impression that the fluid merging and splitting of records represented as key-value maps is only possible in a dynamically typed language. In fact, not only can statically-typed languages support structural typing, many dynamically-typed languages also support nominal typing. These axes have historically loosely correlated, but they are theoretically orthogonal.\n</p></li></ol><p>For counterexamples to these claims, consider Python classes, which are quite nominal despite being dynamic, and TypeScript interfaces, which are structural despite being static. Indeed, modern statically-typed languages are increasingly acquiring native support for structurally-typed records. In these systems, record types work much like hashes in Clojure—they are not distinct, named types but rather anonymous collections of key-value pairs—and they support many of the same expressive manipulation operations that Clojure’s hashes do, all within a statically-typed framework.\n</p><p>If you are interested in exploring static type systems with strong support for structural typing, I would recommend taking a look at any of TypeScript, Flow, PureScript, Elm, OCaml, or Reason, all of which have some sort of support for structurally typed records. What I would <em>not</em> recommend for this purpose is Haskell, which has abysmal support for structural typing; Haskell is (for various reasons outside the scope of this blog post) aggressively nominal.<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup>\n</p><p>Does this mean Haskell is bad, or that it cannot be practically used to solve these kinds of problems? No, certainly not; there are many ways to model these problems in Haskell that work well enough, though some of them suffer from significant boilerplate. The core thesis of this blog post applies just as much to Haskell as it does to any of the other languages I mentioned above. However, I would be remiss not to mention this distinction, as it may give programmers from a dynamically-typed background who have historically found statically-typed languages much more frustrating to work with a better understanding of the <em>real</em> reason they feel that way. (Essentially all mainstream, statically-typed OOP languages are even more nominal than Haskell!)\n</p><p>As closing thoughts: this blog post is not intended to start a flame war, nor is it intended to be an assault on dynamically typed programming. There are many patterns in dynamically-typed languages that are genuinely difficult to translate into a statically-typed context, and I think discussions of those patterns can be productive. The purpose of this blog post is to clarify why one particular discussion is <em>not</em> productive, so please: stop making these arguments. There are much more productive conversations to have about typing than this.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Technically, you could abuse the <code>FromJSON</code> instance to convert an arbitrary string to a <code>UserId</code>, but this would not be as easy as it sounds, since <code>fromJSON</code> can fail. This means you’d somehow have to handle that failure case, so this trick would be unlikely to get you very far unless you’re already in a context where you’re doing input parsing… at which point it would be easier to just do the right thing. So yes, the type system doesn’t prevent you from going out of your way to shoot yourself in the foot, but it guides you towards the right solution (and there is no safeguard in existence that can completely protect a programmer from making their own life miserable if they are determined to do so).\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>I consider this to be Haskell’s most significant flaw at the time of this writing.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li></ol></article>","contentSnippet":"Internet debates about typing disciplines continue to be plagued by a pervasive myth that dynamic type systems are inherently better at modeling “open world” domains. The argument usually goes like this: the goal of static typing is to pin everything down as much as possible, but in the real world, that just isn’t practical. Real systems should be loosely coupled and worry about data representation as little as possible, so dynamic types lead to a more robust system in the large.\n\nThis story sounds compelling, but it isn’t true. The flaw is in the premise: static types are not about “classifying the world” or pinning down the structure of every value in a system. The reality is that static type systems allow specifying exactly how much a component needs to know about the structure of its inputs, and conversely, how much it doesn’t. Indeed, in practice static type systems excel at processing data with only a partially-known structure, as they can be used to ensure application logic doesn’t accidentally assume too much.\n\nTwo typing fallacies\nI’ve wanted to write this blog post for a while, but what finally made me decide to do it were misinformed comments responding to my previous blog post. Two comments in particular caught my eye, the first of which was posted on /r/programming:\n\nStrongly disagree with the post […] it promotes a fundamentally entangled and static view of the world. It assumes that we can or should theorize about what is \"valid\" input at the edge between the program and the world, thus introducing a strong sense of coupling through the entire software, where failure to conform to some schema will automatically crash the program.\n\nThis is touted as a feature here but imagine if the internet worked like this. A server changes their JSON output, and we need to recompile and reprogram the entire internet. This is the static view that is promoted as a feature here. […] The \"parser mentality\" is fundamentally rigid and global, whereas robust system design should be decentralised and leave interpretation of data to the receiver.\n\nGiven the argument being made in the blog post—that you should use precise types whenever possible—one can see where this misinterpretation comes from. How could a proxy server possibly be written in such a style, since it cannot anticipate the structure of its payloads? The commenter’s conclusion is that strict static typing is at odds with programs that don’t know the structure of their inputs ahead of time.\n\nThe second comment was left on Hacker News, and it is significantly shorter than the first one:\n\nWhat would be the type signature of, say, Python's pickle.load()?\n\nThis is a different kind of argument, one that relies on the fact that the types of reflective operations may depend on runtime values, which makes them challenging to capture with static types. This argument suggests that static types limit expressiveness because they forbid such operations outright.\n\nBoth these arguments are fallacious, but in order to show why, we have to make explicit an implicit claim. The two comments focus primarily on illustrating how static type systems can’t process data of an unknown shape, but they simultaneously advance an implicit belief: that dynamically typed languages can process data of an unknown shape. As we’ll see, this belief is misguided; programs are not capable of processing data of a truly unknown shape regardless of typing discipline, and static type systems only make already-present assumptions explicit.\n\nYou can’t process what you don’t know\nThe claim is simple: in a static type system, you must declare the shape of data ahead of time, but in a dynamic type system, the type can be, well, dynamic! It sounds self-evident, so much so that Rich Hickey has practically built a speaking career upon its emotional appeal. The only problem is it isn’t true.\n\nThe hypothetical scenario usually goes like this. Say you have a distributed system, and services in the system emit events that can be consumed by any other service that might need them. Each event is accompanied by a payload, which listening services can use to inform further action. The payload itself is minimally-structured, schemaless data encoded using a generic interchange format such as JSON or EDN.\n\nAs a simple example, a login service might emit an event like this one whenever a new user signs up:\n\n{\n  \"event_type\": \"signup\",\n  \"timestamp\": \"2020-01-19T05:37:09Z\",\n  \"data\": {\n    \"user\": {\n      \"id\": 42,\n      \"name\": \"Alyssa\",\n      \"email\": \"alyssa@example.com\"\n    }\n  }\n}\nSome downstream services might listen for these signup events and take further action whenever they are emitted. For example, a transactional email service might send a welcome email whenever a new user signs up. If the service were written in JavaScript, the handler might look something like this:\n\nconst handleEvent = ({ event_type, data }) => {\n  switch (event_type) {\n    case 'login':\n      /* ... */\n      break\n    case 'signup':\n      sendEmail(data.user.email, `Welcome to Blockchain Emporium, ${data.user.name}!`)\n      break\n  }\n}\nBut what if this service were written in Haskell instead? Being good, reality-fearing Haskell programmers who parse, not validate, the Haskell code might look something like this, instead:\n\ndata Event = Login LoginPayload | Signup SignupPayload\ndata LoginPayload = LoginPayload { userId :: Int }\ndata SignupPayload = SignupPayload\n  { userId :: Int\n  , userName :: Text\n  , userEmail :: Text }\n\ninstance FromJSON Event where\n  parseJSON = withObject \"Event\" \\obj -> do\n    eventType <- obj .: \"event_type\"\n    case eventType of\n      \"login\" -> Login <$> (obj .: \"data\")\n      \"signup\" -> Signup <$> (obj .: \"signup\")\n      _ -> fail $ \"unknown event_type: \" <> eventType\n\ninstance FromJSON LoginPayload where { ... }\ninstance FromJSON SignupPayload where { ... }\n\nhandleEvent :: JSON.Value -> IO ()\nhandleEvent payload = case fromJSON payload of\n  Success (Login LoginPayload { userId }) -> {- ... -}\n  Success (Signup SignupPayload { userName, userEmail }) ->\n    sendEmail userEmail $ \"Welcome to Blockchain Emporium, \" <> userName <> \"!\"\n  Error message -> fail $ \"could not parse event: \" <> message\nIt’s definitely more boilerplate, but some extra overhead for type definitions is to be expected (and is greatly exaggerated in such tiny examples), and the arguments we’re discussing aren’t about boilerplate, anyway. The real problem with this version of the code, according to the Reddit comment from earlier, is that the Haskell code has to be updated whenever a service adds a new event type! A new case has to be added to the Event datatype, and it must be given new parsing logic. And what about when new fields get added to the payload? What a maintenance nightmare.\n\nIn comparison, the JavaScript code is much more permissive. If a new event type is added, it will just fall through the switch and do nothing. If extra fields are added to the payload, the JavaScript code will just ignore them. Seems like a win for dynamic typing.\n\nExcept that no, it isn’t. The only reason the statically typed program fails if we don’t update the Event type is that we wrote handleEvent that way. We could just have easily done the same thing in the JavaScript code, adding a default case that rejects unknown event types:\n\nconst handleEvent = ({ event_type, data }) => {\n  switch (event_type) {\n    /* ... */\n    default:\n      throw new Error(`unknown event_type: ${event_type}`)\n  }\n}\nWe didn’t do that, since in this case it would clearly be silly. If a service receives an event it doesn’t know about, it should just ignore it. This is a case where being permissive is clearly the correct behavior, and we can easily implement that in the Haskell code too:\n\nhandleEvent :: JSON.Value -> IO ()\nhandleEvent payload = case fromJSON payload of\n  {- ... -}\n  Error _ -> pure ()\nThis is still in the spirit of “parse, don’t validate” because we’re still parsing the values we do care about as early as possible, so we don’t fall into the double-validation trap. At no point do we take a code path that depends on a value being well-formed without first ensuring (with the help of the type system) that it is, in fact, actually well-formed. We don’t have to respond to an ill-formed value by raising an error! We just have to be explicit about ignoring it.\n\nThis illustrates an important point: the Event type in this Haskell code doesn’t describe “all possible events,” it describes all the events that the application cares about. Likewise, the code that parses those events’ payloads only worries about the fields the application needs, and it ignores extraneous ones. A static type system doesn’t require you eagerly write a schema for the whole universe, it simply requires you to be up front about the things you need.\n\nThis turns out to have a lot of pleasant benefits even though knowledge about inputs is limited:\n\n\nIt’s easy to discover the assumptions of the Haskell program just by looking at the type definitions. We know, for example, that this application doesn’t care about the timestamp field, since it never appears in any of the payload types. In the dynamically-typed program, we’d have to audit every code path to see whether or not it inspects that field, which would be a lot of error-prone work!\n\n\nWhat’s more, it turns out the Haskell code doesn’t actually use the userId field inside the SignupPayload type, so that type is overly conservative. If we want to ensure it isn’t actually needed (since, for example, maybe we’re phasing out providing the user ID in that payload entirely), we need only delete that record field; if the code typechecks, we can be confident it really doesn’t depend on that field.\n\n\nFinally, we neatly avoid all the gotchas related to shotgun parsing mentioned in the previous blog post, since we still haven’t compromised on any of those principles.\n\n\nWe’ve already invalidated the first half of the claim: that statically typed languages can’t deal with data where the structure isn’t completely known. Let’s now look at the other half, which states that dynamically typed languages can process data where the structure isn’t known at all. Maybe that still sounds right, but if you slow down and think about it more carefully, you’ll find it can’t be.\n\nThe above JavaScript code makes all the same assumptions our Haskell code does: it assumes event payloads are JSON objects with an event_type field, and it assumes signup payloads include data.user.name and data.user.email fields. It certainly can’t do anything useful with truly unknown input! If a new event payload is added, our JavaScript code can’t magically adapt to handle it simply because it is dynamically typed. Dynamic typing just means the types of values are carried alongside them at runtime and checked as the program executes; the types are still there, and this program still implicitly relies on them being particular things.\n\nKeeping opaque data opaque\nIn the previous section, we debunked the idea that statically typed systems can’t process partially-known data, but if you have been paying close attention, you may have noticed it did not fully refute the original claim.\n\nAlthough we were able to handle unknown data, we always simply discarded it, which would not fly if we were trying to implement some sort of proxying. For example, suppose we have a forwarding service that broadcasts events over a public network, attaching a signature to each payload to ensure it can’t be spoofed. We might implement this in JavaScript this way:\n\nconst handleEvent = (payload) => {\n  const signedPayload = { ...payload, signature: signature(payload) }\n  retransmitEvent(signedPayload)\n}\nIn this case, we don’t care about the structure of the payload at all (the signature function just works on any valid JSON object), but we still have to preserve all the information. How could we do that in a statically typed language, since a statically-typed language would have to assign the payload a precise type?\n\nOnce again, the answer involves rejecting the premise: there’s no need to give data a type that’s any more precise than the application needs. The same logic could be written in a straightforward way in Haskell:\n\nhandleEvent :: JSON.Value -> IO ()\nhandleEvent (Object payload) = do\n  let signedPayload = Map.insert \"signature\" (signature payload) payload\n  retransmitEvent signedPayload\nhandleEvent payload = fail $ \"event payload was not an object \" <> show payload\nIn this case, since we don’t care about the structure of the payload, we manipulate a value of type JSON.Value directly. This type is extremely imprecise compared to our Event type from earlier—it can hold any legal JSON value, of any shape—but in this case, we want it to be imprecise.\n\nThanks to that imprecision, the type system helped us here: it caught the fact that we’re assuming the payload is a JSON object, not some other JSON value, and it made us handle the non-object cases explicitly. In this case we chose to raise an error, but of course, as before, you could choose some other form of recovery if you wanted to. You just have to be explicit about it.\n\nOnce more, note that the assumption we were forced to make explicit in Haskell is also made by the JavaScript code! If our JavaScript handleEvent function were called with a string rather than an object, it’s unlikely the behavior would be desirable, since an object spread on a string results in the following surprise:\n\n> { ...\"payload\", signature: \"sig\" }\n{0: \"p\", 1: \"a\", 2: \"y\", 3: \"l\", 4: \"o\", 5: \"a\", 6: \"d\", signature: \"sig\"}\nOops. Once again, the parsing style of programming has helped us out, since if we didn’t “parse” the JSON value into an object by matching on the Object case explicitly, our code would not compile, and if we left off the fallthrough case, we’d get a warning about inexhaustive patterns.\n\nLet’s look at one more example of this phenomenon before moving on. Suppose we’re consuming an API that returns user IDs, and suppose those IDs happen to be UUIDs. A straightforward interpretation of “parse, don’t validate” might suggest we represent user IDs in our Haskell API client using a UUID type:\n\ntype UserId = UUID\nHowever, our Reddit commenter would likely take umbrage with this! Unless the API contract explicitly states that all user IDs will be UUIDs, this representation is overstepping our bounds. Although user IDs might be UUIDs today, perhaps they won’t be tomorrow, and then our code would break for no reason! Is this the fault of static type systems?\n\nAgain, the answer is no. This is a case of improper data modeling, but the static type system is not at fault—it has simply been misused. The appropriate way to represent a UserId is to define a new, opaque type:\n\nnewtype UserId = UserId Text\n  deriving (Eq, FromJSON, ToJSON)\nUnlike the type alias defined above which simply creates a new name for the existing UUID type, this declaration creates a totally new UserId type that is distinct from all other types, including Text. If we keep the datatype’s constructor private (that is, we don’t export it from the module that defines this type), then the only way to produce a UserId will be to go through its FromJSON parser. Dually, the only things you can do with a UserId are compare it with other UserIds for equality or serialize it using the ToJSON instance. Nothing else is permitted: the type system will prevent you from depending on the remote service’s internal representation of user IDs.\n\nThis illustrates another way that static type systems can provide strong, useful guarantees when manipulating completely opaque data. The runtime representation of a UserId is really just a string, but the type system does not allow you to accidentally use it like it’s a string, nor does it allow you to forge a new UserId out of thin air from an arbitrary string.1\n\nThe type system is not a ball and chain forcing you to describe the representation of every value that enters and leaves your program in exquisite detail. Rather, it’s a tool that you can use in whatever way best suits your needs.\n\nReflection is not special\nWe’ve now thoroughly debunked the claims made by the first commenter, but the question posed by the second commenter may still seem like a loophole in our logic. What is the type of Python’s pickle.load()? For those unfamiliar, Python’s cutely-named pickle library allows serializing and deserializing entire Python object graphs. Any object can be serialized and stored in a file using pickle.dump(), and it can be deserialized at a later point in time using pickle.load().\n\nWhat makes this appear challenging to our static type system is that the type of value produced by pickle.load() is difficult to predict—it depends entirely on whatever happened to be written to that file using pickle.dump(). This seems inherently dynamic, since we cannot possibly know what type of value it will produce at compile-time. At first blush, this is something a dynamically typed system can pull off, but a statically-typed one just can’t.\n\nHowever, it turns out this situation is actually identical to the previous examples using JSON, and the fact that Python’s pickling serializes native Python objects directly does not change things. Why? Well, consider what happens after a program calls pickle.load(). Say you write the following function:\n\ndef load_value(f):\n  val = pickle.load(f)\n  # do something with `val`\nThe trouble is that val can now be of any type, and just as you can’t do anything useful with truly unknown, unstructured input, you can’t do anything with a value unless you know at least something about it. If you call any method or access any field on the result, then you’ve already made an assumption about what sort of thing pickle.load(f) returned—and it turns out those assumptions are val’s type!\n\nFor example, imagine the only thing you do with val is call the val.foo() method and return its result, which is expected to be a string. If we were writing Java, then the expected type of val would be quite straightforward—we’d expect it to be an instance of the following interface:\n\ninterface Foo extends Serializable {\n  String foo();\n}\nAnd indeed, it turns out a pickle.load()-like function can be given a perfectly reasonable type in Java:\n\nstatic <T extends Serializable> Optional<T> load(InputStream in, Class<? extends T> cls);\nNitpickers will complain that this isn’t the same as pickle.load(), since you have to pass a Class<T> token to choose what type of thing you want ahead of time. However, nothing is stopping you from passing Serializable.class and branching on the type later, after the object has been loaded. And that’s the key point: the instant you do anything with the object, you must know something about its type, even in a dynamically typed language! The statically-typed language just forces you to be more explicit about it, just as it did when we were talking about JSON payloads.\n\nCan we do this in Haskell, too? Absolutely—we can use the serialise library, which has a similar API to the Java one mentioned above. It also happens to have a very similar interface to the Haskell JSON library, aeson, as it turns out the problem of dealing with unknown JSON data is not terribly different from dealing with an unknown Haskell value—at some point, you have to do a little bit of parsing to do anything with the value.\n\nThat said, while you can emulate the dynamic typing of pickle.load() if you really want to by deferring the type check until the last possible moment, the reality is that doing so is almost never actually useful. At some point, you have to make assumptions about the structure of the value in order to use it, and you know what those assumptions are because you wrote the code. While there are extremely rare exceptions to this that require true dynamic code loading (such as, say, implementing a REPL for your programming language), they do not occur in day-to-day programming, and programmers in statically-typed languages are perfectly happy to supply their assumptions up front.\n\nThis is one of the fundamental disconnects between the static typing camp and the dynamic typing camp. Programmers working in statically-typed languages are perplexed when a programmer suggests they can do something in a dynamically typed language that a statically-typed language “fundamentally” prevents, since a programmer in a statically-typed language may reply the value has simply not been given a sufficiently precise type. From the perspective of a programmer working in a dynamically-typed language, the type system restricts the space of legal behaviors, but from the perspective of a programmer working in a statically-typed language, the set of legal behaviors is a value’s type.\n\nNeither of these perspectives are actually inaccurate, from the appropriate point of view. Static type systems do impose restrictions on program structure, as it is provably impossible to reject all bad programs in a Turing-complete language without also rejecting some good ones (this is Rice’s theorem). But it is simultaneously true that the impossibility of solving the general problem does not preclude solving a slightly more restricted version of the problem in a useful way, and a lot of the so-called “fundamental” inabilities of static type systems are not fundamental at all.\n\nAppendix: the reality behind the myths\nThe key thesis of this blog post has now been delivered: static type systems are not fundamentally worse than dynamic type systems at processing data with an open or partially-known structure. The sorts of claims made in the comments cited at the beginning of this blog post are not accurate depictions of what statically-typed program construction is like, and they misunderstand the limitations of static typing disciplines while exaggerating the capabilities of dynamically typed disciplines.\n\nHowever, although greatly exaggerated, these myths do have some basis in reality. They appear to have developed at least in part from a misunderstanding about the differences between structural and nominal typing. This difference is unfortunately too big to address in this blog post, as it could likely fill several blog posts of its own. About six months ago I attempted to write a blog post on the subject, but I didn’t think it came out very compelling, so I scrapped it. Maybe someday I’ll find a better way to communicate the ideas.\n\nAlthough I can’t give it the full treatment it deserves right now, I’d still like to touch on the idea briefly so that interested readers may be able to find other resources on the subject should they wish to do so. The key idea is that many dynamically typed languages idiomatically reuse simple data structures like hashmaps to represent what in statically-typed languages are often represented by bespoke datatypes (usually defined as classes or structs).\n\nThese two styles facilitate very different flavors of programming. A JavaScript or Clojure program may represent a record as a hashmap from string or symbol keys to values, written using object or hash literals and manipulated using ordinary functions from the standard library that manipulate keys and values in a generic way. This makes it straightforward to take two records and union their fields or to take an arbitrary (or even dynamic) subselection of fields from an existing record.\n\nIn contrast, most static type systems do not allow such free-form manipulation of records because records are not maps at all but unique types distinct from all other types. These types are uniquely identified by their (fully-qualified) name, hence the term nominal typing. If you wish to take a subselection of a struct’s fields, you must define an entirely new struct; doing this often creates an explosion of awkward boilerplate.\n\nThis is one of the main ideas that Rich Hickey has discussed in many of his talks that criticize static typing. He has advanced the idea that this ability to fluidly merge, separate, and transform records makes dynamic typing particularly suited to the domain of distributed, open systems. Unfortunately, this rhetoric has two significant flaws:\n\n\nIt skirts too close to calling this a fundamental limitation of type systems, suggesting that it is not simply inconvenient but impossible to model such systems in a nominal, static type system. Not only is this not true (as this blog post has demonstrated), it misdirects people away from the point of his that actually has value: the practical, pragmatic advantage of a more structural approach to data modeling.\n\n\nIt confuses the structural/nominal distinction with the dynamic/static distinction, incorrectly creating the impression that the fluid merging and splitting of records represented as key-value maps is only possible in a dynamically typed language. In fact, not only can statically-typed languages support structural typing, many dynamically-typed languages also support nominal typing. These axes have historically loosely correlated, but they are theoretically orthogonal.\n\n\nFor counterexamples to these claims, consider Python classes, which are quite nominal despite being dynamic, and TypeScript interfaces, which are structural despite being static. Indeed, modern statically-typed languages are increasingly acquiring native support for structurally-typed records. In these systems, record types work much like hashes in Clojure—they are not distinct, named types but rather anonymous collections of key-value pairs—and they support many of the same expressive manipulation operations that Clojure’s hashes do, all within a statically-typed framework.\n\nIf you are interested in exploring static type systems with strong support for structural typing, I would recommend taking a look at any of TypeScript, Flow, PureScript, Elm, OCaml, or Reason, all of which have some sort of support for structurally typed records. What I would not recommend for this purpose is Haskell, which has abysmal support for structural typing; Haskell is (for various reasons outside the scope of this blog post) aggressively nominal.2\n\nDoes this mean Haskell is bad, or that it cannot be practically used to solve these kinds of problems? No, certainly not; there are many ways to model these problems in Haskell that work well enough, though some of them suffer from significant boilerplate. The core thesis of this blog post applies just as much to Haskell as it does to any of the other languages I mentioned above. However, I would be remiss not to mention this distinction, as it may give programmers from a dynamically-typed background who have historically found statically-typed languages much more frustrating to work with a better understanding of the real reason they feel that way. (Essentially all mainstream, statically-typed OOP languages are even more nominal than Haskell!)\n\nAs closing thoughts: this blog post is not intended to start a flame war, nor is it intended to be an assault on dynamically typed programming. There are many patterns in dynamically-typed languages that are genuinely difficult to translate into a statically-typed context, and I think discussions of those patterns can be productive. The purpose of this blog post is to clarify why one particular discussion is not productive, so please: stop making these arguments. There are much more productive conversations to have about typing than this.\n\n\nTechnically, you could abuse the FromJSON instance to convert an arbitrary string to a UserId, but this would not be as easy as it sounds, since fromJSON can fail. This means you’d somehow have to handle that failure case, so this trick would be unlikely to get you very far unless you’re already in a context where you’re doing input parsing… at which point it would be easier to just do the right thing. So yes, the type system doesn’t prevent you from going out of your way to shoot yourself in the foot, but it guides you towards the right solution (and there is no safeguard in existence that can completely protect a programmer from making their own life miserable if they are determined to do so).\n ↩\n\nI consider this to be Haskell’s most significant flaw at the time of this writing.\n ↩","isoDate":"2020-01-19T00:00:00.000Z","timestamp":"1/18/2020"},{"title":"Parse, don’t validate","pubDate":"2019-11-05T00:00:00.000Z","author":"Alexis King","content":"<article><p>Historically, I’ve struggled to find a concise, simple way to explain what it means to practice type-driven design. Too often, when someone asks me “How did you come up with this approach?” I find I can’t give them a satisfying answer. I know it didn’t just come to me in a vision—I have an iterative design process that doesn’t require plucking the “right” approach out of thin air—yet I haven’t been very successful in communicating that process to others.\n</p><p>However, about a month ago, <a href=\"https://twitter.com/lexi_lambda/status/1182242561655746560\">I was reflecting on Twitter</a> about the differences I experienced parsing JSON in statically- and dynamically-typed languages, and finally, I realized what I was looking for. Now I have a single, snappy slogan that encapsulates what type-driven design means to me, and better yet, it’s only three words long:\n</p><div style=\"text-align: center; font-size: larger\"><strong>Parse, don’t validate.</strong></div><h2><a name=\"the-essence-of-type-driven-design\"></a>The essence of type-driven design</h2><p>Alright, I’ll confess: unless you already know what type-driven design is, my catchy slogan probably doesn’t mean all that much to you. Fortunately, that’s what the remainder of this blog post is for. I’m going to explain precisely what I mean in gory detail—but first, we need to practice a little wishful thinking.\n</p><h3><a name=\"the-realm-of-possibility\"></a>The realm of possibility</h3><p>One of the wonderful things about static type systems is that they can make it possible, and sometimes even easy, to answer questions like “is it possible to write this function?” For an extreme example, consider the following Haskell type signature:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo</span> <span class=\"ow\">::</span> <span class=\"kt\">Integer</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Void</span></code></pre><p>Is it possible to implement <code>foo</code>? Trivially, the answer is <em>no</em>, as <code>Void</code> is a type that contains no values, so it’s impossible for <em>any</em> function to produce a value of type <code>Void</code>.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup> That example is pretty boring, but the question gets much more interesting if we choose a more realistic example:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span></code></pre><p>This function returns the first element from a list. Is it possible to implement? It certainly doesn’t sound like it does anything very complicated, but if we attempt to implement it, the compiler won’t be satisfied:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"kr\">_</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><pre><code>warning: [-Wincomplete-patterns]\n    Pattern match(es) are non-exhaustive\n    In an equation for ‘head’: Patterns not matched: []\n</code></pre><p>This message is helpfully pointing out that our function is <em>partial</em>, which is to say it is not defined for all possible inputs. Specifically, it is not defined when the input is <code>[]</code>, the empty list. This makes sense, as it isn’t possible to return the first element of a list if the list is empty—there’s no element to return! So, remarkably, we learn this function isn’t possible to implement, either.\n</p><h3><a name=\"turning-partial-functions-total\"></a>Turning partial functions total</h3><p>To someone coming from a dynamically-typed background, this might seem perplexing. If we have a list, we might very well want to get the first element in it. And indeed, the operation of “getting the first element of a list” isn’t impossible in Haskell, it just requires a little extra ceremony. There are two different ways to fix the <code>head</code> function, and we’ll start with the simplest one.\n</p><h4><a name=\"managing-expectations\"></a>Managing expectations</h4><p>As established, <code>head</code> is partial because there is no element to return if the list is empty: we’ve made a promise we cannot possibly fulfill. Fortunately, there’s an easy solution to that dilemma: we can weaken our promise. Since we cannot guarantee the caller an element of the list, we’ll have to practice a little expectation management: we’ll do our best return an element if we can, but we reserve the right to return nothing at all. In Haskell, we express this possibility using the <code>Maybe</code> type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"n\">a</span></code></pre><p>This buys us the freedom we need to implement <code>head</code>—it allows us to return <code>Nothing</code> when we discover we can’t produce a value of type <code>a</code> after all:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"n\">a</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"kr\">_</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">Just</span> <span class=\"n\">x</span>\n<span class=\"nf\">head</span> <span class=\"kt\">[]</span>    <span class=\"ow\">=</span> <span class=\"kt\">Nothing</span></code></pre><p>Problem solved, right? For the moment, yes… but this solution has a hidden cost.\n</p><p>Returning <code>Maybe</code> is undoubtably convenient when we’re <em>implementing</em>  <code>head</code>. However, it becomes significantly less convenient when we want to actually use it! Since <code>head</code> always has the potential to return <code>Nothing</code>, the burden falls upon its callers to handle that possibility, and sometimes that passing of the buck can be incredibly frustrating. To see why, consider the following code:\n</p><pre><code class=\"pygments\"><span class=\"nf\">getConfigurationDirectories</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"p\">[</span><span class=\"kt\">FilePath</span><span class=\"p\">]</span>\n<span class=\"nf\">getConfigurationDirectories</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">configDirsString</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getEnv</span> <span class=\"s\">\"CONFIG_DIRS\"</span>\n  <span class=\"kr\">let</span> <span class=\"n\">configDirsList</span> <span class=\"ow\">=</span> <span class=\"n\">split</span> <span class=\"sc\">&#39;,&#39;</span> <span class=\"n\">configDirsString</span>\n  <span class=\"n\">when</span> <span class=\"p\">(</span><span class=\"n\">null</span> <span class=\"n\">configDirsList</span><span class=\"p\">)</span> <span class=\"o\">$</span>\n    <span class=\"n\">throwIO</span> <span class=\"o\">$</span> <span class=\"n\">userError</span> <span class=\"s\">\"CONFIG_DIRS cannot be empty\"</span>\n  <span class=\"n\">pure</span> <span class=\"n\">configDirsList</span>\n\n<span class=\"nf\">main</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">main</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">configDirs</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getConfigurationDirectories</span>\n  <span class=\"kr\">case</span> <span class=\"n\">head</span> <span class=\"n\">configDirs</span> <span class=\"kr\">of</span>\n    <span class=\"kt\">Just</span> <span class=\"n\">cacheDir</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">initializeCache</span> <span class=\"n\">cacheDir</span>\n    <span class=\"kt\">Nothing</span> <span class=\"ow\">-&gt;</span> <span class=\"ne\">error</span> <span class=\"s\">\"should never happen; already checked configDirs is non-empty\"</span></code></pre><p>When <code>getConfigurationDirectories</code> retrieves a list of file paths from the environment, it proactively checks that the list is non-empty. However, when we use <code>head</code> in <code>main</code> to get the first element of the list, the <code>Maybe FilePath</code> result still requires us to handle a <code>Nothing</code> case that we know will never happen! This is terribly bad for several reasons:\n</p><ol><li><p>First, it’s just annoying. We already checked that the list is non-empty, why do we have to clutter our code with another redundant check?\n</p></li><li><p>Second, it has a potential performance cost. Although the cost of the redundant check is trivial in this particular example, one could imagine a more complex scenario where the redundant checks could add up, such as if they were happening in a tight loop.\n</p></li><li><p>Finally, and worst of all, this code is a bug waiting to happen! What if <code>getConfigurationDirectories</code> were modified to stop checking that the list is empty, intentionally or unintentionally? The programmer might not remember to update <code>main</code>, and suddenly the “impossible” error becomes not only possible, but probable.\n</p></li></ol><p>The need for this redundant check has essentially forced us to punch a hole in our type system. If we could statically <em>prove</em> the <code>Nothing</code> case impossible, then a modification to <code>getConfigurationDirectories</code> that stopped checking if the list was empty would invalidate the proof and trigger a compile-time failure. However, as-written, we’re forced to rely on a test suite or manual inspection to catch the bug.\n</p><h4><a name=\"paying-it-forward\"></a>Paying it forward</h4><p>Clearly, our modified version of <code>head</code> leaves some things to be desired. Somehow, we’d like it to be smarter: if we already checked that the list was non-empty, <code>head</code> should unconditionally return the first element without forcing us to handle the case we know is impossible. How can we do that?\n</p><p>Let’s look at the original (partial) type signature for <code>head</code> again:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span></code></pre><p>The previous section illustrated that we can turn that partial type signature into a total one by weakening the promise made in the return type. However, since we don’t want to do that, there’s only one thing left that can be changed: the argument type (in this case, <code>[a]</code>). Instead of weakening the return type, we can <em>strengthen</em> the argument type, eliminating the possibility of <code>head</code> ever being called on an empty list in the first place.\n</p><p>To do this, we need a type that represents non-empty lists. Fortunately, the existing <code>NonEmpty</code> type from <code>Data.List.NonEmpty</code> is exactly that. It has the following definition:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">a</span> <span class=\"kt\">:|</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span></code></pre><p>Note that <code>NonEmpty a</code> is really just a tuple of an <code>a</code> and an ordinary, possibly-empty <code>[a]</code>. This conveniently models a non-empty list by storing the first element of the list separately from the list’s tail: even if the <code>[a]</code> component is <code>[]</code>, the <code>a</code> component must always be present. This makes <code>head</code> completely trivial to implement:<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"nf\">head</span> <span class=\"ow\">::</span> <span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">head</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:|</span><span class=\"kr\">_</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>Unlike before, GHC accepts this definition without complaint—this definition is <em>total</em>, not partial. We can update our program to use the new implementation:\n</p><pre><code class=\"pygments\"><span class=\"nf\">getConfigurationDirectories</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"kt\">FilePath</span><span class=\"p\">)</span>\n<span class=\"nf\">getConfigurationDirectories</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">configDirsString</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getEnv</span> <span class=\"s\">\"CONFIG_DIRS\"</span>\n  <span class=\"kr\">let</span> <span class=\"n\">configDirsList</span> <span class=\"ow\">=</span> <span class=\"n\">split</span> <span class=\"sc\">&#39;,&#39;</span> <span class=\"n\">configDirsString</span>\n  <span class=\"kr\">case</span> <span class=\"n\">nonEmpty</span> <span class=\"n\">configDirsList</span> <span class=\"kr\">of</span>\n    <span class=\"kt\">Just</span> <span class=\"n\">nonEmptyConfigDirsList</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"n\">nonEmptyConfigDirsList</span>\n    <span class=\"kt\">Nothing</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">throwIO</span> <span class=\"o\">$</span> <span class=\"n\">userError</span> <span class=\"s\">\"CONFIG_DIRS cannot be empty\"</span>\n\n<span class=\"nf\">main</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">main</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">configDirs</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getConfigurationDirectories</span>\n  <span class=\"n\">initializeCache</span> <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">configDirs</span><span class=\"p\">)</span></code></pre><p>Note that the redundant check in <code>main</code> is now completely gone! Instead, we perform the check exactly once, in <code>getConfigurationDirectories</code>. It constructs a <code>NonEmpty a</code> from a <code>[a]</code> using the <code>nonEmpty</code> function from <code>Data.List.NonEmpty</code>, which has the following type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">nonEmpty</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>The <code>Maybe</code> is still there, but this time, we handle the <code>Nothing</code> case very early in our program: right in the same place we were already doing the input validation. Once that check has passed, we now have a <code>NonEmpty FilePath</code> value, which preserves (in the type system!) the knowledge that the list really is non-empty. Put another way, you can think of a value of type <code>NonEmpty a</code> as being like a value of type <code>[a]</code>, plus a <em>proof</em> that the list is non-empty.\n</p><p>By strengthening the type of the argument to <code>head</code> instead of weakening the type of its result, we’ve completely eliminated all the problems from the previous section:\n</p><ul><li><p>The code has no redundant checks, so there can’t be any performance overhead.\n</p></li><li><p>Furthermore, if <code>getConfigurationDirectories</code> changes to stop checking that the list is non-empty, its return type must change, too. Consequently, <code>main</code> will fail to typecheck, alerting us to the problem before we even run the program!\n</p></li></ul><p>What’s more, it’s trivial to recover the old behavior of <code>head</code> from the new one by composing <code>head</code> with <code>nonEmpty</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">head&#39;</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"n\">a</span>\n<span class=\"nf\">head&#39;</span> <span class=\"ow\">=</span> <span class=\"n\">fmap</span> <span class=\"n\">head</span> <span class=\"o\">.</span> <span class=\"n\">nonEmpty</span></code></pre><p>Note that the inverse is <em>not</em> true: there is no way to obtain the new version of <code>head</code> from the old one. All in all, the second approach is superior on all axes.\n</p><h3><a name=\"the-power-of-parsing\"></a>The power of parsing</h3><p>You may be wondering what the above example has to do with the title of this blog post. After all, we only examined two different ways to validate that a list was non-empty—no parsing in sight. That interpretation isn’t wrong, but I’d like to propose another perspective: in my mind, the difference between validation and parsing lies almost entirely in how information is preserved. Consider the following pair of functions:\n</p><pre><code class=\"pygments\"><span class=\"nf\">validateNonEmpty</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">validateNonEmpty</span> <span class=\"p\">(</span><span class=\"kr\">_</span><span class=\"kt\">:</span><span class=\"kr\">_</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span>\n<span class=\"nf\">validateNonEmpty</span> <span class=\"kt\">[]</span> <span class=\"ow\">=</span> <span class=\"n\">throwIO</span> <span class=\"o\">$</span> <span class=\"n\">userError</span> <span class=\"s\">\"list cannot be empty\"</span>\n\n<span class=\"nf\">parseNonEmpty</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">NonEmpty</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"nf\">parseNonEmpty</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:</span><span class=\"n\">xs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"kt\">:|</span><span class=\"n\">xs</span><span class=\"p\">)</span>\n<span class=\"nf\">parseNonEmpty</span> <span class=\"kt\">[]</span> <span class=\"ow\">=</span> <span class=\"n\">throwIO</span> <span class=\"o\">$</span> <span class=\"n\">userError</span> <span class=\"s\">\"list cannot be empty\"</span></code></pre><p>These two functions are nearly identical: they check if the provided list is empty, and if it is, they abort the program with an error message. The difference lies entirely in the return type: <code>validateNonEmpty</code> always returns <code>()</code>, the type that contains no information, but <code>parseNonEmpty</code> returns <code>NonEmpty a</code>, a refinement of the input type that preserves the knowledge gained in the type system. Both of these functions check the same thing, but <code>parseNonEmpty</code> gives the caller access to the information it learned, while <code>validateNonEmpty</code> just throws it away.\n</p><p>These two functions elegantly illustrate two different perspectives on the role of a static type system: <code>validateNonEmpty</code> obeys the typechecker well enough, but only <code>parseNonEmpty</code> takes full advantage of it. If you see why <code>parseNonEmpty</code> is preferable, you understand what I mean by the mantra “parse, don’t validate.” Still, perhaps you are skeptical of <code>parseNonEmpty</code>’s name. Is it really <em>parsing</em> anything, or is it merely validating its input and returning a result? While the precise definition of what it means to parse or validate something is debatable, I believe <code>parseNonEmpty</code> is a bona-fide parser (albeit a particularly simple one).\n</p><p>Consider: what is a parser? Really, a parser is just a function that consumes less-structured input and produces more-structured output. By its very nature, a parser is a partial function—some values in the domain do not correspond to any value in the range—so all parsers must have some notion of failure. Often, the input to a parser is text, but this is by no means a requirement, and <code>parseNonEmpty</code> is a perfectly cromulent parser: it parses lists into non-empty lists, signaling failure by terminating the program with an error message.\n</p><p>Under this flexible definition, parsers are an incredibly powerful tool: they allow discharging checks on input up-front, right on the boundary between a program and the outside world, and once those checks have been performed, they never need to be checked again! Haskellers are well-aware of this power, and they use many different types of parsers on a regular basis:\n</p><ul><li><p>The <a href=\"https://hackage.haskell.org/package/aeson\">aeson</a> library provides a <code>Parser</code> type that can be used to parse JSON data into domain types.\n</p></li><li><p>Likewise, <a href=\"https://hackage.haskell.org/package/optparse-applicative\">optparse-applicative</a> provides a set of parser combinators for parsing command-line arguments.\n</p></li><li><p>Database libraries like <a href=\"https://hackage.haskell.org/package/persistent\">persistent</a> and <a href=\"https://hackage.haskell.org/package/postgresql-simple\">postgresql-simple</a> have a mechanism for parsing values held in an external data store.\n</p></li><li><p>The <a href=\"https://hackage.haskell.org/package/servant\">servant</a> ecosystem is built around parsing Haskell datatypes from path components, query parameters, HTTP headers, and more.\n</p></li></ul><p>The common theme between all these libraries is that they sit on the boundary between your Haskell application and the external world. That world doesn’t speak in product and sum types, but in streams of bytes, so there’s no getting around a need to do some parsing. Doing that parsing up front, before acting on the data, can go a long way toward avoiding many classes of bugs, some of which might even be security vulnerabilities.\n</p><p>One drawback to this approach of parsing everything up front is that it sometimes requires values be parsed long before they are actually used. In a dynamically-typed language, this can make keeping the parsing and processing logic in sync a little tricky without extensive test coverage, much of which can be laborious to maintain. However, with a static type system, the problem becomes marvelously simple, as demonstrated by the <code>NonEmpty</code> example above: if the parsing and processing logic go out of sync, the program will fail to even compile.\n</p><h3><a name=\"the-danger-of-validation\"></a>The danger of validation</h3><p>Hopefully, by this point, you are at least somewhat sold on the idea that parsing is preferable to validation, but you may have lingering doubts. Is validation really so bad if the type system is going to force you to do the necessary checks eventually anyway? Maybe the error reporting will be a little bit worse, but a bit of redundant checking can’t hurt, right?\n</p><p>Unfortunately, it isn’t so simple. Ad-hoc validation leads to a phenomenon that the <a href=\"http://langsec.org\">language-theoretic security</a> field calls <em>shotgun parsing</em>. In the 2016 paper, <a href=\"http://langsec.org/papers/langsec-cwes-secdev2016.pdf\">The Seven Turrets of Babel: A Taxonomy of LangSec Errors and How to Expunge Them</a>, its authors provide the following definition:\n</p><blockquote><p>Shotgun parsing is a programming antipattern whereby parsing and input-validating code is mixed with and spread across processing code—throwing a cloud of checks at the input, and hoping, without any systematic justification, that one or another would catch all the “bad” cases.\n</p></blockquote><p>They go on to explain the problems inherent to such validation techniques:\n</p><blockquote><p>Shotgun parsing necessarily deprives the program of the ability to reject invalid input instead of processing it. Late-discovered errors in an input stream will result in some portion of invalid input having been processed, with the consequence that program state is difficult to accurately predict.\n</p></blockquote><p>In other words, a program that does not parse all of its input up front runs the risk of acting upon a valid portion of the input, discovering a different portion is invalid, and suddenly needing to roll back whatever modifications it already executed in order to maintain consistency. Sometimes this is possible—such as rolling back a transaction in an RDBMS—but in general it may not be.\n</p><p>It may not be immediately apparent what shotgun parsing has to do with validation—after all, if you do all your validation up front, you mitigate the risk of shotgun parsing. The problem is that validation-based approaches make it extremely difficult or impossible to determine if everything was actually validated up front or if some of those so-called “impossible” cases might actually happen. The entire program must assume that raising an exception anywhere is not only possible, it’s regularly necessary.\n</p><p>Parsing avoids this problem by stratifying the program into two phases—parsing and execution—where failure due to invalid input can only happen in the first phase. The set of remaining failure modes during execution is minimal by comparison, and they can be handled with the tender care they require.\n</p><h2><a name=\"parsing-not-validating-in-practice\"></a>Parsing, not validating, in practice</h2><p>So far, this blog post has been something of a sales pitch. “You, dear reader, ought to be parsing!” it says, and if I’ve done my job properly, at least some of you are sold. However, even if you understand the “what” and the “why,” you might not feel especially confident about the “how.”\n</p><p>My advice: focus on the datatypes.\n</p><p>Suppose you are writing a function that accepts a list of tuples representing key-value pairs, and you suddenly realize you aren’t sure what to do if the list has duplicate keys. One solution would be to write a function that asserts there aren’t any duplicates in the list:\n</p><pre><code class=\"pygments\"><span class=\"nf\">checkNoDuplicateKeys</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadError</span> <span class=\"kt\">AppError</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Eq</span> <span class=\"n\">k</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">[(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"p\">)]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>However, this check is fragile: it’s extremely easy to forget. Because its return value is unused, it can always be omitted, and the code that needs it would still typecheck. A better solution is to choose a data structure that disallows duplicate keys by construction, such as a <code>Map</code>. Adjust your function’s type signature to accept a <code>Map</code> instead of a list of tuples, and implement it as you normally would.\n</p><p>Once you’ve done that, the call site of your new function will likely fail to typecheck, since it is still being passed a list of tuples. If the caller was given the value via one of its arguments, or if it received it from the result of some other function, you can continue updating the type from list to <code>Map</code>, all the way up the call chain. Eventually, you will either reach the location the value is created, or you’ll find a place where duplicates actually ought to be allowed. At that point, you can insert a call to a modified version of <code>checkNoDuplicateKeys</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">checkNoDuplicateKeys</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadError</span> <span class=\"kt\">AppError</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Eq</span> <span class=\"n\">k</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">[(</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"p\">)]</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Map</span> <span class=\"n\">k</span> <span class=\"n\">v</span><span class=\"p\">)</span></code></pre><p>Now the check <em>cannot</em> be omitted, since its result is actually necessary for the program to proceed!\n</p><p>This hypothetical scenario highlights two simple ideas:\n</p><ol><li><p><strong>Use a data structure that makes illegal states unrepresentable.</strong> Model your data using the most precise data structure you reasonably can. If ruling out a particular possibility is too hard using the encoding you are currently using, consider alternate encodings that can express the property you care about more easily. Don’t be afraid to refactor.\n</p></li><li><p><strong>Push the burden of proof upward as far as possible, but no further.</strong> Get your data into the most precise representation you need as quickly as you can. Ideally, this should happen at the boundary of your system, before <em>any</em> of the data is acted upon.<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup>\n</p><p>If one particular code branch eventually requires a more precise representation of a piece of data, parse the data into the more precise representation as soon as the branch is selected. Use sum types judiciously to allow your datatypes to reflect and adapt to control flow.\n</p></li></ol><p>In other words, write functions on the data representation you <em>wish</em> you had, not the data representation you are given. The design process then becomes an exercise in bridging the gap, often by working from both ends until they meet somewhere in the middle. Don’t be afraid to iteratively adjust parts of the design as you go, since you may learn something new during the refactoring process!\n</p><p>Here are a handful of additional points of advice, arranged in no particular order:\n</p><ul><li><p><strong>Let your datatypes inform your code, don’t let your code control your datatypes.</strong> Avoid the temptation to just stick a <code>Bool</code> in a record somewhere because it’s needed by the function you’re currently writing. Don’t be afraid to refactor code to use the right data representation—the type system will ensure you’ve covered all the places that need changing, and it will likely save you a headache later.\n</p></li><li><p><strong>Treat functions that return <code>m ()</code> with deep suspicion.</strong> Sometimes these are genuinely necessary, as they may perform an imperative effect with no meaningful result, but if the primary purpose of that effect is raising an error, it’s likely there’s a better way.\n</p></li><li><p><strong>Don’t be afraid to parse data in multiple passes.</strong> Avoiding shotgun parsing just means you shouldn’t act on the input data before it’s fully parsed, not that you can’t use some of the input data to decide how to parse other input data. Plenty of useful parsers are context-sensitive.\n</p></li><li><p><strong>Avoid denormalized representations of data, <em>especially</em> if it’s mutable.</strong> Duplicating the same data in multiple places introduces a trivially representable illegal state: the places getting out of sync. Strive for a single source of truth.\n</p><ul><li><p><strong>Keep denormalized representations of data behind abstraction boundaries.</strong> If denormalization is absolutely necessary, use encapsulation to ensure a small, trusted module holds sole responsibility for keeping the representations in sync.\n</p></li></ul></li><li><p><strong>Use abstract datatypes to make validators “look like” parsers.</strong> Sometimes, making an illegal state truly unrepresentable is just plain impractical given the tools Haskell provides, such as ensuring an integer is in a particular range. In that case, use an abstract <code>newtype</code> with a smart constructor to “fake” a parser from a validator.\n</p></li></ul><p>As always, use your best judgement. It probably isn’t worth breaking out <a href=\"https://hackage.haskell.org/package/singletons\">singletons</a> and refactoring your entire application just to get rid of a single <code>error \"impossible\"</code> call somewhere—just make sure to treat those situations like the radioactive substance they are, and handle them with the appropriate care. If all else fails, at least leave a comment to document the invariant for whoever needs to modify the code next.\n</p><h2><a name=\"recap-reflection-and-related-reading\"></a>Recap, reflection, and related reading</h2><p>That’s all, really. Hopefully this blog post proves that taking advantage of the Haskell type system doesn’t require a PhD, and it doesn’t even require using the latest and greatest of GHC’s shiny new language extensions—though they can certainly sometimes help! Sometimes the biggest obstacle to using Haskell to its fullest is simply being aware what options are available, and unfortunately, one downside of Haskell’s small community is a relative dearth of resources that document design patterns and techniques that have become tribal knowledge.\n</p><p>None of the ideas in this blog post are new. In fact, the core idea—“write total functions”—is conceptually quite simple. Despite that, I find it remarkably challenging to communicate actionable, practicable details about the way I write Haskell code. It’s easy to spend lots of time talking about abstract concepts—many of which are quite valuable!—without communicating anything useful about <em>process</em>. My hope is that this is a small step in that direction.\n</p><p>Sadly, I don’t know very many other resources on this particular topic, but I do know of one: I never hesitate to recommend Matt Parson’s fantastic blog post <a href=\"https://www.parsonsmatt.org/2017/10/11/type_safety_back_and_forth.html\">Type Safety Back and Forth</a>. If you want another accessible perspective on these ideas, including another worked example, I’d highly encourage giving it a read. For a significantly more advanced take on many of these ideas, I can also recommend Matt Noonan’s 2018 paper <a href=\"https://kataskeue.com/gdp.pdf\">Ghosts of Departed Proofs</a>, which outlines a handful of techniques for capturing more complex invariants in the type system than I have described here.\n</p><p>As a closing note, I want to say that doing the kind of refactoring described in this blog post is not always easy. The examples I’ve given are simple, but real life is often much less straightforward. Even for those experienced in type-driven design, it can be genuinely difficult to capture certain invariants in the type system, so do not consider it a personal failing if you cannot solve something the way you’d like! Consider the principles in this blog post ideals to strive for, not strict requirements to meet. All that matters is to try.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Technically, in Haskell, this ignores “bottoms,” constructions that can inhabit <em>any</em> value. These aren’t “real” values (unlike <code>null</code> in some other languages)—they’re things like infinite loops or computations that raise exceptions—and in idiomatic Haskell, we usually try to avoid them, so reasoning that pretends they don’t exist still has value. But don’t take my word for it—I’ll let Danielsson et al. convince you that <a href=\"https://www.cs.ox.ac.uk/jeremy.gibbons/publications/fast+loose.pdf\">Fast and Loose Reasoning is Morally Correct</a>.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>In fact, <code>Data.List.NonEmpty</code> already provides a <code>head</code> function with this type, but just for the sake of illustration, we’ll reimplement it ourselves.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>Sometimes it is necessary to perform some kind of authorization before parsing user input to avoid denial of service attacks, but that’s okay: authorization should have a relatively small surface area, and it shouldn’t cause any significant modifications to the state of your system.\n <a href=\"#footnote-ref-3-1\">↩</a></p></li></ol></article>","contentSnippet":"Historically, I’ve struggled to find a concise, simple way to explain what it means to practice type-driven design. Too often, when someone asks me “How did you come up with this approach?” I find I can’t give them a satisfying answer. I know it didn’t just come to me in a vision—I have an iterative design process that doesn’t require plucking the “right” approach out of thin air—yet I haven’t been very successful in communicating that process to others.\n\nHowever, about a month ago, I was reflecting on Twitter about the differences I experienced parsing JSON in statically- and dynamically-typed languages, and finally, I realized what I was looking for. Now I have a single, snappy slogan that encapsulates what type-driven design means to me, and better yet, it’s only three words long:\n\nParse, don’t validate.\nThe essence of type-driven design\nAlright, I’ll confess: unless you already know what type-driven design is, my catchy slogan probably doesn’t mean all that much to you. Fortunately, that’s what the remainder of this blog post is for. I’m going to explain precisely what I mean in gory detail—but first, we need to practice a little wishful thinking.\n\nThe realm of possibility\nOne of the wonderful things about static type systems is that they can make it possible, and sometimes even easy, to answer questions like “is it possible to write this function?” For an extreme example, consider the following Haskell type signature:\n\nfoo :: Integer -> Void\nIs it possible to implement foo? Trivially, the answer is no, as Void is a type that contains no values, so it’s impossible for any function to produce a value of type Void.1 That example is pretty boring, but the question gets much more interesting if we choose a more realistic example:\n\nhead :: [a] -> a\nThis function returns the first element from a list. Is it possible to implement? It certainly doesn’t sound like it does anything very complicated, but if we attempt to implement it, the compiler won’t be satisfied:\n\nhead :: [a] -> a\nhead (x:_) = x\nwarning: [-Wincomplete-patterns]\n    Pattern match(es) are non-exhaustive\n    In an equation for ‘head’: Patterns not matched: []\n\nThis message is helpfully pointing out that our function is partial, which is to say it is not defined for all possible inputs. Specifically, it is not defined when the input is [], the empty list. This makes sense, as it isn’t possible to return the first element of a list if the list is empty—there’s no element to return! So, remarkably, we learn this function isn’t possible to implement, either.\n\nTurning partial functions total\nTo someone coming from a dynamically-typed background, this might seem perplexing. If we have a list, we might very well want to get the first element in it. And indeed, the operation of “getting the first element of a list” isn’t impossible in Haskell, it just requires a little extra ceremony. There are two different ways to fix the head function, and we’ll start with the simplest one.\n\nManaging expectations\nAs established, head is partial because there is no element to return if the list is empty: we’ve made a promise we cannot possibly fulfill. Fortunately, there’s an easy solution to that dilemma: we can weaken our promise. Since we cannot guarantee the caller an element of the list, we’ll have to practice a little expectation management: we’ll do our best return an element if we can, but we reserve the right to return nothing at all. In Haskell, we express this possibility using the Maybe type:\n\nhead :: [a] -> Maybe a\nThis buys us the freedom we need to implement head—it allows us to return Nothing when we discover we can’t produce a value of type a after all:\n\nhead :: [a] -> Maybe a\nhead (x:_) = Just x\nhead []    = Nothing\nProblem solved, right? For the moment, yes… but this solution has a hidden cost.\n\nReturning Maybe is undoubtably convenient when we’re implementing  head. However, it becomes significantly less convenient when we want to actually use it! Since head always has the potential to return Nothing, the burden falls upon its callers to handle that possibility, and sometimes that passing of the buck can be incredibly frustrating. To see why, consider the following code:\n\ngetConfigurationDirectories :: IO [FilePath]\ngetConfigurationDirectories = do\n  configDirsString <- getEnv \"CONFIG_DIRS\"\n  let configDirsList = split ',' configDirsString\n  when (null configDirsList) $\n    throwIO $ userError \"CONFIG_DIRS cannot be empty\"\n  pure configDirsList\n\nmain :: IO ()\nmain = do\n  configDirs <- getConfigurationDirectories\n  case head configDirs of\n    Just cacheDir -> initializeCache cacheDir\n    Nothing -> error \"should never happen; already checked configDirs is non-empty\"\nWhen getConfigurationDirectories retrieves a list of file paths from the environment, it proactively checks that the list is non-empty. However, when we use head in main to get the first element of the list, the Maybe FilePath result still requires us to handle a Nothing case that we know will never happen! This is terribly bad for several reasons:\n\n\nFirst, it’s just annoying. We already checked that the list is non-empty, why do we have to clutter our code with another redundant check?\n\n\nSecond, it has a potential performance cost. Although the cost of the redundant check is trivial in this particular example, one could imagine a more complex scenario where the redundant checks could add up, such as if they were happening in a tight loop.\n\n\nFinally, and worst of all, this code is a bug waiting to happen! What if getConfigurationDirectories were modified to stop checking that the list is empty, intentionally or unintentionally? The programmer might not remember to update main, and suddenly the “impossible” error becomes not only possible, but probable.\n\n\nThe need for this redundant check has essentially forced us to punch a hole in our type system. If we could statically prove the Nothing case impossible, then a modification to getConfigurationDirectories that stopped checking if the list was empty would invalidate the proof and trigger a compile-time failure. However, as-written, we’re forced to rely on a test suite or manual inspection to catch the bug.\n\nPaying it forward\nClearly, our modified version of head leaves some things to be desired. Somehow, we’d like it to be smarter: if we already checked that the list was non-empty, head should unconditionally return the first element without forcing us to handle the case we know is impossible. How can we do that?\n\nLet’s look at the original (partial) type signature for head again:\n\nhead :: [a] -> a\nThe previous section illustrated that we can turn that partial type signature into a total one by weakening the promise made in the return type. However, since we don’t want to do that, there’s only one thing left that can be changed: the argument type (in this case, [a]). Instead of weakening the return type, we can strengthen the argument type, eliminating the possibility of head ever being called on an empty list in the first place.\n\nTo do this, we need a type that represents non-empty lists. Fortunately, the existing NonEmpty type from Data.List.NonEmpty is exactly that. It has the following definition:\n\ndata NonEmpty a = a :| [a]\nNote that NonEmpty a is really just a tuple of an a and an ordinary, possibly-empty [a]. This conveniently models a non-empty list by storing the first element of the list separately from the list’s tail: even if the [a] component is [], the a component must always be present. This makes head completely trivial to implement:2\n\nhead :: NonEmpty a -> a\nhead (x:|_) = x\nUnlike before, GHC accepts this definition without complaint—this definition is total, not partial. We can update our program to use the new implementation:\n\ngetConfigurationDirectories :: IO (NonEmpty FilePath)\ngetConfigurationDirectories = do\n  configDirsString <- getEnv \"CONFIG_DIRS\"\n  let configDirsList = split ',' configDirsString\n  case nonEmpty configDirsList of\n    Just nonEmptyConfigDirsList -> pure nonEmptyConfigDirsList\n    Nothing -> throwIO $ userError \"CONFIG_DIRS cannot be empty\"\n\nmain :: IO ()\nmain = do\n  configDirs <- getConfigurationDirectories\n  initializeCache (head configDirs)\nNote that the redundant check in main is now completely gone! Instead, we perform the check exactly once, in getConfigurationDirectories. It constructs a NonEmpty a from a [a] using the nonEmpty function from Data.List.NonEmpty, which has the following type:\n\nnonEmpty :: [a] -> Maybe (NonEmpty a)\nThe Maybe is still there, but this time, we handle the Nothing case very early in our program: right in the same place we were already doing the input validation. Once that check has passed, we now have a NonEmpty FilePath value, which preserves (in the type system!) the knowledge that the list really is non-empty. Put another way, you can think of a value of type NonEmpty a as being like a value of type [a], plus a proof that the list is non-empty.\n\nBy strengthening the type of the argument to head instead of weakening the type of its result, we’ve completely eliminated all the problems from the previous section:\n\n\nThe code has no redundant checks, so there can’t be any performance overhead.\n\n\nFurthermore, if getConfigurationDirectories changes to stop checking that the list is non-empty, its return type must change, too. Consequently, main will fail to typecheck, alerting us to the problem before we even run the program!\n\n\nWhat’s more, it’s trivial to recover the old behavior of head from the new one by composing head with nonEmpty:\n\nhead' :: [a] -> Maybe a\nhead' = fmap head . nonEmpty\nNote that the inverse is not true: there is no way to obtain the new version of head from the old one. All in all, the second approach is superior on all axes.\n\nThe power of parsing\nYou may be wondering what the above example has to do with the title of this blog post. After all, we only examined two different ways to validate that a list was non-empty—no parsing in sight. That interpretation isn’t wrong, but I’d like to propose another perspective: in my mind, the difference between validation and parsing lies almost entirely in how information is preserved. Consider the following pair of functions:\n\nvalidateNonEmpty :: [a] -> IO ()\nvalidateNonEmpty (_:_) = pure ()\nvalidateNonEmpty [] = throwIO $ userError \"list cannot be empty\"\n\nparseNonEmpty :: [a] -> IO (NonEmpty a)\nparseNonEmpty (x:xs) = pure (x:|xs)\nparseNonEmpty [] = throwIO $ userError \"list cannot be empty\"\nThese two functions are nearly identical: they check if the provided list is empty, and if it is, they abort the program with an error message. The difference lies entirely in the return type: validateNonEmpty always returns (), the type that contains no information, but parseNonEmpty returns NonEmpty a, a refinement of the input type that preserves the knowledge gained in the type system. Both of these functions check the same thing, but parseNonEmpty gives the caller access to the information it learned, while validateNonEmpty just throws it away.\n\nThese two functions elegantly illustrate two different perspectives on the role of a static type system: validateNonEmpty obeys the typechecker well enough, but only parseNonEmpty takes full advantage of it. If you see why parseNonEmpty is preferable, you understand what I mean by the mantra “parse, don’t validate.” Still, perhaps you are skeptical of parseNonEmpty’s name. Is it really parsing anything, or is it merely validating its input and returning a result? While the precise definition of what it means to parse or validate something is debatable, I believe parseNonEmpty is a bona-fide parser (albeit a particularly simple one).\n\nConsider: what is a parser? Really, a parser is just a function that consumes less-structured input and produces more-structured output. By its very nature, a parser is a partial function—some values in the domain do not correspond to any value in the range—so all parsers must have some notion of failure. Often, the input to a parser is text, but this is by no means a requirement, and parseNonEmpty is a perfectly cromulent parser: it parses lists into non-empty lists, signaling failure by terminating the program with an error message.\n\nUnder this flexible definition, parsers are an incredibly powerful tool: they allow discharging checks on input up-front, right on the boundary between a program and the outside world, and once those checks have been performed, they never need to be checked again! Haskellers are well-aware of this power, and they use many different types of parsers on a regular basis:\n\n\nThe aeson library provides a Parser type that can be used to parse JSON data into domain types.\n\n\nLikewise, optparse-applicative provides a set of parser combinators for parsing command-line arguments.\n\n\nDatabase libraries like persistent and postgresql-simple have a mechanism for parsing values held in an external data store.\n\n\nThe servant ecosystem is built around parsing Haskell datatypes from path components, query parameters, HTTP headers, and more.\n\n\nThe common theme between all these libraries is that they sit on the boundary between your Haskell application and the external world. That world doesn’t speak in product and sum types, but in streams of bytes, so there’s no getting around a need to do some parsing. Doing that parsing up front, before acting on the data, can go a long way toward avoiding many classes of bugs, some of which might even be security vulnerabilities.\n\nOne drawback to this approach of parsing everything up front is that it sometimes requires values be parsed long before they are actually used. In a dynamically-typed language, this can make keeping the parsing and processing logic in sync a little tricky without extensive test coverage, much of which can be laborious to maintain. However, with a static type system, the problem becomes marvelously simple, as demonstrated by the NonEmpty example above: if the parsing and processing logic go out of sync, the program will fail to even compile.\n\nThe danger of validation\nHopefully, by this point, you are at least somewhat sold on the idea that parsing is preferable to validation, but you may have lingering doubts. Is validation really so bad if the type system is going to force you to do the necessary checks eventually anyway? Maybe the error reporting will be a little bit worse, but a bit of redundant checking can’t hurt, right?\n\nUnfortunately, it isn’t so simple. Ad-hoc validation leads to a phenomenon that the language-theoretic security field calls shotgun parsing. In the 2016 paper, The Seven Turrets of Babel: A Taxonomy of LangSec Errors and How to Expunge Them, its authors provide the following definition:\n\nShotgun parsing is a programming antipattern whereby parsing and input-validating code is mixed with and spread across processing code—throwing a cloud of checks at the input, and hoping, without any systematic justification, that one or another would catch all the “bad” cases.\n\nThey go on to explain the problems inherent to such validation techniques:\n\nShotgun parsing necessarily deprives the program of the ability to reject invalid input instead of processing it. Late-discovered errors in an input stream will result in some portion of invalid input having been processed, with the consequence that program state is difficult to accurately predict.\n\nIn other words, a program that does not parse all of its input up front runs the risk of acting upon a valid portion of the input, discovering a different portion is invalid, and suddenly needing to roll back whatever modifications it already executed in order to maintain consistency. Sometimes this is possible—such as rolling back a transaction in an RDBMS—but in general it may not be.\n\nIt may not be immediately apparent what shotgun parsing has to do with validation—after all, if you do all your validation up front, you mitigate the risk of shotgun parsing. The problem is that validation-based approaches make it extremely difficult or impossible to determine if everything was actually validated up front or if some of those so-called “impossible” cases might actually happen. The entire program must assume that raising an exception anywhere is not only possible, it’s regularly necessary.\n\nParsing avoids this problem by stratifying the program into two phases—parsing and execution—where failure due to invalid input can only happen in the first phase. The set of remaining failure modes during execution is minimal by comparison, and they can be handled with the tender care they require.\n\nParsing, not validating, in practice\nSo far, this blog post has been something of a sales pitch. “You, dear reader, ought to be parsing!” it says, and if I’ve done my job properly, at least some of you are sold. However, even if you understand the “what” and the “why,” you might not feel especially confident about the “how.”\n\nMy advice: focus on the datatypes.\n\nSuppose you are writing a function that accepts a list of tuples representing key-value pairs, and you suddenly realize you aren’t sure what to do if the list has duplicate keys. One solution would be to write a function that asserts there aren’t any duplicates in the list:\n\ncheckNoDuplicateKeys :: (MonadError AppError m, Eq k) => [(k, v)] -> m ()\nHowever, this check is fragile: it’s extremely easy to forget. Because its return value is unused, it can always be omitted, and the code that needs it would still typecheck. A better solution is to choose a data structure that disallows duplicate keys by construction, such as a Map. Adjust your function’s type signature to accept a Map instead of a list of tuples, and implement it as you normally would.\n\nOnce you’ve done that, the call site of your new function will likely fail to typecheck, since it is still being passed a list of tuples. If the caller was given the value via one of its arguments, or if it received it from the result of some other function, you can continue updating the type from list to Map, all the way up the call chain. Eventually, you will either reach the location the value is created, or you’ll find a place where duplicates actually ought to be allowed. At that point, you can insert a call to a modified version of checkNoDuplicateKeys:\n\ncheckNoDuplicateKeys :: (MonadError AppError m, Eq k) => [(k, v)] -> m (Map k v)\nNow the check cannot be omitted, since its result is actually necessary for the program to proceed!\n\nThis hypothetical scenario highlights two simple ideas:\n\n\nUse a data structure that makes illegal states unrepresentable. Model your data using the most precise data structure you reasonably can. If ruling out a particular possibility is too hard using the encoding you are currently using, consider alternate encodings that can express the property you care about more easily. Don’t be afraid to refactor.\n\n\nPush the burden of proof upward as far as possible, but no further. Get your data into the most precise representation you need as quickly as you can. Ideally, this should happen at the boundary of your system, before any of the data is acted upon.3\n\nIf one particular code branch eventually requires a more precise representation of a piece of data, parse the data into the more precise representation as soon as the branch is selected. Use sum types judiciously to allow your datatypes to reflect and adapt to control flow.\n\n\nIn other words, write functions on the data representation you wish you had, not the data representation you are given. The design process then becomes an exercise in bridging the gap, often by working from both ends until they meet somewhere in the middle. Don’t be afraid to iteratively adjust parts of the design as you go, since you may learn something new during the refactoring process!\n\nHere are a handful of additional points of advice, arranged in no particular order:\n\n\nLet your datatypes inform your code, don’t let your code control your datatypes. Avoid the temptation to just stick a Bool in a record somewhere because it’s needed by the function you’re currently writing. Don’t be afraid to refactor code to use the right data representation—the type system will ensure you’ve covered all the places that need changing, and it will likely save you a headache later.\n\n\nTreat functions that return m () with deep suspicion. Sometimes these are genuinely necessary, as they may perform an imperative effect with no meaningful result, but if the primary purpose of that effect is raising an error, it’s likely there’s a better way.\n\n\nDon’t be afraid to parse data in multiple passes. Avoiding shotgun parsing just means you shouldn’t act on the input data before it’s fully parsed, not that you can’t use some of the input data to decide how to parse other input data. Plenty of useful parsers are context-sensitive.\n\n\nAvoid denormalized representations of data, especially if it’s mutable. Duplicating the same data in multiple places introduces a trivially representable illegal state: the places getting out of sync. Strive for a single source of truth.\n\n\nKeep denormalized representations of data behind abstraction boundaries. If denormalization is absolutely necessary, use encapsulation to ensure a small, trusted module holds sole responsibility for keeping the representations in sync.\n\n\n\nUse abstract datatypes to make validators “look like” parsers. Sometimes, making an illegal state truly unrepresentable is just plain impractical given the tools Haskell provides, such as ensuring an integer is in a particular range. In that case, use an abstract newtype with a smart constructor to “fake” a parser from a validator.\n\n\nAs always, use your best judgement. It probably isn’t worth breaking out singletons and refactoring your entire application just to get rid of a single error \"impossible\" call somewhere—just make sure to treat those situations like the radioactive substance they are, and handle them with the appropriate care. If all else fails, at least leave a comment to document the invariant for whoever needs to modify the code next.\n\nRecap, reflection, and related reading\nThat’s all, really. Hopefully this blog post proves that taking advantage of the Haskell type system doesn’t require a PhD, and it doesn’t even require using the latest and greatest of GHC’s shiny new language extensions—though they can certainly sometimes help! Sometimes the biggest obstacle to using Haskell to its fullest is simply being aware what options are available, and unfortunately, one downside of Haskell’s small community is a relative dearth of resources that document design patterns and techniques that have become tribal knowledge.\n\nNone of the ideas in this blog post are new. In fact, the core idea—“write total functions”—is conceptually quite simple. Despite that, I find it remarkably challenging to communicate actionable, practicable details about the way I write Haskell code. It’s easy to spend lots of time talking about abstract concepts—many of which are quite valuable!—without communicating anything useful about process. My hope is that this is a small step in that direction.\n\nSadly, I don’t know very many other resources on this particular topic, but I do know of one: I never hesitate to recommend Matt Parson’s fantastic blog post Type Safety Back and Forth. If you want another accessible perspective on these ideas, including another worked example, I’d highly encourage giving it a read. For a significantly more advanced take on many of these ideas, I can also recommend Matt Noonan’s 2018 paper Ghosts of Departed Proofs, which outlines a handful of techniques for capturing more complex invariants in the type system than I have described here.\n\nAs a closing note, I want to say that doing the kind of refactoring described in this blog post is not always easy. The examples I’ve given are simple, but real life is often much less straightforward. Even for those experienced in type-driven design, it can be genuinely difficult to capture certain invariants in the type system, so do not consider it a personal failing if you cannot solve something the way you’d like! Consider the principles in this blog post ideals to strive for, not strict requirements to meet. All that matters is to try.\n\n\nTechnically, in Haskell, this ignores “bottoms,” constructions that can inhabit any value. These aren’t “real” values (unlike null in some other languages)—they’re things like infinite loops or computations that raise exceptions—and in idiomatic Haskell, we usually try to avoid them, so reasoning that pretends they don’t exist still has value. But don’t take my word for it—I’ll let Danielsson et al. convince you that Fast and Loose Reasoning is Morally Correct.\n ↩\n\nIn fact, Data.List.NonEmpty already provides a head function with this type, but just for the sake of illustration, we’ll reimplement it ourselves.\n ↩\n\nSometimes it is necessary to perform some kind of authorization before parsing user input to avoid denial of service attacks, but that’s okay: authorization should have a relatively small surface area, and it shouldn’t cause any significant modifications to the state of your system.\n ↩","isoDate":"2019-11-05T00:00:00.000Z","timestamp":"11/4/2019"},{"title":"Empathy and subjective experience in programming languages","pubDate":"2019-10-19T00:00:00.000Z","author":"Alexis King","content":"<article><p>A stereotype about programmers is that they like to think in black and white. Programmers like things to be good or bad, moral or immoral, responsible or irresponsible. Perhaps there is something romantic in the idea that programmers like to be as binary as the computers they program. Reductionist? Almost certainly, but hey, laugh at yourself a bit: we probably deserve to be made fun of from time to time.\n</p><p>Personally, I have no idea if the trope of the nuance-challenged programmer is accurate, but whether it’s a property of programmers or just humans behind a keyboard, the intensity with which we disagree with one another never ceases to amaze. Ask any group of working programmers what their least favorite programming language is, and there’s a pretty good chance things are going to get heated real fast. Why? What is it about programming that makes us feel so strongly that we are right and others are wrong, even when our experiences contradict those of tens or hundreds of thousands of others?\n</p><p>I think about that question a lot.\n</p><h2><a name=\"2015-called-and-they-want-their-dress-back\"></a>2015 called, and they want their dress back</h2><p>Humans have a knack for caring intensely about the most trivial of things. Name almost anything—cats versus dogs, the appropriate way to fasten a necktie, or even which day of the week comes first—and someone somewhere has probably written an essay about it on an internet forum. It would be easy to throw up our hands and give up trying to understand our peers, as sometimes they seem like aliens from another planet.\n</p><p>However, what interests me is how the littlest things seem to get people the most upset. Few people have shouting matches over the best interpretation of quantum mechanics, but friendships will be tested when someone says they just aren’t that into <em>Star Wars</em>. One explanation for this phenomenon is simple accessibility: most people aren’t equipped to understand quantum mechanics well enough to argue about it, but almost anyone can have an opinion on which direction the toilet paper is supposed to go.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup>\n</p><p>There is truth in that explanation, but personally, I don’t think it’s the whole story. Rather, I think we grow so used to the idea that our experiences are universal that discovering someone else experienced the exact same thing we did yet came to a different conclusion is not just frustrating: it’s incomprehensible.\n</p><p>Take 2015’s phenomenon of “<a href=\"https://en.wikipedia.org/wiki/The_dress\">the dress</a>” as an example. Some people see black and blue, others white and gold, and frankly, whether you see one or the other has no impact on anything remotely meaningful. How did <em>this</em>—something so completely irrelevant—become a cross-cultural phenomenon reported on by major news outlets? My guess: people just aren’t used to the idea that vision—the primary way we sense the world—does not provide us with an objective, universal understanding of reality.\n</p><h3><a name=\"when-something-objective-isn-t\"></a>When something objective isn’t</h3><p>Our culture and society works because, in spite of our differences, we’re still all humans. We eat food, we sleep, we like spending time with each other, and we like feeling connected to those around us. So when we watch a movie, and it tickles us in a way that makes us feel good, we can have an awfully hard time understanding how our best friend—who we largely agree with about everything—didn’t like it at all.\n</p><p>The truth, of course, is that very little of what we experience is in any way objective. Yes, we can be pretty confident that basic arithmetic is true anywhere in the universe, and that if we all agree a table is brown it probably is. There are even things we accept as subjective without a second thought, such as the kinds of food people like or the fashions they find attractive. It’s all the in-betweens that are so pernicious! “The dress” was so unbelievable to most people because, nine hundred and ninety nine times out of of a thousand, when two humans look at a picture, they at least mostly agree on the colors contained within. We do not consider that we are seeing different lenses into the same objective reality, we simply think we are perceiving objective truths directly.\n</p><p>In the case of the dress, whether you <a href=\"https://en.wikipedia.org/wiki/Yanny_or_Laurel\">heard “yanny” or “laurel,”</a> or whether you believe the <em>Sonic</em> games were ever any good, subjective disagreement is essentially harmless. But what about when it isn’t? Might incorrect beliefs that our experiences are universal cause genuine harm?\n</p><p>I think the answer is absolutely, unequivocally <em>yes</em>.\n</p><h2><a name=\"subjectivity-in-programming-and-in-programming-languages-specifically\"></a>Subjectivity in programming, and in programming languages specifically</h2><p>Quick question: which is better, functional or imperative programming?\n</p><p>My guess, given the usual subject of my blog, most of my readers would pick the former. However, the actual answer you chose doesn’t matter: my guess is you feel like you have a pretty rational argument to back it up. It certainly isn’t simply a matter of taste… right?\n</p><p>Well, no, I hope not. I don’t think the world is so subjective that we cannot ever advocate for one thing over another—we tried that whole “everything is XML” thing for a while, and I think we agreed it really wasn’t a good idea. But if you truly believe your answer to the above question can be completely objectively justified (as many do), how does one explain the average Hacker News comment thread on just about any post about Haskell?\n</p><p>I generally try not to read Hacker News if I can help it, as I find doing it mostly just makes me angry,<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup> but I did happen to find a link to <a href=\"https://news.ycombinator.com/item?id=21282647\">a recent discussion</a> on a blog post about using Haskell in production. Let’s take a look at a few comments, shall we?\n</p><p>In a <a href=\"https://news.ycombinator.com/item?id=21284383\">branch of the discussion</a>, one user writes:\n</p><blockquote><blockquote><p>Haskell is great for business and great in production\n</p></blockquote><p>I disagree. It's a beautiful language but it lacks a lot of features to make it useable at scale. And in my experience Haskell engineers are extremely smart but the environment/culture they create makes it difficult to foster team spirit.\n</p><p>I've been in 2 companies in the last 4 years who initially used Haskell in production. One has transitioned to Go and the other is rewriting the codebase in Rust.\n</p></blockquote><p>The first paragraph is an assertion without many specifics, but it does sound like it could be reasonable. And although the last two sentences are entirely anecdotal, anecdotes are still better than hunches. Let’s see what someone else has to say in response:\n</p><blockquote><p>I’ve met some pretty damn solid engineers who started on Haskell and, even at a junior level in other languages, produce an elegant solution far more easily than a senior engineer in that language. You probably wouldn’t put the code in production verbatim but you can very easily see what’s going on and it isn’t haunted by spectre of early abstraction, which IMO is the biggest flaw of OOP at scale.\n</p><p>[…]\n</p><p>From my naive perspective it’s easy to make classes out of everything, and to hold state and put side-effects everywhere, but you don’t want to deal with the trouble of a monad until you need it. So you have an automatic inclination towards cleaner code when you start functional and move on.\n</p></blockquote><p>Also pretty vague and high-level, but also sounds reasonable. If you read either of these comments, and your first inclination was to grow frustrated and start crafting counter-arguments in your head, I encourage you to step outside your feelings momentarily (rational as they may be!) and try your very hardest to interpret them charitably. The discussion continues:\n</p><blockquote><p>Haskell gives one plenty of rope to hang himself on complexity.\n</p><p>So much that developers develop an aversion to it as deep as fear. It's unavoidable, the ones that didn't develop it are still buried at the working of their first Rube Goldberg machine and unavailable.\n</p></blockquote><p>Whether you think it’s accurate or not, there is definitely a perception held by a great many people that Haskell is a very complicated language. Surely at least some of them must have given it an honest shot, so have they just not “seen the light” yet? What do you think they’re missing? Perhaps a followup commenter can help elucidate things:\n</p><blockquote><p>Hi, I find that everything people here are complaining about (and they're valid complaints) has also been true of C++. C++ developed a lot of its complexity (particularly 15-20 yrs ago in the template space) after it got popular, so people were already wed to it.\n</p><p>[…]\n</p><p>The C++ community's really gotten good in the last 5 years or so about reigning in the bad impulses and getting people to write clean, clear, efficient code that has reasonable expressiveness.\n</p><p>Coming into Haskell from C++, I have the same instincts. Haskell's been a pure pleasure. The benefits are really there, and they're easy to get. You just have to think of the trade-offs.\n</p></blockquote><p>That argument seems reasonable, too. Everything in moderation, right? If you disagree, and you think Haskell is just not worth it, what does this person value that you don’t? What are they missing that you see?\n</p><h3><a name=\"the-unsatisfying-subjective-reality-of-programming-languages\"></a>The unsatisfying subjective reality of programming languages</h3><p>You can probably see where I’m going with all this. These arguments are not built on hard, refutable facts or rigorous real-world evidence, they’re based in gut feelings and personal preferences. Does that mean they’re wrong, invalid, and worthless, and we should do studies to determine which language allows programmers to ship features the fastest and with the fewest bugs, then all agree to use that?\n</p><p><strong><em>No!</em></strong>\n</p><p>These conversations are subjective because, for better or for worse, humans think in different ways and value different things, and programming languages are the medium in which we express ourselves. To many people who write Haskell (myself included), there is an effervescent joy in modeling a problem with the type system—like capturing something in amber—that others just don’t care about. What’s more, some people clearly loathe Haskell’s significant whitespace and plethora of infix operators, but I’ve never really minded. Is one of us wrong? If so, <em>why?</em> Talk about reliability all you want, but the few rigorous numbers we have don’t provide much evidence one way or the other.\n</p><p>While <a href=\"https://news.ycombinator.com/item?id=21284317\">one commenter</a> in the aforementioned Hacker News thread described Haskell as nothing less than “pain and torture,” <a href=\"https://news.ycombinator.com/item?id=21284540\">another</a> says they “did some Haskell in production and it was delightful.” People push excuses and rationalizations for these differences constantly—they point out that most people are exposed to imperative programming first, while others retort that Haskell is clearly not very widely used despite being around for an awfully long time—but none of their arguments ever seem to change people’s minds.\n</p><p>Often, people walk away from these conversations confused and incensed. To them, their point of view is so obviously apparent that it is hard to fathom anyone else seeing things differently. They rack their brains trying to figure out why their opponents just don’t <em>get it.</em> There must be some key point they’ve misunderstood, some joy they haven’t experienced, some sharp edge they haven’t yet been cut by. But no matter how much time they spend trying to reach these people, somehow, it’s never enough.\n</p><h3><a name=\"empathy-and-how-bad-results-come-from-good-intentions\"></a>Empathy, and how bad results come from good intentions</h3><p>I’ll admit that these kinds of discussions aren’t <em>always</em> fruitless; sometimes they really do manage to change people’s minds or help them see some new idea they had not been able to grasp. When people manage to keep their cool and acknowledge the differences in their mindsets while still helping people learn, everyone benefits.\n</p><p>Sadly, in my experience, this rarely happens. We have a natural tendency to become angry if people don’t see things the way we do; it’s confusing and disorienting, and it can even disgust us. None of those emotions are conducive to empathy. When we fail to account for the ways in which others might think differently, we voluntarily reject any insights we might have otherwise gained from the conversation because we did not allow ourselves to embrace, even just temporarily, someone else’s strange and perhaps uncomfortable set of values and experiences. We refuse to accept that our perception of color might not be as universal as we thought, and we miss out on the amazing insights we could learn about the nature of light, color, and human vision.\n</p><p>Although failing to empathize with those we are arguing with is bad enough, in my mind, this failure to accept the potential subjectivity of one’s own views has even worse, indirect effects. Take this comment for example, again from the same thread:\n</p><blockquote><p>Sounds like you've barely programmed in Haskell and don't know what you're talking about. Haskell was the first language I learned. I didn't think this at all and I still don't. It doesn't strike me as any more difficult than learning Java or something.\n</p></blockquote><p>I have no doubts that this commenter meant what they said: they didn’t find Haskell difficult to learn. The comment they were replying to was vitriolic and combative, so one could almost feel they had a smackdown coming to them… but this isn’t a private conversation. How do you think someone feels when they are learning Haskell, scroll through this thread, and find a comment that tells them they ought to find it easy? If they’ve been struggling, even a little bit, what do you think they might think?\n</p><p>If I were in their place, I might feel a little stupid. I might wonder if I’m really cut out for Haskell or if I should just give up. I definitely wouldn’t feel encouraged and excited to keep trying.\n</p><p>Who knows why this commenter found Haskell straightforward. Maybe they were exposed to certain concepts already, maybe it just fit their style of thinking, perhaps they’re even exceptionally smart. I don’t know. But no matter what the answer is, insulting the intelligence of others, even indirectly in this way, belies a lack of empathy in the face of frustration, and although the intent may not have been to hurt, it can still be seriously harmful.\n</p><p>To be clear, I’m not saying the commenter should have pretended their experiences were different or even kept them to themselves. I don’t believe in being “fake nice”—in my experience, I am best equipped to reach people when speaking genuinely, from the heart. What I would have done is tell my story in a different way, perhaps by writing something like this:\n</p><blockquote><p>It’s true that a lot of people find Haskell challenging, and I totally accept that some people just don’t think it’s worth it. It’s fine if you don’t want to write Haskell. But personally, I really enjoy writing it, as do the people I work with, and I think we ship great software with it because it aligns naturally—even joyfully!—with the way we like to think about program construction.\n</p><p>Personally, I didn’t find Haskell as challenging to learn as I think some people have, but it was still work, and in some ways I was just exposed to it at the right time. Other people I know have struggled quite a lot at first, and reasonably so, but they’ve still managed to become great Haskell programmers, and they found it worthwhile. Our team dynamic just wouldn’t be the same in any other language.\n</p></blockquote><p>When I respond to comments I disagree with, I try to tell a personal story that provides a different perspective <strong>without</strong> invalidating their experiences. Sometimes the result is ungrateful snark anyway (or just no response at all), but you might be surprised how often talking from an emotional place about <em>your own</em> experiences—while being neither aggressive nor especially defensive—can go a long way. Perhaps you can even learn something if they return the favor and explain what they find frustrating, beyond the fundamental, subjective disagreements.\n</p><p>It’s okay to have opinions. It’s okay to like and dislike things. It’s okay to be frustrated that others don’t see things the way you do, and to advocate for the technologies and values you believe in. It’s just not okay to tell someone else their reality is wrong.\n</p><p>Learn to embrace the subjective differences between us all, and you won’t just be kinder. You’ll be <em>happier.</em>\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>This is where I’m supposed to put a snarky footnote saying something like “obviously, the correct way is <em>blah</em>,” but you deserve better. So you, uh, get a <em>meta</em> snarky footnote instead.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>Which, to be entirely fair, may well be as subjective as anything else in this blog post.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li></ol></article>","contentSnippet":"A stereotype about programmers is that they like to think in black and white. Programmers like things to be good or bad, moral or immoral, responsible or irresponsible. Perhaps there is something romantic in the idea that programmers like to be as binary as the computers they program. Reductionist? Almost certainly, but hey, laugh at yourself a bit: we probably deserve to be made fun of from time to time.\n\nPersonally, I have no idea if the trope of the nuance-challenged programmer is accurate, but whether it’s a property of programmers or just humans behind a keyboard, the intensity with which we disagree with one another never ceases to amaze. Ask any group of working programmers what their least favorite programming language is, and there’s a pretty good chance things are going to get heated real fast. Why? What is it about programming that makes us feel so strongly that we are right and others are wrong, even when our experiences contradict those of tens or hundreds of thousands of others?\n\nI think about that question a lot.\n\n2015 called, and they want their dress back\nHumans have a knack for caring intensely about the most trivial of things. Name almost anything—cats versus dogs, the appropriate way to fasten a necktie, or even which day of the week comes first—and someone somewhere has probably written an essay about it on an internet forum. It would be easy to throw up our hands and give up trying to understand our peers, as sometimes they seem like aliens from another planet.\n\nHowever, what interests me is how the littlest things seem to get people the most upset. Few people have shouting matches over the best interpretation of quantum mechanics, but friendships will be tested when someone says they just aren’t that into Star Wars. One explanation for this phenomenon is simple accessibility: most people aren’t equipped to understand quantum mechanics well enough to argue about it, but almost anyone can have an opinion on which direction the toilet paper is supposed to go.1\n\nThere is truth in that explanation, but personally, I don’t think it’s the whole story. Rather, I think we grow so used to the idea that our experiences are universal that discovering someone else experienced the exact same thing we did yet came to a different conclusion is not just frustrating: it’s incomprehensible.\n\nTake 2015’s phenomenon of “the dress” as an example. Some people see black and blue, others white and gold, and frankly, whether you see one or the other has no impact on anything remotely meaningful. How did this—something so completely irrelevant—become a cross-cultural phenomenon reported on by major news outlets? My guess: people just aren’t used to the idea that vision—the primary way we sense the world—does not provide us with an objective, universal understanding of reality.\n\nWhen something objective isn’t\nOur culture and society works because, in spite of our differences, we’re still all humans. We eat food, we sleep, we like spending time with each other, and we like feeling connected to those around us. So when we watch a movie, and it tickles us in a way that makes us feel good, we can have an awfully hard time understanding how our best friend—who we largely agree with about everything—didn’t like it at all.\n\nThe truth, of course, is that very little of what we experience is in any way objective. Yes, we can be pretty confident that basic arithmetic is true anywhere in the universe, and that if we all agree a table is brown it probably is. There are even things we accept as subjective without a second thought, such as the kinds of food people like or the fashions they find attractive. It’s all the in-betweens that are so pernicious! “The dress” was so unbelievable to most people because, nine hundred and ninety nine times out of of a thousand, when two humans look at a picture, they at least mostly agree on the colors contained within. We do not consider that we are seeing different lenses into the same objective reality, we simply think we are perceiving objective truths directly.\n\nIn the case of the dress, whether you heard “yanny” or “laurel,” or whether you believe the Sonic games were ever any good, subjective disagreement is essentially harmless. But what about when it isn’t? Might incorrect beliefs that our experiences are universal cause genuine harm?\n\nI think the answer is absolutely, unequivocally yes.\n\nSubjectivity in programming, and in programming languages specifically\nQuick question: which is better, functional or imperative programming?\n\nMy guess, given the usual subject of my blog, most of my readers would pick the former. However, the actual answer you chose doesn’t matter: my guess is you feel like you have a pretty rational argument to back it up. It certainly isn’t simply a matter of taste… right?\n\nWell, no, I hope not. I don’t think the world is so subjective that we cannot ever advocate for one thing over another—we tried that whole “everything is XML” thing for a while, and I think we agreed it really wasn’t a good idea. But if you truly believe your answer to the above question can be completely objectively justified (as many do), how does one explain the average Hacker News comment thread on just about any post about Haskell?\n\nI generally try not to read Hacker News if I can help it, as I find doing it mostly just makes me angry,2 but I did happen to find a link to a recent discussion on a blog post about using Haskell in production. Let’s take a look at a few comments, shall we?\n\nIn a branch of the discussion, one user writes:\n\n\nHaskell is great for business and great in production\n\nI disagree. It's a beautiful language but it lacks a lot of features to make it useable at scale. And in my experience Haskell engineers are extremely smart but the environment/culture they create makes it difficult to foster team spirit.\n\nI've been in 2 companies in the last 4 years who initially used Haskell in production. One has transitioned to Go and the other is rewriting the codebase in Rust.\n\nThe first paragraph is an assertion without many specifics, but it does sound like it could be reasonable. And although the last two sentences are entirely anecdotal, anecdotes are still better than hunches. Let’s see what someone else has to say in response:\n\nI’ve met some pretty damn solid engineers who started on Haskell and, even at a junior level in other languages, produce an elegant solution far more easily than a senior engineer in that language. You probably wouldn’t put the code in production verbatim but you can very easily see what’s going on and it isn’t haunted by spectre of early abstraction, which IMO is the biggest flaw of OOP at scale.\n\n[…]\n\nFrom my naive perspective it’s easy to make classes out of everything, and to hold state and put side-effects everywhere, but you don’t want to deal with the trouble of a monad until you need it. So you have an automatic inclination towards cleaner code when you start functional and move on.\n\nAlso pretty vague and high-level, but also sounds reasonable. If you read either of these comments, and your first inclination was to grow frustrated and start crafting counter-arguments in your head, I encourage you to step outside your feelings momentarily (rational as they may be!) and try your very hardest to interpret them charitably. The discussion continues:\n\nHaskell gives one plenty of rope to hang himself on complexity.\n\nSo much that developers develop an aversion to it as deep as fear. It's unavoidable, the ones that didn't develop it are still buried at the working of their first Rube Goldberg machine and unavailable.\n\nWhether you think it’s accurate or not, there is definitely a perception held by a great many people that Haskell is a very complicated language. Surely at least some of them must have given it an honest shot, so have they just not “seen the light” yet? What do you think they’re missing? Perhaps a followup commenter can help elucidate things:\n\nHi, I find that everything people here are complaining about (and they're valid complaints) has also been true of C++. C++ developed a lot of its complexity (particularly 15-20 yrs ago in the template space) after it got popular, so people were already wed to it.\n\n[…]\n\nThe C++ community's really gotten good in the last 5 years or so about reigning in the bad impulses and getting people to write clean, clear, efficient code that has reasonable expressiveness.\n\nComing into Haskell from C++, I have the same instincts. Haskell's been a pure pleasure. The benefits are really there, and they're easy to get. You just have to think of the trade-offs.\n\nThat argument seems reasonable, too. Everything in moderation, right? If you disagree, and you think Haskell is just not worth it, what does this person value that you don’t? What are they missing that you see?\n\nThe unsatisfying subjective reality of programming languages\nYou can probably see where I’m going with all this. These arguments are not built on hard, refutable facts or rigorous real-world evidence, they’re based in gut feelings and personal preferences. Does that mean they’re wrong, invalid, and worthless, and we should do studies to determine which language allows programmers to ship features the fastest and with the fewest bugs, then all agree to use that?\n\nNo!\n\nThese conversations are subjective because, for better or for worse, humans think in different ways and value different things, and programming languages are the medium in which we express ourselves. To many people who write Haskell (myself included), there is an effervescent joy in modeling a problem with the type system—like capturing something in amber—that others just don’t care about. What’s more, some people clearly loathe Haskell’s significant whitespace and plethora of infix operators, but I’ve never really minded. Is one of us wrong? If so, why? Talk about reliability all you want, but the few rigorous numbers we have don’t provide much evidence one way or the other.\n\nWhile one commenter in the aforementioned Hacker News thread described Haskell as nothing less than “pain and torture,” another says they “did some Haskell in production and it was delightful.” People push excuses and rationalizations for these differences constantly—they point out that most people are exposed to imperative programming first, while others retort that Haskell is clearly not very widely used despite being around for an awfully long time—but none of their arguments ever seem to change people’s minds.\n\nOften, people walk away from these conversations confused and incensed. To them, their point of view is so obviously apparent that it is hard to fathom anyone else seeing things differently. They rack their brains trying to figure out why their opponents just don’t get it. There must be some key point they’ve misunderstood, some joy they haven’t experienced, some sharp edge they haven’t yet been cut by. But no matter how much time they spend trying to reach these people, somehow, it’s never enough.\n\nEmpathy, and how bad results come from good intentions\nI’ll admit that these kinds of discussions aren’t always fruitless; sometimes they really do manage to change people’s minds or help them see some new idea they had not been able to grasp. When people manage to keep their cool and acknowledge the differences in their mindsets while still helping people learn, everyone benefits.\n\nSadly, in my experience, this rarely happens. We have a natural tendency to become angry if people don’t see things the way we do; it’s confusing and disorienting, and it can even disgust us. None of those emotions are conducive to empathy. When we fail to account for the ways in which others might think differently, we voluntarily reject any insights we might have otherwise gained from the conversation because we did not allow ourselves to embrace, even just temporarily, someone else’s strange and perhaps uncomfortable set of values and experiences. We refuse to accept that our perception of color might not be as universal as we thought, and we miss out on the amazing insights we could learn about the nature of light, color, and human vision.\n\nAlthough failing to empathize with those we are arguing with is bad enough, in my mind, this failure to accept the potential subjectivity of one’s own views has even worse, indirect effects. Take this comment for example, again from the same thread:\n\nSounds like you've barely programmed in Haskell and don't know what you're talking about. Haskell was the first language I learned. I didn't think this at all and I still don't. It doesn't strike me as any more difficult than learning Java or something.\n\nI have no doubts that this commenter meant what they said: they didn’t find Haskell difficult to learn. The comment they were replying to was vitriolic and combative, so one could almost feel they had a smackdown coming to them… but this isn’t a private conversation. How do you think someone feels when they are learning Haskell, scroll through this thread, and find a comment that tells them they ought to find it easy? If they’ve been struggling, even a little bit, what do you think they might think?\n\nIf I were in their place, I might feel a little stupid. I might wonder if I’m really cut out for Haskell or if I should just give up. I definitely wouldn’t feel encouraged and excited to keep trying.\n\nWho knows why this commenter found Haskell straightforward. Maybe they were exposed to certain concepts already, maybe it just fit their style of thinking, perhaps they’re even exceptionally smart. I don’t know. But no matter what the answer is, insulting the intelligence of others, even indirectly in this way, belies a lack of empathy in the face of frustration, and although the intent may not have been to hurt, it can still be seriously harmful.\n\nTo be clear, I’m not saying the commenter should have pretended their experiences were different or even kept them to themselves. I don’t believe in being “fake nice”—in my experience, I am best equipped to reach people when speaking genuinely, from the heart. What I would have done is tell my story in a different way, perhaps by writing something like this:\n\nIt’s true that a lot of people find Haskell challenging, and I totally accept that some people just don’t think it’s worth it. It’s fine if you don’t want to write Haskell. But personally, I really enjoy writing it, as do the people I work with, and I think we ship great software with it because it aligns naturally—even joyfully!—with the way we like to think about program construction.\n\nPersonally, I didn’t find Haskell as challenging to learn as I think some people have, but it was still work, and in some ways I was just exposed to it at the right time. Other people I know have struggled quite a lot at first, and reasonably so, but they’ve still managed to become great Haskell programmers, and they found it worthwhile. Our team dynamic just wouldn’t be the same in any other language.\n\nWhen I respond to comments I disagree with, I try to tell a personal story that provides a different perspective without invalidating their experiences. Sometimes the result is ungrateful snark anyway (or just no response at all), but you might be surprised how often talking from an emotional place about your own experiences—while being neither aggressive nor especially defensive—can go a long way. Perhaps you can even learn something if they return the favor and explain what they find frustrating, beyond the fundamental, subjective disagreements.\n\nIt’s okay to have opinions. It’s okay to like and dislike things. It’s okay to be frustrated that others don’t see things the way you do, and to advocate for the technologies and values you believe in. It’s just not okay to tell someone else their reality is wrong.\n\nLearn to embrace the subjective differences between us all, and you won’t just be kinder. You’ll be happier.\n\n\nThis is where I’m supposed to put a snarky footnote saying something like “obviously, the correct way is blah,” but you deserve better. So you, uh, get a meta snarky footnote instead.\n ↩\n\nWhich, to be entirely fair, may well be as subjective as anything else in this blog post.\n ↩","isoDate":"2019-10-19T00:00:00.000Z","timestamp":"10/18/2019"},{"title":"Demystifying MonadBaseControl","pubDate":"2019-09-07T00:00:00.000Z","author":"Alexis King","content":"<article><p><a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#t:MonadBaseControl\"><code>MonadBaseControl</code> from the <code>monad-control</code> package</a> is a confusing typeclass, and its methods have complicated types. For many people, it’s nothing more than scary, impossible-to-understand magic that is, for some reason, needed when lifting certain kinds of operations. Few resources exist that adequately explain how, why, and when it works, which sadly seems to have resulted in some <a href=\"https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt\">FUD</a> about its use.\n</p><p>There’s no doubt that the machinery of <code>MonadBaseControl</code> is complex, and the role it plays in practice is often subtle. However, its essence is actually much simpler than it appears, and I promise it can be understood by mere mortals. In this blog post, I hope to provide a complete survey of <code>MonadBaseControl</code>—how it works, how it’s designed, and how it can go wrong—in a way that is accessible to anyone with a firm grasp of monads and monad transformers. To start, we’ll motivate <code>MonadBaseControl</code> by reinventing it ourselves.\n</p><h2><a name=\"the-higher-order-action-problem\"></a>The higher-order action problem</h2><p>Say we have a function with the following type:<sup><a id=\"footnote-ref-0-1\" href=\"#footnote-0\">1</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span></code></pre><p>If we have an action built from a transformer stack like\n</p><pre><code class=\"pygments\"><span class=\"nf\">bar</span> <span class=\"ow\">::</span> <span class=\"kt\">StateT</span> <span class=\"kt\">X</span> <span class=\"kt\">IO</span> <span class=\"kt\">Y</span></code></pre><p>then we might wish to apply <code>foo</code> to <code>bar</code>, but that is ill-typed, since <code>IO</code> is not the same as <code>StateT X IO</code>. In cases like these, we often use <code>lift</code>, but it’s not good enough here: <code>lift</code> <em>adds</em> a new monad transformer to an action, but here we need to <em>remove</em> a transformer. So we need a function with a type like this:\n</p><pre><code class=\"pygments\"><span class=\"nf\">unliftState</span> <span class=\"ow\">::</span> <span class=\"kt\">StateT</span> <span class=\"kt\">X</span> <span class=\"kt\">IO</span> <span class=\"kt\">Y</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"kt\">Y</span></code></pre><p>However, if you think about that type just a little bit, it’s clear something’s wrong: it throws away information, namely the state. You may remember that a <code>StateT X IO Y</code> action is equivalent to a function of type <code>X -&gt; IO (Y, X)</code>, so our hypothetical <code>unliftState</code> function has two problems:\n</p><ol><li><p>We have no <code>X</code> to use as the initial state.\n</p></li><li><p>We’ll lose any modifications <code>bar</code> made to the state, since the result type is just <code>Y</code>, not <code>(Y, X)</code>.\n</p></li></ol><p>Clearly, we’ll need something more sophisticated, but what?\n</p><h2><a name=\"a-na-ve-solution\"></a>A naïve solution</h2><p>Given that <code>foo</code> doesn’t know anything about the state, we can’t easily thread it through <code>foo</code> itself. However, by using <code>runStateT</code> explicitly, we could do some of the state management ourselves:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">get</span>\n  <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">foo</span> <span class=\"p\">(</span><span class=\"n\">runStateT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n  <span class=\"n\">put</span> <span class=\"n\">s&#39;</span>\n  <span class=\"n\">pure</span> <span class=\"n\">v</span></code></pre><p>Do you see what’s going on there? It’s not actually very complicated: we get the current state, then pass it as the initial state to <code>runStateT</code>. This produces an action <code>IO (a, s)</code> that has <em>closed over</em> the current state. We can pass that action to <code>foo</code> without issue, since <code>foo</code> is polymorphic in the action’s return type. Finally, all we have to do is <code>put</code> the modified state back into the enclosing <code>StateT</code> computation, and we can get on with our business.\n</p><p>That strategy works okay when we only have one monad transformer, but it gets hairy quickly as soon as we have two or more. For example, if we had <code>baz :: ExceptT X (StateT Y IO) Z</code>, then we <em>could</em> do the same trick by getting the underlying\n</p><pre><code class=\"pygments\"><span class=\"kt\">Y</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">X</span> <span class=\"kt\">Z</span><span class=\"p\">,</span> <span class=\"kt\">Y</span><span class=\"p\">)</span></code></pre><p>function, closing over the state, restoring it, and doing the appropriate case analysis to re-raise any <code>ExceptT</code> errors, but that’s a lot of work to do for every single function! What we’d like to do instead is somehow abstract over the pattern we used to write <code>foo'</code> in a way that scales to arbitrary monad transformers.\n</p><h2><a name=\"the-essence-of-monadbasecontrol\"></a>The essence of <code>MonadBaseControl</code></h2><p>To build a more general solution for “unlifting” arbitrary monad transformers, we need to start thinking about monad transformer state. The technique we used to implement <code>foo'</code> operated on the following process:\n</p><ol><li><p>Capture the action’s input state and close over it.\n</p></li><li><p>Package up the action’s output state with its result and run it.\n</p></li><li><p>Restore the action’s output state into the enclosing transformer.\n</p></li><li><p>Return the action’s result.\n</p></li></ol><p>For <code>StateT s</code>, it turns out that the input state and output state are both <code>s</code>, but other monad transformers have state, too. Consider the input and output state for the following common monad transformers:\n</p><div class=\"table-wrapper\">  <table class=\"no-line-wrapping\">    <thead><tr>      <th>transformer</th>      <th>representation</th>      <th>input state</th>      <th>output state</th>    </tr></thead>    <tr>      <td><code>StateT s m a</code></td>      <td><code>s -&gt; m (a, s)</code></td>      <td><code>s</code></td>      <td><code>s</code></td>    </tr>    <tr>      <td><code>ReaderT r m a</code></td>      <td><code>r -&gt; m a</code></td>      <td><code>r</code></td>      <td><code>()</code></td>    </tr>    <tr>      <td><code>WriterT w m a</code></td>      <td><code>m (a, w)</code></td>      <td><code>()</code></td>      <td><code>w</code></td>    </tr>  </table></div><p>Notice how the input state is whatever is to the left of the <code>-&gt;</code>, while the output state is whatever extra information gets produced alongside the result. Using the same reasoning, we can also deduce the input and output state for compositions of multiple monad transformers, such as the following:\n</p><div class=\"table-wrapper\">  <table class=\"no-line-wrapping\">    <thead><tr>      <th>transformer</th>      <th>representation</th>      <th>input state</th>      <th>output state</th>    </tr></thead>    <tr>      <td><code>ReaderT r (WriterT w m) a</code></td>      <td><code>r -&gt; m (a, w)</code></td>      <td><code>r</code></td>      <td><code>w</code></td>    </tr>    <tr>      <td><code>StateT s (ReaderT r m) a</code></td>      <td><code>r -&gt; s -&gt; m (a, s)</code></td>      <td><code>(r, s)</code></td>      <td><code>s</code></td>    </tr>    <tr>      <td><code>WriterT w (StateT s m) a</code></td>      <td><code>s -&gt; m ((a, w), s)</code></td>      <td><code>s</code></td>      <td><code>(w, s)</code></td>    </tr>  </table></div><p>Notice that when monad transformers are composed, their states are composed, too. This is useful to keep in mind, since our goal is to capture the four steps above in a typeclass, polymorphic in the state of the monad transformers we need to lift through. At minimum, we need two new operations: one to capture the input state and close over it (step 1) and one to restore the output state (step 3). One class we might come up with could look like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"n\">m</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">captureInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">InputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">closeOverInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">InputState</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"ow\">::</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>If we can write instances of that typeclass for various transformers, we can use the class’s operations to implement <code>foo'</code> in a generic way that works with any combination of them:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureInputState</span>\n  <span class=\"kr\">let</span> <span class=\"n\">m&#39;</span> <span class=\"ow\">=</span> <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"n\">s</span>\n  <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBase</span> <span class=\"o\">$</span> <span class=\"n\">foo</span> <span class=\"n\">m&#39;</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">s&#39;</span>\n  <span class=\"n\">pure</span> <span class=\"n\">v</span></code></pre><p>So how do we implement those instances? Let’s start with <code>IO</code>, since that’s the base case:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"kt\">IO</span> <span class=\"ow\">=</span> <span class=\"nb\">()</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"kt\">IO</span> <span class=\"ow\">=</span> <span class=\"nb\">()</span>\n  <span class=\"n\">captureInputState</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span>\n  <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"nb\">()</span> <span class=\"ow\">=</span> <span class=\"n\">m</span> <span class=\"o\">&lt;&amp;&gt;</span> <span class=\"p\">(,</span> <span class=\"nb\">()</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"nb\">()</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span></code></pre><p>Not very exciting. The <code>StateT s</code> instance, on the other hand, is significantly more interesting:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"kt\">InputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">captureInputState</span> <span class=\"ow\">=</span> <span class=\"p\">(,)</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"n\">get</span> <span class=\"o\">&lt;*&gt;</span> <span class=\"n\">lift</span> <span class=\"n\">captureInputState</span>\n  <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"p\">((</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">),</span> <span class=\"n\">ss&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">closeOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runStateT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"n\">ss</span>\n    <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">s&#39;</span><span class=\"p\">,</span> <span class=\"n\">ss&#39;</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"o\">*&gt;</span> <span class=\"n\">put</span> <span class=\"n\">s</span></code></pre><p><strong>This instance alone includes most of the key ideas behind <code>MonadBaseControl</code>.</strong> There’s a lot going on, so let’s break it down, step by step:\n</p><ol><li><p>Start by examining the definitions of <code>InputState</code> and <code>OutputState</code>. Are they what you expected? You’d be forgiven for expecting the following:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">s</span>\n<span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">s</span></code></pre><p>After all, that’s what we wrote in the table, isn’t it?\n</p><p>However, if you give it a try, you’ll find it doesn’t work. <code>InputState</code> and <code>OutputState</code> must capture the state of the <em>entire</em> monad, not just a single transformer layer, so we have to combine the <code>StateT s</code> state with the state of the underlying monad. In the simplest case we get\n</p><pre><code class=\"pygments\"><span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"kt\">IO</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"nb\">()</span><span class=\"p\">)</span></code></pre><p>which is boring, but in a more complex case, we need to get something like this:\n</p><pre><code class=\"pygments\"><span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"kt\">IO</span><span class=\"p\">))</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"nb\">()</span><span class=\"p\">))</span></code></pre><p>Therefore, <code>InputState (StateT s m)</code> combines <code>s</code> with <code>InputState m</code> in a tuple, and <code>OutputState</code> does the same.\n</p></li><li><p>Moving on, take a look at <code>captureInputState</code> and <code>closeOverInputState</code>. Just as <code>InputState</code> and <code>OutputState</code> capture the state of the entire monad, these functions need to be inductive in the same way.\n</p><p><code>captureInputState</code> acquires the current state using <code>get</code>, and it combines it with the remaining monadic state using <code>lift captureInputState</code>. <code>closeOverInputState</code> uses the captured state to peel off the outermost <code>StateT</code> layer, then calls <code>closeOverInputState</code> recursively to peel off the rest of them.\n</p></li><li><p>Finally, <code>restoreOutputState</code> restores the state of the underlying monad stack, then restores the <code>StateT</code> state, ensuring everything ends up back the way it’s supposed to be.\n</p></li></ol><p>Take the time to digest all that—work through it yourself if you need to—as it’s a dense piece of code. Once you feel comfortable with it, take a look at the instances for <code>ReaderT</code> and <code>WriterT</code> as well:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"kt\">InputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">captureInputState</span> <span class=\"ow\">=</span> <span class=\"p\">(,)</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"n\">ask</span> <span class=\"o\">&lt;*&gt;</span> <span class=\"n\">lift</span> <span class=\"n\">captureInputState</span>\n  <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">closeOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runReaderT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"n\">ss</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">InputState</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">InputState</span> <span class=\"n\">m</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">captureInputState</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">captureInputState</span>\n  <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"p\">((</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">),</span> <span class=\"n\">ss&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">closeOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runWriterT</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"n\">ss</span>\n    <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">s&#39;</span><span class=\"p\">,</span> <span class=\"n\">ss&#39;</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"o\">*&gt;</span> <span class=\"n\">tell</span> <span class=\"n\">s</span></code></pre><p>Make sure you understand these instances, too. It should be easier this time, since they share most of their structure with the <code>StateT</code> instance, but note the asymmetry that arises from the differing input and output states. (It may even help to try and write these instances yourself, focusing on the types whenever you get stuck.)\n</p><p>If you feel alright with them, then congratulations: you’re already well on your way to grokking <code>MonadBaseControl</code>!\n</p><h3><a name=\"hiding-the-input-state\"></a>Hiding the input state</h3><p>So far, our implementation of <code>MonadBaseControl</code> works, but it’s actually slightly more complicated than it needs to be. As it happens, all valid uses of <code>MonadBaseControl</code> will always end up performing the following pattern:\n</p><pre><code class=\"pygments\"><span class=\"nf\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureInputState</span>\n<span class=\"kr\">let</span> <span class=\"n\">m&#39;</span> <span class=\"ow\">=</span> <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"n\">s</span></code></pre><p>That is, we close over the input state as soon as we capture it. We can therefore combine <code>captureInputState</code> and <code>closeOverInputState</code> into a single function:\n</p><pre><code class=\"pygments\"><span class=\"nf\">captureAndCloseOverInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">))</span></code></pre><p>What’s more, we no longer need the <code>InputState</code> associated type at all! This is an improvement, since it simplifies the API and removes the possibility for any misuse of the input state, since it’s never directly exposed. On the other hand, it has a more complicated type: it produces a monadic action <em>that returns another monadic action</em>. This can be a little more difficult to grok, which is why I presented the original version first, but it may help to consider how the above type arises naturally from the following definition:\n</p><pre><code class=\"pygments\"><span class=\"nf\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"n\">closeOverInputState</span> <span class=\"n\">m</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"n\">captureInputState</span></code></pre><p>Let’s update the <code>MonadBaseControl</code> class to incorporate this simplification:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"ow\">::</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>We can then update all the instances to use the simpler API by simply fusing the definitions of <code>captureInputState</code> and <code>closeOverInputState</code> together:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"kt\">IO</span> <span class=\"ow\">=</span> <span class=\"nb\">()</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"o\">&lt;&amp;&gt;</span> <span class=\"p\">(,</span> <span class=\"nb\">()</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"nb\">()</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">get</span>\n    <span class=\"n\">m&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runStateT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n    <span class=\"n\">pure</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n      <span class=\"p\">((</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">),</span> <span class=\"n\">ss&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">m&#39;</span>\n      <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">s&#39;</span><span class=\"p\">,</span> <span class=\"n\">ss&#39;</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"o\">*&gt;</span> <span class=\"n\">put</span> <span class=\"n\">s</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">ask</span>\n    <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runReaderT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">m&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runWriterT</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n    <span class=\"n\">pure</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n      <span class=\"p\">((</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">),</span> <span class=\"n\">ss&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">m&#39;</span>\n      <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">s&#39;</span><span class=\"p\">,</span> <span class=\"n\">ss&#39;</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"o\">*&gt;</span> <span class=\"n\">tell</span> <span class=\"n\">s</span></code></pre><p>This is already very close to a full <code>MonadBaseControl</code> implementation. The <code>captureAndCloseOverInputState</code> implementations are getting a little out of hand, but bear with me—they’ll get simpler before this blog post is over.\n</p><h3><a name=\"coping-with-partiality\"></a>Coping with partiality</h3><p>Our <code>MonadBaseControl</code> class now works with <code>StateT</code>, <code>ReaderT</code>, and <code>WriterT</code>, but one transformer we haven’t considered is <code>ExceptT</code>. Let’s try to extend our table from before with a row for <code>ExceptT</code>:\n</p><div class=\"table-wrapper\">  <table class=\"no-line-wrapping\">    <thead><tr>      <th>transformer</th>      <th>representation</th>      <th>input state</th>      <th>output state</th>    </tr></thead>    <tr>      <td><code>ExceptT e m a</code></td>      <td><code>m (Either e a)</code></td>      <td><code>()</code></td>      <td><code>???</code></td>    </tr>  </table></div><p>Hmm… what <em>is</em> the output state for <code>ExceptT</code>?\n</p><p>The answer can’t be <code>e</code>, since we might not end up with an <code>e</code>—the computation might not fail. <code>Maybe e</code> would be closer… could that work?\n</p><p>Well, let’s try it. Let’s write a <code>MonadBaseControl</code> instance for <code>ExceptT</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">OutputState</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"kt\">OutputState</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">m&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runExceptT</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n    <span class=\"n\">pure</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n      <span class=\"p\">((</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">),</span> <span class=\"n\">ss&#39;</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">m&#39;</span>\n      <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">s&#39;</span><span class=\"p\">,</span> <span class=\"n\">ss&#39;</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span> <span class=\"o\">*&gt;</span> <span class=\"kr\">case</span> <span class=\"n\">s</span> <span class=\"kr\">of</span>\n    <span class=\"kt\">Just</span> <span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">throwError</span> <span class=\"n\">e</span>\n    <span class=\"kt\">Nothing</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"nb\">()</span></code></pre><p>Sadly, the above implementation doesn’t typecheck; it is rejected with the following type error:\n</p><pre><code>• Couldn't match type ‘Either e a’ with ‘(a, Maybe e)’\n  Expected type: m (b ((a, Maybe e), OutputState m))\n    Actual type: m (b (Either e a, OutputState m))\n• In the second argument of ‘($)’, namely\n    ‘captureAndCloseOverInputState (runExceptT m)’\n  In a stmt of a 'do' block:\n    m' &lt;- lift $ captureAndCloseOverInputState (runExceptT m)\n  In the expression:\n    do m' &lt;- lift $ captureAndCloseOverInputState (runExceptT m)\n       return do ((v, s'), ss') &lt;- m'\n                 pure (v, (s', ss'))\n</code></pre><p>We promised a <code>(a, Maybe e)</code>, but we have an <code>Either e a</code>, and there’s certainly no way to get the former from the latter. Are we stuck? (If you’d like, take a moment to think about how you’d solve this type error before moving on, as it may be helpful for understanding the following solution.)\n</p><p>The fundamental problem here is <em>partiality</em>. The type of the <code>captureAndCloseOverInputState</code> method always produces an action in the base monad that includes an <code>a</code> <em>in addition</em> to some other output state. But <code>ExceptT</code> is different: when it an error is raised, it doesn’t produce an <code>a</code> at all—it only produces an <code>e</code>. Therefore, as written, it’s impossible to give <code>ExceptT</code> a <code>MonadBaseControl</code> instance.\n</p><p>Of course, we’d very much <em>like</em> to give <code>ExceptT</code> a <code>MonadBaseControl</code> instance, so that isn’t very satisfying. Somehow, we need to change <code>captureAndCloseOverInputState</code> so that it doesn’t always need to produce an <code>a</code>. There are a few ways we could accomplish that, but an elegant way to do it is this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"ow\">::</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>We’ve replaced the old <code>OutputState</code> associated type with a new <code>WithOutputState</code> type, and the key difference between them is that <code>WithOutputState</code> describes the type of a <em>combination</em> of the result (of type <code>a</code>) and the output state, rather than describing the type of the output state alone. For total monad transformers like <code>StateT</code>, <code>ReaderT</code>, and <code>WriterT</code>, <code>WithOutputState m a</code> will just be a tuple of the result value and the output state, the same as before. For example, here’s an updated <code>MonadBaseControl</code> instance for <code>StateT</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">get</span>\n    <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runStateT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span>\n    <span class=\"n\">put</span> <span class=\"n\">s</span>\n    <span class=\"n\">pure</span> <span class=\"n\">a</span></code></pre><p>Before we consider how this helps us with <code>ExceptT</code>, let’s pause for a moment and examine the revised <code>StateT</code> instance in detail, as there are some new things going on here:\n</p><ul><li><p>Take a close look at the definition of <code>WithOutputState (StateT s m) a</code>. Note that we’ve defined it to be <code>WithOutputState m (a, s)</code>, <em>not</em> <code>(WithOutputState m a, s)</code>. Consider, for a moment, the difference between these types. Can you see why we used the former, not the latter?\n</p><p>If it’s unclear to you, that’s okay—let’s illustrate the difference with an example. Consider two similar monad transformer stacks:\n</p><pre><code class=\"pygments\"><span class=\"nf\">m1</span> <span class=\"ow\">::</span> <span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"kt\">IO</span><span class=\"p\">)</span> <span class=\"n\">a</span>\n<span class=\"nf\">m2</span> <span class=\"ow\">::</span> <span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"kt\">IO</span><span class=\"p\">)</span> <span class=\"n\">a</span></code></pre><p>Both these stacks contain <code>StateT</code> and <code>ExceptT</code>, but they are layered in a different order. What’s the difference? Well, consider what <code>m1</code> and <code>m2</code> return once fully unwrapped:\n</p><pre><code class=\"pygments\"><span class=\"nf\">runExceptT</span> <span class=\"p\">(</span><span class=\"n\">runStateT</span> <span class=\"n\">m1</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">))</span>\n<span class=\"nf\">runStateT</span> <span class=\"p\">(</span><span class=\"n\">runExceptT</span> <span class=\"n\">m2</span><span class=\"p\">)</span> <span class=\"n\">s</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">e</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">)</span></code></pre><p>These results are meaningfully different: in <code>m1</code>, the state is discarded if an error is raised, but in <code>m2</code>, the final state is always returned, even if the computation is aborted. What does this mean for <code>WithOutputState</code>?\n</p><p>Here’s the important detail: <strong>the state is discarded when <code>ExceptT</code> is “inside” <code>StateT</code>, not the other way around.</strong> This can be counterintuitive, since the <code>s</code> ends up <em>inside</em> the <code>Either</code> when the <code>StateT</code> constructor is on the <em>outside</em> and vice versa. This is really just a property of how monad transformers compose, not anything specific to <code>MonadBaseControl</code>, so an explanation of why this happens is outside the scope of this blog post, but the relevant insight is that the <code>m</code> in <code>StateT s m a</code> controls the eventual action’s output state.\n</p><p>If we had defined <code>WithOutputState (StateT s m) a</code> to be <code>(WithOutputState m a, s)</code>, we’d be in a pickle, since <code>m</code> would be unable to influence the presence of <code>s</code> in the output state. Therefore, we have no choice but to use <code>WithOutputState m (a, s)</code>. (If you are still confused by this, try it yourself; you’ll find that there’s no way to make the other definition typecheck.)\n</p></li><li><p>Now that we’ve developed an intuitive understanding of why <code>WithOutputState</code> must be defined the way it is, let’s look at things from another perspective. Consider the type of <code>runStateT</code> once more:\n</p><pre><code class=\"pygments\"><span class=\"nf\">runStateT</span> <span class=\"ow\">::</span> <span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">s</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">)</span></code></pre><p>Note that the result type is <code>m (a, s)</code>, with the <code>m</code> on the outside. As it happens, this correspondence simplifies the definition of <code>captureAndCloseOverInputState</code>, since we no longer have to do any fiddling with its result—it’s already in the proper shape, so we can just return it directly.\n</p></li><li><p>Finally, this instance illustrates an interesting change to <code>restoreOutputState</code>. Since the <code>a</code> is now packed inside the <code>WithOutputState m a</code> value, the caller of <code>captureAndCloseOverInputState</code> needs some way to get the <code>a</code> back out! Conveniently, <code>restoreOutputState</code> can play that role, both restoring the output state and unpacking the result.\n</p><p>Even ignoring partial transformers like <code>ExceptT</code>, this is an improvement over the old API, as it conveniently prevents the programmer from forgetting to call <code>restoreOutputState</code>. However, as we’ll see shortly, it is much more than a convenience: once <code>ExceptT</code> comes into play, it is essential!\n</p></li></ul><p>With those details addressed, let’s return to <code>ExceptT</code>. Using the new interface, writing an instance for <code>ExceptT</code> is not only possible, it’s actually rather easy:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">e</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span>\n    <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runExceptT</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span>\n    <span class=\"n\">either</span> <span class=\"n\">throwError</span> <span class=\"n\">pure</span> <span class=\"o\">=&lt;&lt;</span> <span class=\"n\">lift</span> <span class=\"p\">(</span><span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span><span class=\"p\">)</span></code></pre><p>This instance illustrates why it’s so crucial that <code>restoreOutputState</code> have the aforementioned dual role: it must handle the case where no <code>a</code> exists at all! In the case of <code>ExceptT</code>, it restores the state in the enclosing monad by re-raising an error.\n</p><p>Now all that’s left to do is update the other instances:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">a</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"ow\">=</span> <span class=\"n\">pure</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">ask</span>\n    <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runReaderT</span> <span class=\"n\">m</span> <span class=\"n\">s</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span>\n    <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"p\">(</span><span class=\"n\">runWriterT</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">restoreOutputState</span> <span class=\"n\">ss</span>\n    <span class=\"n\">tell</span> <span class=\"n\">s</span>\n    <span class=\"n\">pure</span> <span class=\"n\">a</span></code></pre><p>Finally, we can update our lifted variant of <code>foo</code> to use the new interface so it will work with transformer stacks that include <code>ExceptT</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">m&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"o\">=&lt;&lt;</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">foo</span> <span class=\"n\">m&#39;</span><span class=\"p\">)</span></code></pre><p>At this point, it’s worth considering something: although getting the <code>MonadBaseControl</code> class and instances right was a lot of work, the resulting <code>foo'</code> implementation is actually incredibly simple. That’s a good sign, since we only have to write the <code>MonadBaseControl</code> instances once (in a library), but we have to write functions like <code>foo'</code> quite often.\n</p><h2><a name=\"scaling-to-the-real-monadbasecontrol\"></a>Scaling to the real <code>MonadBaseControl</code></h2><p>The <code>MonadBaseControl</code> class we implemented in the previous section is complete. It is a working, useful class that is equivalent in power to <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#t:MonadBaseControl\">the “real” <code>MonadBaseControl</code> class in the <code>monad-control</code> library</a>. However, if you compare the two, you’ll notice that the version in <code>monad-control</code> looks a little bit different. What gives?\n</p><p>Let’s compare the two classes side by side:\n</p><pre><code class=\"pygments\"><span class=\"c1\">-- ours</span>\n<span class=\"kr\">class</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">))</span>\n  <span class=\"n\">restoreOutputState</span> <span class=\"ow\">::</span> <span class=\"kt\">WithOutputState</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n\n<span class=\"c1\">-- theirs</span>\n<span class=\"kr\">class</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"kr\">where</span>\n  <span class=\"kr\">type</span> <span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">liftBaseWith</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">RunInBase</span> <span class=\"n\">m</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">restoreM</span> <span class=\"ow\">::</span> <span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>Let’s start with the similarities, since those are easy:\n</p><ul><li><p>Our <code>WithOutputState</code> associated type is precisely equivalent to their <code>StM</code> associated type, they just use a (considerably) shorter name.\n</p></li><li><p>Likewise, our <code>restoreOutputState</code> method is precisely equivalent to their <code>restoreM</code> method, simply under a different name.\n</p></li></ul><p>That leaves <code>captureAndCloseOverInputState</code> and <code>liftBaseWith</code>. Those two methods both do similar things, but they aren’t identical, and that’s where all the differences lie. To understand <code>liftBaseWith</code>, let’s start by inlining the definition of the <code>RunInBase</code> type alias so we can see the fully-expanded type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">liftBaseWith</span>\n  <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span>\n  <span class=\"ow\">=&gt;</span> <span class=\"p\">((</span><span class=\"n\">forall</span> <span class=\"n\">c</span><span class=\"o\">.</span> <span class=\"n\">m</span> <span class=\"n\">c</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">c</span><span class=\"p\">))</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>That type is complicated! However, if we break it down, hopefully you’ll find it’s not as scary as it first appears. Let’s reimplement the <code>foo'</code> example from before using <code>liftBaseWith</code> to show how this version of <code>MonadBaseControl</code> works:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">foo</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>This is, in some ways, superficially similar to the version we wrote using our version of <code>MonadBaseControl</code>. Just like in our version, we capture the input state, apply <code>foo</code> in the <code>IO</code> monad, then restore the state. But what exactly is doing the state capturing, and what is <code>runInBase</code>?\n</p><p>Let’s start by adding a type annotation to <code>runInBase</code> to help make it a little clearer what’s going on:\n</p><pre><code class=\"pygments\"><span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">b</span><span class=\"o\">.</span> <span class=\"n\">m</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">b</span><span class=\"p\">))</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">foo</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>That type should look sort of recognizable. If we replace <code>StM</code> with <code>WithOutputState</code>, then we get a type that looks very similar to that of our original <code>closeOverInputState</code> function, except it doesn’t need to take the input state as an argument. How does that work?\n</p><p>Here’s the trick: <code>liftBaseWith</code> starts by capturing the input state, just as before. However, it then builds a function, <code>runInBase</code>, which is like <code>closeOverInputState</code> partially-applied to the input state it captured. It hands that function to us, and we’re free to apply it to <code>m</code>, which produces the <code>IO (StM m a)</code> action we need, and we can now pass that action to <code>foo</code>. The result is returned in the outer monad, and we restore the state using <code>restoreM</code>.\n</p><h3><a name=\"sharing-the-input-state\"></a>Sharing the input state</h3><p>At first, this might seem needlessly complicated. When we first started, we separated capturing the input state and closing over it into two separate operations (<code>captureInputState</code> and <code>closeOverInputState</code>), but we eventually combined them so that we could keep the input state hidden. Why does <code>monad-control</code> split them back into two operations again?\n</p><p>As it turns out, when lifting <code>foo</code>, there’s no advantage to the more complicated API of <code>monad-control</code>. In fact, we could implement our <code>captureAndCloseOverInputState</code> operation in terms of <code>liftBaseWith</code>, and we could use that to implement <code>foo'</code> the same way we did before:\n</p><pre><code class=\"pygments\"><span class=\"nf\">captureAndCloseOverInputState</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">))</span>\n<span class=\"nf\">captureAndCloseOverInputState</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n\n<span class=\"nf\">foo&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">foo&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">m&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">m</span>\n  <span class=\"n\">restoreM</span> <span class=\"o\">=&lt;&lt;</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">foo</span> <span class=\"n\">m&#39;</span><span class=\"p\">)</span></code></pre><p>However, that approach has a downside once we need to lift more complicated functions. <code>foo</code> is exceptionally simple, as it only accepts a single input argument, but what if we wanted to lift a more complicated function that took <em>two</em> monadic arguments, such as this one:\n</p><pre><code class=\"pygments\"><span class=\"nf\">bar</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span></code></pre><p>We could implement that by calling <code>captureAndCloseOverInputState</code> twice, like this:\n</p><pre><code class=\"pygments\"><span class=\"nf\">bar&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">bar&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">ma&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">ma</span>\n  <span class=\"n\">mb&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">captureAndCloseOverInputState</span> <span class=\"n\">mb</span>\n  <span class=\"n\">restoreM</span> <span class=\"o\">=&lt;&lt;</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">bar</span> <span class=\"n\">ma&#39;</span> <span class=\"n\">mb&#39;</span><span class=\"p\">)</span></code></pre><p>However, that would capture the monadic state twice, which is rather inefficient. By using <code>liftBaseWith</code>, the state capturing is done just once, and it’s shared between all calls to <code>runInBase</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">bar&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">bar&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">bar</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">ma</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">mb</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>By providing a “running” function (<code>runInBase</code>) instead of direct access to the input state, <code>liftBaseWith</code> allows sharing the captured input state between multiple actions without exposing it directly.\n</p><h3><a name=\"sidebar-continuation-passing-and-impredicativity\"></a>Sidebar: continuation-passing and impredicativity</h3><p>One last point before we move on: although the above explains why <code>captureAndCloseOverInputState</code> is insufficient, you may be left wondering why <code>liftBaseWith</code> can’t just <em>return</em> <code>runInBase</code>. Why does it need to be given a continuation? After all, it would be nicer if we could just write this:\n</p><pre><code class=\"pygments\"><span class=\"nf\">bar&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">bar&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">runInBase</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">askRunInBase</span>\n  <span class=\"n\">restoreM</span> <span class=\"o\">=&lt;&lt;</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">bar</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">ma</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">mb</span><span class=\"p\">))</span></code></pre><p>To understand the problem with a hypothetical <code>askRunInBase</code> function, remember that the type of <code>runInBase</code> is polymorphic:\n</p><pre><code class=\"pygments\"><span class=\"nf\">runInBase</span> <span class=\"ow\">::</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>This is important, since if you need to lift a function with a type like\n</p><pre><code class=\"pygments\"><span class=\"nf\">baz</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">c</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">b</span> <span class=\"n\">c</span><span class=\"p\">)</span></code></pre><p>then you’ll want to instantiate that <code>a</code> variable with two different types. We’d need to retain that power in <code>askRunInBase</code>, so it would need to have the following type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">askRunInBase</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">))</span></code></pre><p>Sadly, that type is illegal in Haskell. Type constructors must be applied to monomorphic types, but in the above type signature, <code>m</code> is applied to a polymorphic type.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">2</a></sup> The <code>RankNTypes</code> GHC extension introduces a single exception: the <code>(-&gt;)</code> type constructor is special and may be applied to polymorphic types. That’s why <code>liftBaseWith</code> is legal, but <code>askRunInBase</code> is not: since <code>liftBaseWith</code> is passed a higher-order function that receives <code>runInBase</code> as an argument, the polymorphic type appears immediately under an application of <code>(-&gt;)</code>, which is allowed.\n</p><p>The aforementioned restriction means we’re basically out of luck, but if you <em>really</em> want <code>askRunInBase</code>, there is a workaround. GHC is perfectly alright with a field of a datatype being polymorphic, so we can define a newtype that wraps a suitably-polymorphic function:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">RunInBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kt\">RunInBase</span> <span class=\"p\">(</span><span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">))</span></code></pre><p>We can now alter <code>askRunInBase</code> to return our newtype, and we can implement it in terms of <code>liftBaseWith</code>:<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">3</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"nf\">askRunInBase</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"n\">b</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">RunInBase</span> <span class=\"n\">b</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"nf\">askRunInBase</span> <span class=\"ow\">=</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"o\">$</span> <span class=\"kt\">RunInBase</span> <span class=\"n\">runInBase</span></code></pre><p>To use <code>askRunInBase</code>, we have to pattern match on the <code>RunInBase</code> constructor, but it isn’t very noisy, since we can do it directly in a <code>do</code> binding. For example, we could implement a lifted version of <code>baz</code> this way:\n</p><pre><code class=\"pygments\"><span class=\"nf\">baz&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n<span class=\"nf\">baz&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"kt\">RunInBase</span> <span class=\"n\">runInBase</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">askRunInBase</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">baz</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">ma</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">mb</span><span class=\"p\">))</span>\n  <span class=\"n\">bitraverse</span> <span class=\"n\">restoreM</span> <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>As of version 1.0.2.3, <code>monad-control</code> does not provide a newtype like <code>RunInBase</code>, so it also doesn’t provide a function like <code>askRunInBase</code>. For now, you’ll have to use <code>liftBaseWith</code>, but it might be a useful future addition to the library.\n</p><h2><a name=\"pitfalls\"></a>Pitfalls</h2><p>At this point in the blog post, we’ve covered the essentials of <code>MonadBaseControl</code>: how it works, how it’s designed, and how you might go about using it. However, so far, we’ve only considered situations where <code>MonadBaseControl</code> works well, and I’ve intentionally avoided examples where the technique breaks down. In this section, we’re going to take a look at the pitfalls and drawbacks of <code>MonadBaseControl</code>, plus some ways they can be mitigated.\n</p><h3><a name=\"no-polymorphism-no-lifting\"></a>No polymorphism, no lifting</h3><p>All of the pitfalls of <code>MonadBaseControl</code> stem from the same root problem, and that’s the particular technique it uses to save and restore monadic state. We’ll start by considering one of the simplest ways that technique is thwarted, and that’s monomorphism. Consider the following two functions:\n</p><pre><code class=\"pygments\"><span class=\"nf\">poly</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span>\n<span class=\"nf\">mono</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"kt\">X</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"kt\">X</span></code></pre><p>Even after all we’ve covered, it may surprise you to learn that although <code>poly</code> can be easily lifted to <code>MonadBaseControl IO m =&gt; m a -&gt; m a</code>, it’s <em>impossible</em> to lift <code>mono</code> to <code>MonadBaseControl IO m =&gt; m X -&gt; m X</code>. It’s a little unintuitive, as we often think of polymorphic types as being more complicated (so surely lifting polymorphic functions ought to be harder), but in fact, it’s the flexibility of polymorphism that allows <code>MonadBaseControl</code> to work in the first place.\n</p><p>To understand the problem, remember that when we lift a function of type <code>forall a. b a -&gt; b a</code> using <code>MonadBaseControl</code>, we actually instantiate <code>a</code> to <code>(StM m c)</code>. That produces a function of type <code>b (StM m c) -&gt; b (StM m c)</code>, which is isomorphic to the <code>m c -&gt; m c</code> type we want. The instantiation step is easily overlooked, but it’s crucial, since otherwise we have no way to thread the state through the otherwise opaque function we’re trying to lift!\n</p><p>In the case of <code>mono</code>, that’s exactly the problem we’re faced with. <code>mono</code> will not accept an <code>IO (StM m X)</code> as an argument, only precisely an <code>IO X</code>, so we can’t pass along the monadic state. For all its machinery, <code>MonadBaseControl</code> is no help at all if no polymorphism is involved. Trying to generalize <code>mono</code> without modifying its implementation is a lost cause.\n</p><h3><a name=\"the-dangers-of-discarded-state\"></a>The dangers of discarded state</h3><p>Our inability to lift <code>mono</code> is frustrating, but at least it’s conclusively impossible. In practice, however, many functions lie in an insidious in-between: polymorphic enough to be lifted, but not without compromises. The simplest of these functions have types such as the following:\n</p><pre><code class=\"pygments\"><span class=\"nf\">sideEffect</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span></code></pre><p>Unlike <code>mono</code>, it’s entirely possible to lift <code>sideEffect</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">sideEffect&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n<span class=\"nf\">sideEffect&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">sideEffect</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>This definition typechecks, but you may very well prefer it didn’t, since it has a serious problem: any changes made by <code>m</code> to the monadic state are completely discarded once <code>sideEffect'</code> returns! Since <code>sideEffect'</code> never calls <code>restoreM</code>, there’s no way the state of <code>m</code> can be any different from the original state, but it’s impossible to call <code>restoreM</code> since we don’t actually get an <code>StM m ()</code> result from <code>sideEffect</code>.\n</p><p>Sometimes this may be acceptable, since some monad transformers don’t actually have any output state anyway, such as <code>ReaderT r</code>. In other cases, however, <code>sideEffect'</code> could be a bug waiting to happen. One way to make <code>sideEffect'</code> safe would be to add a <code>StM m a ~ a</code> constraint to its context, since that guarantees the monad transformers being lifted through are stateless, and nothing is actually being discarded. Of course, that significantly restricts the set of monad transformers that can be lifted through.\n</p><h4><a name=\"rewindable-state\"></a>Rewindable state</h4><p>One scenario where state discarding can actually be useful is operations with so-called rewindable or transactional state. The most common example of such an operation is <code>catch</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">catch</span> <span class=\"ow\">::</span> <span class=\"kt\">Exception</span> <span class=\"n\">e</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span></code></pre><p>When lifted, state changes from the action <em>or</em> from the exception handler will be “committed,” but never both. If an exception is raised during the computation, those state changes are discarded (“rewound”), giving <code>catch</code> a kind of backtracking semantics. This behavior arises naturally from the way a lifted version of <code>catch</code> must be implemented:\n</p><pre><code class=\"pygments\"><span class=\"nf\">catch&#39;</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">Exception</span> <span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">catch&#39;</span> <span class=\"n\">m</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"o\">.</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>If <code>m</code> raises an exception, it will never return an <code>StM m a</code> value, so there’s no way to get ahold of any of the state changes that happened before the exception. Therefore, the only option is to discard that state.\n</p><p>This behavior is actually quite useful, and it’s definitely not unreasonable. However, useful or not, it’s inconsistent with state changes to mutable values like <code>IORef</code>s or <code>MVar</code>s (they stay modified whether an exception is raised or not), so it can still be a gotcha. Either way, it’s worth being aware of.\n</p><h4><a name=\"partially-discarded-state\"></a>Partially discarded state</h4><p>The next function we’re going to examine is <code>finally</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">finally</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span></code></pre><p>This function has a similar type to <code>catch</code>, and it even has similar semantics. Like <code>catch</code>, <code>finally</code> can be lifted, but unlike <code>catch</code>, its state <em>can’t</em> be given any satisfying treatment. The only way to implement a lifted version is\n</p><pre><code class=\"pygments\"><span class=\"nf\">finally&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">finally&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">finally</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">ma</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"n\">mb</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreM</span> <span class=\"n\">s</span></code></pre><p>which always discards all state changes made by the second argument. This is clear just from looking at <code>finally</code>’s type: since <code>b</code> doesn’t appear anywhere in the return type, there’s simply no way to access that action’s result, and therefore no way to access its modified state.\n</p><p>However, don’t despair: there actually <em>is</em> a way to produce a lifted version of <code>finally</code> that preserves all state changes. It can’t be done by lifting <code>finally</code> directly, but if we reimplement <code>finally</code> in terms of simpler lifted functions that are more amenable to lifting, we can produce a lifted version of <code>finally</code> that preserves all the state:<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">4</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"nf\">finally&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">finally&#39;</span> <span class=\"n\">ma</span> <span class=\"n\">mb</span> <span class=\"ow\">=</span> <span class=\"n\">mask&#39;</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">restore</span> <span class=\"ow\">-&gt;</span> <span class=\"kr\">do</span>\n  <span class=\"n\">a</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"n\">try</span> <span class=\"p\">(</span><span class=\"n\">runInBase</span> <span class=\"p\">(</span><span class=\"n\">restore</span> <span class=\"n\">ma</span><span class=\"p\">))</span>\n  <span class=\"kr\">case</span> <span class=\"n\">a</span> <span class=\"kr\">of</span>\n    <span class=\"kt\">Left</span> <span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">mb</span> <span class=\"o\">*&gt;</span> <span class=\"n\">liftBase</span> <span class=\"p\">(</span><span class=\"n\">throwIO</span> <span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"ow\">::</span> <span class=\"kt\">SomeException</span><span class=\"p\">))</span>\n    <span class=\"kt\">Right</span> <span class=\"n\">s</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">restoreM</span> <span class=\"n\">s</span> <span class=\"o\">&lt;*</span> <span class=\"n\">mb</span></code></pre><p>This illustrates an important (and interesting) point about <code>MonadBaseControl</code>: whether or not an operation can be made state-preserving is not a fundamental property of the operation’s type, but rather a property of the types of the exposed primitives. There is sometimes a way to implement a state-preserving variant of operations that might otherwise seem unliftable given the right primitives and a bit of cleverness.\n</p><h4><a name=\"forking-state\"></a>Forking state</h4><p>As a final example, I want to provide an example where the state may not actually be discarded <em>per se</em>, just inaccessible. Consider the type of <code>forkIO</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">forkIO</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"kt\">ThreadId</span></code></pre><p>Although <code>forkIO</code> isn’t actually polymorphic in its argument, we can convert <em>any</em> <code>IO</code> action to one that produces <code>()</code> via <code>void</code>, so it might as well be. Therefore, we can lift <code>forkIO</code> in much the same way we did with <code>sideEffect</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">forkIO&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">ThreadId</span>\n<span class=\"nf\">forkIO&#39;</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"n\">liftBaseWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">runInBase</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">forkIO</span> <span class=\"p\">(</span><span class=\"n\">void</span> <span class=\"o\">$</span> <span class=\"n\">runInBase</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>As with <code>sideEffect</code>, we can’t recover the output state, but in this case, there’s a fundamental reason that goes deeper than the types: we’ve forked off a concurrent computation! We’ve therefore split the state in two, which might be what we want… but it also might not. <code>forkIO</code> is yet another illustration that it’s important to think about the state-preservation semantics when using <code>MonadBaseControl</code>, or you may end up with a bug!\n</p><h2><a name=\"monadbasecontrol-in-context\"></a><code>MonadBaseControl</code> in context</h2><p>Congratulations: you’ve made it through most of this blog post. If you’ve followed everything so far, you now understand <code>MonadBaseControl</code>. All the tricky parts are over. However, before wrapping up, I’d like to add a little extra information about how <code>MonadBaseControl</code> relates to various other parts of the Haskell ecosystem. In practice, that information can be as important as understanding <code>MonadBaseControl</code> itself.\n</p><h3><a name=\"the-remainder-of-monad-control\"></a>The remainder of <code>monad-control</code></h3><p>If you look at <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html\">the documentation for <code>monad-control</code></a>, you’ll find that it provides more than just the <code>MonadBaseControl</code> typeclass. I’m not going to cover everything else in detail in this blog post, but I do want to touch upon it briefly.\n</p><p>First off, you should definitely take a look at the handful of helper functions provided by <code>monad-control</code>, such as <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#v:control\"><code>control</code></a> and <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#v:liftBaseOp_\"><code>liftBaseOp_</code></a>. These functions provide support for lifting common function types without having to use <code>liftBaseWith</code> directly. It’s useful to understand <code>liftBaseWith</code>, since it’s the most general way to use <code>MonadBaseControl</code>, but in practice, it is simpler and more readable to use the more specialized functions wherever possible. Many of the examples in this very blog post could be simplified using them, and I only stuck to <code>liftBaseWith</code> to introduce as few new concepts at a time as possible.\n</p><p>Second, I’d like to mention the related <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#t:MonadTransControl\"><code>MonadTransControl</code></a> typeclass. You hopefully remember from earlier in the blog post how we defined <code>MonadBaseControl</code> instances inductively so that we could lift all the way down to the base monad. <code>MonadTransControl</code> is like <code>MonadBaseControl</code> if it intentionally did <em>not</em> do that—it allows lifting through a single transformer at a time, rather than through all of them at once.\n</p><p>Usually, <code>MonadTransControl</code> is not terribly useful to use directly (though I did use it once <a href=\"/blog/2017/04/28/lifts-for-free-making-mtl-typeclasses-derivable/#making-mtls-classes-derivable\">in a previous blog post of mine</a> to help derive instances of mtl-style classes), but it <em>is</em> useful for implementing <code>MonadBaseControl</code> instances for your own transformers. If you define a <code>MonadTransControl</code> instance for your monad transformer, you can get a <code>MonadBaseControl</code> implementation for free using the provided <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#t:ComposeSt\"><code>ComposeSt</code></a>, <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#v:defaultLiftBaseWith\"><code>defaultLiftBaseWith</code></a>, and <a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#v:defaultRestoreM\"><code>defaultRestoreM</code></a> bindings; see the documentation for more details.\n</p><h3><a name=\"lifted-base-and-lifted-async\"></a><code>lifted-base</code> and <code>lifted-async</code></h3><p>If you’re going to use <code>MonadBaseControl</code>, the <a href=\"http://hackage.haskell.org/package/lifted-base\"><code>lifted-base</code></a> and <a href=\"http://hackage.haskell.org/package/lifted-async\"><code>lifted-async</code></a> packages are good to know about. As their names imply, they provide lifted versions of bindings in the <code>base</code> and <code>async</code> packages, so you can use them directly without needing to lift them yourself. For example, if you needed a lifted version of <code>mask</code> from <code>Control.Exception</code>, you could swap it for the <code>mask</code> export from <code>Control.Exception.Lifted</code>, and everything would mostly just work (though always be sure to check the documentation for any caveats on state discarding).\n</p><h3><a name=\"relationship-to-monadunliftio\"></a>Relationship to <code>MonadUnliftIO</code></h3><p>Recently, FP Complete has developed the <a href=\"https://hackage.haskell.org/package/unliftio\"><code>unliftio</code></a> package as an alternative to <code>monad-control</code>. It provides the <a href=\"https://hackage.haskell.org/package/unliftio-core-0.1.2.0/docs/Control-Monad-IO-Unlift.html#t:MonadUnliftIO\"><code>MonadUnliftIO</code></a> typeclass, which is similar in spirit to <code>MonadBaseControl</code>, but heavily restricted: it is specialized to <code>IO</code> as the base monad, and it <em>only</em> allows instances for stateless monads, such as <code>ReaderT</code>. This is designed to encourage the so-called <a href=\"https://www.fpcomplete.com/blog/2017/06/readert-design-pattern\"><code>ReaderT</code> design pattern</a>, which avoids ever using stateful monads like <code>ExceptT</code> or <code>StateT</code> over <code>IO</code>, encouraging the use of <code>IO</code> exceptions and mutable variables (e.g. <code>MVar</code>s or <code>TVar</code>s) instead.\n</p><p>I should be clear: I really like most of what FP Complete has done—to this day, I still use <code>stack</code> as my Haskell build tool of choice—and I think the suggestions given in the aforementioned “<code>ReaderT</code> design pattern” blog post have real weight to them. I have a deep respect for Michael Snoyman’s commitment to opinionated, user-friendly tools and libraries. But truthfully, I can’t stand <code>MonadUnliftIO</code>.\n</p><p><code>MonadUnliftIO</code> is designed to avoid all the complexity around state discarding that <code>MonadBaseControl</code> introduces, and on its own, that’s a noble goal. Safety first, after all. The problem is that <code>MonadUnliftIO</code> really is extremely limiting, and what’s more, it can actually be trivially encoded in terms of <code>MonadBaseControl</code> as follows:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">MonadUnliftIO</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"n\">forall</span> <span class=\"n\">a</span><span class=\"o\">.</span> <span class=\"kt\">StM</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"o\">~</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>This alias can be used to define safe, lifted functions that never discard state while still allowing functions that <em>can</em> be safely lifted through stateful transformers to do so. Indeed, the <a href=\"https://hackage.haskell.org/package/lifted-async-0.10.0.4/docs/Control-Concurrent-Async-Lifted-Safe.html\"><code>Control.Concurrent.Async.Lifted.Safe</code></a> module from <code>lifted-async</code> does exactly that (albeit with a slightly different formulation than the above alias).\n</p><p>To be fair, the <code>unliftio</code> README does address this in its <a href=\"https://github.com/fpco/unliftio/tree/bb2e26e7fbbaebb15555f417ba9753a76b3218b2/unliftio#monad-control\">comparison section</a>:\n</p><blockquote><p><code>monad-control</code> allows us to unlift both styles. In theory, we could write a variant of <code>lifted-base</code> that never does state discards […] In other words, this is an advantage of <code>monad-control</code> over <code>MonadUnliftIO</code>. We've avoided providing any such extra typeclass in this package though, for two reasons:\n</p><ul><li><p><code>MonadUnliftIO</code> is a simple typeclass, easy to explain. We don't want to complicated [sic] matters […]\n</p></li><li><p>Having this kind of split would be confusing in user code, when suddenly [certain operations are] not available to us.\n</p></li></ul></blockquote><p>In other words, the authors of <code>unliftio</code> felt that <code>MonadBaseControl</code> was simply not worth the complexity, and they could get away with <code>MonadUnliftIO</code>. Frankly, if you feel the same way, by all means, use <code>unliftio</code>. I just found it too limiting given the way I write Haskell, plain and simple.\n</p><h2><a name=\"recap\"></a>Recap</h2><p>So ends another long blog post. As often seems the case, I set out to write something short, but I ended up writing well over 5,000 words. I suppose that means I learned something from this experience, too: <code>MonadBaseControl</code> is more complicated than I had anticipated! Maybe there’s something to take away from that.\n</p><p>In any case, it’s over now, so I’d like to briefly summarize what we’ve covered:\n</p><ul><li><p><a href=\"https://hackage.haskell.org/package/monad-control-1.0.2.3/docs/Control-Monad-Trans-Control.html#t:MonadBaseControl\"><code>MonadBaseControl</code></a> allows us to lift higher-order monadic operations.\n</p></li><li><p>It operates by capturing the current monadic state and explicitly threading it through the action in the base monad before restoring it.\n</p></li><li><p>That technique works well for polymorphic operations for the type <code>forall a. b a -&gt; b a</code>, but it can be tricky or even impossible for more complex operations, sometimes leading to discarded state.\n</p><p>This can sometimes be mitigated by restricting certain operations to stateless monads using a <code>StM m a ~ a</code> constraint, or by reimplementing the operation in terms of simpler primitives.\n</p></li><li><p>The <a href=\"http://hackage.haskell.org/package/lifted-base\"><code>lifted-base</code></a> and <a href=\"http://hackage.haskell.org/package/lifted-async\"><code>lifted-async</code></a> packages provide lifted versions of existing operations, avoiding the need to lift them yourself.\n</p></li></ul><p>As with many abstractions in Haskell, don’t worry too much if you don’t have a completely firm grasp of <code>MonadBaseControl</code> at first. Insight often comes with repeated experience, and <code>monad-control</code> can still be used in useful ways even without a perfect understanding. My hope is that this blog post has helped you build intuitions about <code>MonadBaseControl</code> even if some of the underlying machinery remains a little fuzzy, and I hope it can also serve as a reference for those who want or need to understand (or just be reminded of) all the little details.\n</p><p>Finally, I’ll admit <code>MonadBaseControl</code> isn’t especially elegant or beautiful as Haskell abstractions go. In fact, in many ways, it’s a bit of a kludge! Perhaps, in time, effect systems will evolve and mature so that it and its ilk are no longer necessary, and they may become distant relics of an inferior past. But in the meantime, it’s here, it’s useful, and I think it’s worth embracing. If you’ve shied away from it in the past, I hope I’ve illuminated it enough to make you consider giving it another try.\n</p><ol class=\"footnotes\"><li id=\"footnote-0\"><p>One example of a function with that type is <code>mask_</code>.\n <a href=\"#footnote-ref-0-1\">↩</a></p></li><li id=\"footnote-1\"><p>Types with polymorphic types under type constructors are called <em>impredicative</em>. GHC technically has limited support for impredicativity via the <code>ImpredicativeTypes</code> language extension, but as of GHC 8.8, it has been fairly broken for some time. A fix is apparently being worked on, but even if that effort is successful, I don’t know what impact it will have on type inference.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>Note that <code>askRunInBase = liftBaseWith (pure . RunInBase)</code> does <em>not</em> typecheck, as it would require impredicative polymorphism: it would require instantiating the type of <code>(.)</code> with polymorphic types. The version using <code>($)</code> works because GHC actually has special typechecking rules for <code>($)</code>! Effectively, <code>f $ x</code> is really syntax in GHC.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>Assume that <code>mask'</code> is a suitably lifted version of <code>mask</code> (which can in fact be made state-preserving).\n <a href=\"#footnote-ref-3-1\">↩</a></p></li></ol></article>","contentSnippet":"MonadBaseControl from the monad-control package is a confusing typeclass, and its methods have complicated types. For many people, it’s nothing more than scary, impossible-to-understand magic that is, for some reason, needed when lifting certain kinds of operations. Few resources exist that adequately explain how, why, and when it works, which sadly seems to have resulted in some FUD about its use.\n\nThere’s no doubt that the machinery of MonadBaseControl is complex, and the role it plays in practice is often subtle. However, its essence is actually much simpler than it appears, and I promise it can be understood by mere mortals. In this blog post, I hope to provide a complete survey of MonadBaseControl—how it works, how it’s designed, and how it can go wrong—in a way that is accessible to anyone with a firm grasp of monads and monad transformers. To start, we’ll motivate MonadBaseControl by reinventing it ourselves.\n\nThe higher-order action problem\nSay we have a function with the following type:1\n\nfoo :: IO a -> IO a\nIf we have an action built from a transformer stack like\n\nbar :: StateT X IO Y\nthen we might wish to apply foo to bar, but that is ill-typed, since IO is not the same as StateT X IO. In cases like these, we often use lift, but it’s not good enough here: lift adds a new monad transformer to an action, but here we need to remove a transformer. So we need a function with a type like this:\n\nunliftState :: StateT X IO Y -> IO Y\nHowever, if you think about that type just a little bit, it’s clear something’s wrong: it throws away information, namely the state. You may remember that a StateT X IO Y action is equivalent to a function of type X -> IO (Y, X), so our hypothetical unliftState function has two problems:\n\n\nWe have no X to use as the initial state.\n\n\nWe’ll lose any modifications bar made to the state, since the result type is just Y, not (Y, X).\n\n\nClearly, we’ll need something more sophisticated, but what?\n\nA naïve solution\nGiven that foo doesn’t know anything about the state, we can’t easily thread it through foo itself. However, by using runStateT explicitly, we could do some of the state management ourselves:\n\nfoo' :: StateT s IO a -> StateT s IO a\nfoo' m = do\n  s <- get\n  (v, s') <- lift $ foo (runStateT m s)\n  put s'\n  pure v\nDo you see what’s going on there? It’s not actually very complicated: we get the current state, then pass it as the initial state to runStateT. This produces an action IO (a, s) that has closed over the current state. We can pass that action to foo without issue, since foo is polymorphic in the action’s return type. Finally, all we have to do is put the modified state back into the enclosing StateT computation, and we can get on with our business.\n\nThat strategy works okay when we only have one monad transformer, but it gets hairy quickly as soon as we have two or more. For example, if we had baz :: ExceptT X (StateT Y IO) Z, then we could do the same trick by getting the underlying\n\nY -> IO (Either X Z, Y)\nfunction, closing over the state, restoring it, and doing the appropriate case analysis to re-raise any ExceptT errors, but that’s a lot of work to do for every single function! What we’d like to do instead is somehow abstract over the pattern we used to write foo' in a way that scales to arbitrary monad transformers.\n\nThe essence of MonadBaseControl\nTo build a more general solution for “unlifting” arbitrary monad transformers, we need to start thinking about monad transformer state. The technique we used to implement foo' operated on the following process:\n\n\nCapture the action’s input state and close over it.\n\n\nPackage up the action’s output state with its result and run it.\n\n\nRestore the action’s output state into the enclosing transformer.\n\n\nReturn the action’s result.\n\n\nFor StateT s, it turns out that the input state and output state are both s, but other monad transformers have state, too. Consider the input and output state for the following common monad transformers:\n\n  \n    \n      transformer      representation      input state      output state    \n    \n      StateT s m a      s -> m (a, s)      s      s    \n    \n      ReaderT r m a      r -> m a      r      ()    \n    \n      WriterT w m a      m (a, w)      ()      w    \n  \n\nNotice how the input state is whatever is to the left of the ->, while the output state is whatever extra information gets produced alongside the result. Using the same reasoning, we can also deduce the input and output state for compositions of multiple monad transformers, such as the following:\n\n  \n    \n      transformer      representation      input state      output state    \n    \n      ReaderT r (WriterT w m) a      r -> m (a, w)      r      w    \n    \n      StateT s (ReaderT r m) a      r -> s -> m (a, s)      (r, s)      s    \n    \n      WriterT w (StateT s m) a      s -> m ((a, w), s)      s      (w, s)    \n  \n\nNotice that when monad transformers are composed, their states are composed, too. This is useful to keep in mind, since our goal is to capture the four steps above in a typeclass, polymorphic in the state of the monad transformers we need to lift through. At minimum, we need two new operations: one to capture the input state and close over it (step 1) and one to restore the output state (step 3). One class we might come up with could look like this:\n\nclass MonadBase b m => MonadBaseControl b m | m -> b where\n  type InputState m\n  type OutputState m\n  captureInputState :: m (InputState m)\n  closeOverInputState :: m a -> InputState m -> b (a, OutputState m)\n  restoreOutputState :: OutputState m -> m ()\nIf we can write instances of that typeclass for various transformers, we can use the class’s operations to implement foo' in a generic way that works with any combination of them:\n\nfoo' :: MonadBaseControl IO m => m a -> m a\nfoo' m = do\n  s <- captureInputState\n  let m' = closeOverInputState m s\n  (v, s') <- liftBase $ foo m'\n  restoreOutputState s'\n  pure v\nSo how do we implement those instances? Let’s start with IO, since that’s the base case:\n\ninstance MonadBaseControl IO IO where\n  type InputState IO = ()\n  type OutputState IO = ()\n  captureInputState = pure ()\n  closeOverInputState m () = m <&> (, ())\n  restoreOutputState () = pure ()\nNot very exciting. The StateT s instance, on the other hand, is significantly more interesting:\n\ninstance MonadBaseControl b m => MonadBaseControl b (StateT s m) where\n  type InputState (StateT s m) = (s, InputState m)\n  type OutputState (StateT s m) = (s, OutputState m)\n  captureInputState = (,) <$> get <*> lift captureInputState\n  closeOverInputState m (s, ss) = do\n    ((v, s'), ss') <- closeOverInputState (runStateT m s) ss\n    pure (v, (s', ss'))\n  restoreOutputState (s, ss) = lift (restoreOutputState ss) *> put s\nThis instance alone includes most of the key ideas behind MonadBaseControl. There’s a lot going on, so let’s break it down, step by step:\n\n\nStart by examining the definitions of InputState and OutputState. Are they what you expected? You’d be forgiven for expecting the following:\n\ntype InputState (StateT s m) = s\ntype OutputState (StateT s m) = s\nAfter all, that’s what we wrote in the table, isn’t it?\n\nHowever, if you give it a try, you’ll find it doesn’t work. InputState and OutputState must capture the state of the entire monad, not just a single transformer layer, so we have to combine the StateT s state with the state of the underlying monad. In the simplest case we get\n\nInputState (StateT s IO) = (s, ())\nwhich is boring, but in a more complex case, we need to get something like this:\n\nInputState (StateT s (ReaderT IO)) = (s, (r, ()))\nTherefore, InputState (StateT s m) combines s with InputState m in a tuple, and OutputState does the same.\n\n\nMoving on, take a look at captureInputState and closeOverInputState. Just as InputState and OutputState capture the state of the entire monad, these functions need to be inductive in the same way.\n\ncaptureInputState acquires the current state using get, and it combines it with the remaining monadic state using lift captureInputState. closeOverInputState uses the captured state to peel off the outermost StateT layer, then calls closeOverInputState recursively to peel off the rest of them.\n\n\nFinally, restoreOutputState restores the state of the underlying monad stack, then restores the StateT state, ensuring everything ends up back the way it’s supposed to be.\n\n\nTake the time to digest all that—work through it yourself if you need to—as it’s a dense piece of code. Once you feel comfortable with it, take a look at the instances for ReaderT and WriterT as well:\n\ninstance MonadBaseControl b m => MonadBaseControl b (ReaderT r m) where\n  type InputState (ReaderT r m) = (r, InputState m)\n  type OutputState (ReaderT r m) = OutputState m\n  captureInputState = (,) <$> ask <*> lift captureInputState\n  closeOverInputState m (s, ss) = closeOverInputState (runReaderT m s) ss\n  restoreOutputState ss = lift (restoreOutputState ss)\n\ninstance (MonadBaseControl b m, Monoid w) => MonadBaseControl b (WriterT w m) where\n  type InputState (WriterT w m) = InputState m\n  type OutputState (WriterT w m) = (w, OutputState m)\n  captureInputState = lift captureInputState\n  closeOverInputState m ss = do\n    ((v, s'), ss') <- closeOverInputState (runWriterT m) ss\n    pure (v, (s', ss'))\n  restoreOutputState (s, ss) = lift (restoreOutputState ss) *> tell s\nMake sure you understand these instances, too. It should be easier this time, since they share most of their structure with the StateT instance, but note the asymmetry that arises from the differing input and output states. (It may even help to try and write these instances yourself, focusing on the types whenever you get stuck.)\n\nIf you feel alright with them, then congratulations: you’re already well on your way to grokking MonadBaseControl!\n\nHiding the input state\nSo far, our implementation of MonadBaseControl works, but it’s actually slightly more complicated than it needs to be. As it happens, all valid uses of MonadBaseControl will always end up performing the following pattern:\n\ns <- captureInputState\nlet m' = closeOverInputState m s\nThat is, we close over the input state as soon as we capture it. We can therefore combine captureInputState and closeOverInputState into a single function:\n\ncaptureAndCloseOverInputState :: m a -> m (b (a, OutputState m))\nWhat’s more, we no longer need the InputState associated type at all! This is an improvement, since it simplifies the API and removes the possibility for any misuse of the input state, since it’s never directly exposed. On the other hand, it has a more complicated type: it produces a monadic action that returns another monadic action. This can be a little more difficult to grok, which is why I presented the original version first, but it may help to consider how the above type arises naturally from the following definition:\n\ncaptureAndCloseOverInputState m = closeOverInputState m <$> captureInputState\nLet’s update the MonadBaseControl class to incorporate this simplification:\n\nclass MonadBase b m => MonadBaseControl b m | m -> b where\n  type OutputState m\n  captureAndCloseOverInputState :: m a -> m (b (a, OutputState m))\n  restoreOutputState :: OutputState m -> m ()\nWe can then update all the instances to use the simpler API by simply fusing the definitions of captureInputState and closeOverInputState together:\n\ninstance MonadBaseControl IO IO where\n  type OutputState IO = ()\n  captureAndCloseOverInputState m = pure (m <&> (, ()))\n  restoreOutputState () = pure ()\n\ninstance MonadBaseControl b m => MonadBaseControl b (StateT s m) where\n  type OutputState (StateT s m) = (s, OutputState m)\n  captureAndCloseOverInputState m = do\n    s <- get\n    m' <- lift $ captureAndCloseOverInputState (runStateT m s)\n    pure $ do\n      ((v, s'), ss') <- m'\n      pure (v, (s', ss'))\n  restoreOutputState (s, ss) = lift (restoreOutputState ss) *> put s\n\ninstance MonadBaseControl b m => MonadBaseControl b (ReaderT r m) where\n  type OutputState (ReaderT r m) = OutputState m\n  captureAndCloseOverInputState m = do\n    s <- ask\n    lift $ captureAndCloseOverInputState (runReaderT m s)\n  restoreOutputState ss = lift (restoreOutputState ss)\n\ninstance (MonadBaseControl b m, Monoid w) => MonadBaseControl b (WriterT w m) where\n  type OutputState (WriterT w m) = (w, OutputState m)\n  captureAndCloseOverInputState m = do\n    m' <- lift $ captureAndCloseOverInputState (runWriterT m)\n    pure $ do\n      ((v, s'), ss') <- m'\n      pure (v, (s', ss'))\n  restoreOutputState (s, ss) = lift (restoreOutputState ss) *> tell s\nThis is already very close to a full MonadBaseControl implementation. The captureAndCloseOverInputState implementations are getting a little out of hand, but bear with me—they’ll get simpler before this blog post is over.\n\nCoping with partiality\nOur MonadBaseControl class now works with StateT, ReaderT, and WriterT, but one transformer we haven’t considered is ExceptT. Let’s try to extend our table from before with a row for ExceptT:\n\n  \n    \n      transformer      representation      input state      output state    \n    \n      ExceptT e m a      m (Either e a)      ()      ???    \n  \n\nHmm… what is the output state for ExceptT?\n\nThe answer can’t be e, since we might not end up with an e—the computation might not fail. Maybe e would be closer… could that work?\n\nWell, let’s try it. Let’s write a MonadBaseControl instance for ExceptT:\n\ninstance MonadBaseControl b m => MonadBaseControl b (ExceptT e m) where\n  type OutputState (ExceptT e m) = (Maybe e, OutputState m)\n  captureAndCloseOverInputState m = do\n    m' <- lift $ captureAndCloseOverInputState (runExceptT m)\n    pure $ do\n      ((v, s'), ss') <- m'\n      pure (v, (s', ss'))\n  restoreOutputState (s, ss) = lift (restoreOutputState ss) *> case s of\n    Just e -> throwError e\n    Nothing -> pure ()\nSadly, the above implementation doesn’t typecheck; it is rejected with the following type error:\n\n• Couldn't match type ‘Either e a’ with ‘(a, Maybe e)’\n  Expected type: m (b ((a, Maybe e), OutputState m))\n    Actual type: m (b (Either e a, OutputState m))\n• In the second argument of ‘($)’, namely\n    ‘captureAndCloseOverInputState (runExceptT m)’\n  In a stmt of a 'do' block:\n    m' <- lift $ captureAndCloseOverInputState (runExceptT m)\n  In the expression:\n    do m' <- lift $ captureAndCloseOverInputState (runExceptT m)\n       return do ((v, s'), ss') <- m'\n                 pure (v, (s', ss'))\n\nWe promised a (a, Maybe e), but we have an Either e a, and there’s certainly no way to get the former from the latter. Are we stuck? (If you’d like, take a moment to think about how you’d solve this type error before moving on, as it may be helpful for understanding the following solution.)\n\nThe fundamental problem here is partiality. The type of the captureAndCloseOverInputState method always produces an action in the base monad that includes an a in addition to some other output state. But ExceptT is different: when it an error is raised, it doesn’t produce an a at all—it only produces an e. Therefore, as written, it’s impossible to give ExceptT a MonadBaseControl instance.\n\nOf course, we’d very much like to give ExceptT a MonadBaseControl instance, so that isn’t very satisfying. Somehow, we need to change captureAndCloseOverInputState so that it doesn’t always need to produce an a. There are a few ways we could accomplish that, but an elegant way to do it is this:\n\nclass MonadBase b m => MonadBaseControl b m | m -> b where\n  type WithOutputState m a\n  captureAndCloseOverInputState :: m a -> m (b (WithOutputState m a))\n  restoreOutputState :: WithOutputState m a -> m a\nWe’ve replaced the old OutputState associated type with a new WithOutputState type, and the key difference between them is that WithOutputState describes the type of a combination of the result (of type a) and the output state, rather than describing the type of the output state alone. For total monad transformers like StateT, ReaderT, and WriterT, WithOutputState m a will just be a tuple of the result value and the output state, the same as before. For example, here’s an updated MonadBaseControl instance for StateT:\n\ninstance MonadBaseControl b m => MonadBaseControl b (StateT s m) where\n  type WithOutputState (StateT s m) a = WithOutputState m (a, s)\n  captureAndCloseOverInputState m = do\n    s <- get\n    lift $ captureAndCloseOverInputState (runStateT m s)\n  restoreOutputState ss = do\n    (a, s) <- lift $ restoreOutputState ss\n    put s\n    pure a\nBefore we consider how this helps us with ExceptT, let’s pause for a moment and examine the revised StateT instance in detail, as there are some new things going on here:\n\n\nTake a close look at the definition of WithOutputState (StateT s m) a. Note that we’ve defined it to be WithOutputState m (a, s), not (WithOutputState m a, s). Consider, for a moment, the difference between these types. Can you see why we used the former, not the latter?\n\nIf it’s unclear to you, that’s okay—let’s illustrate the difference with an example. Consider two similar monad transformer stacks:\n\nm1 :: StateT s (ExceptT e IO) a\nm2 :: ExceptT e (StateT s IO) a\nBoth these stacks contain StateT and ExceptT, but they are layered in a different order. What’s the difference? Well, consider what m1 and m2 return once fully unwrapped:\n\nrunExceptT (runStateT m1 s) :: m (Either e (a, s))\nrunStateT (runExceptT m2) s :: m (Either e a, s)\nThese results are meaningfully different: in m1, the state is discarded if an error is raised, but in m2, the final state is always returned, even if the computation is aborted. What does this mean for WithOutputState?\n\nHere’s the important detail: the state is discarded when ExceptT is “inside” StateT, not the other way around. This can be counterintuitive, since the s ends up inside the Either when the StateT constructor is on the outside and vice versa. This is really just a property of how monad transformers compose, not anything specific to MonadBaseControl, so an explanation of why this happens is outside the scope of this blog post, but the relevant insight is that the m in StateT s m a controls the eventual action’s output state.\n\nIf we had defined WithOutputState (StateT s m) a to be (WithOutputState m a, s), we’d be in a pickle, since m would be unable to influence the presence of s in the output state. Therefore, we have no choice but to use WithOutputState m (a, s). (If you are still confused by this, try it yourself; you’ll find that there’s no way to make the other definition typecheck.)\n\n\nNow that we’ve developed an intuitive understanding of why WithOutputState must be defined the way it is, let’s look at things from another perspective. Consider the type of runStateT once more:\n\nrunStateT :: StateT s m a -> s -> m (a, s)\nNote that the result type is m (a, s), with the m on the outside. As it happens, this correspondence simplifies the definition of captureAndCloseOverInputState, since we no longer have to do any fiddling with its result—it’s already in the proper shape, so we can just return it directly.\n\n\nFinally, this instance illustrates an interesting change to restoreOutputState. Since the a is now packed inside the WithOutputState m a value, the caller of captureAndCloseOverInputState needs some way to get the a back out! Conveniently, restoreOutputState can play that role, both restoring the output state and unpacking the result.\n\nEven ignoring partial transformers like ExceptT, this is an improvement over the old API, as it conveniently prevents the programmer from forgetting to call restoreOutputState. However, as we’ll see shortly, it is much more than a convenience: once ExceptT comes into play, it is essential!\n\n\nWith those details addressed, let’s return to ExceptT. Using the new interface, writing an instance for ExceptT is not only possible, it’s actually rather easy:\n\ninstance MonadBaseControl b m => MonadBaseControl b (ExceptT e m) where\n  type WithOutputState (ExceptT e m) a = WithOutputState m (Either e a)\n  captureAndCloseOverInputState m =\n    lift $ captureAndCloseOverInputState (runExceptT m)\n  restoreOutputState ss =\n    either throwError pure =<< lift (restoreOutputState ss)\nThis instance illustrates why it’s so crucial that restoreOutputState have the aforementioned dual role: it must handle the case where no a exists at all! In the case of ExceptT, it restores the state in the enclosing monad by re-raising an error.\n\nNow all that’s left to do is update the other instances:\n\ninstance MonadBaseControl IO IO where\n  type WithOutputState IO a = a\n  captureAndCloseOverInputState = pure\n  restoreOutputState = pure\n\ninstance MonadBaseControl b m => MonadBaseControl b (ReaderT r m) where\n  type WithOutputState (ReaderT r m) a = WithOutputState m a\n  captureAndCloseOverInputState m = do\n    s <- ask\n    lift $ captureAndCloseOverInputState (runReaderT m s)\n  restoreOutputState ss = lift $ restoreOutputState ss\n\ninstance (MonadBaseControl b m, Monoid w) => MonadBaseControl b (WriterT w m) where\n  type WithOutputState (WriterT w m) a = WithOutputState m (a, w)\n  captureAndCloseOverInputState m =\n    lift $ captureAndCloseOverInputState (runWriterT m)\n  restoreOutputState ss = do\n    (a, s) <- lift $ restoreOutputState ss\n    tell s\n    pure a\nFinally, we can update our lifted variant of foo to use the new interface so it will work with transformer stacks that include ExceptT:\n\nfoo' :: MonadBaseControl IO m => m a -> m a\nfoo' m = do\n  m' <- captureAndCloseOverInputState m\n  restoreOutputState =<< liftBase (foo m')\nAt this point, it’s worth considering something: although getting the MonadBaseControl class and instances right was a lot of work, the resulting foo' implementation is actually incredibly simple. That’s a good sign, since we only have to write the MonadBaseControl instances once (in a library), but we have to write functions like foo' quite often.\n\nScaling to the real MonadBaseControl\nThe MonadBaseControl class we implemented in the previous section is complete. It is a working, useful class that is equivalent in power to the “real” MonadBaseControl class in the monad-control library. However, if you compare the two, you’ll notice that the version in monad-control looks a little bit different. What gives?\n\nLet’s compare the two classes side by side:\n\n-- ours\nclass MonadBase b m => MonadBaseControl b m | m -> b where\n  type WithOutputState m a\n  captureAndCloseOverInputState :: m a -> m (b (WithOutputState m a))\n  restoreOutputState :: WithOutputState m a -> m a\n\n-- theirs\nclass MonadBase b m => MonadBaseControl b m | m -> b where\n  type StM m a\n  liftBaseWith :: (RunInBase m b -> b a) -> m a\n  restoreM :: StM m a -> m a\nLet’s start with the similarities, since those are easy:\n\n\nOur WithOutputState associated type is precisely equivalent to their StM associated type, they just use a (considerably) shorter name.\n\n\nLikewise, our restoreOutputState method is precisely equivalent to their restoreM method, simply under a different name.\n\n\nThat leaves captureAndCloseOverInputState and liftBaseWith. Those two methods both do similar things, but they aren’t identical, and that’s where all the differences lie. To understand liftBaseWith, let’s start by inlining the definition of the RunInBase type alias so we can see the fully-expanded type:\n\nliftBaseWith\n  :: MonadBaseControl b m\n  => ((forall c. m c -> b (StM m c)) -> b a)\n  -> m a\nThat type is complicated! However, if we break it down, hopefully you’ll find it’s not as scary as it first appears. Let’s reimplement the foo' example from before using liftBaseWith to show how this version of MonadBaseControl works:\n\nfoo' :: MonadBaseControl IO m => m a -> m a\nfoo' m = do\n  s <- liftBaseWith $ \\runInBase -> foo (runInBase m)\n  restoreM s\nThis is, in some ways, superficially similar to the version we wrote using our version of MonadBaseControl. Just like in our version, we capture the input state, apply foo in the IO monad, then restore the state. But what exactly is doing the state capturing, and what is runInBase?\n\nLet’s start by adding a type annotation to runInBase to help make it a little clearer what’s going on:\n\nfoo' :: forall m a. MonadBaseControl IO m => m a -> m a\nfoo' m = do\n  s <- liftBaseWith $ \\(runInBase :: forall b. m b -> IO (StM m b)) ->\n    foo (runInBase m)\n  restoreM s\nThat type should look sort of recognizable. If we replace StM with WithOutputState, then we get a type that looks very similar to that of our original closeOverInputState function, except it doesn’t need to take the input state as an argument. How does that work?\n\nHere’s the trick: liftBaseWith starts by capturing the input state, just as before. However, it then builds a function, runInBase, which is like closeOverInputState partially-applied to the input state it captured. It hands that function to us, and we’re free to apply it to m, which produces the IO (StM m a) action we need, and we can now pass that action to foo. The result is returned in the outer monad, and we restore the state using restoreM.\n\nSharing the input state\nAt first, this might seem needlessly complicated. When we first started, we separated capturing the input state and closing over it into two separate operations (captureInputState and closeOverInputState), but we eventually combined them so that we could keep the input state hidden. Why does monad-control split them back into two operations again?\n\nAs it turns out, when lifting foo, there’s no advantage to the more complicated API of monad-control. In fact, we could implement our captureAndCloseOverInputState operation in terms of liftBaseWith, and we could use that to implement foo' the same way we did before:\n\ncaptureAndCloseOverInputState :: MonadBaseControl b m => m a -> m (b (StM m a))\ncaptureAndCloseOverInputState m = liftBaseWith $ \\runInBase -> pure (runInBase m)\n\nfoo' :: MonadBaseControl IO m => m a -> m a\nfoo' m = do\n  m' <- captureAndCloseOverInputState m\n  restoreM =<< liftBase (foo m')\nHowever, that approach has a downside once we need to lift more complicated functions. foo is exceptionally simple, as it only accepts a single input argument, but what if we wanted to lift a more complicated function that took two monadic arguments, such as this one:\n\nbar :: IO a -> IO a -> IO a\nWe could implement that by calling captureAndCloseOverInputState twice, like this:\n\nbar' :: MonadBaseControl IO m => m a -> m a -> m a\nbar' ma mb = do\n  ma' <- captureAndCloseOverInputState ma\n  mb' <- captureAndCloseOverInputState mb\n  restoreM =<< liftBase (bar ma' mb')\nHowever, that would capture the monadic state twice, which is rather inefficient. By using liftBaseWith, the state capturing is done just once, and it’s shared between all calls to runInBase:\n\nbar' :: MonadBaseControl IO m => m a -> m a -> m a\nbar' ma mb = do\n  s <- liftBaseWith $ \\runInBase ->\n    bar (runInBase ma) (runInBase mb)\n  restoreM s\nBy providing a “running” function (runInBase) instead of direct access to the input state, liftBaseWith allows sharing the captured input state between multiple actions without exposing it directly.\n\nSidebar: continuation-passing and impredicativity\nOne last point before we move on: although the above explains why captureAndCloseOverInputState is insufficient, you may be left wondering why liftBaseWith can’t just return runInBase. Why does it need to be given a continuation? After all, it would be nicer if we could just write this:\n\nbar' :: MonadBaseControl IO m => m a -> m a -> m a\nbar' ma mb = do\n  runInBase <- askRunInBase\n  restoreM =<< liftBase (bar (runInBase ma) (runInBase mb))\nTo understand the problem with a hypothetical askRunInBase function, remember that the type of runInBase is polymorphic:\n\nrunInBase :: forall a. m a -> b (StM m a)\nThis is important, since if you need to lift a function with a type like\n\nbaz :: IO b -> IO c -> IO (Either b c)\nthen you’ll want to instantiate that a variable with two different types. We’d need to retain that power in askRunInBase, so it would need to have the following type:\n\naskRunInBase :: MonadBaseControl b m => m (forall a. m a -> b (StM m a))\nSadly, that type is illegal in Haskell. Type constructors must be applied to monomorphic types, but in the above type signature, m is applied to a polymorphic type.2 The RankNTypes GHC extension introduces a single exception: the (->) type constructor is special and may be applied to polymorphic types. That’s why liftBaseWith is legal, but askRunInBase is not: since liftBaseWith is passed a higher-order function that receives runInBase as an argument, the polymorphic type appears immediately under an application of (->), which is allowed.\n\nThe aforementioned restriction means we’re basically out of luck, but if you really want askRunInBase, there is a workaround. GHC is perfectly alright with a field of a datatype being polymorphic, so we can define a newtype that wraps a suitably-polymorphic function:\n\nnewtype RunInBase b m = RunInBase (forall a. m a -> b (StM m a))\nWe can now alter askRunInBase to return our newtype, and we can implement it in terms of liftBaseWith:3\n\naskRunInBase :: MonadBaseControl b m => m (RunInBase b m)\naskRunInBase = liftBaseWith $ \\runInBase -> pure $ RunInBase runInBase\nTo use askRunInBase, we have to pattern match on the RunInBase constructor, but it isn’t very noisy, since we can do it directly in a do binding. For example, we could implement a lifted version of baz this way:\n\nbaz' :: MonadBaseControl IO m => m a -> m b -> m (Either a b)\nbaz' ma mb = do\n  RunInBase runInBase <- askRunInBase\n  s <- liftBase (baz (runInBase ma) (runInBase mb))\n  bitraverse restoreM restoreM s\nAs of version 1.0.2.3, monad-control does not provide a newtype like RunInBase, so it also doesn’t provide a function like askRunInBase. For now, you’ll have to use liftBaseWith, but it might be a useful future addition to the library.\n\nPitfalls\nAt this point in the blog post, we’ve covered the essentials of MonadBaseControl: how it works, how it’s designed, and how you might go about using it. However, so far, we’ve only considered situations where MonadBaseControl works well, and I’ve intentionally avoided examples where the technique breaks down. In this section, we’re going to take a look at the pitfalls and drawbacks of MonadBaseControl, plus some ways they can be mitigated.\n\nNo polymorphism, no lifting\nAll of the pitfalls of MonadBaseControl stem from the same root problem, and that’s the particular technique it uses to save and restore monadic state. We’ll start by considering one of the simplest ways that technique is thwarted, and that’s monomorphism. Consider the following two functions:\n\npoly :: IO a -> IO a\nmono :: IO X -> IO X\nEven after all we’ve covered, it may surprise you to learn that although poly can be easily lifted to MonadBaseControl IO m => m a -> m a, it’s impossible to lift mono to MonadBaseControl IO m => m X -> m X. It’s a little unintuitive, as we often think of polymorphic types as being more complicated (so surely lifting polymorphic functions ought to be harder), but in fact, it’s the flexibility of polymorphism that allows MonadBaseControl to work in the first place.\n\nTo understand the problem, remember that when we lift a function of type forall a. b a -> b a using MonadBaseControl, we actually instantiate a to (StM m c). That produces a function of type b (StM m c) -> b (StM m c), which is isomorphic to the m c -> m c type we want. The instantiation step is easily overlooked, but it’s crucial, since otherwise we have no way to thread the state through the otherwise opaque function we’re trying to lift!\n\nIn the case of mono, that’s exactly the problem we’re faced with. mono will not accept an IO (StM m X) as an argument, only precisely an IO X, so we can’t pass along the monadic state. For all its machinery, MonadBaseControl is no help at all if no polymorphism is involved. Trying to generalize mono without modifying its implementation is a lost cause.\n\nThe dangers of discarded state\nOur inability to lift mono is frustrating, but at least it’s conclusively impossible. In practice, however, many functions lie in an insidious in-between: polymorphic enough to be lifted, but not without compromises. The simplest of these functions have types such as the following:\n\nsideEffect :: IO a -> IO ()\nUnlike mono, it’s entirely possible to lift sideEffect:\n\nsideEffect' :: MonadBaseControl IO m => m a -> m ()\nsideEffect' m = liftBaseWith $ \\runInBase -> sideEffect (runInBase m)\nThis definition typechecks, but you may very well prefer it didn’t, since it has a serious problem: any changes made by m to the monadic state are completely discarded once sideEffect' returns! Since sideEffect' never calls restoreM, there’s no way the state of m can be any different from the original state, but it’s impossible to call restoreM since we don’t actually get an StM m () result from sideEffect.\n\nSometimes this may be acceptable, since some monad transformers don’t actually have any output state anyway, such as ReaderT r. In other cases, however, sideEffect' could be a bug waiting to happen. One way to make sideEffect' safe would be to add a StM m a ~ a constraint to its context, since that guarantees the monad transformers being lifted through are stateless, and nothing is actually being discarded. Of course, that significantly restricts the set of monad transformers that can be lifted through.\n\nRewindable state\nOne scenario where state discarding can actually be useful is operations with so-called rewindable or transactional state. The most common example of such an operation is catch:\n\ncatch :: Exception e => IO a -> (e -> IO a) -> IO a\nWhen lifted, state changes from the action or from the exception handler will be “committed,” but never both. If an exception is raised during the computation, those state changes are discarded (“rewound”), giving catch a kind of backtracking semantics. This behavior arises naturally from the way a lifted version of catch must be implemented:\n\ncatch' :: (Exception e, MonadBaseControl IO m) => m a -> (e -> m a) -> m a\ncatch' m f = do\n  s <- liftBaseWith $ \\runInBase ->\n    catch (runInBase m) (runInBase . f)\n  restoreM s\nIf m raises an exception, it will never return an StM m a value, so there’s no way to get ahold of any of the state changes that happened before the exception. Therefore, the only option is to discard that state.\n\nThis behavior is actually quite useful, and it’s definitely not unreasonable. However, useful or not, it’s inconsistent with state changes to mutable values like IORefs or MVars (they stay modified whether an exception is raised or not), so it can still be a gotcha. Either way, it’s worth being aware of.\n\nPartially discarded state\nThe next function we’re going to examine is finally:\n\nfinally :: IO a -> IO b -> IO a\nThis function has a similar type to catch, and it even has similar semantics. Like catch, finally can be lifted, but unlike catch, its state can’t be given any satisfying treatment. The only way to implement a lifted version is\n\nfinally' :: MonadBaseControl IO m => m a -> m b -> m a\nfinally' ma mb = do\n  s <- liftBaseWith $ \\runInBase ->\n    finally (runInBase ma) (runInBase mb)\n  restoreM s\nwhich always discards all state changes made by the second argument. This is clear just from looking at finally’s type: since b doesn’t appear anywhere in the return type, there’s simply no way to access that action’s result, and therefore no way to access its modified state.\n\nHowever, don’t despair: there actually is a way to produce a lifted version of finally that preserves all state changes. It can’t be done by lifting finally directly, but if we reimplement finally in terms of simpler lifted functions that are more amenable to lifting, we can produce a lifted version of finally that preserves all the state:4\n\nfinally' :: MonadBaseControl IO m => m a -> m b -> m a\nfinally' ma mb = mask' $ \\restore -> do\n  a <- liftBaseWith $ \\runInBase ->\n    try (runInBase (restore ma))\n  case a of\n    Left e -> mb *> liftBase (throwIO (e :: SomeException))\n    Right s -> restoreM s <* mb\nThis illustrates an important (and interesting) point about MonadBaseControl: whether or not an operation can be made state-preserving is not a fundamental property of the operation’s type, but rather a property of the types of the exposed primitives. There is sometimes a way to implement a state-preserving variant of operations that might otherwise seem unliftable given the right primitives and a bit of cleverness.\n\nForking state\nAs a final example, I want to provide an example where the state may not actually be discarded per se, just inaccessible. Consider the type of forkIO:\n\nforkIO :: IO () -> IO ThreadId\nAlthough forkIO isn’t actually polymorphic in its argument, we can convert any IO action to one that produces () via void, so it might as well be. Therefore, we can lift forkIO in much the same way we did with sideEffect:\n\nforkIO' :: MonadBaseControl IO m => m () -> m ThreadId\nforkIO' m = liftBaseWith $ \\runInBase -> forkIO (void $ runInBase m)\nAs with sideEffect, we can’t recover the output state, but in this case, there’s a fundamental reason that goes deeper than the types: we’ve forked off a concurrent computation! We’ve therefore split the state in two, which might be what we want… but it also might not. forkIO is yet another illustration that it’s important to think about the state-preservation semantics when using MonadBaseControl, or you may end up with a bug!\n\nMonadBaseControl in context\nCongratulations: you’ve made it through most of this blog post. If you’ve followed everything so far, you now understand MonadBaseControl. All the tricky parts are over. However, before wrapping up, I’d like to add a little extra information about how MonadBaseControl relates to various other parts of the Haskell ecosystem. In practice, that information can be as important as understanding MonadBaseControl itself.\n\nThe remainder of monad-control\nIf you look at the documentation for monad-control, you’ll find that it provides more than just the MonadBaseControl typeclass. I’m not going to cover everything else in detail in this blog post, but I do want to touch upon it briefly.\n\nFirst off, you should definitely take a look at the handful of helper functions provided by monad-control, such as control and liftBaseOp_. These functions provide support for lifting common function types without having to use liftBaseWith directly. It’s useful to understand liftBaseWith, since it’s the most general way to use MonadBaseControl, but in practice, it is simpler and more readable to use the more specialized functions wherever possible. Many of the examples in this very blog post could be simplified using them, and I only stuck to liftBaseWith to introduce as few new concepts at a time as possible.\n\nSecond, I’d like to mention the related MonadTransControl typeclass. You hopefully remember from earlier in the blog post how we defined MonadBaseControl instances inductively so that we could lift all the way down to the base monad. MonadTransControl is like MonadBaseControl if it intentionally did not do that—it allows lifting through a single transformer at a time, rather than through all of them at once.\n\nUsually, MonadTransControl is not terribly useful to use directly (though I did use it once in a previous blog post of mine to help derive instances of mtl-style classes), but it is useful for implementing MonadBaseControl instances for your own transformers. If you define a MonadTransControl instance for your monad transformer, you can get a MonadBaseControl implementation for free using the provided ComposeSt, defaultLiftBaseWith, and defaultRestoreM bindings; see the documentation for more details.\n\nlifted-base and lifted-async\nIf you’re going to use MonadBaseControl, the lifted-base and lifted-async packages are good to know about. As their names imply, they provide lifted versions of bindings in the base and async packages, so you can use them directly without needing to lift them yourself. For example, if you needed a lifted version of mask from Control.Exception, you could swap it for the mask export from Control.Exception.Lifted, and everything would mostly just work (though always be sure to check the documentation for any caveats on state discarding).\n\nRelationship to MonadUnliftIO\nRecently, FP Complete has developed the unliftio package as an alternative to monad-control. It provides the MonadUnliftIO typeclass, which is similar in spirit to MonadBaseControl, but heavily restricted: it is specialized to IO as the base monad, and it only allows instances for stateless monads, such as ReaderT. This is designed to encourage the so-called ReaderT design pattern, which avoids ever using stateful monads like ExceptT or StateT over IO, encouraging the use of IO exceptions and mutable variables (e.g. MVars or TVars) instead.\n\nI should be clear: I really like most of what FP Complete has done—to this day, I still use stack as my Haskell build tool of choice—and I think the suggestions given in the aforementioned “ReaderT design pattern” blog post have real weight to them. I have a deep respect for Michael Snoyman’s commitment to opinionated, user-friendly tools and libraries. But truthfully, I can’t stand MonadUnliftIO.\n\nMonadUnliftIO is designed to avoid all the complexity around state discarding that MonadBaseControl introduces, and on its own, that’s a noble goal. Safety first, after all. The problem is that MonadUnliftIO really is extremely limiting, and what’s more, it can actually be trivially encoded in terms of MonadBaseControl as follows:\n\ntype MonadUnliftIO m = (MonadBaseControl IO m, forall a. StM m a ~ a)\nThis alias can be used to define safe, lifted functions that never discard state while still allowing functions that can be safely lifted through stateful transformers to do so. Indeed, the Control.Concurrent.Async.Lifted.Safe module from lifted-async does exactly that (albeit with a slightly different formulation than the above alias).\n\nTo be fair, the unliftio README does address this in its comparison section:\n\nmonad-control allows us to unlift both styles. In theory, we could write a variant of lifted-base that never does state discards […] In other words, this is an advantage of monad-control over MonadUnliftIO. We've avoided providing any such extra typeclass in this package though, for two reasons:\n\n\nMonadUnliftIO is a simple typeclass, easy to explain. We don't want to complicated [sic] matters […]\n\n\nHaving this kind of split would be confusing in user code, when suddenly [certain operations are] not available to us.\n\n\nIn other words, the authors of unliftio felt that MonadBaseControl was simply not worth the complexity, and they could get away with MonadUnliftIO. Frankly, if you feel the same way, by all means, use unliftio. I just found it too limiting given the way I write Haskell, plain and simple.\n\nRecap\nSo ends another long blog post. As often seems the case, I set out to write something short, but I ended up writing well over 5,000 words. I suppose that means I learned something from this experience, too: MonadBaseControl is more complicated than I had anticipated! Maybe there’s something to take away from that.\n\nIn any case, it’s over now, so I’d like to briefly summarize what we’ve covered:\n\n\nMonadBaseControl allows us to lift higher-order monadic operations.\n\n\nIt operates by capturing the current monadic state and explicitly threading it through the action in the base monad before restoring it.\n\n\nThat technique works well for polymorphic operations for the type forall a. b a -> b a, but it can be tricky or even impossible for more complex operations, sometimes leading to discarded state.\n\nThis can sometimes be mitigated by restricting certain operations to stateless monads using a StM m a ~ a constraint, or by reimplementing the operation in terms of simpler primitives.\n\n\nThe lifted-base and lifted-async packages provide lifted versions of existing operations, avoiding the need to lift them yourself.\n\n\nAs with many abstractions in Haskell, don’t worry too much if you don’t have a completely firm grasp of MonadBaseControl at first. Insight often comes with repeated experience, and monad-control can still be used in useful ways even without a perfect understanding. My hope is that this blog post has helped you build intuitions about MonadBaseControl even if some of the underlying machinery remains a little fuzzy, and I hope it can also serve as a reference for those who want or need to understand (or just be reminded of) all the little details.\n\nFinally, I’ll admit MonadBaseControl isn’t especially elegant or beautiful as Haskell abstractions go. In fact, in many ways, it’s a bit of a kludge! Perhaps, in time, effect systems will evolve and mature so that it and its ilk are no longer necessary, and they may become distant relics of an inferior past. But in the meantime, it’s here, it’s useful, and I think it’s worth embracing. If you’ve shied away from it in the past, I hope I’ve illuminated it enough to make you consider giving it another try.\n\n\nOne example of a function with that type is mask_.\n ↩\n\nTypes with polymorphic types under type constructors are called impredicative. GHC technically has limited support for impredicativity via the ImpredicativeTypes language extension, but as of GHC 8.8, it has been fairly broken for some time. A fix is apparently being worked on, but even if that effort is successful, I don’t know what impact it will have on type inference.\n ↩\n\nNote that askRunInBase = liftBaseWith (pure . RunInBase) does not typecheck, as it would require impredicative polymorphism: it would require instantiating the type of (.) with polymorphic types. The version using ($) works because GHC actually has special typechecking rules for ($)! Effectively, f $ x is really syntax in GHC.\n ↩\n\nAssume that mask' is a suitably lifted version of mask (which can in fact be made state-preserving).\n ↩","isoDate":"2019-09-07T00:00:00.000Z","timestamp":"9/6/2019"},{"title":"Defeating Racket’s separate compilation guarantee","pubDate":"2019-04-21T00:00:00.000Z","author":"Alexis King","content":"<article><p>Being a self-described <a href=\"https://felleisen.org/matthias/manifesto/sec_pl-pl.html\">programming-language programming language</a> is an ambitious goal. To preserve predictability while permitting linguistic extension, Racket comes equipped with a module system carefully designed to accommodate <a href=\"https://www.cs.utah.edu/plt/publications/macromod.pdf\">composable and compilable macros</a>. One of the module system’s foundational properties is its <a href=\"https://docs.racket-lang.org/reference/eval-model.html#%28part._separate-compilation%29\"><em>separate compilation guarantee</em></a>, which imposes strong, unbreakable limits on the extent of compile-time side-effects. It is <em>essential</em> for preserving static guarantees in a world where compiling a module can execute arbitrary code, and despite numerous unsafe trapdoors that have crept into Racket since its birth as PLT Scheme, none have ever given the programmer the ability to cheat it.\n</p><p>Yet today, in this blog post, we’re going to do exactly that.\n</p><h2><a name=\"what-is-the-separate-compilation-guarantee\"></a>What is the separate compilation guarantee?</h2><p>Before we get to the fun part (i.e. breaking things), let’s go over some fundamentals so we understand what we’re breaking. The authoritative source for the separate compilation guarantee is <a href=\"https://docs.racket-lang.org/reference/eval-model.html#%28part._separate-compilation%29\">the Racket reference</a>, but it is dense, as authoritative sources tend to be. Although I enjoy reading technical manuals for sport, it is my understanding that not all the people who read this blog are as strange as I am, so let’s start with a quick primer, instead. (If you’re already an expert, feel free to <a href=\"#section:main-start\">skip to the next section</a>.)\n</p><p>Racket is a macro-enabled programming language. In Racket, a macro is a user-defined, code-to-code transformation that occurs at compile-time. These transformations cannot make arbitrary changes to the program—in Racket, they are usually required to be <em>local</em>, affecting a single expression or definition at a time—but they may be implemented using arbitrary code. This means that a macro can, if it so desires, read the SSH keys off your filesystem and issue an HTTP request to send them someplace.\n</p><p>That kind of attack is bad, admittedly, but it’s also <em>uninteresting</em>: Racket allows you do all that and then some, making no attempt to prevent it.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup> Racket calls these “external effects,” things that affect state outside of the programming language. They sound scary, but in practice, <em>internal effects</em>—effects that mutate state inside the programming language—are a much bigger obstacle to practical programming. Let’s take a look at why.\n</p><p>Let’s say we have a module with some global, mutable state. Perhaps it is used to keep track of a set of delicious foods:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; foods.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">delicious-food?</span> <span class=\"n\">add-delicious-food!</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">delicious-foods</span> <span class=\"p\">(</span><span class=\"nb\">mutable-set</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">delicious-food?</span> <span class=\"n\">food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">set-member?</span> <span class=\"n\">delicious-foods</span> <span class=\"n\">food</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"n\">new-food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">set-add!</span> <span class=\"n\">delicious-foods</span> <span class=\"n\">new-food</span><span class=\"p\">))</span></code></pre><p>Using this interface, let’s write a program that checks if a particular food, given as a command-line argument, is delicious:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; check-food.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"s2\">\"foods.rkt\"</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"s2\">\"pineapple\"</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"s2\">\"sushi\"</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"s2\">\"cheesecake\"</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">command-line</span>\n  <span class=\"kd\">#:args</span> <span class=\"p\">[</span><span class=\"n\">food-to-check</span><span class=\"p\">]</span>\n  <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">delicious-food?</span> <span class=\"n\">food-to-check</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"~a is a delicious food.</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">food-to-check</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"~a is not delicious.</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">food-to-check</span><span class=\"p\">)))</span></code></pre><pre><code class=\"pygments\">$ racket check-food.rkt cheesecake\ncheesecake is a delicious food.\n$ racket check-food.rkt licorice\nlicorice is not delicious.</code></pre><p>Exhilarating. (Sorry, licorice fans.) But what if a <em>macro</em> were to call <code>add-delicious-food!</code>? What would happen? For example, what if we wrote a macro to add a lot of foods at once?<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">add-food-combinations!</span> <span class=\"p\">[</span><span class=\"n\">fst:string</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n                                             <span class=\"p\">[</span><span class=\"n\">snd:string</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n  <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">for*</span> <span class=\"p\">([</span><span class=\"n\">fst-str</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"nb\">syntax-&gt;datum</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">fst</span> <span class=\"k\">...</span><span class=\"p\">]))]</span>\n               <span class=\"p\">[</span><span class=\"n\">snd-str</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"nb\">syntax-&gt;datum</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">snd</span> <span class=\"k\">...</span><span class=\"p\">]))])</span>\n          <span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"p\">(</span><span class=\"nb\">string-append</span> <span class=\"n\">fst-str</span> <span class=\"s2\">\" \"</span> <span class=\"n\">snd-str</span><span class=\"p\">)))]</span>\n  <span class=\"p\">(</span><span class=\"nb\">void</span><span class=\"p\">))</span>\n\n<span class=\"c1\">; should add “fried chicken,” “roasted chicken”, “fried potato,” and “roasted potato”</span>\n<span class=\"p\">(</span><span class=\"n\">add-food-combinations!</span> <span class=\"p\">[</span><span class=\"s2\">\"fried\"</span> <span class=\"s2\">\"roasted\"</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"s2\">\"chicken\"</span> <span class=\"s2\">\"potato\"</span><span class=\"p\">])</span></code></pre><p>Now, what do you think executing <code>racket check-food.rkt 'fried chicken'</code> will do?\n</p><p>Clearly, the program should print <code>fried chicken is a delicious food</code>, and indeed, many traditional Lisp systems would happily produce such a result. After all, running <code>racket check-food.rkt 'fried chicken'</code> must load the source code inside <code>check-food.rkt</code>, expand and compile it, then run the result. While the program is being expanded, the compile-time calls to <code>add-delicious-food!</code> should add new elements to the <code>delicious-food</code> set, so when the program is executed, the string <code>\"fried chicken\"</code> ought to be in it.\n</p><p>But if you actually try this yourself, you will find that <em>isn’t</em> what happens. Instead, Racket rejects the program:\n</p><pre><code class=\"pygments\">$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\ncheck-food.rkt:12:11: add-delicious-food!: reference to an unbound identifier\n  at phase: <span class=\"m\">1</span><span class=\"p\">;</span> the transformer environment\n  in: add-delicious-food!</code></pre><p>Why does Racket reject this program? Well, consider that Racket allows programs to be pre-compiled using <code>raco make</code>, doing all the work of macroexpansion and compilation to bytecode ahead of time. Subsequent runs of the program will use the pre-compiled version, without having to run all the macros again. This is a problem, since expanding the <code>add-food-combinations!</code> macro had side-effects that our program depended on!\n</p><p>If Racket allowed the above program, it might do different things depending on whether it was pre-compiled. Running directly from source code might treat <code>'fried chicken'</code> as a delicious food, while running from pre-compiled bytecode might not. Racket considers this unacceptable, so it disallows the program entirely.\n</p><h3><a name=\"preserving-separate-compilation-via-phases\"></a>Preserving separate compilation via phases</h3><p>Hopefully, you are now mostly convinced that the above program is a bad one, but you might have some lingering doubts. You might, for example, wonder if Racket disallows mutable compile-time state entirely. That is not the case—Racket really does allow everything that happens at runtime to happen at compile-time—but it does prevent compile-time and run-time state from ever <em>interacting</em>. Racket stratifies every program into a compile-time part and a run-time part, and it restricts communication between them to limited, well-defined channels (mainly via expanding to code that does something at run-time).\n</p><p>Racket calls this system of stratification <em>phases</em>. Code that executes at run-time belongs to the <em>run-time phase</em>, while code that executes at compile-time (i.e. macros) belongs to the <em>compile-time phase</em>. When a variable is defined, it is always defined in a particular phase, so bindings declared with <code>define</code> can only be used at run-time, while bindings declared with <code>define-for-syntax</code> can only be used at compile-time. Since <code>add-delicious-food!</code> was declared using <code>define</code>, it was not allowed (and in fact was not even visible) in the body of the <code>add-food-combinations!</code> macro.\n</p><p>While the whole macro system could work precisely as just described, such a strict stratification would be incredibly rigid. Since every definition would belong to either run-time or compile-time, but never both, reusing run-time code to implement macros would be impossible. While the example in the previous section might make it seem like that’s a good thing, it very often isn’t: imagine if general-purpose functions like <code>map</code> and <code>filter</code> all needed to be written twice!\n</p><p>To avoid this problem, Racket allows modules to be imported at both run-time and compile-time, so long as it’s done explicitly. Writing <code>(require \"some-library.rkt\")</code> requires <code>some-library.rkt</code> for run-time code, but writing <code>(require (for-syntax \"some-library.rkt\"))</code> requires it for compile-time code. Requiring a module <code>for-syntax</code> is sort of like implicitly adjusting all of its uses of <code>define</code> to be <code>define-for-syntax</code>, instead, effectively shifting all the code from run-time to compile-time. This kind of operation is therefore known as <em>phase shifting</em> in Racket terminology.\n</p><p>We can use phase shifting to make the program we wrote compile. If we adjust the <code>require</code> at the beginning of our program, then we can ensure <code>add-delicious-food!</code> is visible to both the run-time and compile-time parts of <code>check-food.rkt</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"s2\">\"foods.rkt\"</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"s2\">\"foods.rkt\"</span><span class=\"p\">))</span></code></pre><p>Now our program compiles. However, if you’ve been following everything carefully, you should be wondering why! According to the last section, sharing state between run-time and compile-time fundamentally can’t work without introducing inconsistencies between uncompiled and pre-compiled code. And that’s true—such a thing would cause all sorts of problems, and Racket doesn’t allow it. If you run the program, whether pre-compiled or not, you’ll find it always does the same thing:\n</p><pre><code class=\"pygments\">$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nfried chicken is not delicious.</code></pre><p>This seems rather confusing. What happened to the calls to <code>add-delicious-food!</code> inside our <code>add-food-combinations!</code> macro? If we stick a <code>printf</code> inside <code>add-delicious-food!</code>, we’ll find that it really does get called:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"n\">new-food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"Registering ~a as a delicious food.</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">new-food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">set-add!</span> <span class=\"n\">delicious-foods</span> <span class=\"n\">new-food</span><span class=\"p\">))</span></code></pre><pre><code class=\"pygments\">$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nRegistering fried chicken as a delicious food.\nRegistering fried potato as a delicious food.\nRegistering roasted chicken as a delicious food.\nRegistering roasted potato as a delicious food.\nRegistering pineapple as a delicious food.\nRegistering sushi as a delicious food.\nRegistering cheesecake as a delicious food.\nfried chicken is not delicious.</code></pre><p>And in fact, if we pre-compile <code>check-food.rkt</code>, we’ll see that the first four registrations appear at compile-time, exactly as we expect:\n</p><pre><code class=\"pygments\">$ raco make check-food.rkt\nRegistering fried chicken as a delicious food.\nRegistering fried potato as a delicious food.\nRegistering roasted chicken as a delicious food.\nRegistering roasted potato as a delicious food.\n$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nRegistering pineapple as a delicious food.\nRegistering sushi as a delicious food.\nRegistering cheesecake as a delicious food.\nfried chicken is not delicious.</code></pre><p>The compile-time registrations really are happening, but Racket is automatically restricting the compile-time side-effects so they only apply at compile-time. After compilation has finished, Racket ensures that compile-time side effects are thrown away, and the run-time code starts over with fresh, untouched state. This guarantees consistent behavior, since it becomes impossible to distinguish at run-time whether a module was just compiled on the fly, or if it was pre-compiled long ago (possibly even on someone else’s computer).\n</p><p>This is the essence of the separate compilation guarantee. To summarize:\n</p><ul><li><p>Run-time and compile-time are distinct <em>phases</em> of execution, which cannot interact.\n</p></li><li><p>Modules can be required at multiple phases via <em>phase shifting</em>, but their state is kept separate. Each phase gets its own copy of the state.\n</p></li><li><p>Ensuring that the state is kept separate ensures predictable program behavior, no matter when the program is compiled.\n</p></li></ul><p>This summary is a simplification of phases in Racket. The full Racket module system does not have only two phases, since macros can also be <em>used</em> at compile-time to implement other macros, effectively creating a separate “compile-time” for the compile-time code. Each compile-time pass is isolated to its own phase, creating a finite but arbitrarily large number of distinct program phases (all but one of which occur at compile-time).\n</p><p>Furthermore, the separate compilation guarantee does not just isolate the state of each phase from the state of other phases but also isolates all compile-time state from the compile-time state of other modules. This ensures that compilation is still deterministic even if modules are compiled in a different <em>order</em>, or if several modules are sometimes compiled individually while other times compiled together all at once.\n</p><p>If you want to learn more, the full details of the module system are described at length in the <a href=\"https://docs.racket-lang.org/guide/phases.html\">General Phase Levels</a> section of the Racket Guide, but the abridged summary I’ve described is enough for the purposes of this blog post. If the bulleted list above mostly made sense to you, you’re ready to move on.\n</p><h2 id=\"section:main-start\">How we’re going to break it</h2><p>The separate compilation guarantee is a sturdy opponent, but it is not without weaknesses. Although no API in Racket, safe or unsafe, allows arbitrarily disabling phase separation, a couple features of Racket are already known to allow limited forms of cross-phase communication.\n</p><p>The most significant of these, and the one we’ll be using as our vector of attack, is the logger. Unlike many logging systems, which are exclusively string-oriented, Racket’s logging interface allows structured logging by associating an arbitrary Racket value with each and every log message. Since it is possible to set up listeners within Racket that receive log messages sent to a particular “topic,” the logger can be used as a communication channel to send values between different parts of a program.\n</p><p>The following program illustrates how this works. One thread creates a listener for all log messages on the topic <code>'send-me-a-value</code> using <code>make-log-receiver</code>, then uses <code>sync</code> to block until a value is received. Meanwhile, a second thread sends values through the logger using <code>log-message</code>. Together, this creates a makeshift buffered, asynchronous channel:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; log-comm.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t1</span>\n  <span class=\"p\">(</span><span class=\"nb\">thread</span>\n   <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">()</span>\n     <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">recv</span> <span class=\"p\">(</span><span class=\"nb\">make-log-receiver</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"o\">&#39;</span><span class=\"ss\">send-me-a-value</span><span class=\"p\">))</span>\n     <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">()</span>\n       <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"p\">(</span><span class=\"nb\">sync</span> <span class=\"n\">recv</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"n\">loop</span><span class=\"p\">)))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t2</span>\n  <span class=\"p\">(</span><span class=\"nb\">thread</span>\n   <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">()</span>\n     <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">([</span><span class=\"n\">n</span> <span class=\"mi\">0</span><span class=\"p\">])</span>\n       <span class=\"p\">(</span><span class=\"nb\">log-message</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"o\">&#39;</span><span class=\"ss\">send-me-a-value</span> <span class=\"s2\">\"\"</span> <span class=\"n\">n</span> <span class=\"no\">#f</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"nb\">sleep</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"n\">n</span><span class=\"p\">))))))</span>\n\n<span class=\"p\">(</span><span class=\"nb\">thread-wait</span> <span class=\"n\">t1</span><span class=\"p\">)</span> <span class=\"c1\">; wait forever</span></code></pre><pre><code>$ racket log-comm.rkt\n'#(debug \"\" 1 send-me-a-value)\n'#(debug \"\" 2 send-me-a-value)\n'#(debug \"\" 3 send-me-a-value)\n'#(debug \"\" 4 send-me-a-value)\n^Cuser break\n</code></pre><p>In this program, the value being sent through the logger is just a number, which isn’t very interesting. But the value really can be <em>any</em> value, even arbitrary closures or mutable data structures. It’s even possible to send a <a href=\"https://docs.racket-lang.org/guide/concurrency.html#%28part._.Channels%29\">channel</a> through a logger, which can subsequently be used to communicate directly, without having to abuse the logger.\n</p><p>Generally, this feature of loggers isn’t very useful, since Racket has plenty of features for cross-thread communication. What’s special about the logger, however, is that it is global, and it is cross-phase.\n</p><p>The cross-phase nature of the logger makes some sense. If a Racket program creates a namespace (that is, a fresh environment for dynamic evaluation), then uses it to expand and compile a Racket module, the process of compilation might produce some log messages, and the calling thread might wish to receive them. It wouldn’t be a very useful logging system if log messages during compile-time were always lost. However, this convenience is a loophole in the phase separation system, since it allows values to flow—bidirectionally—between phases.\n</p><p>This concept forms the foundation of our exploit, but it alone is not a new technique, and I did not discover it. However, all existing uses I know of that use the logger for cross-phase communication require control of the parent namespace in which modules are being compiled, which means some code must exist “outside” the actual program. That technique does not work for ordinary programs run directly with <code>racket</code> or compiled directly with <code>raco make</code>, so to get there, we’ll need something more clever.\n</p><h3><a name=\"the-challenge\"></a>The challenge</h3><p>Our goal, therefore, is to share state between phases <em>without</em> controlling the compilation namespace. More precisely, we want to be able to create an arbitrary module-level definition that is <em>cross-phase persistent</em>, which means it will be evaluated once and only once no matter how many times its enclosing module is re-instantiated (i.e. given a fresh, untouched state) at various phases. A phase-shifted <code>require</code> of the module that contains the definition should share state with an unshifted version of the module, breaking the separate compilation guarantee wide open.\n</p><p>To use the example from the previous section, we should be able to adjust <code>foods.rkt</code> very slightly…\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; foods.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"s2\">\"define-cross-phase.rkt\"</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">delicious-food?</span> <span class=\"n\">add-delicious-food!</span><span class=\"p\">)</span>\n\n<span class=\"c1\">; share across phases</span>\n<span class=\"p\">(</span><span class=\"n\">define/cross-phase</span> <span class=\"n\">delicious-foods</span> <span class=\"p\">(</span><span class=\"nb\">mutable-set</span><span class=\"p\">))</span>\n\n<span class=\"cm\">#| ... |#</span></code></pre><p>…and the <code>delicious-foods</code> mutable state should magically become cross-phase persistent. When running <code>check-food.rkt</code> from source, we should see the side-effects persisted from the module’s compilation, while running from pre-compiled bytecode should give us the result with compile-time effects discarded.\n</p><p>We already know the logger is going to be part of our exploit, but implementing <code>define/cross-phase</code> on top of it is more subtle than it might seem. In our previous example that used <code>make-log-receiver</code>, we had well-defined sender and receiver threads, but who is the “sender” in our multi-phased world? And what exactly is the sender sending?\n</p><p>To answer those questions, allow me to outline the general idea of our approach:\n</p><ol><li><p>The first time our <code>foods.rkt</code> module is instantiated, at any phase, it evaluates the <code>(mutable-set)</code> expression to produce a new mutable set. It spawns a sender thread that sends this value via the logger to anyone who will listen, and that thread lingers in the background for the remaining duration of the program.\n</p></li><li><p>All subsequent instantiations of <code>foods.rkt</code> do <em>not</em> evaluate the <code>(mutable-set)</code> expression. Instead, they obtain the existing set by creating a log receiver and obtaining the value the sender thread is broadcasting. This ensures that a single value is shared across all instantiations of the module.\n</p></li></ol><p>This sounds deceptively simple, but the crux of the problem is how to determine whether <code>foods.rkt</code> has previously been instantiated or not. Since we can only communicate across phases via the logger, we cannot use any shared state to directly record the first time the module is instantiated. We can listen to a log receiver and wait to see if we get a response, but this introduces a race condition: how long do we wait until giving up and deciding we’re the first instantiation? Worse, what if two threads instantiate the module at the same time, and both threads end up spawning a new sender thread, duplicating the state?\n</p><p>The true challenge, therefore, is to develop a protocol by which we can be <em>certain</em> we are the first instantiation of a module, without relying on any unspecified behavior, and without introducing any race conditions. This is possible, but it isn’t obvious, and it requires combining loggers with some extra tools available to the Racket programmer.\n</p><h3><a name=\"the-key-idea\"></a>The key idea</h3><p>It’s finally time to tackle the key idea at the heart of our exploit: garbage collection. In Racket, garbage collection is an observable effect, since Racket allows attaching finalizers to values via <a href=\"https://docs.racket-lang.org/reference/willexecutor.html\">wills and executors</a>. Since a single heap is necessarily shared by the entire VM, behavior happening on other threads (even in other phases) can be indirectly observed by creating a unique value—a “canary”—then sending it to another thread, and waiting to see if it will be garbage collected or not (that is, whether or not the canary “dies”).\n</p><p>Remember that logs and log receivers are effectively buffered, multicast, asynchronous FIFO channels. Since they are buffered, if any thread is already listening to a logger topic when a value is sent, it cannot possibly be garbage collected until that thread either reads it and discards it or the receiver itself is garbage collected. It’s possible to use this mechanism to observe whether or not another thread is already listening on a topic, as the following program demonstrates:<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup>\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; check-receivers.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">executor</span> <span class=\"p\">(</span><span class=\"nb\">make-will-executor</span><span class=\"p\">))</span>\n  <span class=\"c1\">; limit scope of `canary` so we don’t retain a reference</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">canary</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span> <span class=\"o\">&#39;</span><span class=\"ss\">canary</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"nb\">will-register</span> <span class=\"n\">executor</span> <span class=\"n\">canary</span> <span class=\"nb\">void</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">log-message</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"n\">topic</span> <span class=\"s2\">\"\"</span> <span class=\"n\">canary</span> <span class=\"no\">#f</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"k\">begin</span>\n        <span class=\"p\">(</span><span class=\"nb\">collect-garbage</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"nb\">collect-garbage</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"nb\">collect-garbage</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"nb\">sync/timeout</span> <span class=\"mi\">0</span> <span class=\"n\">executor</span><span class=\"p\">))</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"no receivers for ~v</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"receiver exists for ~v</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">topic</span><span class=\"p\">)))</span>\n\n<span class=\"c1\">; add a receiver on topic &#39;foo</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">recv</span> <span class=\"p\">(</span><span class=\"nb\">make-log-receiver</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"o\">&#39;</span><span class=\"ss\">foo</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t1</span> <span class=\"p\">(</span><span class=\"nb\">thread</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"o\">&#39;</span><span class=\"ss\">foo</span><span class=\"p\">))))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t2</span> <span class=\"p\">(</span><span class=\"nb\">thread</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"o\">&#39;</span><span class=\"ss\">bar</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"nb\">thread-wait</span> <span class=\"n\">t1</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"nb\">thread-wait</span> <span class=\"n\">t2</span><span class=\"p\">)</span></code></pre><pre><code>$ racket check-receivers.rkt\nno receivers for 'bar\nreceiver exists for 'foo\n</code></pre><p>However, this program has some problems. For one, it needs to call <code>collect-garbage</code> several times to be certain that the canary will be collected if there are no listeners, which can take a second or two, and it also assumes that three calls to <code>collect-garbage</code> will be enough to collect the canary, though there is no guarantee that will be true.\n</p><p>A bulletproof solution should be both reasonably performant and guaranteed to work. To get there, we have to combine this idea with something more. Here’s the trick: instead of sending the canary alone, send a <a href=\"https://docs.racket-lang.org/guide/concurrency.html#%28part._.Channels%29\">channel</a> alongside it. Synchronize on both the canary’s executor <em>and</em> the channel so that the thread will unblock if either the canary is collected <em>or</em> the channel is received and sent a value using <code>channel-put</code>. Have the receiver listen for the channel on a separate thread, and when it receives it, send a value back to unblock the waiting thread as quickly as possible, without needing to rely on a timeout or a particular number of calls to <code>collect-garbage</code>.\n</p><p>Using that idea, we can revise the program:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; check-receivers.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">chan</span> <span class=\"p\">(</span><span class=\"nb\">make-channel</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">executor</span> <span class=\"p\">(</span><span class=\"nb\">make-will-executor</span><span class=\"p\">))</span>\n  <span class=\"c1\">; limit scope of `canary` so we don’t retain a reference</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">canary</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span> <span class=\"o\">&#39;</span><span class=\"ss\">canary</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"nb\">will-register</span> <span class=\"n\">executor</span> <span class=\"n\">canary</span> <span class=\"nb\">void</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">log-message</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"n\">topic</span> <span class=\"s2\">\"\"</span>\n                 <span class=\"c1\">; send the channel + the canary</span>\n                 <span class=\"p\">(</span><span class=\"nb\">vector-immutable</span> <span class=\"n\">chan</span> <span class=\"n\">canary</span><span class=\"p\">)</span> <span class=\"no\">#f</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">([</span><span class=\"n\">n</span> <span class=\"mi\">0</span><span class=\"p\">])</span>\n        <span class=\"p\">(</span><span class=\"nb\">sleep</span><span class=\"p\">)</span> <span class=\"c1\">; yield to try to let the receiver thread work</span>\n        <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"p\">(</span><span class=\"nb\">sync/timeout</span> <span class=\"mi\">0</span>\n                             <span class=\"p\">(</span><span class=\"nb\">wrap-evt</span> <span class=\"n\">chan</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">received</span><span class=\"p\">))</span>\n                             <span class=\"p\">(</span><span class=\"nb\">wrap-evt</span> <span class=\"n\">executor</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">collected</span><span class=\"p\">)))</span>\n          <span class=\"p\">[</span><span class=\"o\">&#39;</span><span class=\"ss\">collected</span> <span class=\"no\">#t</span><span class=\"p\">]</span>\n          <span class=\"p\">[</span><span class=\"o\">&#39;</span><span class=\"ss\">received</span>  <span class=\"no\">#f</span><span class=\"p\">]</span>\n          <span class=\"p\">[</span><span class=\"k\">_</span> <span class=\"c1\">; collect garbage and try again</span>\n           <span class=\"p\">(</span><span class=\"nb\">collect-garbage</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">&lt;</span> <span class=\"n\">n</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">minor</span> <span class=\"o\">&#39;</span><span class=\"ss\">major</span><span class=\"p\">))</span>\n           <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"n\">n</span><span class=\"p\">))]))</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"no receivers for ~v</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">printf</span> <span class=\"s2\">\"receiver exists for ~v</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span> <span class=\"n\">topic</span><span class=\"p\">)))</span>\n\n<span class=\"c1\">; add a receiver on topic &#39;foo</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">recv</span> <span class=\"p\">(</span><span class=\"nb\">make-log-receiver</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"o\">&#39;</span><span class=\"ss\">foo</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"nb\">void</span> <span class=\"p\">(</span><span class=\"nb\">thread</span>\n       <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span>\n         <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">()</span>\n           <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"p\">(</span><span class=\"nb\">sync</span> <span class=\"n\">recv</span><span class=\"p\">)</span>\n             <span class=\"p\">[(</span><span class=\"nb\">vector</span> <span class=\"k\">_</span> <span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"nb\">vector</span> <span class=\"n\">chan</span> <span class=\"k\">_</span><span class=\"p\">)</span> <span class=\"k\">_</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"nb\">channel-put</span> <span class=\"n\">chan</span> <span class=\"no\">#t</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"n\">loop</span><span class=\"p\">)])))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t1</span> <span class=\"p\">(</span><span class=\"nb\">thread</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"o\">&#39;</span><span class=\"ss\">foo</span><span class=\"p\">))))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">t2</span> <span class=\"p\">(</span><span class=\"nb\">thread</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"n\">check-receivers</span> <span class=\"o\">&#39;</span><span class=\"ss\">bar</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"nb\">thread-wait</span> <span class=\"n\">t1</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"nb\">thread-wait</span> <span class=\"n\">t2</span><span class=\"p\">)</span></code></pre><p>Now the program completes almost instantly. For this simple program, the explicit <code>(sleep)</code> call is effective enough at yielding that, on my machine, <code>(check-receivers 'foo)</code> returns without ever calling <code>collect-garbage</code>, and <code>(check-receivers 'bar)</code> returns after performing a single minor collection.\n</p><p>This is extremely close to a bulletproof solution, but there are two remaining subtle issues:\n</p><ol><li><p>There is technically a race condition between the <code>(sync recv)</code> in the receiver thread and the subsequent <code>channel-put</code>, since it’s possible for the canary to be received, discarded, and garbage collected before reaching the call to <code>channel-put</code>, which the sending thread would incorrectly interpret as indicating the topic has no receivers.\n</p><p>To fix that, the receiver thread can send the canary itself back through the channel, which fundamentally has to work, since the value cannot be collected until it has been received by the sending thread, at which point the <code>sync</code> has already chosen the channel.\n</p></li><li><p>It is possible for the receiver thread to receive the log message and call <code>channel-put</code>, but for the sending thread to somehow die in the meantime (which cannot be protected against in general in Racket, since <code>thread-kill</code> immediately and forcibly terminates a thread). If this were to happen, the sending thread would never obtain the value from the channel, blocking the receiving thread indefinitely.\n</p><p>A solution is to spawn a new thread for each <code>channel-put</code> instead of calling it directly from the receiving thread. Conveniently, this both ensures the receiving thread never gets stuck and avoids resource leaks, since the Racket runtime is smart enough to GC a thread blocked on a channel that has no other references and therefore can never be unblocked.\n</p></li></ol><p>With those fixes in place, the program is, to the best of my knowledge, bulletproof. It will always correctly determine whether or not a logger has a listener, with no race conditions or reliance upon unspecified behavior of the Racket runtime. It does, however, make a couple of assumptions.\n</p><p>First, it assumes that the value of <code>(current-logger)</code> is shared between the threads. It is true that <code>(current-logger)</code> can be changed, and sometimes is, but it’s usually done via <code>parameterize</code>, not mutation of the parameter directly. Therefore, this can largely be mitigated by storing the value of <code>(current-logger)</code> at module instantiation time.\n</p><p>Second, it assumes that no other receivers are listening on the same topic. Technically, even using a unique, uninterned key for the topic is insufficient to ensure that no receivers are listening to it, since a receiver can choose to listen to all topics. However, in practice, it is highly unlikely that any receiver would willfully choose to listen to all topics at the <code>'debug</code> level, since the receiver would be inundated with enormous amounts of useless information. Even if such a receiver were to be created, it is highly likely that it would dequeue the messages as quickly as possible and discard the accompanying payload, since doing otherwise would cause all messages to be retained in memory, leading to a significant memory leak.\n</p><p>Both these problems can be mitigated by using a logger other than the root logger, which is easy in this example. However, for the purpose of subverting the separate compilation guarantee, we would have no way to share the logger object itself across phases, defeating the whole purpose, so we are forced to use the root logger and hope the above two assumptions remain true (but they usually do).\n</p><h3><a name=\"preparing-the-exploit\"></a>Preparing the exploit</h3><p>If you’ve made it here, congratulations! The most difficult part of this blog post is over. All that’s left is the fun part: performing the exploit.\n</p><p>The bulk of our implementation is a slightly adapted version of <code>check-receivers</code>:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; define-cross-phase.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">root-logger</span> <span class=\"p\">(</span><span class=\"nb\">current-logger</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">make-cross-phase</span> <span class=\"n\">topic</span> <span class=\"k\">thunk</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">receiver</span> <span class=\"p\">(</span><span class=\"nb\">make-log-receiver</span> <span class=\"n\">root-logger</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"n\">topic</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">chan</span> <span class=\"p\">(</span><span class=\"nb\">make-channel</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">executor</span> <span class=\"p\">(</span><span class=\"nb\">make-will-executor</span><span class=\"p\">))</span>\n\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">canary</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span> <span class=\"o\">&#39;</span><span class=\"ss\">canary</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"nb\">will-register</span> <span class=\"n\">executor</span> <span class=\"n\">canary</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">collected</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"nb\">log-message</span> <span class=\"n\">root-logger</span> <span class=\"o\">&#39;</span><span class=\"ss\">debug</span> <span class=\"n\">topic</span> <span class=\"s2\">\"\"</span>\n                 <span class=\"p\">(</span><span class=\"nb\">vector-immutable</span> <span class=\"n\">canary</span> <span class=\"n\">chan</span><span class=\"p\">)</span> <span class=\"no\">#f</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">()</span>\n      <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"p\">(</span><span class=\"nb\">sync</span> <span class=\"n\">receiver</span><span class=\"p\">)</span>\n        <span class=\"p\">[(</span><span class=\"nb\">vector</span> <span class=\"k\">_</span> <span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"nb\">vector</span> <span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"k\">==</span> <span class=\"n\">chan</span> <span class=\"nb\">eq?</span><span class=\"p\">))</span> <span class=\"k\">_</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"nb\">void</span><span class=\"p\">)]</span>\n        <span class=\"p\">[</span><span class=\"k\">_</span>\n         <span class=\"p\">(</span><span class=\"n\">loop</span><span class=\"p\">)])))</span>\n\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">execute-evt</span> <span class=\"p\">(</span><span class=\"nb\">wrap-evt</span> <span class=\"n\">executor</span> <span class=\"nb\">will-execute</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">result</span> <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">([</span><span class=\"n\">n</span> <span class=\"mi\">0</span><span class=\"p\">])</span>\n                   <span class=\"p\">(</span><span class=\"nb\">sleep</span><span class=\"p\">)</span>\n                   <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"p\">(</span><span class=\"nb\">sync/timeout</span> <span class=\"mi\">0</span> <span class=\"n\">chan</span> <span class=\"n\">execute-evt</span><span class=\"p\">)</span>\n                       <span class=\"p\">(</span><span class=\"k\">begin</span>\n                         <span class=\"p\">(</span><span class=\"nb\">collect-garbage</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">&lt;</span> <span class=\"n\">n</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">minor</span> <span class=\"o\">&#39;</span><span class=\"ss\">major</span><span class=\"p\">))</span>\n                         <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"n\">n</span><span class=\"p\">))))))</span>\n\n  <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"n\">result</span>\n    <span class=\"p\">[(</span><span class=\"nb\">vector</span> <span class=\"k\">_</span> <span class=\"n\">value</span><span class=\"p\">)</span>\n     <span class=\"n\">value</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"o\">&#39;</span><span class=\"ss\">collected</span>\n     <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">value</span> <span class=\"p\">(</span><span class=\"k\">thunk</span><span class=\"p\">))</span>\n     <span class=\"p\">(</span><span class=\"nb\">thread</span>\n      <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span>\n        <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">()</span>\n          <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"p\">(</span><span class=\"nb\">sync</span> <span class=\"n\">receiver</span><span class=\"p\">)</span>\n            <span class=\"p\">[(</span><span class=\"nb\">vector</span> <span class=\"k\">_</span> <span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"nb\">vector</span> <span class=\"n\">canary</span> <span class=\"n\">chan</span><span class=\"p\">)</span> <span class=\"k\">_</span><span class=\"p\">)</span>\n             <span class=\"p\">(</span><span class=\"nb\">thread</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"nb\">channel-put</span> <span class=\"n\">chan</span> <span class=\"p\">(</span><span class=\"nb\">vector-immutable</span> <span class=\"n\">canary</span> <span class=\"n\">value</span><span class=\"p\">))))</span>\n             <span class=\"p\">(</span><span class=\"n\">loop</span><span class=\"p\">)]))))</span>\n     <span class=\"n\">value</span><span class=\"p\">]))</span></code></pre><p>There are a few minor differences, which I’ll list:\n</p><ol><li><p>The most obvious difference is that <code>make-cross-phase</code> does the work of both checking if a receiver exists—which I’ll call the <em>manager thread</em>—and spawning it if it doesn’t. If it does end up spawning a manager thread, it evaluates the given thunk to produce a value, which becomes the cross-phase value that will be sent through the channel alongside the canary.\n</p></li><li><p>Once the manager thread is created, subsequent calls to <code>make-cross-phase</code> will receive the value through the channel and return it instead of re-invoking <code>thunk</code>. This is what ensures the right-hand side of each use of <code>define/cross-phase</code> is only ever evaluated once.\n</p></li><li><p>Since <code>make-cross-phase</code> needs to create a log receiver if no manager thread exists, it does so immediately, before sending the canary through the logger. This avoids a race condition between multiple threads that are simultaneously competing to become the manager thread, where both threads could send a canary through the logger before either was listening, both canaries would get GC’d, and both threads would spawn a new manager.<sup><a id=\"footnote-ref-4-1\" href=\"#footnote-4\">4</a></sup>\n</p><p>Creating the receiver before sending the canary avoids this problem, but the thread now needs to receive its own canary and discard it before synchronizing on the channel and executor, since otherwise it will retain a reference to the canary. It’s possible that in between creating the receiver and sending the canary, another thread also sent a canary, so it needs to drop any log messages it finds that don’t include its own canary.\n</p><p>This ends up working out perfectly, since every thread drops all the messages received before the one containing its own canary, but retains all subsequent values. This means that only one thread can ever “win” and become the manager, since the first thread to send a canary is guaranteed to retain all subsequent canaries, yet also guaranteed its canary will be GC’d. Other threads racing to become the manager will remain blocked until the manager thread is created, since its canaries will be retained by the manager-to-be until it dequeues them.\n</p><p>(This is the most subtle part of the process to get right, but conveniently, it mostly just works out without very much code. If you didn’t understand any of the above three paragraphs, it isn’t a big deal.)\n</p></li></ol><p>The final piece to this puzzle is to define the <code>define/cross-phase</code> macro that wraps <code>make-cross-phase</code>. The macro is actually slightly more involved than just generating a call to <code>make-cross-phase</code> directly, since we’d like to use an uninterned symbol for the topic instead of an interned one, just to ensure it is unique. Ordinarily, this might seem impossible, since an uninterned symbol is fundamentally a unique value that needs to be communicated across phases, and the whole problem we are solving is creating a communication channel that spans phases. However, Racket actually provides some built-in support for sharing uninterned symbols across phases (plus some other kinds of values, but they must always be immutable). To do this, we need to generate a <a href=\"https://docs.racket-lang.org/reference/eval-model.html#%28part._cross-phase._persistent-modules%29\">cross-phase persistent submodule</a> that exports an uninterned symbol, then pass that symbol as the topic to <code>make-cross-phase</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">racket/syntax</span><span class=\"p\">)</span>\n         <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">define/cross-phase</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">define/cross-phase</span> <span class=\"n\">x:id</span> <span class=\"n\">e:expr</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">topic-mod-name</span> <span class=\"p\">(</span><span class=\"n\">generate-temporary</span> <span class=\"o\">&#39;</span><span class=\"ss\">cross-phase-topic-key</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">begin</span>\n    <span class=\"p\">(</span><span class=\"k\">module</span> <span class=\"n\">topic-mod-name</span> <span class=\"o\">&#39;</span><span class=\"ss\">#%kernel</span>\n      <span class=\"p\">(</span><span class=\"k\">#%declare</span> <span class=\"kd\">#:cross-phase-persistent</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"k\">#%provide</span> <span class=\"n\">topic</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">[</span><span class=\"n\">topic</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span> <span class=\"s2\">\"cross-phase\"</span><span class=\"p\">)))</span>\n    <span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"o\">&#39;</span><span class=\"ss\">topic-mod-name</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"p\">(</span><span class=\"n\">make-cross-phase</span> <span class=\"n\">topic</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">()</span> <span class=\"n\">e</span><span class=\"p\">)))))</span></code></pre><p>And that’s really it. We’re done.\n</p><h3><a name=\"executing-the-exploit\"></a>Executing the exploit</h3><p>With our implementation of <code>define/cross-phase</code> in hand, all that’s left to do is run our original <code>check-foods.rkt</code> program and see what happens:\n</p><pre><code class=\"pygments\">$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nset-add!: contract violation:\nexpected: set?\ngiven: <span class=\"o\">(</span>mutable-set <span class=\"s2\">\"fried chicken\"</span> <span class=\"s2\">\"roasted chicken\"</span> <span class=\"s2\">\"roasted potato\"</span> <span class=\"s2\">\"fried potato\"</span><span class=\"o\">)</span>\nargument position: 1st\nother arguments...:\n  x: <span class=\"s2\">\"pineapple\"</span></code></pre><p>Well, I don’t know what you expected. Play stupid games, win stupid prizes.\n</p><p>This error actually makes sense, but it belies one reason (of many) why this whole endeavor is probably a bad idea. Although we’ve managed to make our mutable set cross-phase persistent, our references to set operations like <code>set-add!</code> and <code>set-member?</code> are not, and every time <code>racket/set</code> is instantiated in a fresh phase, it creates an entirely new instance of the <code>set</code> structure type. This means that even though we have a bona fide mutable set, it isn’t actually the type of set that this phase’s <code>set-add!</code> understands!\n</p><p>Of course, this isn’t a problem that some liberal application of <code>define/cross-phase</code> can’t solve:\n</p><pre><code class=\"pygments\"><span class=\"c1\">;; foods.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"s2\">\"define-cross-phase.rkt\"</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">delicious-food?</span> <span class=\"n\">add-delicious-food!</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define/cross-phase</span> <span class=\"n\">cross:set-member?</span> <span class=\"nb\">set-member?</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define/cross-phase</span> <span class=\"n\">cross:set-add!</span> <span class=\"nb\">set-add!</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define/cross-phase</span> <span class=\"n\">delicious-foods</span> <span class=\"p\">(</span><span class=\"nb\">mutable-set</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">delicious-food?</span> <span class=\"n\">food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">cross:set-member?</span> <span class=\"n\">delicious-foods</span> <span class=\"n\">food</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add-delicious-food!</span> <span class=\"n\">new-food</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">cross:set-add!</span> <span class=\"n\">delicious-foods</span> <span class=\"n\">new-food</span><span class=\"p\">))</span></code></pre><pre><code class=\"pygments\">$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nfried chicken is a delicious food.\n$ raco make check-food.rkt\n$ racket check-food.rkt <span class=\"s1\">&#39;fried chicken&#39;</span>\nfried chicken is not delicious.</code></pre><p>And thus we find that another so-called “guarantee” isn’t.\n</p><h2><a name=\"reflection\"></a>Reflection</h2><p>Now comes the time in the blog post when I have to step back and think about what I’ve done. Have mercy.\n</p><p>Everything in this blog post is a terrible idea. No, you should not use loggers for anything that isn’t logging, you shouldn’t use wills and executors for critical control flow, and obviously you should absolutely not intentionally break one of the most helpful guarantees the Racket module system affords you.\n</p><p>But I thought it was fun to do all that, anyway.\n</p><p>The meaningful takeaways from this blog post aren’t that the separate compilation guarantee can be broken, nor that any of the particular techniques I used hold, but that\n</p><ol><li><p>ensuring non-trivial guarantees is really hard,\n</p></li><li><p>despite that, the separate compilation guarantee is really, really hard to break,\n</p></li><li><p>the separate compilation guarantee is good, and you should appreciate the luxury it affords you while writing Racket macros,\n</p></li><li><p>avoiding races in a concurrent environment can be extremely subtle,\n</p></li><li><p>and Racket is totally <em>awesome</em> for giving me this much rope to hang myself with.\n</p></li></ol><p>If you want to hang yourself with Racket, too, <a href=\"https://gist.github.com/lexi-lambda/f173a84fc9727977bcea657b3bb0cd4f\">runnable code from this blog post is available here</a>.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>This isn’t <em>strictly</em> true, since Racket provides sandboxing mechanisms that can compile and execute untrusted code without file system or network access, but this is not the default compilation mode. Usually, it doesn’t matter nearly as much as it might sound: most of the time, if you’re compiling untrusted code, you’re also going to run it, and running untrusted code can do all those things, anyway.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>This is actually a <em>terrible</em> use case for a macro, since an ordinary function would do just fine, but I’m simplifying a little to keep the example small.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>Racket actually provides this functionality directly via the <code>log-level?</code> procedure. However, since <code>log-level?</code> provides no way to determine how <em>many</em> receivers are listening to a topic, using it to guard against creating a receiver is vulnerable to a race condition that the garbage collection-based approach can avoid, as is discussed later. Furthermore, the GC technique is more likely to be resilient to nosy log receivers listening on all topics at the <code>'debug</code> level, since they will almost certainly dequeue and discard the value quickly (as otherwise they would leak large quantities of memory).\n <a href=\"#footnote-ref-3-1\">↩</a></p></li><li id=\"footnote-4\"><p>This race is the one that makes using <code>log-level?</code> untenable, since the receiver needs to be created before the topic is checked for listeners to avoid the race, which can’t be done with <code>log-level?</code> (since it would always return <code>#t</code>).\n <a href=\"#footnote-ref-4-1\">↩</a></p></li></ol></article>","contentSnippet":"Being a self-described programming-language programming language is an ambitious goal. To preserve predictability while permitting linguistic extension, Racket comes equipped with a module system carefully designed to accommodate composable and compilable macros. One of the module system’s foundational properties is its separate compilation guarantee, which imposes strong, unbreakable limits on the extent of compile-time side-effects. It is essential for preserving static guarantees in a world where compiling a module can execute arbitrary code, and despite numerous unsafe trapdoors that have crept into Racket since its birth as PLT Scheme, none have ever given the programmer the ability to cheat it.\n\nYet today, in this blog post, we’re going to do exactly that.\n\nWhat is the separate compilation guarantee?\nBefore we get to the fun part (i.e. breaking things), let’s go over some fundamentals so we understand what we’re breaking. The authoritative source for the separate compilation guarantee is the Racket reference, but it is dense, as authoritative sources tend to be. Although I enjoy reading technical manuals for sport, it is my understanding that not all the people who read this blog are as strange as I am, so let’s start with a quick primer, instead. (If you’re already an expert, feel free to skip to the next section.)\n\nRacket is a macro-enabled programming language. In Racket, a macro is a user-defined, code-to-code transformation that occurs at compile-time. These transformations cannot make arbitrary changes to the program—in Racket, they are usually required to be local, affecting a single expression or definition at a time—but they may be implemented using arbitrary code. This means that a macro can, if it so desires, read the SSH keys off your filesystem and issue an HTTP request to send them someplace.\n\nThat kind of attack is bad, admittedly, but it’s also uninteresting: Racket allows you do all that and then some, making no attempt to prevent it.1 Racket calls these “external effects,” things that affect state outside of the programming language. They sound scary, but in practice, internal effects—effects that mutate state inside the programming language—are a much bigger obstacle to practical programming. Let’s take a look at why.\n\nLet’s say we have a module with some global, mutable state. Perhaps it is used to keep track of a set of delicious foods:\n\n;; foods.rkt\n#lang racket\n(provide delicious-food? add-delicious-food!)\n\n(define delicious-foods (mutable-set))\n\n(define (delicious-food? food)\n  (set-member? delicious-foods food))\n\n(define (add-delicious-food! new-food)\n  (set-add! delicious-foods new-food))\nUsing this interface, let’s write a program that checks if a particular food, given as a command-line argument, is delicious:\n\n;; check-food.rkt\n#lang racket\n(require \"foods.rkt\")\n\n(add-delicious-food! \"pineapple\")\n(add-delicious-food! \"sushi\")\n(add-delicious-food! \"cheesecake\")\n\n(command-line\n  #:args [food-to-check]\n  (if (delicious-food? food-to-check)\n      (printf \"~a is a delicious food.\\n\" food-to-check)\n      (printf \"~a is not delicious.\\n\" food-to-check)))\n$ racket check-food.rkt cheesecake\ncheesecake is a delicious food.\n$ racket check-food.rkt licorice\nlicorice is not delicious.\nExhilarating. (Sorry, licorice fans.) But what if a macro were to call add-delicious-food!? What would happen? For example, what if we wrote a macro to add a lot of foods at once?2\n\n(require syntax/parse/define)\n(define-simple-macro (add-food-combinations! [fst:string ...]\n                                             [snd:string ...])\n  #:do [(for* ([fst-str (in-list (syntax->datum #'[fst ...]))]\n               [snd-str (in-list (syntax->datum #'[snd ...]))])\n          (add-delicious-food! (string-append fst-str \" \" snd-str)))]\n  (void))\n\n; should add “fried chicken,” “roasted chicken”, “fried potato,” and “roasted potato”\n(add-food-combinations! [\"fried\" \"roasted\"] [\"chicken\" \"potato\"])\nNow, what do you think executing racket check-food.rkt 'fried chicken' will do?\n\nClearly, the program should print fried chicken is a delicious food, and indeed, many traditional Lisp systems would happily produce such a result. After all, running racket check-food.rkt 'fried chicken' must load the source code inside check-food.rkt, expand and compile it, then run the result. While the program is being expanded, the compile-time calls to add-delicious-food! should add new elements to the delicious-food set, so when the program is executed, the string \"fried chicken\" ought to be in it.\n\nBut if you actually try this yourself, you will find that isn’t what happens. Instead, Racket rejects the program:\n\n$ racket check-food.rkt 'fried chicken'\ncheck-food.rkt:12:11: add-delicious-food!: reference to an unbound identifier\n  at phase: 1; the transformer environment\n  in: add-delicious-food!\nWhy does Racket reject this program? Well, consider that Racket allows programs to be pre-compiled using raco make, doing all the work of macroexpansion and compilation to bytecode ahead of time. Subsequent runs of the program will use the pre-compiled version, without having to run all the macros again. This is a problem, since expanding the add-food-combinations! macro had side-effects that our program depended on!\n\nIf Racket allowed the above program, it might do different things depending on whether it was pre-compiled. Running directly from source code might treat 'fried chicken' as a delicious food, while running from pre-compiled bytecode might not. Racket considers this unacceptable, so it disallows the program entirely.\n\nPreserving separate compilation via phases\nHopefully, you are now mostly convinced that the above program is a bad one, but you might have some lingering doubts. You might, for example, wonder if Racket disallows mutable compile-time state entirely. That is not the case—Racket really does allow everything that happens at runtime to happen at compile-time—but it does prevent compile-time and run-time state from ever interacting. Racket stratifies every program into a compile-time part and a run-time part, and it restricts communication between them to limited, well-defined channels (mainly via expanding to code that does something at run-time).\n\nRacket calls this system of stratification phases. Code that executes at run-time belongs to the run-time phase, while code that executes at compile-time (i.e. macros) belongs to the compile-time phase. When a variable is defined, it is always defined in a particular phase, so bindings declared with define can only be used at run-time, while bindings declared with define-for-syntax can only be used at compile-time. Since add-delicious-food! was declared using define, it was not allowed (and in fact was not even visible) in the body of the add-food-combinations! macro.\n\nWhile the whole macro system could work precisely as just described, such a strict stratification would be incredibly rigid. Since every definition would belong to either run-time or compile-time, but never both, reusing run-time code to implement macros would be impossible. While the example in the previous section might make it seem like that’s a good thing, it very often isn’t: imagine if general-purpose functions like map and filter all needed to be written twice!\n\nTo avoid this problem, Racket allows modules to be imported at both run-time and compile-time, so long as it’s done explicitly. Writing (require \"some-library.rkt\") requires some-library.rkt for run-time code, but writing (require (for-syntax \"some-library.rkt\")) requires it for compile-time code. Requiring a module for-syntax is sort of like implicitly adjusting all of its uses of define to be define-for-syntax, instead, effectively shifting all the code from run-time to compile-time. This kind of operation is therefore known as phase shifting in Racket terminology.\n\nWe can use phase shifting to make the program we wrote compile. If we adjust the require at the beginning of our program, then we can ensure add-delicious-food! is visible to both the run-time and compile-time parts of check-food.rkt:\n\n(require \"foods.rkt\" (for-syntax \"foods.rkt\"))\nNow our program compiles. However, if you’ve been following everything carefully, you should be wondering why! According to the last section, sharing state between run-time and compile-time fundamentally can’t work without introducing inconsistencies between uncompiled and pre-compiled code. And that’s true—such a thing would cause all sorts of problems, and Racket doesn’t allow it. If you run the program, whether pre-compiled or not, you’ll find it always does the same thing:\n\n$ racket check-food.rkt 'fried chicken'\nfried chicken is not delicious.\nThis seems rather confusing. What happened to the calls to add-delicious-food! inside our add-food-combinations! macro? If we stick a printf inside add-delicious-food!, we’ll find that it really does get called:\n\n(define (add-delicious-food! new-food)\n  (printf \"Registering ~a as a delicious food.\\n\" new-food)\n  (set-add! delicious-foods new-food))\n$ racket check-food.rkt 'fried chicken'\nRegistering fried chicken as a delicious food.\nRegistering fried potato as a delicious food.\nRegistering roasted chicken as a delicious food.\nRegistering roasted potato as a delicious food.\nRegistering pineapple as a delicious food.\nRegistering sushi as a delicious food.\nRegistering cheesecake as a delicious food.\nfried chicken is not delicious.\nAnd in fact, if we pre-compile check-food.rkt, we’ll see that the first four registrations appear at compile-time, exactly as we expect:\n\n$ raco make check-food.rkt\nRegistering fried chicken as a delicious food.\nRegistering fried potato as a delicious food.\nRegistering roasted chicken as a delicious food.\nRegistering roasted potato as a delicious food.\n$ racket check-food.rkt 'fried chicken'\nRegistering pineapple as a delicious food.\nRegistering sushi as a delicious food.\nRegistering cheesecake as a delicious food.\nfried chicken is not delicious.\nThe compile-time registrations really are happening, but Racket is automatically restricting the compile-time side-effects so they only apply at compile-time. After compilation has finished, Racket ensures that compile-time side effects are thrown away, and the run-time code starts over with fresh, untouched state. This guarantees consistent behavior, since it becomes impossible to distinguish at run-time whether a module was just compiled on the fly, or if it was pre-compiled long ago (possibly even on someone else’s computer).\n\nThis is the essence of the separate compilation guarantee. To summarize:\n\n\nRun-time and compile-time are distinct phases of execution, which cannot interact.\n\n\nModules can be required at multiple phases via phase shifting, but their state is kept separate. Each phase gets its own copy of the state.\n\n\nEnsuring that the state is kept separate ensures predictable program behavior, no matter when the program is compiled.\n\n\nThis summary is a simplification of phases in Racket. The full Racket module system does not have only two phases, since macros can also be used at compile-time to implement other macros, effectively creating a separate “compile-time” for the compile-time code. Each compile-time pass is isolated to its own phase, creating a finite but arbitrarily large number of distinct program phases (all but one of which occur at compile-time).\n\nFurthermore, the separate compilation guarantee does not just isolate the state of each phase from the state of other phases but also isolates all compile-time state from the compile-time state of other modules. This ensures that compilation is still deterministic even if modules are compiled in a different order, or if several modules are sometimes compiled individually while other times compiled together all at once.\n\nIf you want to learn more, the full details of the module system are described at length in the General Phase Levels section of the Racket Guide, but the abridged summary I’ve described is enough for the purposes of this blog post. If the bulleted list above mostly made sense to you, you’re ready to move on.\n\nHow we’re going to break it\nThe separate compilation guarantee is a sturdy opponent, but it is not without weaknesses. Although no API in Racket, safe or unsafe, allows arbitrarily disabling phase separation, a couple features of Racket are already known to allow limited forms of cross-phase communication.\n\nThe most significant of these, and the one we’ll be using as our vector of attack, is the logger. Unlike many logging systems, which are exclusively string-oriented, Racket’s logging interface allows structured logging by associating an arbitrary Racket value with each and every log message. Since it is possible to set up listeners within Racket that receive log messages sent to a particular “topic,” the logger can be used as a communication channel to send values between different parts of a program.\n\nThe following program illustrates how this works. One thread creates a listener for all log messages on the topic 'send-me-a-value using make-log-receiver, then uses sync to block until a value is received. Meanwhile, a second thread sends values through the logger using log-message. Together, this creates a makeshift buffered, asynchronous channel:\n\n;; log-comm.rkt\n#lang racket\n\n(define t1\n  (thread\n   (lambda ()\n     (define recv (make-log-receiver (current-logger) 'debug 'send-me-a-value))\n     (let loop ()\n       (println (sync recv))\n       (loop)))))\n\n(define t2\n  (thread\n   (lambda ()\n     (let loop ([n 0])\n       (log-message (current-logger) 'debug 'send-me-a-value \"\" n #f)\n       (sleep 1)\n       (loop (add1 n))))))\n\n(thread-wait t1) ; wait forever\n$ racket log-comm.rkt\n'#(debug \"\" 1 send-me-a-value)\n'#(debug \"\" 2 send-me-a-value)\n'#(debug \"\" 3 send-me-a-value)\n'#(debug \"\" 4 send-me-a-value)\n^Cuser break\n\nIn this program, the value being sent through the logger is just a number, which isn’t very interesting. But the value really can be any value, even arbitrary closures or mutable data structures. It’s even possible to send a channel through a logger, which can subsequently be used to communicate directly, without having to abuse the logger.\n\nGenerally, this feature of loggers isn’t very useful, since Racket has plenty of features for cross-thread communication. What’s special about the logger, however, is that it is global, and it is cross-phase.\n\nThe cross-phase nature of the logger makes some sense. If a Racket program creates a namespace (that is, a fresh environment for dynamic evaluation), then uses it to expand and compile a Racket module, the process of compilation might produce some log messages, and the calling thread might wish to receive them. It wouldn’t be a very useful logging system if log messages during compile-time were always lost. However, this convenience is a loophole in the phase separation system, since it allows values to flow—bidirectionally—between phases.\n\nThis concept forms the foundation of our exploit, but it alone is not a new technique, and I did not discover it. However, all existing uses I know of that use the logger for cross-phase communication require control of the parent namespace in which modules are being compiled, which means some code must exist “outside” the actual program. That technique does not work for ordinary programs run directly with racket or compiled directly with raco make, so to get there, we’ll need something more clever.\n\nThe challenge\nOur goal, therefore, is to share state between phases without controlling the compilation namespace. More precisely, we want to be able to create an arbitrary module-level definition that is cross-phase persistent, which means it will be evaluated once and only once no matter how many times its enclosing module is re-instantiated (i.e. given a fresh, untouched state) at various phases. A phase-shifted require of the module that contains the definition should share state with an unshifted version of the module, breaking the separate compilation guarantee wide open.\n\nTo use the example from the previous section, we should be able to adjust foods.rkt very slightly…\n\n;; foods.rkt\n#lang racket\n(require \"define-cross-phase.rkt\")\n(provide delicious-food? add-delicious-food!)\n\n; share across phases\n(define/cross-phase delicious-foods (mutable-set))\n\n#| ... |#\n…and the delicious-foods mutable state should magically become cross-phase persistent. When running check-food.rkt from source, we should see the side-effects persisted from the module’s compilation, while running from pre-compiled bytecode should give us the result with compile-time effects discarded.\n\nWe already know the logger is going to be part of our exploit, but implementing define/cross-phase on top of it is more subtle than it might seem. In our previous example that used make-log-receiver, we had well-defined sender and receiver threads, but who is the “sender” in our multi-phased world? And what exactly is the sender sending?\n\nTo answer those questions, allow me to outline the general idea of our approach:\n\n\nThe first time our foods.rkt module is instantiated, at any phase, it evaluates the (mutable-set) expression to produce a new mutable set. It spawns a sender thread that sends this value via the logger to anyone who will listen, and that thread lingers in the background for the remaining duration of the program.\n\n\nAll subsequent instantiations of foods.rkt do not evaluate the (mutable-set) expression. Instead, they obtain the existing set by creating a log receiver and obtaining the value the sender thread is broadcasting. This ensures that a single value is shared across all instantiations of the module.\n\n\nThis sounds deceptively simple, but the crux of the problem is how to determine whether foods.rkt has previously been instantiated or not. Since we can only communicate across phases via the logger, we cannot use any shared state to directly record the first time the module is instantiated. We can listen to a log receiver and wait to see if we get a response, but this introduces a race condition: how long do we wait until giving up and deciding we’re the first instantiation? Worse, what if two threads instantiate the module at the same time, and both threads end up spawning a new sender thread, duplicating the state?\n\nThe true challenge, therefore, is to develop a protocol by which we can be certain we are the first instantiation of a module, without relying on any unspecified behavior, and without introducing any race conditions. This is possible, but it isn’t obvious, and it requires combining loggers with some extra tools available to the Racket programmer.\n\nThe key idea\nIt’s finally time to tackle the key idea at the heart of our exploit: garbage collection. In Racket, garbage collection is an observable effect, since Racket allows attaching finalizers to values via wills and executors. Since a single heap is necessarily shared by the entire VM, behavior happening on other threads (even in other phases) can be indirectly observed by creating a unique value—a “canary”—then sending it to another thread, and waiting to see if it will be garbage collected or not (that is, whether or not the canary “dies”).\n\nRemember that logs and log receivers are effectively buffered, multicast, asynchronous FIFO channels. Since they are buffered, if any thread is already listening to a logger topic when a value is sent, it cannot possibly be garbage collected until that thread either reads it and discards it or the receiver itself is garbage collected. It’s possible to use this mechanism to observe whether or not another thread is already listening on a topic, as the following program demonstrates:3\n\n;; check-receivers.rkt\n#lang racket\n\n(define (check-receivers topic)\n  (define executor (make-will-executor))\n  ; limit scope of `canary` so we don’t retain a reference\n  (let ()\n    (define canary (gensym 'canary))\n    (will-register executor canary void)\n    (log-message (current-logger) 'debug topic \"\" canary #f))\n  (if (begin\n        (collect-garbage)\n        (collect-garbage)\n        (collect-garbage)\n        (sync/timeout 0 executor))\n      (printf \"no receivers for ~v\\n\" topic)\n      (printf \"receiver exists for ~v\\n\" topic)))\n\n; add a receiver on topic 'foo\n(define recv (make-log-receiver (current-logger) 'debug 'foo))\n\n(define t1 (thread (λ () (check-receivers 'foo))))\n(define t2 (thread (λ () (check-receivers 'bar))))\n\n(thread-wait t1)\n(thread-wait t2)\n$ racket check-receivers.rkt\nno receivers for 'bar\nreceiver exists for 'foo\n\nHowever, this program has some problems. For one, it needs to call collect-garbage several times to be certain that the canary will be collected if there are no listeners, which can take a second or two, and it also assumes that three calls to collect-garbage will be enough to collect the canary, though there is no guarantee that will be true.\n\nA bulletproof solution should be both reasonably performant and guaranteed to work. To get there, we have to combine this idea with something more. Here’s the trick: instead of sending the canary alone, send a channel alongside it. Synchronize on both the canary’s executor and the channel so that the thread will unblock if either the canary is collected or the channel is received and sent a value using channel-put. Have the receiver listen for the channel on a separate thread, and when it receives it, send a value back to unblock the waiting thread as quickly as possible, without needing to rely on a timeout or a particular number of calls to collect-garbage.\n\nUsing that idea, we can revise the program:\n\n;; check-receivers.rkt\n#lang racket\n\n(define (check-receivers topic)\n  (define chan (make-channel))\n  (define executor (make-will-executor))\n  ; limit scope of `canary` so we don’t retain a reference\n  (let ()\n    (define canary (gensym 'canary))\n    (will-register executor canary void)\n    (log-message (current-logger) 'debug topic \"\"\n                 ; send the channel + the canary\n                 (vector-immutable chan canary) #f))\n  (if (let loop ([n 0])\n        (sleep) ; yield to try to let the receiver thread work\n        (match (sync/timeout 0\n                             (wrap-evt chan (λ (v) 'received))\n                             (wrap-evt executor (λ (v) 'collected)))\n          ['collected #t]\n          ['received  #f]\n          [_ ; collect garbage and try again\n           (collect-garbage (if (< n 3) 'minor 'major))\n           (loop (add1 n))]))\n      (printf \"no receivers for ~v\\n\" topic)\n      (printf \"receiver exists for ~v\\n\" topic)))\n\n; add a receiver on topic 'foo\n(define recv (make-log-receiver (current-logger) 'debug 'foo))\n(void (thread\n       (λ ()\n         (let loop ()\n           (match (sync recv)\n             [(vector _ _ (vector chan _) _)\n              (channel-put chan #t)\n              (loop)])))))\n\n(define t1 (thread (λ () (check-receivers 'foo))))\n(define t2 (thread (λ () (check-receivers 'bar))))\n\n(thread-wait t1)\n(thread-wait t2)\nNow the program completes almost instantly. For this simple program, the explicit (sleep) call is effective enough at yielding that, on my machine, (check-receivers 'foo) returns without ever calling collect-garbage, and (check-receivers 'bar) returns after performing a single minor collection.\n\nThis is extremely close to a bulletproof solution, but there are two remaining subtle issues:\n\n\nThere is technically a race condition between the (sync recv) in the receiver thread and the subsequent channel-put, since it’s possible for the canary to be received, discarded, and garbage collected before reaching the call to channel-put, which the sending thread would incorrectly interpret as indicating the topic has no receivers.\n\nTo fix that, the receiver thread can send the canary itself back through the channel, which fundamentally has to work, since the value cannot be collected until it has been received by the sending thread, at which point the sync has already chosen the channel.\n\n\nIt is possible for the receiver thread to receive the log message and call channel-put, but for the sending thread to somehow die in the meantime (which cannot be protected against in general in Racket, since thread-kill immediately and forcibly terminates a thread). If this were to happen, the sending thread would never obtain the value from the channel, blocking the receiving thread indefinitely.\n\nA solution is to spawn a new thread for each channel-put instead of calling it directly from the receiving thread. Conveniently, this both ensures the receiving thread never gets stuck and avoids resource leaks, since the Racket runtime is smart enough to GC a thread blocked on a channel that has no other references and therefore can never be unblocked.\n\n\nWith those fixes in place, the program is, to the best of my knowledge, bulletproof. It will always correctly determine whether or not a logger has a listener, with no race conditions or reliance upon unspecified behavior of the Racket runtime. It does, however, make a couple of assumptions.\n\nFirst, it assumes that the value of (current-logger) is shared between the threads. It is true that (current-logger) can be changed, and sometimes is, but it’s usually done via parameterize, not mutation of the parameter directly. Therefore, this can largely be mitigated by storing the value of (current-logger) at module instantiation time.\n\nSecond, it assumes that no other receivers are listening on the same topic. Technically, even using a unique, uninterned key for the topic is insufficient to ensure that no receivers are listening to it, since a receiver can choose to listen to all topics. However, in practice, it is highly unlikely that any receiver would willfully choose to listen to all topics at the 'debug level, since the receiver would be inundated with enormous amounts of useless information. Even if such a receiver were to be created, it is highly likely that it would dequeue the messages as quickly as possible and discard the accompanying payload, since doing otherwise would cause all messages to be retained in memory, leading to a significant memory leak.\n\nBoth these problems can be mitigated by using a logger other than the root logger, which is easy in this example. However, for the purpose of subverting the separate compilation guarantee, we would have no way to share the logger object itself across phases, defeating the whole purpose, so we are forced to use the root logger and hope the above two assumptions remain true (but they usually do).\n\nPreparing the exploit\nIf you’ve made it here, congratulations! The most difficult part of this blog post is over. All that’s left is the fun part: performing the exploit.\n\nThe bulk of our implementation is a slightly adapted version of check-receivers:\n\n;; define-cross-phase.rkt\n#lang racket\n\n(define root-logger (current-logger))\n\n(define (make-cross-phase topic thunk)\n  (define receiver (make-log-receiver root-logger 'debug topic))\n  (define chan (make-channel))\n  (define executor (make-will-executor))\n\n  (let ()\n    (define canary (gensym 'canary))\n    (will-register executor canary (λ (v) 'collected))\n    (log-message root-logger 'debug topic \"\"\n                 (vector-immutable canary chan) #f)\n    (let loop ()\n      (match (sync receiver)\n        [(vector _ _ (vector _ (== chan eq?)) _)\n         (void)]\n        [_\n         (loop)])))\n\n  (define execute-evt (wrap-evt executor will-execute))\n  (define result (let loop ([n 0])\n                   (sleep)\n                   (or (sync/timeout 0 chan execute-evt)\n                       (begin\n                         (collect-garbage (if (< n 3) 'minor 'major))\n                         (loop (add1 n))))))\n\n  (match result\n    [(vector _ value)\n     value]\n    ['collected\n     (define value (thunk))\n     (thread\n      (λ ()\n        (let loop ()\n          (match (sync receiver)\n            [(vector _ _ (vector canary chan) _)\n             (thread (λ () (channel-put chan (vector-immutable canary value))))\n             (loop)]))))\n     value]))\nThere are a few minor differences, which I’ll list:\n\n\nThe most obvious difference is that make-cross-phase does the work of both checking if a receiver exists—which I’ll call the manager thread—and spawning it if it doesn’t. If it does end up spawning a manager thread, it evaluates the given thunk to produce a value, which becomes the cross-phase value that will be sent through the channel alongside the canary.\n\n\nOnce the manager thread is created, subsequent calls to make-cross-phase will receive the value through the channel and return it instead of re-invoking thunk. This is what ensures the right-hand side of each use of define/cross-phase is only ever evaluated once.\n\n\nSince make-cross-phase needs to create a log receiver if no manager thread exists, it does so immediately, before sending the canary through the logger. This avoids a race condition between multiple threads that are simultaneously competing to become the manager thread, where both threads could send a canary through the logger before either was listening, both canaries would get GC’d, and both threads would spawn a new manager.4\n\nCreating the receiver before sending the canary avoids this problem, but the thread now needs to receive its own canary and discard it before synchronizing on the channel and executor, since otherwise it will retain a reference to the canary. It’s possible that in between creating the receiver and sending the canary, another thread also sent a canary, so it needs to drop any log messages it finds that don’t include its own canary.\n\nThis ends up working out perfectly, since every thread drops all the messages received before the one containing its own canary, but retains all subsequent values. This means that only one thread can ever “win” and become the manager, since the first thread to send a canary is guaranteed to retain all subsequent canaries, yet also guaranteed its canary will be GC’d. Other threads racing to become the manager will remain blocked until the manager thread is created, since its canaries will be retained by the manager-to-be until it dequeues them.\n\n(This is the most subtle part of the process to get right, but conveniently, it mostly just works out without very much code. If you didn’t understand any of the above three paragraphs, it isn’t a big deal.)\n\n\nThe final piece to this puzzle is to define the define/cross-phase macro that wraps make-cross-phase. The macro is actually slightly more involved than just generating a call to make-cross-phase directly, since we’d like to use an uninterned symbol for the topic instead of an interned one, just to ensure it is unique. Ordinarily, this might seem impossible, since an uninterned symbol is fundamentally a unique value that needs to be communicated across phases, and the whole problem we are solving is creating a communication channel that spans phases. However, Racket actually provides some built-in support for sharing uninterned symbols across phases (plus some other kinds of values, but they must always be immutable). To do this, we need to generate a cross-phase persistent submodule that exports an uninterned symbol, then pass that symbol as the topic to make-cross-phase:\n\n(require (for-syntax racket/syntax)\n         syntax/parse/define)\n\n(provide define/cross-phase)\n\n(define-simple-macro (define/cross-phase x:id e:expr)\n  #:with topic-mod-name (generate-temporary 'cross-phase-topic-key)\n  (begin\n    (module topic-mod-name '#%kernel\n      (#%declare #:cross-phase-persistent)\n      (#%provide topic)\n      (define-values [topic] (gensym \"cross-phase\")))\n    (require 'topic-mod-name)\n    (define x (make-cross-phase topic (λ () e)))))\nAnd that’s really it. We’re done.\n\nExecuting the exploit\nWith our implementation of define/cross-phase in hand, all that’s left to do is run our original check-foods.rkt program and see what happens:\n\n$ racket check-food.rkt 'fried chicken'\nset-add!: contract violation:\nexpected: set?\ngiven: (mutable-set \"fried chicken\" \"roasted chicken\" \"roasted potato\" \"fried potato\")\nargument position: 1st\nother arguments...:\n  x: \"pineapple\"\nWell, I don’t know what you expected. Play stupid games, win stupid prizes.\n\nThis error actually makes sense, but it belies one reason (of many) why this whole endeavor is probably a bad idea. Although we’ve managed to make our mutable set cross-phase persistent, our references to set operations like set-add! and set-member? are not, and every time racket/set is instantiated in a fresh phase, it creates an entirely new instance of the set structure type. This means that even though we have a bona fide mutable set, it isn’t actually the type of set that this phase’s set-add! understands!\n\nOf course, this isn’t a problem that some liberal application of define/cross-phase can’t solve:\n\n;; foods.rkt\n#lang racket\n(require \"define-cross-phase.rkt\")\n(provide delicious-food? add-delicious-food!)\n\n(define/cross-phase cross:set-member? set-member?)\n(define/cross-phase cross:set-add! set-add!)\n\n(define/cross-phase delicious-foods (mutable-set))\n\n(define (delicious-food? food)\n  (cross:set-member? delicious-foods food))\n\n(define (add-delicious-food! new-food)\n  (cross:set-add! delicious-foods new-food))\n$ racket check-food.rkt 'fried chicken'\nfried chicken is a delicious food.\n$ raco make check-food.rkt\n$ racket check-food.rkt 'fried chicken'\nfried chicken is not delicious.\nAnd thus we find that another so-called “guarantee” isn’t.\n\nReflection\nNow comes the time in the blog post when I have to step back and think about what I’ve done. Have mercy.\n\nEverything in this blog post is a terrible idea. No, you should not use loggers for anything that isn’t logging, you shouldn’t use wills and executors for critical control flow, and obviously you should absolutely not intentionally break one of the most helpful guarantees the Racket module system affords you.\n\nBut I thought it was fun to do all that, anyway.\n\nThe meaningful takeaways from this blog post aren’t that the separate compilation guarantee can be broken, nor that any of the particular techniques I used hold, but that\n\n\nensuring non-trivial guarantees is really hard,\n\n\ndespite that, the separate compilation guarantee is really, really hard to break,\n\n\nthe separate compilation guarantee is good, and you should appreciate the luxury it affords you while writing Racket macros,\n\n\navoiding races in a concurrent environment can be extremely subtle,\n\n\nand Racket is totally awesome for giving me this much rope to hang myself with.\n\n\nIf you want to hang yourself with Racket, too, runnable code from this blog post is available here.\n\n\nThis isn’t strictly true, since Racket provides sandboxing mechanisms that can compile and execute untrusted code without file system or network access, but this is not the default compilation mode. Usually, it doesn’t matter nearly as much as it might sound: most of the time, if you’re compiling untrusted code, you’re also going to run it, and running untrusted code can do all those things, anyway.\n ↩\n\nThis is actually a terrible use case for a macro, since an ordinary function would do just fine, but I’m simplifying a little to keep the example small.\n ↩\n\nRacket actually provides this functionality directly via the log-level? procedure. However, since log-level? provides no way to determine how many receivers are listening to a topic, using it to guard against creating a receiver is vulnerable to a race condition that the garbage collection-based approach can avoid, as is discussed later. Furthermore, the GC technique is more likely to be resilient to nosy log receivers listening on all topics at the 'debug level, since they will almost certainly dequeue and discard the value quickly (as otherwise they would leak large quantities of memory).\n ↩\n\nThis race is the one that makes using log-level? untenable, since the receiver needs to be created before the topic is checked for listeners to avoid the race, which can’t be done with log-level? (since it would always return #t).\n ↩","isoDate":"2019-04-21T00:00:00.000Z","timestamp":"4/20/2019"},{"title":"Macroexpand anywhere with local-apply-transformer!","pubDate":"2018-10-06T00:00:00.000Z","author":"Alexis King","content":"<article><p>Racket programmers are accustomed to the language’s incredible capacity for extension and customization. Writing useful macros that do complicated things is easy, and it’s simple to add new syntactic forms to meet domain-specific needs. However, it doesn’t take long before many budding macrologists bump into the realization that only <em>certain positions</em> in Racket code are subject to macroexpansion.\n</p><p>To illustrate, consider a macro that provides a Clojure-style <code>let</code> form:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">clj-let</span> <span class=\"p\">[{</span><span class=\"n\">~seq</span> <span class=\"n\">x:id</span> <span class=\"n\">e:expr</span><span class=\"p\">}</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">body:expr</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>This can be used anywhere an expression is expected, and it does as one would expect:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">clj-let</span> <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"mi\">1</span>\n            <span class=\"n\">y</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n    <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"mi\">3</span></code></pre><p>However, a novice macro programmer might realize that <code>clj-let</code> really only modifies the syntax of <em>binding pairs</em> for a <code>let</code> form. Therefore, could one define a macro that only adjusts the binding pairs of some existing <code>let</code> form instead of expanding to an entire <code>let</code>? That is, could one write the above example like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span> <span class=\"p\">[{</span><span class=\"n\">~seq</span> <span class=\"n\">x:id</span> <span class=\"n\">e:expr</span><span class=\"p\">}</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n  <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span>\n        <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"mi\">1</span>\n         <span class=\"n\">y</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n    <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"mi\">3</span></code></pre><p>The answer is <em>no</em>: the binding pairs of a <code>let</code> form are not subject to macroexpansion, so the above attempt fails with a syntax error. In this blog post, we will examine the reasons behind this limitation, then explain how to overcome it using a solution that allows macroexpansion <em>anywhere</em> in a Racket program.\n</p><h2><a name=\"why-only-some-positions-are-subject-to-macroexpansion\"></a>Why only some positions are subject to macroexpansion</h2><p>To understand <em>why</em> the macroexpander refuses to touch certain positions in a program, we must first understand how the macro system operates. In Racket, a macro is defined as a compile-time function associated with a particular binding, and macros are given complete control over the syntax trees they are surrounded with. If we define a macro <em><code>mac</code></em>, then we write the expression <code>(<em>mac</em> <em>form</em>)</code>, <em><code>form</code></em> is provided as-is to <em><code>mac</code></em> as a syntax object. Its structure can be anything at all, since <em><code>mac</code></em> can be an arbitrary Racket function, and that function can use <em><code>form</code></em> however it pleases.\n</p><p>To give a concrete illustration, consider a macro that binds some identifiers to symbols in a local scope:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">let-symbols</span> <span class=\"p\">(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"ss\">x</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">let-symbols</span> <span class=\"p\">(</span><span class=\"n\">hello</span> <span class=\"n\">goodbye</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"n\">hello</span> <span class=\"n\">goodbye</span><span class=\"p\">))</span>\n<span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"ss\">hello</span> <span class=\"ss\">goodbye</span><span class=\"p\">)</span></code></pre><p>It isn’t the most exciting macro in the world, but it illustrates a key point: the first subform to <code>let-symbols</code> is a list of identifiers that are eventually put in <em>binding</em> position. This means that <code>hello</code> and <code>goodbye</code> are bindings, not uses, and such bindings shadow any existing bindings that might have been in scope:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">foo</span> <span class=\"mi\">42</span><span class=\"p\">])</span>\n    <span class=\"p\">(</span><span class=\"n\">let-symbols</span> <span class=\"p\">(</span><span class=\"n\">foo</span><span class=\"p\">)</span>\n      <span class=\"n\">foo</span><span class=\"p\">))</span>\n<span class=\"o\">&#39;</span><span class=\"ss\">foo</span></code></pre><p>This might not seem very interesting, but it’s critical to understand, since it means that the expander <em>can’t know</em> which sub-pieces of a use of <code>let-symbols</code> will eventually be expressions themselves until it expands the macro and discovers it produces a <code>let</code> form, so it can’t know where it’s safe to perform macroexpansion. To make this more explicit, imagine we define a macro under some name, then try and use that name with our <code>let-symbols</code> macro:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">hello</span> <span class=\"n\">x:id</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">x:id</span><span class=\"p\">))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">let-symbols</span> <span class=\"p\">(</span><span class=\"n\">hello</span> <span class=\"n\">goodbye</span><span class=\"p\">)</span>\n    <span class=\"n\">hello</span><span class=\"p\">)</span></code></pre><p>What should the above program do? If we treat the first use of <code>hello</code> in the <code>let-symbols</code> form as a macro application, then <code>(hello goodbye)</code> should be transformed into <code>(goodbye)</code>, and the use of <code>hello</code> in the body should be a syntax error. But if the first use of <code>hello</code> was instead intended to be a binder, then it should shadow the <code>hello</code> definition above, and the output of the program should be <code>'hello</code>.\n</p><p>To avoid the chaos that would ensue if defining a macro could completely break local reasoning about other macros, Racket chooses the second option, and the program produces <code>'hello</code>. The macroexpander has no way of knowing <em>how</em> each macro will inspect its constituent pieces, so it avoids touching anything until the macro expands. After it discovers the <code>let</code> form in the expansion of <code>let-symbols</code>, it can safely determine that the body expressions are, indeed, expressions, and it can recursively expand any macros they contain. To put things another way, a macro’s sub-forms are never expanded before the macro itself is expanded, only after.\n</p><h2><a name=\"forcing-sub-form-expansion\"></a>Forcing sub-form expansion</h2><p>The above section explains why the expander must operate as it does, but it’s a little bit unsatisfying. What if we write a macro where we <em>want</em> certain sub-forms to be expanded before they are passed to us? Fortunately, the Racket macro system provides an API to handle this use case, too.\n</p><p>It is true that the Racket macro system never <em>automatically</em> expands sub-forms before outer forms are expanded, but macro transformers can explicitly op-in to recursive expansion via the <a href=\"http://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._local-expand%29%29\"><code>local-expand</code></a> function. This function effectively yields control back to the expander to expand some arbitrary piece of syntax as an expression, and when it returns, the macro transformer can inspect the expanded expression however it wishes. In theory, this can be used to implement extensible macros that allow macroexpansion in locations other than expression position.\n</p><p>To give an example of such a macro, consider the Racket <code>match</code> form, which implements an expressive pattern-matcher as a macro. One of the most interesting qualities of Racket’s <code>match</code> macro is that its pattern language is user-extensible, essentially allowing pattern-level macros. For example, a user might find they frequently match against natural numbers, and they wish to be able to write <code>(nat n)</code> as a shorthand for <code>(? exact-nonnegative-integer? n)</code>. Fortunately, this is easy using <code>define-match-expander</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-match-expander</span> <span class=\"n\">nat</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">pat</span><span class=\"p\">)</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">?</span> <span class=\"nb\">exact-nonnegative-integer?</span> <span class=\"n\">pat</span><span class=\"p\">)]))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"mi\">-5</span> <span class=\"mi\">-2</span> <span class=\"mi\">4</span> <span class=\"mi\">-7</span><span class=\"p\">)</span>\n    <span class=\"p\">[(</span><span class=\"nb\">list</span> <span class=\"k\">_</span> <span class=\"k\">...</span> <span class=\"p\">(</span><span class=\"n\">nat</span> <span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"k\">_</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n     <span class=\"n\">n</span><span class=\"p\">])</span>\n<span class=\"mi\">4</span></code></pre><p>Clearly, <code>match</code> is somehow expanding the <code>nat</code> match expander as a part of its expansion. Is it using <code>local-expand</code>?\n</p><p>Well, no. While <a href=\"/blog/2018/04/15/reimplementing-hackett-s-type-language-expanding-to-custom-core-forms-in-racket/\">a previous blog post of mine</a> has illustrated that it is possible to do such a thing with <code>local-expand</code> via some clever trickery, <code>local-expand</code> is really designed to expand <em>expressions</em>. This is a problem, since <code>(nat n)</code> is not an expression, it’s a pattern: it will expand into <code>(? exact-nonnegative-integer? n)</code>, which will lead to a syntax error, since <code>?</code> is not bound in the world of expressions. Instead, for a long while, <code>match</code> and forms like it have emulated how the expander performs macroexpansion in ad-hoc ways. Fortunately, as of Racket v7.0, the new <a href=\"http://docs.racket-lang.org/syntax/transformer-helpers.html#%28def._%28%28lib._syntax%2Fapply-transformer..rkt%29._local-apply-transformer%29%29\"><code>local-apply-transformer</code></a> API provides a way to invoke recursive macroexpansion in a consistent way, and it doesn’t assume that what’s being expanded is an expression.\n</p><h3><a name=\"a-closer-look-at-local-apply-transformer\"></a>A closer look at <code>local-apply-transformer</code></h3><p>If <code>local-apply-transformer</code> is the answer, what does it actually do? Well, <code>local-apply-transformer</code> allows explicitly invoking a transformer function on some piece of syntax and retrieving the result. In other words, <code>local-apply-transformer</code> allows expanding an arbitrary macro, but since it doesn’t make any assumptions about what the output will be, it only expands it <em>once</em>: just a single step of macro transformation.\n</p><p>To illustrate, we can write a macro that uses <code>local-apply-transformer</code> to invoke a transformer function and preserve the result using <code>quote-syntax</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">syntax/apply-transformer</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-for-syntax</span> <span class=\"n\">flip</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"n\">a</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)]))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">mac</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">result</span> <span class=\"p\">(</span><span class=\"n\">local-apply-transformer</span> <span class=\"n\">flip</span> <span class=\"o\">#&#39;</span><span class=\"p\">(([</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"k\">let</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">quote-syntax</span> <span class=\"n\">result</span><span class=\"p\">))</span></code></pre><p>When we use <code>mac</code>, our <code>flip</code> function will be applied, as a macro, to the syntax object we provide:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">mac</span><span class=\"p\">)</span>\n<span class=\"n\">#&lt;syntax</span> <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">((</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">))</span> <span class=\"n\">x</span><span class=\"p\">)</span><span class=\"nb\">&gt;</span></code></pre><p>Alright, so this works, but it raises some questions. Why is <code>flip</code> defined as a function at phase 1 (using <code>define-for-syntax</code>) instead of as a macro (using <code>define-syntax</code>)? What’s the deal with the <code>'expression</code> argument to <code>local-apply-transformer</code> given that <code>local-apply-transformer</code> is supposedly decoupled from expression expansion? And finally, how is this any different from just calling our <code>flip</code> function on the syntax object directly by writing <code>(flip #'(([x 1]) let x))</code>?\n</p><p>Let’s start with the first of those questions: why is <code>flip</code> defined as a function rather than as a macro? Well, <code>local-apply-transformer</code> is a fairly low-level operation: remember, it doesn’t assume <em>anything</em> about the argument it’s given! Therefore, it doesn’t take an expression containing a macro and expand it based on its structure, it needs to be explicitly provided the macro transformer function to apply. In practice, this might not seem very useful, since presumably we want to write our macros as macros, not as phase 1 functions. Fortunately, it’s possible to look up the function associated with a macro binding using the <a href=\"http://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._syntax-local-value%29%29\"><code>syntax-local-value</code></a> function, so if we use that, we can define <code>flip</code> using <code>define-syntax</code> as usual:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">flip</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"n\">a</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)]))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">mac</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">result</span> <span class=\"p\">(</span><span class=\"n\">local-apply-transformer</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-value</span> <span class=\"o\">#&#39;</span><span class=\"n\">flip</span><span class=\"p\">)</span>\n                                         <span class=\"o\">#&#39;</span><span class=\"p\">(([</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"k\">let</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n                                         <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">quote-syntax</span> <span class=\"n\">result</span><span class=\"p\">))</span></code></pre><p>Now for the next question: what is the meaning of the <code>'expression</code> argument? This one is more of a historical artifact than anything else: when the expander applies a macro transformer, it does it in a “context”, which is accessible using the <a href=\"http://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._syntax-local-context%29%29\"><code>syntax-local-context</code></a> function. This context can be one of a predefined enumeration of cases, including <code>'expression</code>, <code>'top-level</code>, <code>'module</code>, <code>'module-begin</code>, or a list representing a definition context. Whether or not any of those actually apply to our use case, we still have to pick one, but aside from how they affect the value returned by <code>syntax-local-context</code> (which some macros inspect), the value we choose is largely irrelevant. Using <code>'expression</code> will do, even if it’s a bit of a lie.\n</p><p>Finally, how does any of this differ from just applying the function we get directly? Well, the critical answer is all about <em>hygiene</em>. Racket’s macro system is hygienic, which, among other things, ensures bindings defined with the same name in different places do not unintentionally conflict. Racket’s hygiene mechanism is implemented in the macroexpander, when macro transformers are applied. If we just applied the <code>flip</code> transformer procedure to a syntax object directly, we would circumvent this hygiene mechanism, potentially causing all sorts of problems. By using <code>local-apply-transformer</code>, we ensure hygiene is preserved.\n</p><p>There is one small problem left with our program, however. Can you spot it? The key is to consider what would happen if we used <code>flip</code> as an ordinary macro, without using <code>local-apply-transformer</code>:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">flip</span> <span class=\"p\">(([</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"k\">let</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n<span class=\"n\">let:</span> <span class=\"n\">bad</span> <span class=\"k\">syntax</span>\n  <span class=\"n\">in:</span> <span class=\"k\">let</span></code></pre><p>What happened? Well, remember that when a macro in Racket is used, it receives the whole use site as a syntax object: in this case, <code>#'(flip (([x 1]) let x))</code>. This means that <code>flip</code> ought to be written to parse its argument slightly differently:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">flip</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"n\">a</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)]))</span></code></pre><p>Indeed, now that we’ve properly restructured the macro, we can easily switch to using the convenient <code>define-simple-macro</code> shorthand:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">flip</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"n\">b</span> <span class=\"n\">a</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>This means we also need to update our definition of <code>mac</code> to provide the full syntax object the expander would:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">mac</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">result</span> <span class=\"p\">(</span><span class=\"n\">local-apply-transformer</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-value</span> <span class=\"o\">#&#39;</span><span class=\"n\">flip</span><span class=\"p\">)</span>\n                                         <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">flip</span> <span class=\"p\">(([</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"k\">let</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n                                         <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">quote-syntax</span> <span class=\"n\">result</span><span class=\"p\">))</span></code></pre><p>This might seem redundant, but remember, <code>local-apply-transformer</code> is very low-level! While the convention that <code>(<em>mac</em> . _)</code> is the syntax for a macro transformation might seem obvious, <code>local-apply-transformer</code> makes no assumptions. It just does what we tell it to do.\n</p><h3><a name=\"applying-local-apply-transformer\"></a>Applying <code>local-apply-transformer</code></h3><p>So what does <code>local-apply-transformer</code> have to do with the problem at the beginning of this blog post? Well, as it happens, we can use <code>local-apply-transformer</code> to implement a macro that allows expansion <em>anywhere</em> using some simple tricks. While it’s true that we cannot magically divine which locations ought to be expanded, what we <em>can</em> do is explicitly annotate which places to expand.\n</p><p>To do this, we will implement a macro, <code>expand-inside</code>, that looks for subforms annotated with a special <code>$expand</code> identifier and performs macro transformation on those locations before proceeding with ordinary macroexpansion. Using the <code>clj-binding-pairs</code> example from the beginning of this blog post, our solution to that problem will look like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span> <span class=\"p\">[{</span><span class=\"n\">~seq</span> <span class=\"n\">x:id</span> <span class=\"n\">e:expr</span><span class=\"p\">}</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n  <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">expand-inside</span>\n   <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">(</span><span class=\"n\">$expand</span>\n         <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span>\n          <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"mi\">1</span>\n           <span class=\"n\">y</span> <span class=\"mi\">2</span><span class=\"p\">]))</span>\n     <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)))</span>\n<span class=\"mi\">3</span></code></pre><p>Put another way, <code>expand-inside</code> will force eager expansion on any subform surrounded with an <code>$expand</code> annotation.\n</p><p>We’ll start by defining the <code>$expand</code> binding itself. This binding won’t mean anything at all outside of <code>expand-inside</code>, but we’d like it to be a unique binding so that users can rename it (using, <code>rename-in</code>, for example) if they wish. To do this, we’ll use the usual trick of defining it as a macro that always produces an error if it’s ever used:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"p\">(</span><span class=\"n\">$expand</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">raise-syntax-error</span> <span class=\"no\">#f</span> <span class=\"s2\">\"illegal outside an ‘expand-inside’ form\"</span> <span class=\"n\">stx</span><span class=\"p\">))</span></code></pre><p>Next, we’ll implement a syntax class that will form the bulk of our implementation of <code>expand-inside</code>. Since we need to find uses of <code>$expand</code> that might be deeply-nested inside the syntax object provided to <code>expand-inside</code>, we need to recursively look through the syntax object, find any instances of <code>$expand</code>, and put it all back together once we’re done. This can be done relatively cleanly using a recursive syntax class:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">do-expand-inside</span>\n    <span class=\"kd\">#:literals</span> <span class=\"p\">[</span><span class=\"n\">$expand</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"n\">$expand</span> <span class=\"p\">(</span><span class=\"n\">$expand</span> <span class=\"o\">.</span> <span class=\"k\">_</span><span class=\"p\">)}</span>\n             <span class=\"kd\">#:with</span> <span class=\"n\">:do-expand-inside</span> <span class=\"p\">(</span><span class=\"n\">do-$expand</span> <span class=\"n\">this-syntax</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">a:do-expand-inside</span> <span class=\"o\">.</span> <span class=\"n\">b:do-expand-inside</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span>\n             <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">reassembled</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">a.expansion</span><span class=\"p\">)</span>\n                                      <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">b.expansion</span><span class=\"p\">))])</span>\n               <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">syntax?</span> <span class=\"n\">this-syntax</span><span class=\"p\">)</span>\n                   <span class=\"p\">(</span><span class=\"nb\">datum-&gt;syntax</span> <span class=\"n\">this-syntax</span> <span class=\"n\">reassembled</span>\n                                  <span class=\"n\">this-syntax</span> <span class=\"n\">this-syntax</span><span class=\"p\">)</span>\n                   <span class=\"n\">reassembled</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"k\">_</span> <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]))</span></code></pre><p>There are some tricky details to get right in the reassembly of pairs, since syntax lists are actually composed of ordinary pairs rather than syntax pairs, but ultimately, the code for walking a syntax object is small. The key case of this syntax class is the call to <code>do-$expand</code> in the first clause, which we have not yet defined. This function will actually handle performing the expansion by invoking <code>local-apply-transformer</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">do-$expand</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"n\">stx</span>\n      <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">form</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"n\">trans</span> <span class=\"p\">(</span><span class=\"n\">trans</span> <span class=\"o\">.</span> <span class=\"k\">_</span><span class=\"p\">)}})</span>\n       <span class=\"kd\">#:declare</span> <span class=\"n\">trans</span> <span class=\"p\">(</span><span class=\"n\">static</span> <span class=\"p\">(</span><span class=\"nb\">disjoin</span> <span class=\"nb\">procedure?</span> <span class=\"nb\">set!-transformer?</span><span class=\"p\">)</span>\n                               <span class=\"s2\">\"syntax transformer\"</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"n\">local-apply-transformer</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">trans.value</span><span class=\"p\">)</span>\n                                <span class=\"o\">#&#39;</span><span class=\"n\">form</span>\n                                <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">)])))</span></code></pre><p>This uses the handy <code>static</code> syntax class that comes with <code>syntax/parse</code>, which implicitly handles the call to <code>syntax-local-value</code> and produces a nice error message if the value returned does not match a predicate. All we have to do is apply the transformer value bound to the <code>trans.value</code> attribute using <code>local-apply-transformer</code>, and now the <code>expand-macro</code> can be written in just a couple lines of code:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">expand-inside</span>\n  <span class=\"kd\">#:track-literals</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">form:do-expand-inside</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">form.expansion</span><span class=\"p\">])</span></code></pre><p>(Using the <code>#:track-literals</code> option, also new in Racket v7.0, ensures that Check Syntax will be able to recognize the uses of <code>$expand</code> that disappear from after <code>expand-inside</code> is expanded.)\n</p><p>Putting everything together, our example from above really works:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span> <span class=\"p\">[{</span><span class=\"n\">~seq</span> <span class=\"n\">x:id</span> <span class=\"n\">e:expr</span><span class=\"p\">}</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n  <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">expand-inside</span>\n   <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">(</span><span class=\"n\">$expand</span>\n         <span class=\"p\">(</span><span class=\"n\">clj-binding-pairs</span>\n          <span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"mi\">1</span>\n           <span class=\"n\">y</span> <span class=\"mi\">2</span><span class=\"p\">]))</span>\n     <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)))</span>\n<span class=\"mi\">3</span></code></pre><p>That’s it. All told, the entire implementation is only about 30 lines of code. For a full, compilable, working example, see <a href=\"https://gist.github.com/lexi-lambda/65d69043023b519694f50dfca2dc7d33\">this gist</a>.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Racket programmers are accustomed to the language’s incredible capacity for extension and customization. Writing useful macros that do complicated things is easy, and it’s simple to add new syntactic forms to meet domain-specific needs. However, it doesn’t take long before many budding macrologists bump into the realization that only certain positions in Racket code are subject to macroexpansion.\n\nTo illustrate, consider a macro that provides a Clojure-style let form:\n\n(require syntax/parse/define)\n\n(define-simple-macro (clj-let [{~seq x:id e:expr} ...] body:expr ...+)\n  (let ([x e] ...) body ...))\nThis can be used anywhere an expression is expected, and it does as one would expect:\n\n> (clj-let [x 1\n            y 2]\n    (+ x y))\n3\nHowever, a novice macro programmer might realize that clj-let really only modifies the syntax of binding pairs for a let form. Therefore, could one define a macro that only adjusts the binding pairs of some existing let form instead of expanding to an entire let? That is, could one write the above example like this:\n\n(define-simple-macro (clj-binding-pairs [{~seq x:id e:expr} ...])\n  ([x e] ...))\n\n> (let (clj-binding-pairs\n        [x 1\n         y 2])\n    (+ x y))\n3\nThe answer is no: the binding pairs of a let form are not subject to macroexpansion, so the above attempt fails with a syntax error. In this blog post, we will examine the reasons behind this limitation, then explain how to overcome it using a solution that allows macroexpansion anywhere in a Racket program.\n\nWhy only some positions are subject to macroexpansion\nTo understand why the macroexpander refuses to touch certain positions in a program, we must first understand how the macro system operates. In Racket, a macro is defined as a compile-time function associated with a particular binding, and macros are given complete control over the syntax trees they are surrounded with. If we define a macro mac, then we write the expression (mac form), form is provided as-is to mac as a syntax object. Its structure can be anything at all, since mac can be an arbitrary Racket function, and that function can use form however it pleases.\n\nTo give a concrete illustration, consider a macro that binds some identifiers to symbols in a local scope:\n\n(define-simple-macro (let-symbols (x:id ...) body ...+)\n  (let ([x 'x] ...) body ...))\n\n> (let-symbols (hello goodbye)\n    (list hello goodbye))\n'(hello goodbye)\nIt isn’t the most exciting macro in the world, but it illustrates a key point: the first subform to let-symbols is a list of identifiers that are eventually put in binding position. This means that hello and goodbye are bindings, not uses, and such bindings shadow any existing bindings that might have been in scope:\n\n> (let ([foo 42])\n    (let-symbols (foo)\n      foo))\n'foo\nThis might not seem very interesting, but it’s critical to understand, since it means that the expander can’t know which sub-pieces of a use of let-symbols will eventually be expressions themselves until it expands the macro and discovers it produces a let form, so it can’t know where it’s safe to perform macroexpansion. To make this more explicit, imagine we define a macro under some name, then try and use that name with our let-symbols macro:\n\n(define-simple-macro (hello x:id)\n  (x:id))\n\n> (let-symbols (hello goodbye)\n    hello)\nWhat should the above program do? If we treat the first use of hello in the let-symbols form as a macro application, then (hello goodbye) should be transformed into (goodbye), and the use of hello in the body should be a syntax error. But if the first use of hello was instead intended to be a binder, then it should shadow the hello definition above, and the output of the program should be 'hello.\n\nTo avoid the chaos that would ensue if defining a macro could completely break local reasoning about other macros, Racket chooses the second option, and the program produces 'hello. The macroexpander has no way of knowing how each macro will inspect its constituent pieces, so it avoids touching anything until the macro expands. After it discovers the let form in the expansion of let-symbols, it can safely determine that the body expressions are, indeed, expressions, and it can recursively expand any macros they contain. To put things another way, a macro’s sub-forms are never expanded before the macro itself is expanded, only after.\n\nForcing sub-form expansion\nThe above section explains why the expander must operate as it does, but it’s a little bit unsatisfying. What if we write a macro where we want certain sub-forms to be expanded before they are passed to us? Fortunately, the Racket macro system provides an API to handle this use case, too.\n\nIt is true that the Racket macro system never automatically expands sub-forms before outer forms are expanded, but macro transformers can explicitly op-in to recursive expansion via the local-expand function. This function effectively yields control back to the expander to expand some arbitrary piece of syntax as an expression, and when it returns, the macro transformer can inspect the expanded expression however it wishes. In theory, this can be used to implement extensible macros that allow macroexpansion in locations other than expression position.\n\nTo give an example of such a macro, consider the Racket match form, which implements an expressive pattern-matcher as a macro. One of the most interesting qualities of Racket’s match macro is that its pattern language is user-extensible, essentially allowing pattern-level macros. For example, a user might find they frequently match against natural numbers, and they wish to be able to write (nat n) as a shorthand for (? exact-nonnegative-integer? n). Fortunately, this is easy using define-match-expander:\n\n(define-match-expander nat\n  (syntax-parser\n    [(_ pat)\n     #'(? exact-nonnegative-integer? pat)]))\n\n> (match '(-5 -2 4 -7)\n    [(list _ ... (nat n) _ ...)\n     n])\n4\nClearly, match is somehow expanding the nat match expander as a part of its expansion. Is it using local-expand?\n\nWell, no. While a previous blog post of mine has illustrated that it is possible to do such a thing with local-expand via some clever trickery, local-expand is really designed to expand expressions. This is a problem, since (nat n) is not an expression, it’s a pattern: it will expand into (? exact-nonnegative-integer? n), which will lead to a syntax error, since ? is not bound in the world of expressions. Instead, for a long while, match and forms like it have emulated how the expander performs macroexpansion in ad-hoc ways. Fortunately, as of Racket v7.0, the new local-apply-transformer API provides a way to invoke recursive macroexpansion in a consistent way, and it doesn’t assume that what’s being expanded is an expression.\n\nA closer look at local-apply-transformer\nIf local-apply-transformer is the answer, what does it actually do? Well, local-apply-transformer allows explicitly invoking a transformer function on some piece of syntax and retrieving the result. In other words, local-apply-transformer allows expanding an arbitrary macro, but since it doesn’t make any assumptions about what the output will be, it only expands it once: just a single step of macro transformation.\n\nTo illustrate, we can write a macro that uses local-apply-transformer to invoke a transformer function and preserve the result using quote-syntax:\n\n(require (for-syntax syntax/apply-transformer))\n\n(define-for-syntax flip\n  (syntax-parser\n    [(a b more ...)\n     #'(b a more ...)]))\n\n(define-simple-macro (mac)\n  #:with result (local-apply-transformer flip #'(([x 1]) let x) 'expression)\n  (quote-syntax result))\nWhen we use mac, our flip function will be applied, as a macro, to the syntax object we provide:\n\n> (mac)\n#<syntax (let ((x 1)) x)>\nAlright, so this works, but it raises some questions. Why is flip defined as a function at phase 1 (using define-for-syntax) instead of as a macro (using define-syntax)? What’s the deal with the 'expression argument to local-apply-transformer given that local-apply-transformer is supposedly decoupled from expression expansion? And finally, how is this any different from just calling our flip function on the syntax object directly by writing (flip #'(([x 1]) let x))?\n\nLet’s start with the first of those questions: why is flip defined as a function rather than as a macro? Well, local-apply-transformer is a fairly low-level operation: remember, it doesn’t assume anything about the argument it’s given! Therefore, it doesn’t take an expression containing a macro and expand it based on its structure, it needs to be explicitly provided the macro transformer function to apply. In practice, this might not seem very useful, since presumably we want to write our macros as macros, not as phase 1 functions. Fortunately, it’s possible to look up the function associated with a macro binding using the syntax-local-value function, so if we use that, we can define flip using define-syntax as usual:\n\n(define-syntax flip\n  (syntax-parser\n    [(a b more ...)\n     #'(b a more ...)]))\n\n(define-simple-macro (mac)\n  #:with result (local-apply-transformer (syntax-local-value #'flip)\n                                         #'(([x 1]) let x)\n                                         'expression)\n  (quote-syntax result))\nNow for the next question: what is the meaning of the 'expression argument? This one is more of a historical artifact than anything else: when the expander applies a macro transformer, it does it in a “context”, which is accessible using the syntax-local-context function. This context can be one of a predefined enumeration of cases, including 'expression, 'top-level, 'module, 'module-begin, or a list representing a definition context. Whether or not any of those actually apply to our use case, we still have to pick one, but aside from how they affect the value returned by syntax-local-context (which some macros inspect), the value we choose is largely irrelevant. Using 'expression will do, even if it’s a bit of a lie.\n\nFinally, how does any of this differ from just applying the function we get directly? Well, the critical answer is all about hygiene. Racket’s macro system is hygienic, which, among other things, ensures bindings defined with the same name in different places do not unintentionally conflict. Racket’s hygiene mechanism is implemented in the macroexpander, when macro transformers are applied. If we just applied the flip transformer procedure to a syntax object directly, we would circumvent this hygiene mechanism, potentially causing all sorts of problems. By using local-apply-transformer, we ensure hygiene is preserved.\n\nThere is one small problem left with our program, however. Can you spot it? The key is to consider what would happen if we used flip as an ordinary macro, without using local-apply-transformer:\n\n> (flip (([x 1]) let x))\nlet: bad syntax\n  in: let\nWhat happened? Well, remember that when a macro in Racket is used, it receives the whole use site as a syntax object: in this case, #'(flip (([x 1]) let x)). This means that flip ought to be written to parse its argument slightly differently:\n\n(define-syntax flip\n  (syntax-parser\n    [(_ (a b more ...))\n     #'(b a more ...)]))\nIndeed, now that we’ve properly restructured the macro, we can easily switch to using the convenient define-simple-macro shorthand:\n\n(define-simple-macro (flip (a b more ...))\n  (b a more ...))\nThis means we also need to update our definition of mac to provide the full syntax object the expander would:\n\n(define-simple-macro (mac)\n  #:with result (local-apply-transformer (syntax-local-value #'flip)\n                                         #'(flip (([x 1]) let x))\n                                         'expression)\n  (quote-syntax result))\nThis might seem redundant, but remember, local-apply-transformer is very low-level! While the convention that (mac . _) is the syntax for a macro transformation might seem obvious, local-apply-transformer makes no assumptions. It just does what we tell it to do.\n\nApplying local-apply-transformer\nSo what does local-apply-transformer have to do with the problem at the beginning of this blog post? Well, as it happens, we can use local-apply-transformer to implement a macro that allows expansion anywhere using some simple tricks. While it’s true that we cannot magically divine which locations ought to be expanded, what we can do is explicitly annotate which places to expand.\n\nTo do this, we will implement a macro, expand-inside, that looks for subforms annotated with a special $expand identifier and performs macro transformation on those locations before proceeding with ordinary macroexpansion. Using the clj-binding-pairs example from the beginning of this blog post, our solution to that problem will look like this:\n\n(define-simple-macro (clj-binding-pairs [{~seq x:id e:expr} ...])\n  ([x e] ...))\n\n> (expand-inside\n   (let ($expand\n         (clj-binding-pairs\n          [x 1\n           y 2]))\n     (+ x y)))\n3\nPut another way, expand-inside will force eager expansion on any subform surrounded with an $expand annotation.\n\nWe’ll start by defining the $expand binding itself. This binding won’t mean anything at all outside of expand-inside, but we’d like it to be a unique binding so that users can rename it (using, rename-in, for example) if they wish. To do this, we’ll use the usual trick of defining it as a macro that always produces an error if it’s ever used:\n\n(define-syntax ($expand stx)\n  (raise-syntax-error #f \"illegal outside an ‘expand-inside’ form\" stx))\nNext, we’ll implement a syntax class that will form the bulk of our implementation of expand-inside. Since we need to find uses of $expand that might be deeply-nested inside the syntax object provided to expand-inside, we need to recursively look through the syntax object, find any instances of $expand, and put it all back together once we’re done. This can be done relatively cleanly using a recursive syntax class:\n\n(begin-for-syntax\n  (define-syntax-class do-expand-inside\n    #:literals [$expand]\n    #:attributes [expansion]\n    [pattern {~or $expand ($expand . _)}\n             #:with :do-expand-inside (do-$expand this-syntax)]\n    [pattern (a:do-expand-inside . b:do-expand-inside)\n             #:attr expansion\n             (let ([reassembled (cons (attribute a.expansion)\n                                      (attribute b.expansion))])\n               (if (syntax? this-syntax)\n                   (datum->syntax this-syntax reassembled\n                                  this-syntax this-syntax)\n                   reassembled))]\n    [pattern _ #:attr expansion this-syntax]))\nThere are some tricky details to get right in the reassembly of pairs, since syntax lists are actually composed of ordinary pairs rather than syntax pairs, but ultimately, the code for walking a syntax object is small. The key case of this syntax class is the call to do-$expand in the first clause, which we have not yet defined. This function will actually handle performing the expansion by invoking local-apply-transformer:\n\n(begin-for-syntax\n  (define (do-$expand stx)\n    (syntax-parse stx\n      [(_ {~and form {~or trans (trans . _)}})\n       #:declare trans (static (disjoin procedure? set!-transformer?)\n                               \"syntax transformer\")\n       (local-apply-transformer (attribute trans.value)\n                                #'form\n                                'expression)])))\nThis uses the handy static syntax class that comes with syntax/parse, which implicitly handles the call to syntax-local-value and produces a nice error message if the value returned does not match a predicate. All we have to do is apply the transformer value bound to the trans.value attribute using local-apply-transformer, and now the expand-macro can be written in just a couple lines of code:\n\n(define-syntax-parser expand-inside\n  #:track-literals\n  [(_ form:do-expand-inside) #'form.expansion])\n(Using the #:track-literals option, also new in Racket v7.0, ensures that Check Syntax will be able to recognize the uses of $expand that disappear from after expand-inside is expanded.)\n\nPutting everything together, our example from above really works:\n\n(define-simple-macro (clj-binding-pairs [{~seq x:id e:expr} ...])\n  ([x e] ...))\n\n> (expand-inside\n   (let ($expand\n         (clj-binding-pairs\n          [x 1\n           y 2]))\n     (+ x y)))\n3\nThat’s it. All told, the entire implementation is only about 30 lines of code. For a full, compilable, working example, see this gist.","isoDate":"2018-10-06T00:00:00.000Z","timestamp":"10/5/2018"},{"title":"Custom core forms in Racket, part II: generalizing to arbitrary expressions and internal definitions","pubDate":"2018-09-13T00:00:00.000Z","author":"Alexis King","content":"<article><p>In my <a href=\"/blog/2018/04/15/reimplementing-hackett-s-type-language-expanding-to-custom-core-forms-in-racket/\">previous blog post</a>, I covered the process involved in creating a small language with a custom set of core forms. Specifically, it discussed what was necessary to create Hackett’s type language, which involved expanding to custom expressions. While somewhat involved, Hackett’s type language was actually a relatively simple example to use, since it only made use of a subset of the linguistic features Racket supports. In this blog post, I’ll demonstrate how that same technique can be generalized to support runtime bindings and internal definitions, two key concepts useful if intending to develop a more featureful language than Hackett’s intentionally-restrictive type system.\n</p><h2><a name=\"what-are-internal-definitions\"></a>What are internal definitions?</h2><p>This blog post is going to be largely focused on how to properly implement a form that handles the expansion of <em>internal definitions</em> in Racket. This is a tricky topic to get right, but before we can discuss internal definitions, we have to establish what definitions themselves are and how they relate to other binding forms.\n</p><p>In a traditional Lisp, there are two kinds of bindings: top-level bindings and local bindings. In Scheme and its descendants, this distinction is characterized by two different binding forms, <code>define</code> and <code>let</code>. To a first approximation, <code>define</code> is used for defining top-level, global bindings, and it resembles variable definitions in many mainstream languages in the sense that definitions using <code>define</code> are not really expressions. They don’t produce a value, they define a new binding. Definitions written with <code>define</code> look like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">y</span> <span class=\"s2\">\"hello\"</span><span class=\"p\">)</span></code></pre><p>Each definition is made up of two parts: the <em>binding identifier</em>, in this case <code>x</code> and <code>y</code>, and the <em>right hand side</em>, or RHS for short. Each RHS is a single expression that will be evaluated and used as the value for the introduced binding.\n</p><p>In Scheme and Racket, <code>define</code> also supports a shorthand form for defining functions in a natural syntax without the explicit need to write <code>lambda</code>, which looks like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">double</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">))</span></code></pre><p>However, this is just syntactic sugar. The above form is really just a macro for the following equivalent, expanded version:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">double</span>\n  <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">)))</span></code></pre><p>Since we only care about fully-expanded programs, we’ll focus exclusively on the expanded version of <code>define</code> in this blog post, since if we handle that, we’ll also handle the function shorthand’s expansion.\n</p><p>In contrast to <code>define</code>, there is also <code>let</code>, which has a rather different shape. A <code>let</code> form <em>is</em> an expression, and it creates local bindings in a delimited scope:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n      <span class=\"p\">[</span><span class=\"n\">y</span> <span class=\"mi\">3</span><span class=\"p\">])</span>\n  <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">))</span></code></pre><p>The binding clauses of a <code>let</code> expression are known as the <em>binding pairs</em>, and the sequence of expressions afterwards are known as the <em>body</em> of the <code>let</code>. Each binding pair consists of a binding identifier and a RHS, just like a top-level definition created with <code>define</code>, but while <code>define</code> is a standalone form, the binding pairs cannot meaningfully exist outside of a <code>let</code>—they are recognized as part of the grammar of the <code>let</code> form itself.\n</p><p>Like other Lisps, Racket distinguishes between top-level—or, more precisely, <em>module-level</em>—bindings and local bindings. A module-level binding can be exported using <code>provide</code>, which will allow other modules to access the binding by importing the module with <code>require</code>. Such definitions are treated specially by the macroexpander, compiler, and runtime system alike. There is a pervasive, meaningful difference between module-level definitions and local definitions besides simply scope.\n</p><p>I am making an effort to make this as clear as possible before discussing internal definitions because without it, the following point can be rather confusing: internal definitions are written using <code>define</code>, but they are local bindings, <em>not</em> module-level ones! In Racket, <code>define</code> is allowed to appear in the body of virtually all block forms like <code>let</code>, so the following is a legal program:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">y</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">))</span></code></pre><p>This program is equivalent to the one expressed using <code>let</code>. In fact, when the Racket macroexpander expands these local uses of <code>define</code>, it actually translates them into uses of <code>letrec</code>. After expanding the above expression, it would look closer to the following:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n  <span class=\"p\">(</span><span class=\"k\">letrec</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n           <span class=\"p\">[</span><span class=\"n\">y</span> <span class=\"mi\">3</span><span class=\"p\">])</span>\n    <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)))</span></code></pre><p>In this sense, <code>define</code> is a form with a double life in Racket. When used at the module level, it creates module-level definitions, which remain in a fully-expanded program and can be imported by other modules. When used inside local blocks, it creates internal definitions, which do not remain in fully expanded programs, since they are translated into recursive local binding forms.\n</p><p>In this blog post, we will ignore module-level definitions. Like in the previous blog post, we will focus exclusively on expanding expressions, not whole modules. However, we will extend our language to allow internal definitions inside local binding forms, and we will translate them into <code>letrec</code> forms in the same way as the Racket macroexpander.\n</p><h2><a name=\"revisiting-and-generalizing-the-expression-expander\"></a>Revisiting and generalizing the expression expander</h2><p>In the previous blog post, our expander expanded types, which were essentially expressions from the perspective of the Racket macroexpander. We wrote a syntax class that handled the parsing of a restricted type grammar that disallowed most Racket-level expression forms, like <code>begin</code>, <code>if</code>, <code>#%plain-lambda</code>, and <code>quote</code>. After all, Hackett is not dependently-typed, and it disallows explicit type abstraction to preserve type inference, so it would be a very bad thing if we allowed <code>if</code> or explicit lambda abstraction to appear in our types. For this blog post, however, we will restructure the type expander to handle the full grammar of expressions permitted by Racket.\n</p><p>While the syntax class approach used in the previous blog post was cute, this blog post will use ordinary functions defined at phase 1 instead of syntax classes. In practice, this provides superior error reporting, since it reports syntax errors in terms of the form that went wrong, not the form prior to expansion. Since we can still use <code>syntax-parse</code> to parse the arguments to these functions, we don’t lose any expressive power in the expression of our pattern language.\n</p><p>To start, we’ll extract the call to <code>local-expand</code> into its own function. This corresponds to the <code>type</code> syntax class from the previous blog post, but we’ll use phase 1 parameters to avoid threading so many explicit function arguments around:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">current-context</span> <span class=\"p\">(</span><span class=\"nb\">make-parameter</span> <span class=\"no\">#f</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">current-stop-list</span> <span class=\"p\">(</span><span class=\"nb\">make-parameter</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"o\">#&#39;</span><span class=\"k\">define-values</span> <span class=\"o\">#&#39;</span><span class=\"k\">define-syntaxes</span><span class=\"p\">)))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">current-intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">make-parameter</span> <span class=\"no\">#f</span><span class=\"p\">))</span>\n\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"n\">stx</span>\n                  <span class=\"p\">(</span><span class=\"n\">current-context</span><span class=\"p\">)</span>\n                  <span class=\"p\">(</span><span class=\"n\">current-stop-list</span><span class=\"p\">)</span>\n                  <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">))))</span></code></pre><p>Due to the way <code>local-expand</code> implicitly extends the stop list, as discussed in the previous blog post, we can initialize the stop list to a list containing just <code>define-values</code> and <code>define-syntaxes</code>, and the other forms we care about will be included automatically.\n</p><p>Next, we’ll use this function to implement a <code>expand-expression</code> function, which will emulate the way the expander expands a single expression, as the name implies. We’ll ignore any custom core forms for now, so we’ll just focus exclusively on the Racket core forms.\n</p><p>A few of Racket’s core forms are not actually subject to any expansion at all, and they expand to themselves. These forms are <code>quote</code>, <code>quote-syntax</code>, and <code>#%variable-reference</code>. Additionally, <code>#%top</code> is not something useful to handle ourselves, since it involves no recursive expansion, so we’ll treat it as if it expands to itself as well and allow the expander to raise any unbound identifier errors it produces. Here’s what the <code>expand-expression</code> function looks like when exclusively handling these things:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">])</span>\n                    <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"n\">stx</span><span class=\"p\">))</span>\n      <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span><span class=\"p\">]</span>\n      <span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"k\">quote</span> <span class=\"ss\">quote-syntax</span> <span class=\"k\">#%top</span> <span class=\"k\">#%variable-reference</span><span class=\"p\">}</span> <span class=\"n\">~!</span> <span class=\"o\">.</span> <span class=\"k\">_</span><span class=\"p\">)</span>\n       <span class=\"n\">this-syntax</span><span class=\"p\">]))</span></code></pre><p>Another set of Racket core forms are simple expressions which contain subforms, all of which are themselves expressions. These forms include things like <code>#%expression</code>, <code>begin</code>, and <code>if</code>, and they can be expanded recursively. We’ll add another clause to handle these, which can be written with a straightforward recursive call to <code>expand-expression</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">[({</span><span class=\"n\">~and</span> <span class=\"n\">head</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"k\">#%expression</span> <span class=\"k\">#%plain-app</span> <span class=\"k\">begin</span> <span class=\"k\">begin0</span> <span class=\"k\">if</span> <span class=\"k\">with-continuation-mark</span><span class=\"p\">}}</span> <span class=\"n\">~!</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>Another easy form to handle is <code>set!</code>, since it also requires simple recursive expansion, but it can’t be handled in the same way as the above forms since one of its subforms (the variable to mutate) should not be expanded. It needs another small clause:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:set!</span> <span class=\"n\">~!</span> <span class=\"n\">x:id</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">quasisyntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">x</span> <span class=\"o\">#,</span><span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"o\">#&#39;</span><span class=\"n\">rhs</span><span class=\"p\">)))]</span></code></pre><p>The other expressions are harder, since they’re all the binding forms. Fully-expanded Racket code has four local binding forms: <code>#%plain-lambda</code>, <code>case-lambda</code>, <code>let-values</code>, and <code>letrec-values</code>. Additionally, as discussed in the previous blog post, <code>local-expand</code> can also produce <code>letrec-syntaxes+values</code> forms produced by local syntax bindings. In the type expander, we completely disallowed runtime bindings from appearing in the resulting program, so we completely removed <code>letrec-syntaxes+values</code> in our expansion, but in the case of handling arbitrary Racket programs, we actually want to leave a <code>letrec-values</code> form behind to hold any runtime bindings (i.e. the <code>values</code> part of <code>letrec-syntaxes+values</code>).\n</p><p>We’ll start with <code>#%plain-lambda</code>, which is the simplest of all the five aforementioned binding forms. It binds a sequence of identifiers at runtime, and they are in scope within the body of the lambda expression. Just as we created and used an internal-definition context to hold the bindings of a <code>letrec-syntax+values</code> form in the previous blog post, we’ll do the same for Racket’s other binding forms as well:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:#%plain-lambda</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                      <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>However, the above handling of <code>#%plain-lambda</code> isn’t <em>quite</em> right, since the argument list can also include a “rest argument” binding in addition to a sequence of positional arguments. To accommodate this, we can introduce a simple syntax class that handles the different permutations:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">plain-formals</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"formals\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[[</span><span class=\"n\">id</span> <span class=\"mi\">1</span><span class=\"p\">]]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">id*:id</span> <span class=\"k\">...</span> <span class=\"o\">.</span> <span class=\"n\">id**:id</span><span class=\"p\">)</span> <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">id*</span> <span class=\"k\">...</span> <span class=\"n\">id**</span><span class=\"p\">]]))</span></code></pre><p>Now we can use this to adjust <code>#%plain-lambda</code> to handle rest arguments:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:#%plain-lambda</span> <span class=\"n\">~!</span> <span class=\"n\">formals:plain-formals</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">formals.id</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"kd\">#:with</span> <span class=\"n\">formals*</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"n\">formals</span><span class=\"p\">)</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                      <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">formals*</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>Next, we’ll handle <code>case-lambda</code>. As it turns out, expanding <code>case-lambda</code> is almost exactly the same as expanding <code>#%plain-lambda</code>, except that it has multiple clauses. Since each clause is expanded identically to the body of a <code>#%plain-lambda</code>, and it even has the same shape, the clauses can be extracted into a separate syntax class to share code between the two forms:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">lambda-clause</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">[</span><span class=\"n\">formals:plain-formals</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n             <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n                   <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">formals.id</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n             <span class=\"kd\">#:with</span> <span class=\"n\">formals*</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"n\">formals</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                                  <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">formals*</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]]))</span></code></pre><p>Now, both <code>#%plain-lambda</code> and <code>case-lambda</code> can be handled in a few lines of code each:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:#%plain-lambda</span> <span class=\"n\">~!</span> <span class=\"o\">.</span> <span class=\"n\">clause:lambda-clause</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"o\">.</span> <span class=\"n\">clause.expansion</span><span class=\"p\">))]</span>\n\n<span class=\"p\">[(</span><span class=\"n\">head:case-lambda</span> <span class=\"n\">~!</span> <span class=\"n\">clause:lambda-clause</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">clause.expansion</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>Finally, we need to tackle the three <code>let</code> forms. None of these involve any fundamentally new ideas, but they are a little bit more involved than the variants of lambda due to the need to handle the RHSs. Each variant is slightly different, but not dramatically so: the bindings aren’t in scope when expanding the RHSs of <code>let-values</code>, but they are for <code>letrec-values</code> and <code>letrec-syntaxes+values</code>, and <code>letrec-syntaxes+values</code> creates transformer bindings and must evaluate some RHSs in phase 1 while <code>let-values</code> and <code>letrec-values</code> exclusively bind runtime bindings. It would be possible to implement these three forms in separate clauses, but since we’d ideally like to duplicate as little code as possible, we can write a rather elaborate <code>syntax/parse</code> pattern to handle all three binding forms all at once.\n</p><p>We’ll start by handling <code>let-values</code> alone to keep things simple:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:let-values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"nb\">append*</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">rhs*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">))</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                      <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>This isn’t dramatically different from the implementation of <code>#%plain-lambda</code>. The only difference is that we have to recursively invoke <code>expand-expression</code> on the RHSs in addition to expanding the body expressions. To handle <code>letrec-values</code> in the same clause, however, we’ll have to get a little more creative.\n</p><p>So far, we haven’t actually tapped very far into <code>syntax/parse</code>’s pattern language over the course of these two blog posts. The full language available to patterns is rather extensive, and we can take advantage of that to write a modification of the above clause that handles both <code>let-values</code> and <code>letrec-values</code> at once:\n</p><pre><code class=\"pygments\"><span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:let-values</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#f</span><span class=\"p\">]}}</span>\n       <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:letrec-values</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]}}}</span>\n  <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"nb\">append*</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">rhs*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rec?</span><span class=\"p\">)</span>\n                       <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                         <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n                       <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                      <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n   <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))]</span></code></pre><p>The <code>~bind</code> pattern allows us to explicitly control how attributes are bound as part of the pattern-matching process, which allows us to track when we want to enable the recursive binding behavior of <code>letrec-values</code> in our handler code. Since the vast majority of the logic is otherwise identical, this is a significant improvement over duplicating the clause.\n</p><p>Adding support for <code>letrec-syntaxes+values</code> is done in the same general way, but the pattern is even more involved. In addition to tracking whether or not the bindings are recursive, we have to track if any syntax bindings were present at all, and if they were, bind them with <code>syntax-local-bind-syntaxes</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:let-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#f</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}</span>\n            <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:letrec-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}}</span>\n       <span class=\"p\">{</span><span class=\"n\">~seq</span> <span class=\"n\">head:letrec-syntaxes+values</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#t</span><span class=\"p\">]}</span>\n             <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">x/s:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs/s</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)}}</span>\n  <span class=\"p\">([(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"nb\">append*</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">xs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x/s</span><span class=\"p\">))]</span>\n               <span class=\"p\">[</span><span class=\"n\">rhs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs/s</span><span class=\"p\">))])</span>\n           <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">xs/s</span> <span class=\"n\">rhs/s</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)))]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">rhs*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rec?</span><span class=\"p\">)</span>\n                       <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                         <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n                       <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                      <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n     <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"p\">(</span><span class=\"k\">syntax/loc</span> <span class=\"n\">this-syntax</span>\n           <span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n         <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))</span>\n     <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n       <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">)))]</span></code></pre><p>This behemoth clause handles all three varieties of <code>let</code> forms that can appear in the result of <code>local-expand</code>. Notably, in the <code>letrec-syntaxes+values</code> case, we expand into <code>letrec-values</code>, since the transformer bindings are effectively erased, and we use <code>syntax-track-origin</code> to record that the result originally came from a use of <code>letrec-syntaxes+values</code>.\n</p><p>With these five clauses, we’ve handled all the special forms that can appear in expression position in Racket’s kernel language. To tie things off, we just need to handle the cases of a variable reference, which is represented by a bare identifier not bound to syntax, or literal data, like numbers or strings. We can add one more clause at the end to handle those:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"k\">_</span>\n <span class=\"n\">this-syntax</span><span class=\"p\">]</span></code></pre><p>Putting them all together, our <code>expand-expression</code> function looks as follows:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">])</span>\n                    <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"n\">stx</span><span class=\"p\">))</span>\n      <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span><span class=\"p\">]</span>\n      <span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"k\">quote</span> <span class=\"ss\">quote-syntax</span> <span class=\"k\">#%top</span> <span class=\"k\">#%variable-reference</span><span class=\"p\">}</span> <span class=\"n\">~!</span> <span class=\"o\">.</span> <span class=\"k\">_</span><span class=\"p\">)</span>\n       <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n\n      <span class=\"p\">[({</span><span class=\"n\">~and</span> <span class=\"n\">head</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"k\">#%expression</span> <span class=\"k\">#%plain-app</span> <span class=\"k\">begin</span> <span class=\"k\">begin0</span> <span class=\"k\">if</span> <span class=\"k\">with-continuation-mark</span><span class=\"p\">}}</span> <span class=\"n\">~!</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n       <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n         <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))]</span>\n\n      <span class=\"p\">[(</span><span class=\"n\">head:#%plain-lambda</span> <span class=\"n\">~!</span> <span class=\"o\">.</span> <span class=\"n\">clause:lambda-clause</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n         <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"o\">.</span> <span class=\"n\">clause.expansion</span><span class=\"p\">))]</span>\n\n      <span class=\"p\">[(</span><span class=\"n\">head:case-lambda</span> <span class=\"n\">~!</span> <span class=\"n\">clause:lambda-clause</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n         <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">clause.expansion</span> <span class=\"k\">...</span><span class=\"p\">))]</span>\n\n      <span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:let-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#f</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}</span>\n                  <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:letrec-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}}</span>\n             <span class=\"p\">{</span><span class=\"n\">~seq</span> <span class=\"n\">head:letrec-syntaxes+values</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#t</span><span class=\"p\">]}</span>\n                   <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">x/s:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs/s</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)}}</span>\n        <span class=\"p\">([(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n       <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n             <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"nb\">append*</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n             <span class=\"p\">(</span><span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n               <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">xs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x/s</span><span class=\"p\">))]</span>\n                     <span class=\"p\">[</span><span class=\"n\">rhs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs/s</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">xs/s</span> <span class=\"n\">rhs/s</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)))]</span>\n       <span class=\"kd\">#:with</span> <span class=\"p\">[[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n       <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">rhs*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rec?</span><span class=\"p\">)</span>\n                             <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                               <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n                             <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n       <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                            <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n           <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"p\">(</span><span class=\"k\">syntax/loc</span> <span class=\"n\">this-syntax</span>\n                 <span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))</span>\n           <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n             <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span> <span class=\"k\">...</span><span class=\"p\">)))]</span>\n\n      <span class=\"p\">[</span><span class=\"k\">_</span>\n       <span class=\"n\">this-syntax</span><span class=\"p\">])))</span></code></pre><p>If we try it out, we’ll see that it really does work! Even complicated local binding forms are handled properly by our expander:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"mi\">42</span><span class=\"p\">])</span>\n       <span class=\"p\">(</span><span class=\"k\">letrec-syntax</span> <span class=\"p\">([</span><span class=\"n\">y</span> <span class=\"p\">(</span><span class=\"nb\">make-rename-transformer</span> <span class=\"o\">#&#39;</span><span class=\"n\">z</span><span class=\"p\">)]</span>\n                       <span class=\"p\">[</span><span class=\"n\">z</span> <span class=\"p\">(</span><span class=\"nb\">make-rename-transformer</span> <span class=\"o\">#&#39;</span><span class=\"n\">x</span><span class=\"p\">)])</span>\n         <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">y</span> <span class=\"mi\">3</span><span class=\"p\">))))</span>\n<span class=\"n\">#&lt;syntax</span> <span class=\"p\">(</span><span class=\"k\">let-values</span> <span class=\"p\">(((</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"mi\">42</span><span class=\"p\">))</span>\n           <span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"p\">()</span>\n             <span class=\"p\">(</span><span class=\"k\">#%plain-app</span> <span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"mi\">3</span><span class=\"p\">)))</span><span class=\"nb\">&gt;</span></code></pre><p>We are now able to expand arbitrary Racket expressions in the same way that the expander does. While this might not seem immediately useful—after all, we haven’t actually gained anything here over just calling <code>local-expand</code> with an empty stop list—we can use this as the basis of an expander that can extensibly handle custom core forms, which I may cover in a future blog post.\n</p><h2><a name=\"adding-support-for-internal-definitions\"></a>Adding support for internal definitions</h2><p>In the previous section, we defined an expander that could expand arbitrary Racket expressions, but our expander is still imperfect: we still do not support internal definitions. For all forms that have bodies, including <code>#%plain-lambda</code>, <code>case-lambda</code>, <code>let-values</code>, <code>letrec-values</code>, and <code>letrec-syntaxes+values</code>, Racket permits the use of internal definitions.\n</p><p>In practice, internal-definition contexts allow for an increased degree of modularity compared to traditional local binding forms, since they provide an <em>extensible</em> binding language. Users may mix many different binding forms within a single definition context, such as <code>define</code>, <code>define-syntax</code>, <code>match-define</code>, and even <code>struct</code>. However, this means the rewriting process described earlier in this blog post is not as simple as detecting the definitions and lifting them into a local binding form, since it’s not immediately apparent which forms are binding forms and which are expressions!\n</p><p>For this reason, expanding internal-definition contexts happens to be a nontrivial problem in itself. It involves a little more care than expanding expressions does, since it requires using partial expansion to discover which forms are definitions and which forms are expressions. We must take care to never expand too much, but also to expand enough that we reveal all uses of <code>define-values</code> and <code>define-syntaxes</code> (which all definition forms eventually expand into). We also must handle the splicing behavior of <code>begin</code>, which is necessary to allow single forms to expand into multiple definitions.\n</p><p>We’ll start by writing an <code>expand-body</code> function, which operates similarly to our previous <code>expand-expression</code> function. Unlike <code>expand-expression</code>, <code>expand-body</code> will accept a <em>list</em> of syntax objects, which represents the sequence of forms that make up the body. Logically, each body will create a first-class definition context with <code>syntax-local-make-definition-context</code> to represent the sequence of definitions:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-body</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n    <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span><span class=\"p\">))]</span>\n                   <span class=\"p\">[</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n      <span class=\"p\">)))</span></code></pre><p>The bulk of our <code>expand-body</code> function will be a loop that partially expands body forms, adds definitions to the definition context as it discovers them, and returns the expressions and runtime definitions to be rewritten into binding pairs for a <code>letrec-values</code> form. Additionally, the loop will also track so-called <em>disappeared uses</em> and <em>disappeared bindings</em>, which are attached to the expansion using syntax properties to allow tools like DrRacket to learn about the binding structure of phase 1 definitions that are erased as part of macroexpansion.\n</p><p>The skeleton of this loop is relatively straightforward to write. We will iterate over the syntax objects that make up the body, expand them, and process the expansion using <code>syntax-parse</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-body</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n    <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span><span class=\"p\">))]</span>\n                   <span class=\"p\">[</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n      <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">[</span><span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">]</span>\n        <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">([</span><span class=\"n\">stxs</span> <span class=\"n\">stxs</span><span class=\"p\">]</span>\n                   <span class=\"p\">[</span><span class=\"n\">binding-clauses</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">exprs</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">disappeared-uses</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">disappeared-bindings</span> <span class=\"o\">&#39;</span><span class=\"p\">()])</span>\n          <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">empty?</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"p\">(</span><span class=\"nb\">reverse</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">reverse</span> <span class=\"n\">exprs</span><span class=\"p\">)</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"p\">(</span><span class=\"nb\">first</span> <span class=\"n\">stxs</span><span class=\"p\">))</span>\n                <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span><span class=\"p\">]</span>\n                <span class=\"p\">)))))))</span></code></pre><p>The hard part, of course, is actually handling the potential results of that expansion. We need to handle three forms specially: <code>begin</code>, <code>define-values</code>, and <code>define-syntaxes</code>. All other results of partial expansion will be treated as expressions. We’ll start by handling <code>begin</code>, since it’s the simplest case; we only need to prepend the subforms to the list of body forms to be processed, then continue looping:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:begin</span> <span class=\"n\">~!</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">append</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">)</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span>\n       <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>However, as is often the case, this isn’t quite perfect, since the information that these forms came from a surrounding <code>begin</code> is lost, which tools like DrRacket want to know. To solve this problem, the expander adjusts the <code>origin</code> property for all spliced forms, which we can mimic using <code>syntax-track-origin</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:begin</span> <span class=\"n\">~!</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">append</span> <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">form</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">form</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))</span>\n               <span class=\"n\">stxs</span><span class=\"p\">)</span>\n       <span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>This is sufficient for <code>begin</code>, so we can move onto the actual definitions themselves. This actually isn’t too hard, since we just need to add the bindings we discover to the first-class definition context and preserve <code>define-values</code> bindings as binding pairs:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:define-values</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"o\">#&#39;</span><span class=\"p\">[(</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span> <span class=\"n\">exprs</span>\n       <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>This solution is missing one thing, however, which is the use of <code>syntax-local-identifier-as-binding</code> to any use-site scopes that were added to the binding identifier while expanding the binding form in the definition context. Explaining precisely why this is necessary is outside the scope of this blog post, and is best understood by reading <a href=\"http://www.cs.utah.edu/plt/scope-sets/pattern-macros.html#%28part._use-site%29\">the section on use-site scopes</a> in the paper that describes the theory behind Racket’s current macro system, Bindings as Sets of Scopes. In any case, the impact on our implementation is small:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:define-values</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">syntax-local-identifier-as-binding</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"o\">#&#39;</span><span class=\"p\">[(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span> <span class=\"n\">exprs</span>\n       <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>Finally, as with <code>begin</code>, we want to track that the binding pairs we generate actually came from a use of <code>define-values</code> (which in turn likely came from a use of some other definition form). Therefore, we’ll add another use of <code>syntax-track-origin</code> to copy and extend the necessary properties:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:define-values</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">syntax-local-identifier-as-binding</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span>\n  <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"o\">#&#39;</span><span class=\"p\">[(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span>\n  <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>That’s it for <code>define-values</code>. All that’s left is to handle <code>define-syntaxes</code>, which is quite similar, but instead of storing the definition in a binding pair, its RHS is immediately evaluated and added to the definition context using <code>syntax-local-bind-syntaxes</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"n\">head:define-syntaxes</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">syntax-local-identifier-as-binding</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">rhs</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span>\n       <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span> <span class=\"n\">disappeared-uses</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">))]</span></code></pre><p>As the above snippet indicates, this is also where the disappeared uses and disappeared bindings come in. In previous cases, we’ve used <code>syntax-track-origin</code> to indicate that a piece of syntax was the result of expanding a different piece of syntax, but in this case, <code>define-syntaxes</code> doesn’t expand into anything at all; it’s simply removed from the expansion entirely. Therefore, we need to resort to tracking the information in syntax properties on the resulting <code>letrec-values</code> form, so we’ll save them for later.\n</p><p>Finally, to finish things up, we can add a catchall clause that handles all other forms, which are now guaranteed to be expressions:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"k\">_</span>\n <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"n\">this-syntax</span> <span class=\"n\">exprs</span><span class=\"p\">)</span>\n       <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span></code></pre><p>This completes our loop that processes definition forms, so all that’s left to do is handle the results. The only significant remaining work is to actually expand the RHSs of the binding pairs we collected and the body expressions, which can be done by calling our own <code>expand-expression</code> function directly:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expanded-binding-clauses</span>\n  <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">binding-clause</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)])</span>\n    <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"n\">binding-clause</span>\n      <span class=\"p\">[[(</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span>\n       <span class=\"p\">(</span><span class=\"n\">quasisyntax/loc/props</span> <span class=\"n\">this-syntax</span>\n         <span class=\"p\">[(</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"o\">#,</span><span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"o\">#&#39;</span><span class=\"n\">rhs</span><span class=\"p\">)])])))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expanded-exprs</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"n\">exprs</span><span class=\"p\">))</span></code></pre><p>Finally, we can assemble all the pieces together into a single local binding form with the appropriate syntax properties:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"o\">#,</span><span class=\"n\">expanded-binding-clauses</span> <span class=\"o\">#,@</span><span class=\"n\">expanded-exprs</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">&#39;</span><span class=\"ss\">disappeared-uses</span> <span class=\"n\">disappeared-uses</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">&#39;</span><span class=\"ss\">disappeared-bindings</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">))</span></code></pre><p>That’s it. We’ve now written an <code>expand-body</code> function that can process internal definition contexts in the same way that the macroexpander does. Overall, the whole function is just under 45 lines of code:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-body</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n    <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"p\">(</span><span class=\"nb\">gensym</span><span class=\"p\">))]</span>\n                   <span class=\"p\">[</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n      <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">[</span><span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">]</span>\n        <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"n\">loop</span> <span class=\"p\">([</span><span class=\"n\">stxs</span> <span class=\"n\">stxs</span><span class=\"p\">]</span>\n                   <span class=\"p\">[</span><span class=\"n\">binding-clauses</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">exprs</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">disappeared-uses</span> <span class=\"o\">&#39;</span><span class=\"p\">()]</span>\n                   <span class=\"p\">[</span><span class=\"n\">disappeared-bindings</span> <span class=\"o\">&#39;</span><span class=\"p\">()])</span>\n          <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">empty?</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"p\">(</span><span class=\"nb\">reverse</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">reverse</span> <span class=\"n\">exprs</span><span class=\"p\">)</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"p\">(</span><span class=\"nb\">first</span> <span class=\"n\">stxs</span><span class=\"p\">))</span>\n                <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span><span class=\"p\">]</span>\n                <span class=\"p\">[(</span><span class=\"n\">head:begin</span> <span class=\"n\">~!</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n                 <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">append</span> <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">form</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))])</span>\n                                 <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">form</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))</span>\n                               <span class=\"n\">stxs</span><span class=\"p\">)</span>\n                       <span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span>\n                <span class=\"p\">[(</span><span class=\"n\">head:define-values</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n                 <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">syntax-local-identifier-as-binding</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n                 <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n                 <span class=\"p\">(</span><span class=\"n\">loop</span>\n                  <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span>\n                  <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"o\">#&#39;</span><span class=\"p\">[(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)</span>\n                  <span class=\"n\">exprs</span> <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]</span>\n                <span class=\"p\">[(</span><span class=\"n\">head:define-syntaxes</span> <span class=\"n\">~!</span> <span class=\"p\">[</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">rhs</span><span class=\"p\">)</span>\n                 <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">syntax-local-identifier-as-binding</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n                 <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">rhs</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n                 <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span> <span class=\"n\">exprs</span>\n                       <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span> <span class=\"n\">disappeared-uses</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x*</span><span class=\"p\">)</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">))]</span>\n                <span class=\"p\">[</span><span class=\"k\">_</span>\n                 <span class=\"p\">(</span><span class=\"n\">loop</span> <span class=\"p\">(</span><span class=\"nb\">rest</span> <span class=\"n\">stxs</span><span class=\"p\">)</span> <span class=\"n\">binding-clauses</span> <span class=\"p\">(</span><span class=\"nb\">cons</span> <span class=\"n\">this-syntax</span> <span class=\"n\">exprs</span><span class=\"p\">)</span>\n                       <span class=\"n\">disappeared-uses</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)]))))</span>\n      <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expanded-binding-clauses</span>\n        <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">binding-clause</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"n\">binding-clauses</span><span class=\"p\">)])</span>\n          <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"n\">binding-clause</span>\n            <span class=\"p\">[[(</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span>\n             <span class=\"p\">(</span><span class=\"n\">quasisyntax/loc/props</span> <span class=\"n\">this-syntax</span>\n               <span class=\"p\">[(</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"o\">#,</span><span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"o\">#&#39;</span><span class=\"n\">rhs</span><span class=\"p\">)])])))</span>\n      <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expanded-exprs</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"n\">exprs</span><span class=\"p\">))</span>\n      <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"o\">#,</span><span class=\"n\">expanded-binding-clauses</span> <span class=\"o\">#,@</span><span class=\"n\">expanded-exprs</span><span class=\"p\">)</span>\n          <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">&#39;</span><span class=\"ss\">disappeared-uses</span> <span class=\"n\">disappeared-uses</span><span class=\"p\">)</span>\n          <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">&#39;</span><span class=\"ss\">disappeared-bindings</span> <span class=\"n\">disappeared-bindings</span><span class=\"p\">)))))</span></code></pre><p>The next step is to actually use this function. We need to replace certain recursive calls to <code>expand-expression</code> with calls to <code>expand-body</code>, but if we do this naïvely, we’ll have some problems. Currently, when we expand body forms, they’re always immediately inside another definition context (i.e. the bindings introduced by lambda formals or by <code>let</code> binding pairs), but they haven’t actually been expanded in that context yet. When we call <code>expand-body</code>, we create a nested context, which will inherit the bindings, but won’t automatically add the parent context’s scope. Therefore, we need to manually call <code>internal-definition-context-introduce</code> on the body syntax objects before calling <code>expand-body</code>. We can write a small helper function to make this easier:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-body/in-ctx</span> <span class=\"n\">stxs</span> <span class=\"n\">ctx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add-ctx-scope</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">ctx</span> <span class=\"n\">stx</span> <span class=\"o\">&#39;</span><span class=\"ss\">add</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">ctx</span><span class=\"p\">])</span>\n      <span class=\"p\">(</span><span class=\"n\">add-ctx-scope</span> <span class=\"p\">(</span><span class=\"n\">expand-body</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">add-ctx-scope</span> <span class=\"n\">stxs</span><span class=\"p\">))))))</span></code></pre><p>Now we just need to replace the relevant calls to <code>expand-expression</code> with calls to <code>expand-body/in-ctx</code>, starting with a minor adjustment to our <code>lambda-clause</code> syntax class from earlier:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">lambda-clause</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">[</span><span class=\"n\">formals:plain-formals</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n             <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n                   <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">formals.id</span><span class=\"p\">)</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)]</span>\n             <span class=\"kd\">#:with</span> <span class=\"n\">formals*</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"n\">formals</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:with</span> <span class=\"n\">body*</span> <span class=\"p\">(</span><span class=\"n\">expand-body/in-ctx</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">formals*</span> <span class=\"n\">body*</span><span class=\"p\">]]))</span></code></pre><p>The only other change must occur in the handling of the various <code>let</code> forms, which similarly replaces <code>expand-expression</code> with <code>expand-body/in-ctx</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">[({</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:let-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#f</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}</span>\n            <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">head:letrec-values</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#f</span><span class=\"p\">]}}}</span>\n       <span class=\"p\">{</span><span class=\"n\">~seq</span> <span class=\"n\">head:letrec-syntaxes+values</span> <span class=\"p\">{</span><span class=\"n\">~bind</span> <span class=\"p\">[</span><span class=\"n\">rec?</span> <span class=\"no\">#t</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"n\">stxs?</span> <span class=\"no\">#t</span><span class=\"p\">]}</span>\n             <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">x/s:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs/s</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)}}</span>\n  <span class=\"p\">([(</span><span class=\"n\">x:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"p\">(</span><span class=\"n\">current-intdef-ctx</span><span class=\"p\">)))</span>\n       <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"p\">(</span><span class=\"nb\">append*</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"no\">#f</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"k\">when</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">xs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">x/s</span><span class=\"p\">))]</span>\n               <span class=\"p\">[</span><span class=\"n\">rhs/s</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs/s</span><span class=\"p\">))])</span>\n           <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">xs/s</span> <span class=\"n\">rhs/s</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)))]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[[</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">internal-definition-context-introduce</span> <span class=\"n\">intdef-ctx</span> <span class=\"o\">#&#39;</span><span class=\"p\">[[</span><span class=\"n\">x</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">rhs*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rec?</span><span class=\"p\">)</span>\n                       <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-intdef-ctx</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">])</span>\n                         <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n                       <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"n\">expand-expression</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">rhs</span><span class=\"p\">)))</span>\n <span class=\"kd\">#:with</span> <span class=\"n\">body*</span> <span class=\"p\">(</span><span class=\"n\">expand-body/in-ctx</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">body</span><span class=\"p\">)</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">stxs?</span><span class=\"p\">)</span>\n     <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"p\">(</span><span class=\"k\">syntax/loc</span> <span class=\"n\">this-syntax</span>\n           <span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span><span class=\"p\">))</span>\n         <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))</span>\n     <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n       <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([(</span><span class=\"n\">x*</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">rhs*</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body*</span><span class=\"p\">)))]</span></code></pre><p>With these changes, we’ve now extended our expression expander with the ability to expand internal definitions. We can see this in action on a simple example:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n       <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">y</span> <span class=\"p\">(</span><span class=\"nb\">make-rename-transformer</span> <span class=\"o\">#&#39;</span><span class=\"n\">z</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">z</span> <span class=\"p\">(</span><span class=\"nb\">make-rename-transformer</span> <span class=\"o\">#&#39;</span><span class=\"n\">x</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">y</span> <span class=\"mi\">3</span><span class=\"p\">)))</span>\n<span class=\"n\">#&lt;syntax</span> <span class=\"p\">(</span><span class=\"k\">let-values</span> <span class=\"p\">()</span>\n           <span class=\"p\">(</span><span class=\"k\">letrec-values</span> <span class=\"p\">([(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"mi\">42</span><span class=\"p\">])</span>\n             <span class=\"p\">(</span><span class=\"k\">#%app</span> <span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"mi\">3</span><span class=\"p\">)))</span><span class=\"nb\">&gt;</span></code></pre><p>Just as we’d like, the transformer bindings were expanded and subsequently eliminated, and the runtime binding was collected into a <code>letrec-values</code> form. The outer <code>let-values</code> is left over from the outer <code>let</code>, which is needed only to create an internal-definition context to hold our internal definitions.\n</p><h2><a name=\"putting-the-expression-expander-to-work\"></a>Putting the expression expander to work</h2><p>So far, we’ve done a lot of work to emulate the behavior of Racket’s macroexpander, and as the above example demonstrates, we’ve been fairly successful in that goal. However, you might be wondering <em>why</em> we did any of this, as replicating the behavior of <code>local-expand</code> is not very useful on its own. As mentioned above, this can be used as the foundation of an expander for custom core forms that extends, rather than replaces, the built-in Racket core forms, It can also be used to “cheat” and expand through the behavior of the <code>local-expand</code> stop list, which implicitly adds the Racket core forms to any non-empty stop list. Hopefully, I’ll have a chance to cover some of these things more deeply in the future, but for now, I’ll just give a small taste of the latter.\n</p><p>By using the power of our <code>expand-expression</code> function, it’s actually possible to use this kind of expression expander to do genuinely nefarious things, such as hijack the behavior of arbitrary macros! For example, we could do something evil like make <code>for</code> loops run in reverse order by adding <code>for</code> to <code>current-stop-list</code>, then adding an additional special case to <code>expand-expression</code> for <code>for</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">current-stop-list</span> <span class=\"p\">(</span><span class=\"nb\">make-parameter</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"o\">#&#39;</span><span class=\"k\">define-values</span> <span class=\"o\">#&#39;</span><span class=\"k\">define-syntaxes</span> <span class=\"o\">#&#39;</span><span class=\"k\">for</span><span class=\"p\">)))</span>\n\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"p\">(</span><span class=\"k\">parameterize</span> <span class=\"p\">([</span><span class=\"n\">current-context</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span><span class=\"p\">])</span>\n                    <span class=\"p\">(</span><span class=\"n\">current-expand</span> <span class=\"n\">stx</span><span class=\"p\">))</span>\n      <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span><span class=\"p\">]</span>\n      <span class=\"kd\">#:literals</span> <span class=\"p\">[</span><span class=\"k\">for</span><span class=\"p\">]</span>\n      <span class=\"c1\">; ...</span>\n      <span class=\"p\">[(</span><span class=\"n\">head:for</span> <span class=\"p\">([</span><span class=\"n\">x:id</span> <span class=\"n\">seq:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">body</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n         <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"nb\">reverse</span> <span class=\"p\">(</span><span class=\"nb\">sequence-&gt;list</span> <span class=\"n\">seq</span><span class=\"p\">)))]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n           <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">))]</span>\n      <span class=\"c1\">; ...</span>\n    <span class=\"p\">)))</span></code></pre><p>Amazingly, due to the fact that we’ve taken complete control of the expansion process, this will rewrite uses of <code>for</code> <em>even if they are introduced by macroexpansion</em>. For example, we could write a small macro that expands into a use of <code>for</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">print-up-to</span> <span class=\"n\">n</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">i</span> <span class=\"p\">(</span><span class=\"nb\">in-range</span> <span class=\"n\">n</span><span class=\"p\">)])</span>\n    <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"n\">i</span><span class=\"p\">)))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">print-up-to</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"mi\">0</span>\n<span class=\"mi\">1</span>\n<span class=\"mi\">2</span>\n<span class=\"mi\">3</span>\n<span class=\"mi\">4</span></code></pre><p>If we write a wrapper macro that applies our evil version of <code>expand-expression</code> to its body, then wrap a use of our <code>print-up-to</code> macro with it, it will execute the loop in reverse order:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">hijack-for-loops</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">form:expr</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">expand-expression</span> <span class=\"o\">#&#39;</span><span class=\"n\">form</span><span class=\"p\">)])</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">hijack-for-loops</span>\n   <span class=\"p\">(</span><span class=\"n\">print-up-to</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n<span class=\"mi\">4</span>\n<span class=\"mi\">3</span>\n<span class=\"mi\">2</span>\n<span class=\"mi\">1</span>\n<span class=\"mi\">0</span></code></pre><p>On its own, this is not that impressive, since we could have just used <code>local-expand</code> on the body directly to achieve this. However, what’s remarkable about <code>hijack-for-loops</code> is that it will work even if the <code>for</code> loop is buried deep inside some arbitrary expression:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">foo</span>\n    <span class=\"p\">(</span><span class=\"n\">hijack-for-loops</span>\n     <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n       <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">n</span> <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"n\">print-up-to</span> <span class=\"n\">n</span><span class=\"p\">))))</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">foo</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"mi\">5</span>\n<span class=\"mi\">4</span>\n<span class=\"mi\">3</span>\n<span class=\"mi\">2</span>\n<span class=\"mi\">1</span>\n<span class=\"mi\">0</span></code></pre><p>Of course, this example is rather contrived—mucking with <code>for</code> loops like this isn’t useful at all, and nobody would really write <code>print-up-to</code> as a macro, anyway—but there is potential for using this technique to do more interesting things.\n</p><h2><a name=\"closing-thoughts\"></a>Closing thoughts</h2><p>The system outlined in this blog post is not something I would recommend using in any real macro. It is enormously complicated, requires knowledge well above that of your average working macrologist, and it involves doing rather horrible things to the macro system, things it was undoubtably never designed to do. Still, I believe this blog post is useful, for a few different reasons:\n</p><ol><li><p>The technology outlined in this post, while perhaps not directly applicable to existing real-world problems, provides a framework for implementing various new kinds of syntax transformations in Racket <em>without</em> extending the macro system. It demonstrates the expressive power of the macro system, and it hopefully lays the foundation for a better, more high-level interface for users who wish to define their own languages with custom core forms.\n</p></li><li><p>This system provides insight into the way the Racket macroexpander operates, <em>in terms of the userspace syntax API</em>. The canonical existing model of hygienic macroexpansion, in the aforementioned <a href=\"http://www.cs.utah.edu/plt/scope-sets/\">Bindings as Sets of Scopes</a> paper, does not explain the workings of internal definition contexts in detail, and it certainly doesn’t explain them in terms that a Racket programmer would already be familiar with. By reencoding those ideas within the macro system itself, an advanced macro writer may be able to more easily connect concepts in the macro system’s implementation to concepts they have already been exposed to.\n</p></li><li><p>The capability of the proof-of-concept outlined here demonstrates that the limitation imposed by the existing implementation of the stop list (namely, the way it is implicitly extended with additional identifiers) is essentially artificial, and it can be hacked around with sufficient (albeit significant) effort. This isn’t enormously important, but it is somewhat relevant to a recent debate in <a href=\"https://github.com/racket/racket/issues/2154\">a GitHub issue</a> about the handling of the <code>local-expand</code> stop list.\n</p></li><li><p>Finally, for myself as much as anyone else, this implementation records in a concise way (perhaps overly concise at times) the collection of very subtle details I’ve learned over the past six months about how information is preserved and propagated during the expansion process.\n</p></li></ol><p>This blog post is not for everybody. If you made it to the end, give yourself a pat on the back. If you made it to the end <em>and</em> understood everything you read: congratulations, you are a certified expert in Racket macro programming. If not, do not fear, and do not lose hope—I plan for something significantly more mellow next time.\n</p><p>As always, I’d like to give thanks to the people who contributed significantly, if indirectly, to the contents of this blog post, namely <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a>, <a href=\"http://mballantyne.net\">Michael Ballantyne</a>, and <a href=\"http://www.ccs.neu.edu/home/ryanc/\">Ryan Culpepper</a>. And finally, for those interested, all of the code in this blog post can be found in a runnable form <a href=\"https://gist.github.com/lexi-lambda/c4f4b91ac9c0a555447d72d02e18be7b\">in this GitHub gist</a>.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"In my previous blog post, I covered the process involved in creating a small language with a custom set of core forms. Specifically, it discussed what was necessary to create Hackett’s type language, which involved expanding to custom expressions. While somewhat involved, Hackett’s type language was actually a relatively simple example to use, since it only made use of a subset of the linguistic features Racket supports. In this blog post, I’ll demonstrate how that same technique can be generalized to support runtime bindings and internal definitions, two key concepts useful if intending to develop a more featureful language than Hackett’s intentionally-restrictive type system.\n\nWhat are internal definitions?\nThis blog post is going to be largely focused on how to properly implement a form that handles the expansion of internal definitions in Racket. This is a tricky topic to get right, but before we can discuss internal definitions, we have to establish what definitions themselves are and how they relate to other binding forms.\n\nIn a traditional Lisp, there are two kinds of bindings: top-level bindings and local bindings. In Scheme and its descendants, this distinction is characterized by two different binding forms, define and let. To a first approximation, define is used for defining top-level, global bindings, and it resembles variable definitions in many mainstream languages in the sense that definitions using define are not really expressions. They don’t produce a value, they define a new binding. Definitions written with define look like this:\n\n(define x 42)\n(define y \"hello\")\nEach definition is made up of two parts: the binding identifier, in this case x and y, and the right hand side, or RHS for short. Each RHS is a single expression that will be evaluated and used as the value for the introduced binding.\n\nIn Scheme and Racket, define also supports a shorthand form for defining functions in a natural syntax without the explicit need to write lambda, which looks like this:\n\n(define (double x)\n  (* x 2))\nHowever, this is just syntactic sugar. The above form is really just a macro for the following equivalent, expanded version:\n\n(define double\n  (lambda (x) (* x 2)))\nSince we only care about fully-expanded programs, we’ll focus exclusively on the expanded version of define in this blog post, since if we handle that, we’ll also handle the function shorthand’s expansion.\n\nIn contrast to define, there is also let, which has a rather different shape. A let form is an expression, and it creates local bindings in a delimited scope:\n\n(let ([x 2]\n      [y 3])\n  (+ x y))\nThe binding clauses of a let expression are known as the binding pairs, and the sequence of expressions afterwards are known as the body of the let. Each binding pair consists of a binding identifier and a RHS, just like a top-level definition created with define, but while define is a standalone form, the binding pairs cannot meaningfully exist outside of a let—they are recognized as part of the grammar of the let form itself.\n\nLike other Lisps, Racket distinguishes between top-level—or, more precisely, module-level—bindings and local bindings. A module-level binding can be exported using provide, which will allow other modules to access the binding by importing the module with require. Such definitions are treated specially by the macroexpander, compiler, and runtime system alike. There is a pervasive, meaningful difference between module-level definitions and local definitions besides simply scope.\n\nI am making an effort to make this as clear as possible before discussing internal definitions because without it, the following point can be rather confusing: internal definitions are written using define, but they are local bindings, not module-level ones! In Racket, define is allowed to appear in the body of virtually all block forms like let, so the following is a legal program:\n\n(let ()\n  (define x 2)\n  (define y 3)\n  (+ x y))\nThis program is equivalent to the one expressed using let. In fact, when the Racket macroexpander expands these local uses of define, it actually translates them into uses of letrec. After expanding the above expression, it would look closer to the following:\n\n(let ()\n  (letrec ([x 2]\n           [y 3])\n    (+ x y)))\nIn this sense, define is a form with a double life in Racket. When used at the module level, it creates module-level definitions, which remain in a fully-expanded program and can be imported by other modules. When used inside local blocks, it creates internal definitions, which do not remain in fully expanded programs, since they are translated into recursive local binding forms.\n\nIn this blog post, we will ignore module-level definitions. Like in the previous blog post, we will focus exclusively on expanding expressions, not whole modules. However, we will extend our language to allow internal definitions inside local binding forms, and we will translate them into letrec forms in the same way as the Racket macroexpander.\n\nRevisiting and generalizing the expression expander\nIn the previous blog post, our expander expanded types, which were essentially expressions from the perspective of the Racket macroexpander. We wrote a syntax class that handled the parsing of a restricted type grammar that disallowed most Racket-level expression forms, like begin, if, #%plain-lambda, and quote. After all, Hackett is not dependently-typed, and it disallows explicit type abstraction to preserve type inference, so it would be a very bad thing if we allowed if or explicit lambda abstraction to appear in our types. For this blog post, however, we will restructure the type expander to handle the full grammar of expressions permitted by Racket.\n\nWhile the syntax class approach used in the previous blog post was cute, this blog post will use ordinary functions defined at phase 1 instead of syntax classes. In practice, this provides superior error reporting, since it reports syntax errors in terms of the form that went wrong, not the form prior to expansion. Since we can still use syntax-parse to parse the arguments to these functions, we don’t lose any expressive power in the expression of our pattern language.\n\nTo start, we’ll extract the call to local-expand into its own function. This corresponds to the type syntax class from the previous blog post, but we’ll use phase 1 parameters to avoid threading so many explicit function arguments around:\n\n(begin-for-syntax\n  (define current-context (make-parameter #f))\n  (define current-stop-list (make-parameter (list #'define-values #'define-syntaxes)))\n  (define current-intdef-ctx (make-parameter #f))\n\n  (define (current-expand stx)\n    (local-expand stx\n                  (current-context)\n                  (current-stop-list)\n                  (current-intdef-ctx))))\nDue to the way local-expand implicitly extends the stop list, as discussed in the previous blog post, we can initialize the stop list to a list containing just define-values and define-syntaxes, and the other forms we care about will be included automatically.\n\nNext, we’ll use this function to implement a expand-expression function, which will emulate the way the expander expands a single expression, as the name implies. We’ll ignore any custom core forms for now, so we’ll just focus exclusively on the Racket core forms.\n\nA few of Racket’s core forms are not actually subject to any expansion at all, and they expand to themselves. These forms are quote, quote-syntax, and #%variable-reference. Additionally, #%top is not something useful to handle ourselves, since it involves no recursive expansion, so we’ll treat it as if it expands to itself as well and allow the expander to raise any unbound identifier errors it produces. Here’s what the expand-expression function looks like when exclusively handling these things:\n\n(define (expand-expression stx)\n    (syntax-parse (parameterize ([current-context 'expression])\n                    (current-expand stx))\n      #:literal-sets [kernel-literals]\n      [({~or quote quote-syntax #%top #%variable-reference} ~! . _)\n       this-syntax]))\nAnother set of Racket core forms are simple expressions which contain subforms, all of which are themselves expressions. These forms include things like #%expression, begin, and if, and they can be expanded recursively. We’ll add another clause to handle these, which can be written with a straightforward recursive call to expand-expression:\n\n[({~and head {~or #%expression #%plain-app begin begin0 if with-continuation-mark}} ~! form ...)\n #:with [form* ...] (map expand-expression (attribute form))\n (syntax/loc/props this-syntax\n   (head form* ...))]\nAnother easy form to handle is set!, since it also requires simple recursive expansion, but it can’t be handled in the same way as the above forms since one of its subforms (the variable to mutate) should not be expanded. It needs another small clause:\n\n[(head:set! ~! x:id rhs)\n (quasisyntax/loc/props this-syntax\n   (head x #,(expand-expression #'rhs)))]\nThe other expressions are harder, since they’re all the binding forms. Fully-expanded Racket code has four local binding forms: #%plain-lambda, case-lambda, let-values, and letrec-values. Additionally, as discussed in the previous blog post, local-expand can also produce letrec-syntaxes+values forms produced by local syntax bindings. In the type expander, we completely disallowed runtime bindings from appearing in the resulting program, so we completely removed letrec-syntaxes+values in our expansion, but in the case of handling arbitrary Racket programs, we actually want to leave a letrec-values form behind to hold any runtime bindings (i.e. the values part of letrec-syntaxes+values).\n\nWe’ll start with #%plain-lambda, which is the simplest of all the five aforementioned binding forms. It binds a sequence of identifiers at runtime, and they are in scope within the body of the lambda expression. Just as we created and used an internal-definition context to hold the bindings of a letrec-syntax+values form in the previous blog post, we’ll do the same for Racket’s other binding forms as well:\n\n[(head:#%plain-lambda ~! [x:id ...] body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (attribute x) #f intdef-ctx)]\n #:with [x* ...] (internal-definition-context-introduce intdef-ctx #'[x ...])\n #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                      (map expand-expression (attribute body)))\n (syntax/loc/props this-syntax\n   (head [x* ...] body* ...))]\nHowever, the above handling of #%plain-lambda isn’t quite right, since the argument list can also include a “rest argument” binding in addition to a sequence of positional arguments. To accommodate this, we can introduce a simple syntax class that handles the different permutations:\n\n(begin-for-syntax\n  (define-syntax-class plain-formals\n    #:description \"formals\"\n    #:attributes [[id 1]]\n    #:commit\n    [pattern (id:id ...)]\n    [pattern (id*:id ... . id**:id) #:with [id ...] #'[id* ... id**]]))\nNow we can use this to adjust #%plain-lambda to handle rest arguments:\n\n[(head:#%plain-lambda ~! formals:plain-formals body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (attribute formals.id) #f intdef-ctx)]\n #:with formals* (internal-definition-context-introduce intdef-ctx #'formals)\n #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                      (map expand-expression (attribute body)))\n (syntax/loc/props this-syntax\n   (head formals* body* ...))]\nNext, we’ll handle case-lambda. As it turns out, expanding case-lambda is almost exactly the same as expanding #%plain-lambda, except that it has multiple clauses. Since each clause is expanded identically to the body of a #%plain-lambda, and it even has the same shape, the clauses can be extracted into a separate syntax class to share code between the two forms:\n\n(begin-for-syntax\n  (define-syntax-class lambda-clause\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    [pattern [formals:plain-formals body ...]\n             #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n                   (syntax-local-bind-syntaxes (attribute formals.id) #f intdef-ctx)]\n             #:with formals* (internal-definition-context-introduce intdef-ctx #'formals)\n             #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                                  (map expand-expression (attribute body)))\n             #:attr expansion #'[formals* body* ...]]))\nNow, both #%plain-lambda and case-lambda can be handled in a few lines of code each:\n\n[(head:#%plain-lambda ~! . clause:lambda-clause)\n (syntax/loc/props this-syntax\n   (head . clause.expansion))]\n\n[(head:case-lambda ~! clause:lambda-clause ...)\n (syntax/loc/props this-syntax\n   (head clause.expansion ...))]\nFinally, we need to tackle the three let forms. None of these involve any fundamentally new ideas, but they are a little bit more involved than the variants of lambda due to the need to handle the RHSs. Each variant is slightly different, but not dramatically so: the bindings aren’t in scope when expanding the RHSs of let-values, but they are for letrec-values and letrec-syntaxes+values, and letrec-syntaxes+values creates transformer bindings and must evaluate some RHSs in phase 1 while let-values and letrec-values exclusively bind runtime bindings. It would be possible to implement these three forms in separate clauses, but since we’d ideally like to duplicate as little code as possible, we can write a rather elaborate syntax/parse pattern to handle all three binding forms all at once.\n\nWe’ll start by handling let-values alone to keep things simple:\n\n[(head:let-values ~! ([(x:id ...) rhs] ...) body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (append* (attribute x)) #f intdef-ctx)]\n #:with [[x* ...] ...] (internal-definition-context-introduce intdef-ctx #'[[x ...] ...])\n #:with [rhs* ...] (map expand-expression (attribute rhs))\n #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                      (map expand-expression (attribute body)))\n (syntax/loc/props this-syntax\n   (head ([(x* ...) rhs*] ...) body* ...))]\nThis isn’t dramatically different from the implementation of #%plain-lambda. The only difference is that we have to recursively invoke expand-expression on the RHSs in addition to expanding the body expressions. To handle letrec-values in the same clause, however, we’ll have to get a little more creative.\n\nSo far, we haven’t actually tapped very far into syntax/parse’s pattern language over the course of these two blog posts. The full language available to patterns is rather extensive, and we can take advantage of that to write a modification of the above clause that handles both let-values and letrec-values at once:\n\n[({~or {~and head:let-values {~bind [rec? #f]}}\n       {~and head:letrec-values {~bind [rec? #t]}}}\n  ~! ([(x:id ...) rhs] ...) body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (append* (attribute x)) #f intdef-ctx)]\n #:with [[x* ...] ...] (internal-definition-context-introduce intdef-ctx #'[[x ...] ...])\n #:with [rhs* ...] (if (attribute rec?)\n                       (parameterize ([current-intdef-ctx intdef-ctx])\n                         (map expand-expression (attribute rhs)))\n                       (map expand-expression (attribute rhs)))\n #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                      (map expand-expression (attribute body)))\n (syntax/loc/props this-syntax\n   (head ([(x* ...) rhs*] ...) body* ...))]\nThe ~bind pattern allows us to explicitly control how attributes are bound as part of the pattern-matching process, which allows us to track when we want to enable the recursive binding behavior of letrec-values in our handler code. Since the vast majority of the logic is otherwise identical, this is a significant improvement over duplicating the clause.\n\nAdding support for letrec-syntaxes+values is done in the same general way, but the pattern is even more involved. In addition to tracking whether or not the bindings are recursive, we have to track if any syntax bindings were present at all, and if they were, bind them with syntax-local-bind-syntaxes:\n\n[({~or {~or {~and head:let-values ~! {~bind [rec? #f] [stxs? #f]}}\n            {~and head:letrec-values ~! {~bind [rec? #t] [stxs? #f]}}}\n       {~seq head:letrec-syntaxes+values {~bind [rec? #t] [stxs? #t]}\n             ~! ([(x/s:id ...) rhs/s] ...)}}\n  ([(x:id ...) rhs] ...) body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (append* (attribute x)) #f intdef-ctx)\n       (when (attribute stxs?)\n         (for ([xs/s (in-list (attribute x/s))]\n               [rhs/s (in-list (attribute rhs/s))])\n           (syntax-local-bind-syntaxes xs/s rhs/s intdef-ctx)))]\n #:with [[x* ...] ...] (internal-definition-context-introduce intdef-ctx #'[[x ...] ...])\n #:with [rhs* ...] (if (attribute rec?)\n                       (parameterize ([current-intdef-ctx intdef-ctx])\n                         (map expand-expression (attribute rhs)))\n                       (map expand-expression (attribute rhs)))\n #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                      (map expand-expression (attribute body)))\n (if (attribute stxs?)\n     (~> (syntax/loc this-syntax\n           (letrec-values ([(x* ...) rhs*] ...) body* ...))\n         (syntax-track-origin this-syntax #'head))\n     (syntax/loc/props this-syntax\n       (head ([(x* ...) rhs*] ...) body* ...)))]\nThis behemoth clause handles all three varieties of let forms that can appear in the result of local-expand. Notably, in the letrec-syntaxes+values case, we expand into letrec-values, since the transformer bindings are effectively erased, and we use syntax-track-origin to record that the result originally came from a use of letrec-syntaxes+values.\n\nWith these five clauses, we’ve handled all the special forms that can appear in expression position in Racket’s kernel language. To tie things off, we just need to handle the cases of a variable reference, which is represented by a bare identifier not bound to syntax, or literal data, like numbers or strings. We can add one more clause at the end to handle those:\n\n[_\n this-syntax]\nPutting them all together, our expand-expression function looks as follows:\n\n(begin-for-syntax\n  (define (expand-expression stx)\n    (syntax-parse (parameterize ([current-context 'expression])\n                    (current-expand stx))\n      #:literal-sets [kernel-literals]\n      [({~or quote quote-syntax #%top #%variable-reference} ~! . _)\n       this-syntax]\n\n      [({~and head {~or #%expression #%plain-app begin begin0 if with-continuation-mark}} ~! form ...)\n       #:with [form* ...] (map expand-expression (attribute form))\n       (syntax/loc/props this-syntax\n         (head form* ...))]\n\n      [(head:#%plain-lambda ~! . clause:lambda-clause)\n       (syntax/loc/props this-syntax\n         (head . clause.expansion))]\n\n      [(head:case-lambda ~! clause:lambda-clause ...)\n       (syntax/loc/props this-syntax\n         (head clause.expansion ...))]\n\n      [({~or {~or {~and head:let-values ~! {~bind [rec? #f] [stxs? #f]}}\n                  {~and head:letrec-values ~! {~bind [rec? #t] [stxs? #f]}}}\n             {~seq head:letrec-syntaxes+values {~bind [rec? #t] [stxs? #t]}\n                   ~! ([(x/s:id ...) rhs/s] ...)}}\n        ([(x:id ...) rhs] ...) body ...)\n       #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n             (syntax-local-bind-syntaxes (append* (attribute x)) #f intdef-ctx)\n             (when (attribute stxs?)\n               (for ([xs/s (in-list (attribute x/s))]\n                     [rhs/s (in-list (attribute rhs/s))])\n                 (syntax-local-bind-syntaxes xs/s rhs/s intdef-ctx)))]\n       #:with [[x* ...] ...] (internal-definition-context-introduce intdef-ctx #'[[x ...] ...])\n       #:with [rhs* ...] (if (attribute rec?)\n                             (parameterize ([current-intdef-ctx intdef-ctx])\n                               (map expand-expression (attribute rhs)))\n                             (map expand-expression (attribute rhs)))\n       #:with [body* ...] (parameterize ([current-intdef-ctx intdef-ctx])\n                            (map expand-expression (attribute body)))\n       (if (attribute stxs?)\n           (~> (syntax/loc this-syntax\n                 (letrec-values ([(x* ...) rhs*] ...) body* ...))\n               (syntax-track-origin this-syntax #'head))\n           (syntax/loc/props this-syntax\n             (head ([(x* ...) rhs*] ...) body* ...)))]\n\n      [_\n       this-syntax])))\nIf we try it out, we’ll see that it really does work! Even complicated local binding forms are handled properly by our expander:\n\n> (expand-expression\n   #'(let ([x 42])\n       (letrec-syntax ([y (make-rename-transformer #'z)]\n                       [z (make-rename-transformer #'x)])\n         (+ y 3))))\n#<syntax (let-values (((x) '42))\n           (letrec-values ()\n             (#%plain-app + x '3)))>\nWe are now able to expand arbitrary Racket expressions in the same way that the expander does. While this might not seem immediately useful—after all, we haven’t actually gained anything here over just calling local-expand with an empty stop list—we can use this as the basis of an expander that can extensibly handle custom core forms, which I may cover in a future blog post.\n\nAdding support for internal definitions\nIn the previous section, we defined an expander that could expand arbitrary Racket expressions, but our expander is still imperfect: we still do not support internal definitions. For all forms that have bodies, including #%plain-lambda, case-lambda, let-values, letrec-values, and letrec-syntaxes+values, Racket permits the use of internal definitions.\n\nIn practice, internal-definition contexts allow for an increased degree of modularity compared to traditional local binding forms, since they provide an extensible binding language. Users may mix many different binding forms within a single definition context, such as define, define-syntax, match-define, and even struct. However, this means the rewriting process described earlier in this blog post is not as simple as detecting the definitions and lifting them into a local binding form, since it’s not immediately apparent which forms are binding forms and which are expressions!\n\nFor this reason, expanding internal-definition contexts happens to be a nontrivial problem in itself. It involves a little more care than expanding expressions does, since it requires using partial expansion to discover which forms are definitions and which forms are expressions. We must take care to never expand too much, but also to expand enough that we reveal all uses of define-values and define-syntaxes (which all definition forms eventually expand into). We also must handle the splicing behavior of begin, which is necessary to allow single forms to expand into multiple definitions.\n\nWe’ll start by writing an expand-body function, which operates similarly to our previous expand-expression function. Unlike expand-expression, expand-body will accept a list of syntax objects, which represents the sequence of forms that make up the body. Logically, each body will create a first-class definition context with syntax-local-make-definition-context to represent the sequence of definitions:\n\n(begin-for-syntax\n  (define (expand-body stxs)\n    (define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n    (parameterize ([current-context (list (gensym))]\n                   [current-intdef-ctx intdef-ctx])\n      )))\nThe bulk of our expand-body function will be a loop that partially expands body forms, adds definitions to the definition context as it discovers them, and returns the expressions and runtime definitions to be rewritten into binding pairs for a letrec-values form. Additionally, the loop will also track so-called disappeared uses and disappeared bindings, which are attached to the expansion using syntax properties to allow tools like DrRacket to learn about the binding structure of phase 1 definitions that are erased as part of macroexpansion.\n\nThe skeleton of this loop is relatively straightforward to write. We will iterate over the syntax objects that make up the body, expand them, and process the expansion using syntax-parse:\n\n(begin-for-syntax\n  (define (expand-body stxs)\n    (define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n    (parameterize ([current-context (list (gensym))]\n                   [current-intdef-ctx intdef-ctx])\n      (define-values [binding-clauses exprs disappeared-uses disappeared-bindings]\n        (let loop ([stxs stxs]\n                   [binding-clauses '()]\n                   [exprs '()]\n                   [disappeared-uses '()]\n                   [disappeared-bindings '()])\n          (if (empty? stxs)\n              (values (reverse binding-clauses) (reverse exprs) disappeared-uses disappeared-bindings)\n              (syntax-parse (current-expand (first stxs))\n                #:literal-sets [kernel-literals]\n                )))))))\nThe hard part, of course, is actually handling the potential results of that expansion. We need to handle three forms specially: begin, define-values, and define-syntaxes. All other results of partial expansion will be treated as expressions. We’ll start by handling begin, since it’s the simplest case; we only need to prepend the subforms to the list of body forms to be processed, then continue looping:\n\n[(head:begin ~! form ...)\n (loop (append (attribute form) stxs) binding-clauses exprs\n       disappeared-uses disappeared-bindings)]\nHowever, as is often the case, this isn’t quite perfect, since the information that these forms came from a surrounding begin is lost, which tools like DrRacket want to know. To solve this problem, the expander adjusts the origin property for all spliced forms, which we can mimic using syntax-track-origin:\n\n[(head:begin ~! form ...)\n (loop (append (for/list ([form (in-list (attribute form))])\n                 (syntax-track-origin form this-syntax #'head))\n               stxs)\n       binding-clauses exprs disappeared-uses disappeared-bindings)]\nThis is sufficient for begin, so we can move onto the actual definitions themselves. This actually isn’t too hard, since we just need to add the bindings we discover to the first-class definition context and preserve define-values bindings as binding pairs:\n\n[(head:define-values ~! [x:id ...] rhs)\n #:do [(syntax-local-bind-syntaxes (attribute x) #f intdef-ctx)]\n (loop (rest stxs) (cons #'[(x ...) rhs] binding-clauses) exprs\n       disappeared-uses disappeared-bindings)]\nThis solution is missing one thing, however, which is the use of syntax-local-identifier-as-binding to any use-site scopes that were added to the binding identifier while expanding the binding form in the definition context. Explaining precisely why this is necessary is outside the scope of this blog post, and is best understood by reading the section on use-site scopes in the paper that describes the theory behind Racket’s current macro system, Bindings as Sets of Scopes. In any case, the impact on our implementation is small:\n\n[(head:define-values ~! [x:id ...] rhs)\n #:with [x* ...] (map syntax-local-identifier-as-binding (attribute x))\n #:do [(syntax-local-bind-syntaxes (attribute x*) #f intdef-ctx)]\n (loop (rest stxs) (cons #'[(x* ...) rhs] binding-clauses) exprs\n       disappeared-uses disappeared-bindings)]\nFinally, as with begin, we want to track that the binding pairs we generate actually came from a use of define-values (which in turn likely came from a use of some other definition form). Therefore, we’ll add another use of syntax-track-origin to copy and extend the necessary properties:\n\n[(head:define-values ~! [x:id ...] rhs)\n #:with [x* ...] (map syntax-local-identifier-as-binding (attribute x))\n #:do [(syntax-local-bind-syntaxes (attribute x*) #f intdef-ctx)]\n (loop\n  (rest stxs)\n  (cons (syntax-track-origin #'[(x* ...) rhs] this-syntax #'head) binding-clauses)\n  exprs disappeared-uses disappeared-bindings)]\nThat’s it for define-values. All that’s left is to handle define-syntaxes, which is quite similar, but instead of storing the definition in a binding pair, its RHS is immediately evaluated and added to the definition context using syntax-local-bind-syntaxes:\n\n[(head:define-syntaxes ~! [x:id ...] rhs)\n #:with [x* ...] (map syntax-local-identifier-as-binding (attribute x))\n #:do [(syntax-local-bind-syntaxes (attribute x*) #'rhs intdef-ctx)]\n (loop (rest stxs) binding-clauses exprs\n       (cons #'head disappeared-uses) (cons (attribute x*) disappeared-bindings))]\nAs the above snippet indicates, this is also where the disappeared uses and disappeared bindings come in. In previous cases, we’ve used syntax-track-origin to indicate that a piece of syntax was the result of expanding a different piece of syntax, but in this case, define-syntaxes doesn’t expand into anything at all; it’s simply removed from the expansion entirely. Therefore, we need to resort to tracking the information in syntax properties on the resulting letrec-values form, so we’ll save them for later.\n\nFinally, to finish things up, we can add a catchall clause that handles all other forms, which are now guaranteed to be expressions:\n\n[_\n (loop (rest stxs) binding-clauses (cons this-syntax exprs)\n       disappeared-uses disappeared-bindings)]\nThis completes our loop that processes definition forms, so all that’s left to do is handle the results. The only significant remaining work is to actually expand the RHSs of the binding pairs we collected and the body expressions, which can be done by calling our own expand-expression function directly:\n\n(define expanded-binding-clauses\n  (for/list ([binding-clause (in-list binding-clauses)])\n    (syntax-parse binding-clause\n      [[(x ...) rhs]\n       (quasisyntax/loc/props this-syntax\n         [(x ...) #,(expand-expression #'rhs)])])))\n(define expanded-exprs (map expand-expression exprs))\nFinally, we can assemble all the pieces together into a single local binding form with the appropriate syntax properties:\n\n(~> #`(letrec-values #,expanded-binding-clauses #,@expanded-exprs)\n    (syntax-property 'disappeared-uses disappeared-uses)\n    (syntax-property 'disappeared-bindings disappeared-bindings))\nThat’s it. We’ve now written an expand-body function that can process internal definition contexts in the same way that the macroexpander does. Overall, the whole function is just under 45 lines of code:\n\n(begin-for-syntax\n  (define (expand-body stxs)\n    (define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n    (parameterize ([current-context (list (gensym))]\n                   [current-intdef-ctx intdef-ctx])\n      (define-values [binding-clauses exprs disappeared-uses disappeared-bindings]\n        (let loop ([stxs stxs]\n                   [binding-clauses '()]\n                   [exprs '()]\n                   [disappeared-uses '()]\n                   [disappeared-bindings '()])\n          (if (empty? stxs)\n              (values (reverse binding-clauses) (reverse exprs) disappeared-uses disappeared-bindings)\n              (syntax-parse (current-expand (first stxs))\n                #:literal-sets [kernel-literals]\n                [(head:begin ~! form ...)\n                 (loop (append (for/list ([form (in-list (attribute form))])\n                                 (syntax-track-origin form this-syntax #'head))\n                               stxs)\n                       binding-clauses exprs disappeared-uses disappeared-bindings)]\n                [(head:define-values ~! [x:id ...] rhs)\n                 #:with [x* ...] (map syntax-local-identifier-as-binding (attribute x))\n                 #:do [(syntax-local-bind-syntaxes (attribute x*) #f intdef-ctx)]\n                 (loop\n                  (rest stxs)\n                  (cons (syntax-track-origin #'[(x* ...) rhs] this-syntax #'head) binding-clauses)\n                  exprs disappeared-uses disappeared-bindings)]\n                [(head:define-syntaxes ~! [x:id ...] rhs)\n                 #:with [x* ...] (map syntax-local-identifier-as-binding (attribute x))\n                 #:do [(syntax-local-bind-syntaxes (attribute x*) #'rhs intdef-ctx)]\n                 (loop (rest stxs) binding-clauses exprs\n                       (cons #'head disappeared-uses) (cons (attribute x*) disappeared-bindings))]\n                [_\n                 (loop (rest stxs) binding-clauses (cons this-syntax exprs)\n                       disappeared-uses disappeared-bindings)]))))\n      (define expanded-binding-clauses\n        (for/list ([binding-clause (in-list binding-clauses)])\n          (syntax-parse binding-clause\n            [[(x ...) rhs]\n             (quasisyntax/loc/props this-syntax\n               [(x ...) #,(expand-expression #'rhs)])])))\n      (define expanded-exprs (map expand-expression exprs))\n      (~> #`(letrec-values #,expanded-binding-clauses #,@expanded-exprs)\n          (syntax-property 'disappeared-uses disappeared-uses)\n          (syntax-property 'disappeared-bindings disappeared-bindings)))))\nThe next step is to actually use this function. We need to replace certain recursive calls to expand-expression with calls to expand-body, but if we do this naïvely, we’ll have some problems. Currently, when we expand body forms, they’re always immediately inside another definition context (i.e. the bindings introduced by lambda formals or by let binding pairs), but they haven’t actually been expanded in that context yet. When we call expand-body, we create a nested context, which will inherit the bindings, but won’t automatically add the parent context’s scope. Therefore, we need to manually call internal-definition-context-introduce on the body syntax objects before calling expand-body. We can write a small helper function to make this easier:\n\n(begin-for-syntax\n  (define (expand-body/in-ctx stxs ctx)\n    (define (add-ctx-scope stx)\n      (internal-definition-context-introduce ctx stx 'add))\n    (parameterize ([current-intdef-ctx ctx])\n      (add-ctx-scope (expand-body (map add-ctx-scope stxs))))))\nNow we just need to replace the relevant calls to expand-expression with calls to expand-body/in-ctx, starting with a minor adjustment to our lambda-clause syntax class from earlier:\n\n(begin-for-syntax\n  (define-syntax-class lambda-clause\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    [pattern [formals:plain-formals body ...]\n             #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n                   (syntax-local-bind-syntaxes (attribute formals.id) #f intdef-ctx)]\n             #:with formals* (internal-definition-context-introduce intdef-ctx #'formals)\n             #:with body* (expand-body/in-ctx (attribute body) intdef-ctx)\n             #:attr expansion #'[formals* body*]]))\nThe only other change must occur in the handling of the various let forms, which similarly replaces expand-expression with expand-body/in-ctx:\n\n[({~or {~or {~and head:let-values ~! {~bind [rec? #f] [stxs? #f]}}\n            {~and head:letrec-values ~! {~bind [rec? #t] [stxs? #f]}}}\n       {~seq head:letrec-syntaxes+values {~bind [rec? #t] [stxs? #t]}\n             ~! ([(x/s:id ...) rhs/s] ...)}}\n  ([(x:id ...) rhs] ...) body ...)\n #:do [(define intdef-ctx (syntax-local-make-definition-context (current-intdef-ctx)))\n       (syntax-local-bind-syntaxes (append* (attribute x)) #f intdef-ctx)\n       (when (attribute stxs?)\n         (for ([xs/s (in-list (attribute x/s))]\n               [rhs/s (in-list (attribute rhs/s))])\n           (syntax-local-bind-syntaxes xs/s rhs/s intdef-ctx)))]\n #:with [[x* ...] ...] (internal-definition-context-introduce intdef-ctx #'[[x ...] ...])\n #:with [rhs* ...] (if (attribute rec?)\n                       (parameterize ([current-intdef-ctx intdef-ctx])\n                         (map expand-expression (attribute rhs)))\n                       (map expand-expression (attribute rhs)))\n #:with body* (expand-body/in-ctx (attribute body) intdef-ctx)\n (if (attribute stxs?)\n     (~> (syntax/loc this-syntax\n           (letrec-values ([(x* ...) rhs*] ...) body*))\n         (syntax-track-origin this-syntax #'head))\n     (syntax/loc/props this-syntax\n       (head ([(x* ...) rhs*] ...) body*)))]\nWith these changes, we’ve now extended our expression expander with the ability to expand internal definitions. We can see this in action on a simple example:\n\n> (expand-expression\n   #'(let ()\n       (define x 42)\n       (define-syntax y (make-rename-transformer #'z))\n       (define-syntax z (make-rename-transformer #'x))\n       (+ y 3)))\n#<syntax (let-values ()\n           (letrec-values ([(x) '42])\n             (#%app + x '3)))>\nJust as we’d like, the transformer bindings were expanded and subsequently eliminated, and the runtime binding was collected into a letrec-values form. The outer let-values is left over from the outer let, which is needed only to create an internal-definition context to hold our internal definitions.\n\nPutting the expression expander to work\nSo far, we’ve done a lot of work to emulate the behavior of Racket’s macroexpander, and as the above example demonstrates, we’ve been fairly successful in that goal. However, you might be wondering why we did any of this, as replicating the behavior of local-expand is not very useful on its own. As mentioned above, this can be used as the foundation of an expander for custom core forms that extends, rather than replaces, the built-in Racket core forms, It can also be used to “cheat” and expand through the behavior of the local-expand stop list, which implicitly adds the Racket core forms to any non-empty stop list. Hopefully, I’ll have a chance to cover some of these things more deeply in the future, but for now, I’ll just give a small taste of the latter.\n\nBy using the power of our expand-expression function, it’s actually possible to use this kind of expression expander to do genuinely nefarious things, such as hijack the behavior of arbitrary macros! For example, we could do something evil like make for loops run in reverse order by adding for to current-stop-list, then adding an additional special case to expand-expression for for:\n\n(begin-for-syntax\n  (define current-stop-list (make-parameter (list #'define-values #'define-syntaxes #'for)))\n\n  (define (expand-expression stx)\n    (syntax-parse (parameterize ([current-context 'expression])\n                    (current-expand stx))\n      #:literal-sets [kernel-literals]\n      #:literals [for]\n      ; ...\n      [(head:for ([x:id seq:expr] ...) body ...+)\n       (syntax/loc/props this-syntax\n         (head ([x (in-list (reverse (sequence->list seq)))] ...)\n           body ...))]\n      ; ...\n    )))\nAmazingly, due to the fact that we’ve taken complete control of the expansion process, this will rewrite uses of for even if they are introduced by macroexpansion. For example, we could write a small macro that expands into a use of for:\n\n(define-simple-macro (print-up-to n)\n  (for ([i (in-range n)])\n    (println i)))\n\n> (print-up-to 5)\n0\n1\n2\n3\n4\nIf we write a wrapper macro that applies our evil version of expand-expression to its body, then wrap a use of our print-up-to macro with it, it will execute the loop in reverse order:\n\n(define-syntax-parser hijack-for-loops\n  [(_ form:expr) (expand-expression #'form)])\n\n> (hijack-for-loops\n   (print-up-to 5))\n4\n3\n2\n1\n0\nOn its own, this is not that impressive, since we could have just used local-expand on the body directly to achieve this. However, what’s remarkable about hijack-for-loops is that it will work even if the for loop is buried deep inside some arbitrary expression:\n\n> (define foo\n    (hijack-for-loops\n     (lambda (x)\n       (define n (* x 2))\n       (print-up-to n))))\n> (foo 3)\n5\n4\n3\n2\n1\n0\nOf course, this example is rather contrived—mucking with for loops like this isn’t useful at all, and nobody would really write print-up-to as a macro, anyway—but there is potential for using this technique to do more interesting things.\n\nClosing thoughts\nThe system outlined in this blog post is not something I would recommend using in any real macro. It is enormously complicated, requires knowledge well above that of your average working macrologist, and it involves doing rather horrible things to the macro system, things it was undoubtably never designed to do. Still, I believe this blog post is useful, for a few different reasons:\n\n\nThe technology outlined in this post, while perhaps not directly applicable to existing real-world problems, provides a framework for implementing various new kinds of syntax transformations in Racket without extending the macro system. It demonstrates the expressive power of the macro system, and it hopefully lays the foundation for a better, more high-level interface for users who wish to define their own languages with custom core forms.\n\n\nThis system provides insight into the way the Racket macroexpander operates, in terms of the userspace syntax API. The canonical existing model of hygienic macroexpansion, in the aforementioned Bindings as Sets of Scopes paper, does not explain the workings of internal definition contexts in detail, and it certainly doesn’t explain them in terms that a Racket programmer would already be familiar with. By reencoding those ideas within the macro system itself, an advanced macro writer may be able to more easily connect concepts in the macro system’s implementation to concepts they have already been exposed to.\n\n\nThe capability of the proof-of-concept outlined here demonstrates that the limitation imposed by the existing implementation of the stop list (namely, the way it is implicitly extended with additional identifiers) is essentially artificial, and it can be hacked around with sufficient (albeit significant) effort. This isn’t enormously important, but it is somewhat relevant to a recent debate in a GitHub issue about the handling of the local-expand stop list.\n\n\nFinally, for myself as much as anyone else, this implementation records in a concise way (perhaps overly concise at times) the collection of very subtle details I’ve learned over the past six months about how information is preserved and propagated during the expansion process.\n\n\nThis blog post is not for everybody. If you made it to the end, give yourself a pat on the back. If you made it to the end and understood everything you read: congratulations, you are a certified expert in Racket macro programming. If not, do not fear, and do not lose hope—I plan for something significantly more mellow next time.\n\nAs always, I’d like to give thanks to the people who contributed significantly, if indirectly, to the contents of this blog post, namely Matthew Flatt, Michael Ballantyne, and Ryan Culpepper. And finally, for those interested, all of the code in this blog post can be found in a runnable form in this GitHub gist.","isoDate":"2018-09-13T00:00:00.000Z","timestamp":"9/12/2018"},{"title":"Reimplementing Hackett’s type language: expanding to custom core forms in Racket","pubDate":"2018-04-15T00:00:00.000Z","author":"Alexis King","content":"<article><p>In the past couple of weeks, I <a href=\"https://github.com/lexi-lambda/hackett/commit/ba64193da38f63dab2523f42c1b7614cdfa8c935\">completely rewrote the implementation of Hackett’s type language</a> to improve the integration between the type representation and Racket’s macro system. The new type language effectively implements a way to reuse as much of the Racket macroexpanding infrastructure as possible while expanding a completely custom language, which uses a custom set of core forms. The fundamental technique used to do so is not novel, and it seems to be periodically rediscovered every so often, but it has never been published or documented anywhere, and getting it right involves understanding a great number of subtleties about the Racket macro system. While I cannot entirely eliminate the need to understand those subtleties, in this blog post, I hope to make the secret sauce considerably less secret.\n</p><p>This blog post is both a case study on how I implemented the expander for Hackett’s new type language and a discussion of how such a technique can apply more generally. Like <a href=\"/blog/2017/10/27/a-space-of-their-own-adding-a-type-namespace-to-hackett/\">my previous blog post on Hackett</a>, which covered the implementation of its namespace system, the implementation section of this blog post is highly technical and probably requires significant experience with Racket’s macro system to completely comprehend. However, the surrounding material is written to be more accessible, so even if you are not a Racket programmer, you should hopefully be able to understand the big ideas behind this change.\n</p><h2><a name=\"what-are-core-forms\"></a>What are core forms?</h2><p>Before we can get started writing <em>custom core forms</em>, we need to understand the meaning of Racket’s plain old <em>core forms</em>. What is a core form? In order to answer that question, we need to think about how Racket’s expansion and compilation model works.\n</p><p>To start, let’s consider a simple Racket program. Racket programs are organized into modules, which are usually written with a <code>#lang</code> line at the top. In this case, we’ll use <code>#lang racket</code> to keep things simple:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add2</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">add2</span> <span class=\"mi\">3</span><span class=\"p\">)</span></code></pre><p>How does Racket see this program? Well, before it can do anything with it, it must parse the program text, which is known in Racket as <em>reading</em> the program. The <code>#lang</code> line controls how the program is read—some <code>#lang</code>s provide parsers that allow syntax that is very different from the parser used for <code>#lang racket</code>—but no matter which reader is used, the result is an s-expression (actually a syntax object, but essentially an s-expression) representing a module. In the case of the above program, the result looks like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">module</span> <span class=\"n\">m</span> <span class=\"n\">racket</span>\n  <span class=\"p\">(</span><span class=\"k\">#%module-begin</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">add2</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n\n    <span class=\"p\">(</span><span class=\"n\">add2</span> <span class=\"mi\">3</span><span class=\"p\">)))</span></code></pre><p>Note the introduction of <code>#%module-begin</code>. Despite the fancy name, this is really just an ordinary macro provided by the <code>racket</code> language. By convention, the reader and expander cooperate to ensure the body of every module is wrapped with <code>#%module-begin</code>; as we’ll see shortly, this allows languages to add functionality that affects the entire contents of the module.\n</p><p>One the program has been read, it is subsequently <em>expanded</em> by the macroexpander. As the name implies, this is the phase that expands all the macros in a module. What does the above module look like after expansion? Well, it doesn’t look unrecognizable, but it certainly does look different:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">module</span> <span class=\"n\">m</span> <span class=\"n\">racket</span>\n  <span class=\"p\">(</span><span class=\"k\">#%plain-module-begin</span>\n    <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">(</span><span class=\"n\">add2</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"k\">#%plain-app</span> <span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"mi\">2</span><span class=\"p\">)))</span>\n\n    <span class=\"p\">(</span><span class=\"k\">#%plain-app</span> <span class=\"nb\">call-with-values</span>\n                 <span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"p\">()</span> <span class=\"p\">(</span><span class=\"k\">#%plain-app</span> <span class=\"n\">add2</span> <span class=\"o\">&#39;</span><span class=\"mi\">3</span><span class=\"p\">))</span>\n                 <span class=\"n\">print-values</span><span class=\"p\">)))</span></code></pre><p>Let’s note the things that changed:\n</p><ol><li><p><code>#%module-begin</code> was replaced with <code>#%plain-module-begin</code>. <code>#%plain-module-begin</code> is a binding that wraps the body of every expanded module, and all definitions of <code>#%module-begin</code> in any language must eventually expand to <code>#%plain-module-begin</code>. However, <code>#lang racket</code>’s <code>#%module-begin</code> doesn’t <em>just</em> expand to <code>#%plain-module-begin</code>, it also wraps bare expressions at the top level of a module so that their results are printed. This is why running the above program prints <code>5</code> even though there is no code related to printing in the original program!\n</p></li><li><p>The lambda shorthand used with <code>define</code> was converted to an explicit use of <code>lambda</code>, and it was expanded to <code>define-values</code>. In Racket, <code>define</code> and <code>define-syntax</code> are really just macros for <code>define-values</code> and <code>define-syntaxes</code> that only bind a single identifier.\n</p></li><li><p>All function applications were tagged explicitly with <code>#%plain-app</code>. This syntactically distinguishes function applications from uses of forms like <code>define-values</code> or <code>lambda</code>. It also allows languages to customize function application by providing their own macros named <code>#%app</code> (just like languages can provide their own macros named <code>#%module-begin</code> that expand to <code>#%plain-module-begin</code>), but that is outside the scope of this blog post.\n</p></li><li><p>All literals have been wrapped with <code>quote</code>, so <code>2</code> became <code>'2</code> and <code>3</code> became <code>'3</code>.\n</p></li></ol><p>Importantly, the resulting program contains <strong>no macros</strong>. Such programs are called <em>fully expanded</em>, since all macros have been eliminated and no further expansion can take place.\n</p><p>So what’s left behind? Well, some of the things in the program are literal data, like the numbers <code>2</code> and <code>3</code>. There are also some variable references, <code>x</code> and <code>add2</code>. Most of the program, however, is built out of primitives like <code>module</code>, <code>#%plain-module-begin</code>, <code>#%plain-app</code>, <code>define-values</code>, and <code>lambda</code>. These primitives are <em>core forms</em>—they are not variables, since they do not represent bindings that contain values at runtime, but they are also not macros, since they cannot be expanded any further.\n</p><p>In this sense, a fully-expanded program is just like a program in most languages that do not have macros. Core forms in Racket correspond to the syntax of other languages. We can imagine a JavaScript program similar to the above fully-expanded Racket program:\n</p><pre><code class=\"pygments\"><span class=\"n\">var</span> <span class=\"n\">add2</span> <span class=\"o\">=</span>\n  <span class=\"n\">function</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"k\">return</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">;</span> <span class=\"p\">};</span>\n\n<span class=\"n\">console</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">add2</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">));</span></code></pre><p>Just as this JavaScript program is internally transformed into an AST containing a definition node, a function abstraction node, and some function application nodes, a fully-expanded Racket program represents an AST ready to be sent off to be <em>compiled</em>. The Racket compiler has built-in rules for how to compile core forms like <code>define-values</code>, <code>lambda</code>, and <code>#%plain-app</code>, and the result is optimized Racket bytecode.\n</p><p>In the remainder of this blog post, as most discussions of macros do, we’ll ignore the <em>read</em> and <em>compile</em> steps of the Racket program pipeline and focus exclusively on the <em>expand</em> step. It’s useful, however, to keep the other steps in mind, since we’re going to be discussing what it means to implement custom core forms, and core forms really only make sense in the context of the subsequent compilation step that consumes them.\n</p><h3><a name=\"racket-s-default-core-forms\"></a>Racket’s default core forms</h3><p>So, now that we know what core forms are in an abstract sense, what are they in practice? We’ve already encountered <code>module</code>, <code>#%plain-module-begin</code>, <code>#%plain-app</code>, <code>define-values</code>, <code>lambda</code>, and <code>quote</code>, but there are many more. The full list is available in the section of the Racket reference named <a href=\"http://docs.racket-lang.org/reference/syntax-model.html#%28part._fully-expanded%29\">Fully Expanded Programs</a>, and I will not list all of them here. In general, they are more or less what you’d expect. The list of Racket’s core forms also includes things like <code>define-syntaxes</code>, <code>if</code>, <code>let-values</code>, <code>letrec-values</code>, <code>begin</code>, <code>quote-syntax</code>, and <code>set!</code>. Fundamentally, these correspond to the basic operations the Racket compiler understands, and it allows the remainder of Racket’s compilation pipeline to ignore the complexities of macroexpansion.\n</p><p>These forms are fairly versatile, and it’s easy to build high-level abstractions on top of them. For example, <code>#lang racket</code> implements <code>cond</code> as a macro that eventually expands into <code>if</code>, and it implements <code>syntax</code> as a macro that eventually expands into function calls and <code>quote-syntax</code>. The real power comes in the way new macros can be built out of other macros, not just core forms, so Racket’s <code>match</code> can expand into uses of <code>let</code> and <code>cond</code>, and it doesn’t need to concern itself with using <code>let-values</code> and <code>if</code>. For this reason, Racket’s core forms are quite capable of representing any language imaginable, since fully-expanded programs are essentially instructions for the Racket virtual machine, and macros are mini-compilers that can be mixed and matched.\n</p><h3><a name=\"the-need-for-custom-core-forms\"></a>The need for custom core forms</h3><p>With that in mind, why might we wish to define <em>custom</em> core forms? In fact, what would such a thing even mean? By their very nature, <em>all</em> Racket programs eventually expand into Racket’s core forms; new core forms cannot be added because Racket’s underlying compiler infrastructure is not (currently) extensible. New forms can be added that are defined in terms of other forms, but adding new primitives doesn’t make any sense, since the compiler would not know what to do with them.\n</p><p>Despite this, there <em>are</em> at least two use-cases in which a programmer might wish to customize the set of core forms produced by the macroexpander. Each situation is slightly different, but they both revolve around the same idea.\n</p><h4><a name=\"supporting-multiple-backends\"></a>Supporting multiple backends</h4><p>The most commonly discussed use case for customizing the set of core forms is for languages that wish to use the Racket macroexpander, but target backends that are not the Racket compiler. For example, a user might implement a Racket <code>#lang</code> that describes electronic circuits, and they might even implement a way to execute such a program in Racket, but they might <em>also</em> wish to compile the result to a more traditional hardware description language. Like other languages in the Racket ecosystem, such a language would be made up of a tower of macros built on top of core forms; unlike other languages, the core forms might need to be more abstract than the ones provided by Racket to efficiently compile to other targets.\n</p><p>In the case of a hardware description language, the custom core forms might include things like <code>input</code> and <code>output</code> for declaring circuit inputs and outputs, and expressions might be built out of hardware operations rather than high-level things like function calls. The Racket macroexpander would expand the input program into the custom set of core forms, at which point an external compiler program could compile the resutling AST in a more traditional way. If the language author wished, they could <em>additionally</em> define implementations of these core forms as Racket macros that eventually expand into Racket, which would allow them to emulate their circuits in Racket at little cost, but this would be a wholly optional step.\n</p><p>Essentially, this use case stems from a desire to reuse Racket’s advanced language-development technology, such as the macroexpander, the module system, and editor tooling, without also committing to using Racket as a runtime, which is not always appropriate for all languages. This use case is not nearly as easy as it ought to be, but it is a common request, and it is possible that future improvements to the Racket toolchain will be designed specifically to address this problem.\n</p><h4><a name=\"compiling-an-extensible-embedded-language\"></a>Compiling an extensible embedded language</h4><p>A second use case for custom core forms is less frequently discussed, but I think it might actually be significantly more common in practice were it available in a form accessible to working macro programmers. In this scenario, users might wish to remain within Racket, but still want to define a custom language that other macros can consume.\n</p><p>This concept is a little more vague and fuzzily-defined than the case of developing a separate backend, so allow me to propose an example. Imagine a Racket programmer decides to build an embedded DSL for asynchronously producing and consuming events, similar to first-order functional reactive programming. In this case, the DSL is designed to be used in larger Racket programs, so it <em>will</em> eventually expand to Racket’s core forms. However, it’s possible that such a language might wish to enforce static invariants about the network graph, and in doing so, it might be able to produce significantly more optimal Racket code via a compile-time analysis.\n</p><p>Performing such a compile-time analysis is essentially writing a custom optimizer as part of a macro, which has been done numerous times already within the Racket ecosystem. One of the most prominent examples of such a thing is the <code>match</code> macro, which parses users’ patterns into compile-time data structures, performs a fairly traditional optimization pass designed to efficiently compile pattern matching, and it emits optimized Racket code as a result. This approach works well for fairly contained problems like pattern-matching, but it works less well for entirely new embedded languages that include everything from their own notion of evaluation to their own binding forms.\n</p><p>Existing DSLs of this type are rare, but they do exist. <code>syntax/parse</code> provides an expressive, specialized pattern-matching language designed specifically for matching syntax objects, and it uses a different model from <code>racket/match</code> to be more suitable for that task. It allows backtracking with cuts, an extensible pattern language, an abstraction language for defining reusable parsers that can accept inputs and produce outputs, and fine-grained control over both parsing and binding. While <code>match</code> is essentially just a traditional pattern-matcher, albeit an extensible one, <code>syntax-parse</code> is its own programming language, closer in some ways to Prolog than to Racket.\n</p><p>For this reason, <code>syntax/parse</code> has an extensive language to do everything from creating new bindings to controlling when and how parsing fails. This language is represented in two ways: an inline pattern language, and an alternate syntax known as <a href=\"http://docs.racket-lang.org/syntax/stxparse-specifying.html#%28part._.Pattern_.Directives%29\"><em>pattern directives</em></a>. Here is an example of pattern directives in action, from my own <code>threading</code> library:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">ex:expr</span> <span class=\"n\">cl:clause</span> <span class=\"n\">remaining:clause</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">syntax-&gt;list</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl.call</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"n\">post</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"nb\">split-at</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">cl.insertion-point</span><span class=\"p\">)</span> <span class=\"mi\">0</span><span class=\"p\">))))]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">pre</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">pre</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">post</span>\n <span class=\"kd\">#:with</span> <span class=\"n\">app/ctx</span> <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"k\">...</span> <span class=\"n\">ex</span> <span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"n\">app/ctx</span> <span class=\"n\">remaining</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">this-syntax</span><span class=\"p\">)]</span></code></pre><p>Each directive is represented by a keyword, in this case <code>#:do</code> and <code>#:with</code>. Each directive has a corresponding keyword in the pattern language, in this case <code>~do</code> and <code>~parse</code>. Therefore, the above pattern could equivalently be written this way:\n</p><pre><code class=\"pygments\"><span class=\"p\">[{</span><span class=\"n\">~and</span> <span class=\"p\">(</span><span class=\"k\">_</span> <span class=\"n\">ex:expr</span> <span class=\"n\">cl:clause</span> <span class=\"n\">remaining:clause</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n       <span class=\"p\">{</span><span class=\"n\">~do</span> <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">syntax-&gt;list</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl.call</span><span class=\"p\">))</span>\n            <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"n\">post</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"nb\">split-at</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">cl.insertion-point</span><span class=\"p\">)</span> <span class=\"mi\">0</span><span class=\"p\">))))}</span>\n       <span class=\"p\">{</span><span class=\"n\">~parse</span> <span class=\"p\">[</span><span class=\"n\">pre</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">pre</span><span class=\"p\">}</span>\n       <span class=\"p\">{</span><span class=\"n\">~parse</span> <span class=\"p\">[</span><span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">post</span><span class=\"p\">}</span>\n       <span class=\"p\">{</span><span class=\"n\">~parse</span> <span class=\"n\">app/ctx</span> <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"k\">...</span> <span class=\"n\">ex</span> <span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl</span><span class=\"p\">)}}</span>\n <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"n\">app/ctx</span> <span class=\"n\">remaining</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">this-syntax</span><span class=\"p\">)]</span></code></pre><p>The transformation can go in the other direction, too—each syntax class annotation on each pattern variable can be extracted into the directive language using <code>#:declare</code>, so this is also equivalent:\n</p><pre><code class=\"pygments\"><span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">ex</span> <span class=\"n\">cl</span> <span class=\"n\">remaining</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n <span class=\"kd\">#:declare</span> <span class=\"n\">ex</span> <span class=\"n\">expr</span>\n <span class=\"kd\">#:declare</span> <span class=\"n\">cl</span> <span class=\"n\">clause</span>\n <span class=\"kd\">#:declare</span> <span class=\"n\">remaining</span> <span class=\"n\">clause</span>\n <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">syntax-&gt;list</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl.call</span><span class=\"p\">))</span>\n       <span class=\"p\">(</span><span class=\"k\">define-values</span> <span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"n\">post</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"nb\">split-at</span> <span class=\"n\">call</span> <span class=\"p\">(</span><span class=\"nb\">add1</span> <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">cl.insertion-point</span><span class=\"p\">)</span> <span class=\"mi\">0</span><span class=\"p\">))))]</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">pre</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">pre</span>\n <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"n\">post</span>\n <span class=\"kd\">#:with</span> <span class=\"n\">app/ctx</span> <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">pre</span> <span class=\"k\">...</span> <span class=\"n\">ex</span> <span class=\"n\">post</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">cl</span><span class=\"p\">)</span>\n <span class=\"p\">(</span><span class=\"n\">adjust-outer-context</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"n\">app/ctx</span> <span class=\"n\">remaining</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">this-syntax</span><span class=\"p\">)]</span></code></pre><p>This is very much a programming language, but it has very different semantics from programming in Racket! Failure to match against a <code>#:with</code> or <code>~parse</code> pattern causes pattern-matching to backtrack, and though it’s possible to escape to Racket using <code>#:do</code> or <code>~do</code>, practical uses of <code>syntax/parse</code> really do involve quite a lot of programming in its pattern DSL.\n</p><p>But the Racket programmer might not find this DSL wholly satisfying. Why? Well, it isn’t extensible! The pattern directives—<code>#:declare</code>, <code>#:do</code>, and <code>#:with</code>, among others—are essentially the core forms of <code>syntax/parse</code>’s pattern-matching language, but new ones cannot be defined. The desire to make this language easy to analyze statically in order to emit optimal pattern-matching code meant its author opted to define the language in terms of a specific grammar rather than a tower of macros.\n</p><p>But what if <code>syntax/parse</code> could define its own core forms? What if, instead of <code>#:do</code>, <code>#:declare</code>, and <code>#:with</code> being implemented as keyword options specially recognized by the <code>syntax-parse</code> grammar, it defined <code>do</code>, <code>declare</code>, and <code>with</code> as core forms for a new, macro-enabled language? A user of the language could then define a completely ordinary Racket macro and use it with this new language as long as it eventually expanded into the <code>syntax/parse</code> core forms. The implementation of <code>syntax/parse</code> could then invoke the macroexpander to request each clause be expanded into its core forms, perform its static analysis on the result, and finally emit optimized Racket code.\n</p><p>Now, to be fair, <code>syntax/parse</code> is not actually entirely inextensible. While new directives cannot be defined, new patterns can be added through a pattern-expander API that was added to the library after its initial design. However, pattern expanders are still not ideal because they are not ordinary Racket macros—users must explicitly define each pattern expander differently from how they would a macro—and they cannot use existing Racket forms, even ones that would theoretically be compatible with an arbitrary set of core forms.\n</p><p>The technique described in this blog post avoids all those problems. In the following sections, I’ll show that it’s possible to define an embedded language with a custom set of core forms that works well with the rest of the Racket ecosystem and still permits arbitrary static analysis.\n</p><h2><a name=\"the-need-for-a-custom-type-language-in-hackett\"></a>The need for a custom type language in Hackett</h2><p>In the previous section, I described two use cases for custom core forms. Hackett, in fact, has uses for <em>both</em> of them:\n</p><ul><li><p>Hackett can definitely make use of custom core forms to compile to multiple backends. Eventually, it would be nice to compile Hackett to an intermediate language that can target both the Racket runtime and Haskell or GHC Core. This would allow Hackett to take advantage of GHC’s advanced optimizing compiler that already has decades of tuning for a pure, lazy, functional programming language, at the cost of not having access to the rest of Racket’s ecosystem of libraries at runtime.\n</p></li><li><p>Hackett can <em>also</em> make use of custom core forms for an embedded DSL. In this case, that embedded DSL is actually Hackett’s type language.\n</p></li></ul><p>The second of those two use cases is simpler, and it’s what I ended up implementing first, so it’s what I will focus on in this blog post. Hackett’s type language is fundamentally quite simple, so its set of custom core forms is small as well. Everything in the type language eventually compiles into only seven core forms:\n</p><ul><li><p><code>(#%type:con <em>id</em>)</code> — Type constructors, like <code>Integer</code> or <code>Maybe</code>. These are one of the fundamental building blocks of Hackett types.\n</p></li><li><p><code>(#%type:app <em>type</em> <em>type</em>)</code> — Type application, such as <code>(Maybe Integer)</code>. Types are curried, so type constructors that accept multiple arguments are represented by nested uses of <code>#%type:app</code>.\n</p></li><li><p><code>(#%type:forall <em>id</em> <em>type</em>)</code> — Universal quantification. This is essentially a binding form, which binds any uses of <code>(#%type:bound-var <em>id</em>)</code> in <code><em>type</em></code>.\n</p></li><li><p><code>(#%type:qual <em>type</em> <em>type</em>)</code> — Qualified types, aka types with typeclass constraints. Constraints in Hackett, like in GHC, are represented by types, so typeclass names like <code>Eq</code> are bound as type constructors.\n</p></li><li><p>Finally, Hackett types support three different varieties of type variables:\n</p><ul><li><p><code>(#%type:bound-var <em>id</em>)</code> — Bound type variables. These are only legal under a corresponding <code>#%type:forall</code>.\n</p></li><li><p><code>(#%type:wobbly-var <em>id</em>)</code> — Solver variables, which may unify with any other type as part of the typechecking process.\n</p></li><li><p><code>(#%type:rigid-var <em>id</em>)</code> — Rigid variables, aka skolem variables, which only unify with themselves. They represent a unique, anonymous type used to ensure types are suitably polymorphic.\n</p></li></ul></li></ul><p>To implement our custom core forms in Racket, we need to somehow define them, but how? Intentionally, these should never be expanded, since we want the expander to stop expanding whenever it encounters one of these identifiers. While we can’t encode this directly, we <em>can</em> bind them to macros that do nothing but raise an exception if something attempts to expand them:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntaxes</span> <span class=\"p\">[</span><span class=\"n\">#%type:con</span> <span class=\"n\">#%type:app</span> <span class=\"n\">#%type:forall</span> <span class=\"n\">#%type:qual</span>\n                  <span class=\"n\">#%type:bound-var</span> <span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">#%type:rigid-var</span><span class=\"p\">]</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">type-literal</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">raise-syntax-error</span> <span class=\"no\">#f</span> <span class=\"s2\">\"cannot be used as an expression\"</span> <span class=\"n\">stx</span><span class=\"p\">))])</span>\n    <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span>\n            <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span><span class=\"p\">)))</span></code></pre><p>This will ensure our core forms are never accidentally expanded, and we’ll instruct the macroexpander to stop whenever it sees one of them via a separate mechanism.\n</p><h3><a name=\"expanding-types-in-our-type-language\"></a>Expanding types in our type language</h3><p>We’ve now defined our core forms, but we’ve intentionally left them meaningless. How do we actually inform the expander about how our types ought to be expanded? While it’s true that we don’t want the core forms themselves to be eliminated, we <em>do</em> want to expand some of their subforms. For example, in the type <code>(#%type:app a b)</code>, we want to recursively expand <code>a</code> and <code>b</code>.\n</p><p>In order to do this, we’ll use the API made available by the expander for manually invoking macroexpansion from within another macro. This API is called <a href=\"http://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._local-expand%29%29\"><code>local-expand</code></a>, and it has an option relevant to our needs: the stop list.\n</p><p>Often, <code>local-expand</code> is used to force the expander to completely, recursively expand a form. For example, by using <code>local-expand</code>, we can produce a fragment of a fully-expanded program from a piece of syntax that still includes macros:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"mi\">2</span><span class=\"p\">))</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span> <span class=\"o\">&#39;</span><span class=\"p\">())</span>\n<span class=\"c1\">; =&gt; (let-values ([(x) &#39;1]) (#%plain-app + x &#39;2))</span></code></pre><p>The third argument to <code>local-expand</code> is the <em>stop list</em>, which controls how deep the expander ought to expand a given form. By providing an empty list, we ask for a complete, recursive expansion. In this case, however, we don’t want a complete expansion! We can inform the expander to stop whenever it sees any of our custom core forms by passing a list of our core form identifiers instead of an empty list:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">type-literal-ids</span>\n    <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:con</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:app</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:forall</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:qual</span>\n          <span class=\"o\">#&#39;</span><span class=\"n\">#%type:bound-var</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:rigid-var</span><span class=\"p\">))</span>\n\n  <span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:forall</span> <span class=\"n\">x</span> <span class=\"n\">t</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span> <span class=\"n\">type-literal-ids</span><span class=\"p\">))</span>\n  <span class=\"c1\">; =&gt; (#%type:forall x t)</span></code></pre><p>Of course, this isn’t very interesting, since it just gives us back exactly what we gave it. It spotted the <code>#%type:forall</code> identifier, which is in our stop list, and immediately halted expansion. It didn’t attempt to continue expanding <code>t</code> since the expander has no way of knowing which pieces of <code>(#%type:forall x t)</code> it should expand! In this case, we want it to recur to expand <code>t</code>, since it should be a type, but not <code>x</code>, since <code>#%type:forall</code> essentially puts <code>x</code> in binding position.\n</p><p>Therefore, we have to get more clever. We need to call <code>local-expand</code> to produce a type, then we have to pattern-match on it and subsequently call <code>local-expand</code> <em>again</em> on any of the pieces of syntax we want to keep expanding. Eventually, we’ll run out of things to expand, and our type will be fully-expanded.\n</p><p>One good way to do this is to use <code>syntax/parse</code> syntax classes, since they provide a convenient way for other macros to invoke the type expander. To implement our type expander, we’ll use two mutually recursive syntax classes: one to perform the actual expansion using <code>local-expand</code> and a second to pattern-match on the resulting expanded type. For example, here’s what these two classes would look like if they only handled <code>#%type:con</code> and <code>#%type:app</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-literal-set</span> <span class=\"n\">type-literals</span>\n    <span class=\"p\">[</span><span class=\"n\">#%type:con</span> <span class=\"n\">#%type:app</span> <span class=\"n\">#%type:forall</span> <span class=\"n\">#%type:qual</span>\n     <span class=\"n\">#%type:bound-var</span> <span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">#%type:rigid-var</span><span class=\"p\">])</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">type</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"type\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"k\">_</span> <span class=\"kd\">#:with</span> <span class=\"n\">:expanded-type</span>\n                      <span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"n\">this-syntax</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span> <span class=\"n\">type-literal-ids</span><span class=\"p\">)])</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">expanded-type</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">type-literals</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">~!</span> <span class=\"n\">a:type</span> <span class=\"n\">b:type</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]))</span></code></pre><p>This blog post is definitely <em>not</em> a <code>syntax/parse</code> tutorial, so I will not explain in detail everything that’s going on here, but the gist of it is that the above code defines two syntax classes, both of which produce a single output attribute named <code>expansion</code>. This attribute contains the fully expanded version of the type currently being parsed. In the <code>#%type:con</code> case, <code>expansion</code> is just <code>this-syntax</code>, which holds the current piece of syntax being parsed. This makes sense, since uses of <code>#%type:con</code> just expand to themselves—expanding <code>(#%type:con Maybe)</code> should not perform any additional expansion on <code>Maybe</code>. This is one of Hackett’s atomic types.\n</p><p>In contrast, <code>#%type:app</code> <em>does</em> recursively expand its arguments. By annotating its two subforms with <code>:type</code>, the <code>type</code> syntax class will invoke <code>local-expand</code> on each subform, which will in turn use <code>expanded-type</code> to parse the resulting type. This is what implements the expansion loop that will eventually expand each type completely. Once <code>a</code> and <code>b</code> have been expanded, <code>#%type:app</code> reassembles them into a new syntax object using <code>#'(#%type:app a.expansion b.expansion)</code>, which replaces their unexpanded versions with their new, expanded versions.\n</p><p>We can see this behavior by writing a small <code>expand-type</code> function that will expand its argument:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expand-type</span> <span class=\"p\">(</span><span class=\"n\">syntax-parser</span> <span class=\"p\">[</span><span class=\"n\">t:type</span> <span class=\"o\">#&#39;</span><span class=\"n\">t.expansion</span><span class=\"p\">])))</span></code></pre><p>Now we can use it to observe what happens when we try expanding a type using <code>#%type:app</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">expand-type</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n<span class=\"c1\">; =&gt; #%type:app: expected type</span>\n<span class=\"c1\">;      at: Maybe</span>\n<span class=\"c1\">;      in: (#%type:app Maybe Integer)</span></code></pre><p>Okay, it failed with an error, which is not ideal, but it makes sense. We haven’t actually defined <code>Maybe</code> or <code>Integer</code> anywhere. Let’s do so! We can define them as simple macros that expand into uses of <code>#%type:con</code>, which can be done easily using <a href=\"http://docs.racket-lang.org/syntax/transformer-helpers.html#%28def._%28%28lib._syntax%2Ftransformer..rkt%29._make-variable-like-transformer%29%29\"><code>make-variable-like-transformer</code></a> from <code>syntax/transformer</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">Maybe</span> <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">Maybe</span><span class=\"p\">)))</span>\n<span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">Integer</span> <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">Integer</span><span class=\"p\">)))</span></code></pre><p>Now, if we try expanding that same type again:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">expand-type</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n<span class=\"c1\">; =&gt; (#%type:app (#%type:con Maybe) (#%type:con Integer))</span></code></pre><p>…it works! Neat. Now we just need to add the cases for the remaining forms in our type language:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">expanded-type</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">type-literals</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">~!</span> <span class=\"n\">a:type</span> <span class=\"n\">b:type</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:forall</span> <span class=\"n\">~!</span> <span class=\"n\">x:id</span> <span class=\"n\">t:type</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:forall</span> <span class=\"n\">x</span> <span class=\"n\">t.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:qual</span> <span class=\"n\">~!</span> <span class=\"n\">a:type</span> <span class=\"n\">b:type</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:qual</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:bound-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:rigid-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]))</span></code></pre><p>This is pretty good already, and to a first approximation, it’s done! However, it doesn’t actually work as well as we’d really like it to. One of the whole points of doing things this way is to allow other macros like <code>let-syntax</code> to work in types. For example, we ought to be able to create a local type binding with <code>let-syntax</code> and have it just work. Unfortunately, it doesn’t:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">expand-type</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let-syntax</span> <span class=\"p\">([</span><span class=\"n\">Bool</span> <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">Bool</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Bool</span><span class=\"p\">)))</span>\n<span class=\"c1\">; =&gt; let-syntax: expected one of these identifiers: `#%type:con&#39;, `#%type:app&#39;, `#%type:forall&#39;, `#%type:qual&#39;, `#%type:bound-var&#39;, `#%type:wobbly-var&#39;, or `#%type:rigid-var&#39;</span>\n<span class=\"c1\">;     at: letrec-syntaxes+values</span>\n<span class=\"c1\">;     in: (let-syntax ((Bool (make-variable-like-transformer (syntax Bool)))) (#%type:app Maybe Bool))</span></code></pre><p>What went wrong? And why is it complaining about <code>letrec-syntaxes+values</code>? Well, if you read the documentation for <code>local-expand</code>, you’ll find that its behavior is a little more complicated than you might at first believe:\n</p><blockquote><p>If <em><code>stop-ids</code></em> is [a nonempty list containing more than just <code>module*</code>], then <code>begin</code>, <code>quote</code>, <code>set!</code>, <code>#%plain-lambda</code>, <code>case-lambda</code>, <code>let-values</code>, <code>letrec-values</code>, <code>if</code>, <code>begin0</code>, <code>with-continuation-mark</code>, <code>letrec-syntaxes+values</code>, <code>#%plain-app</code>, <code>#%expression</code>, <code>#%top</code>, and <code>#%variable-reference</code> are implicitly added to <em><code>stop-ids</code></em>. Expansion stops when the expander encounters any of the forms in <em><code>stop-ids</code></em>, and the result is the partially-expanded form.\n</p></blockquote><p>That’s a little strange, isn’t it? I am not completely sure why the behavior works quite this way, though I’m sure backwards compatibility plays a significant part, but while some of the behavior seems unnecessary, the issue with <code>letrec-syntaxes+values</code> (which <code>let-syntax</code> expands to) is a reasonable one. If the expander naïvely expanded <code>letrec-syntaxes+values</code> in the presence of a nonempty stop list, it could cause some significant problems!\n</p><p>Allow me to illustrate with an example. Let’s imagine we are the expander, and we are instructed to expand the following program:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">let-syntax</span> <span class=\"p\">([</span><span class=\"n\">Bool</span> <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">Bool</span><span class=\"p\">))])</span>\n  <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Bool</span><span class=\"p\">))</span></code></pre><p>We see <code>let-syntax</code>, so we start by evaluating the expression on the right hand side of the <code>Bool</code> binding. This produces a transformer expression, so we bind <code>Bool</code> to the transformer in the local environment, then move onto expanding the body. At this point, the expander is looking at this:\n</p><pre><code class=\"pygments\"><span class=\"c1\">; local bindings:</span>\n<span class=\"c1\">;   Bool -&gt; #&lt;variable-like-transformer&gt;</span>\n<span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Bool</span><span class=\"p\">)</span></code></pre><p>Now, the identifier in application position is <code>#%type:app</code>, and <code>#%type:app</code> is in the stop list. Therefore, expansion must stop, and it does not attempt to expand any further. But what should the result of expansion be? Well, the <code>let-syntax</code> needs to go away when we expand it—local syntax bindings are erased as part of macroexpansion—so the logical thing to expand into is <code>(#%type:app Maybe Bool)</code>. But this is a problem, because when we then go to expand <code>Bool</code>, <code>Bool</code> isn’t in the local binding table anymore! The <code>let-syntax</code> was already erased, and <code>Bool</code> is unbound!\n</p><p>When expanding recursively, this isn’t a problem, since the entire expression is guaranteed to be expanded while the local binding is still in the expander’s environment. As soon as we introduce partial expansion, however, we run the risk of a binding getting erased too early. So we’re stuck: we can’t recursively expand, or we’ll expand too much, but we can’t partially expand, since we might expand too little.\n</p><p>Confronted with this problem, there is some good news and some bad news. The good news is that, while the macroexpander can’t help us, we can help the macroexpander by doing some of the necessary bookkeeping for it. We can do this using first-class definition contexts, which allow us to manually extend the local environment when we call <code>local-expand</code>. The bad news is that first-class definition contexts are <em>complicated</em>, and using them properly is a surprisingly subtle problem.\n</p><p>Fortunately, I’ve already spent a lot of time figuring out what needs to be done to properly manipulate the necessary definition contexts in this particular situation. The first step is to parameterize our <code>type</code> and <code>expanded-type</code> syntax classes so that we may thread a definition context around as we recursively expand:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"p\">[</span><span class=\"n\">intdef-ctx</span> <span class=\"no\">#f</span><span class=\"p\">])</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"type\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"k\">_</span> <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">||</span> <span class=\"p\">(</span><span class=\"n\">expanded-type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span>\n                      <span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"n\">this-syntax</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span> <span class=\"n\">type-literal-ids</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)])</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"p\">(</span><span class=\"n\">expanded-type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">type-literals</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:forall</span> <span class=\"n\">~!</span> <span class=\"n\">x:id</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:forall</span> <span class=\"n\">x</span> <span class=\"n\">t.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:qual</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:qual</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:bound-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:rigid-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]))</span></code></pre><p>Now, we can add an additional case to <code>expanded-type</code> to handle <code>letrec-syntaxes+values</code>, which will explicitly create a new definition context, add bindings to it, and use it when parsing the body:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"k\">letrec-syntaxes+values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">e:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">()</span> <span class=\"n\">t:expr</span><span class=\"p\">)</span>\n         <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">ids</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">id</span><span class=\"p\">))]</span>\n                     <span class=\"p\">[</span><span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">e</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">ids</span> <span class=\"n\">e</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">))]</span>\n         <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t*</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">)}</span> <span class=\"o\">#&#39;</span><span class=\"n\">t</span>\n         <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"n\">t*.expansion</span><span class=\"p\">]</span></code></pre><p>But even this isn’t quite right. The problem with this implementation is that it throws away the existing <code>intdef-ctx</code> argument to <code>expanded-type</code>, which means those bindings will be lost as soon as we introduce a new set. To fix this, we have to make the new definition context a <em>child</em> of the previous definition context by passing the old context as an argument to <code>syntax-local-make-definition-context</code>. This will ensure the parent bindings are brought into scope when expanding using the child context:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"k\">letrec-syntaxes+values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">e:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">()</span> <span class=\"n\">t:expr</span><span class=\"p\">)</span>\n         <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">ids</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">id</span><span class=\"p\">))]</span>\n                     <span class=\"p\">[</span><span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">e</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">ids</span> <span class=\"n\">e</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">))]</span>\n         <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t*</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">)}</span> <span class=\"o\">#&#39;</span><span class=\"n\">t</span>\n         <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"n\">t*.expansion</span><span class=\"p\">]</span></code></pre><p>With this in place, our example using <code>let-syntax</code> actually works!\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">expand-type</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let-syntax</span> <span class=\"p\">([</span><span class=\"n\">Bool</span> <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">Bool</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"n\">#%type:app</span> <span class=\"n\">Maybe</span> <span class=\"n\">Bool</span><span class=\"p\">)))</span>\n<span class=\"c1\">; =&gt; (#%type:app (#%type:con Maybe) (#%type:con Bool))</span></code></pre><p>Pretty cool, isn’t it?\n</p><h3><a name=\"preserving-syntax-properties-and-source-locations\"></a>Preserving syntax properties and source locations</h3><p>We’ve now managed to essentially implement an expander for our custom language by periodically yielding to the Racket macroexpander, and for the most part, it works. However, our implementation isn’t perfect. The real Racket macroexpander takes great care to preserve source locations and syntax properties on syntax objects wherever possible, which our implementation does not do. Normally we don’t have to worry so much about such things, since the macroexpander automatically copies properties when expanding macros, but since we’re circumventing the expander, we don’t get that luxury. In order to properly preserve this information, we’ll have to be a little more careful.\n</p><p>To start, we really ought to copy the identifier in application position into the output wherever we can. In addition to preserving source location information and syntax properties, it also preserves the even more visible renamings. For example, if a user imports <code>#%type:app</code> under a different name, like <code>#%type:apply</code>, we should expand to a piece of syntax that still has <code>#%type:apply</code> in application position instead of replacing it with <code>#%type:app</code>.\n</p><p>To do this, we just need to bind each of the identifiers in application position, then use that binding when we produce output. For example, we would adjust the <code>#%type:app</code> clause to the following:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:app</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n         <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">)]</span></code></pre><p>But even after doing this, some source locations and syntax properties are lost, since we’re still reconstructing the pair from scratch. To ensure we copy <em>everything</em>, we can define two helper macros, <code>syntax/loc/props</code> and <code>quasisyntax/loc/props</code>, which are like <code>syntax/loc</code> and <code>quasisyntax/loc</code> but copy properties in addition to source location information:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define-syntaxes</span> <span class=\"p\">[</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">quasisyntax/loc/props</span><span class=\"p\">]</span>\n    <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n      <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"n\">name</span> <span class=\"n\">syntax-id</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n          <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">from-stx-expr:expr</span> <span class=\"p\">{</span><span class=\"n\">~describe</span> <span class=\"s2\">\"template\"</span> <span class=\"n\">template</span><span class=\"p\">})</span>\n           <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">from-stx</span> <span class=\"n\">from-stx-expr</span><span class=\"p\">])</span>\n               <span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"nb\">syntax?</span> <span class=\"n\">from-stx</span><span class=\"p\">)</span>\n                 <span class=\"p\">(</span><span class=\"nb\">raise-argument-error</span> <span class=\"o\">&#39;#,</span><span class=\"ss\">name</span> <span class=\"s2\">\"syntax?\"</span> <span class=\"n\">from-stx</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">let*</span> <span class=\"p\">([</span><span class=\"n\">stx</span> <span class=\"p\">(</span><span class=\"o\">#,</span><span class=\"n\">syntax-id</span> <span class=\"n\">template</span><span class=\"p\">)]</span>\n                      <span class=\"p\">[</span><span class=\"n\">stx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-disarm</span> <span class=\"n\">stx</span> <span class=\"no\">#f</span><span class=\"p\">)])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-rearm</span> <span class=\"p\">(</span><span class=\"nb\">datum-&gt;syntax</span> <span class=\"n\">stx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-e</span> <span class=\"n\">stx*</span><span class=\"p\">)</span> <span class=\"n\">from-stx</span> <span class=\"n\">from-stx</span><span class=\"p\">)</span> <span class=\"n\">stx</span><span class=\"p\">)))]))</span>\n      <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"o\">&#39;</span><span class=\"ss\">syntax/loc/props</span> <span class=\"o\">#&#39;</span><span class=\"k\">syntax</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"o\">&#39;</span><span class=\"ss\">quasisyntax/loc/props</span> <span class=\"o\">#&#39;</span><span class=\"k\">quasisyntax</span><span class=\"p\">)))))</span></code></pre><p>Using <code>syntax/loc/props</code>, we can be truly thorough about ensuring all properties are preserved:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:app</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n         <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                            <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">))]</span></code></pre><p>Applying this to the other relevant clauses, we get an updated version of the <code>expanded-type</code> syntax class:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"p\">(</span><span class=\"n\">expanded-type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span> <span class=\"n\">type-literals</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"k\">letrec-syntaxes+values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">e:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">()</span> <span class=\"n\">t:expr</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">))</span>\n                   <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">ids</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">id</span><span class=\"p\">))]</span>\n                         <span class=\"p\">[</span><span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">e</span><span class=\"p\">))])</span>\n                     <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">ids</span> <span class=\"n\">e</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">))]</span>\n             <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t*</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">)}</span> <span class=\"o\">#&#39;</span><span class=\"n\">t</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"o\">#&#39;</span><span class=\"n\">t*.expansion</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:app</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:forall</span> <span class=\"n\">~!</span> <span class=\"n\">x:id</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">x</span> <span class=\"n\">t.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:qual</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:bound-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:rigid-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]))</span></code></pre><p>Now we’re getting closer, but if you can believe it, even <em>this</em> isn’t good enough. The real expander’s implementation of <code>letrec-syntaxes+values</code> does two things our implementation does not: it copies properties and updates the <code>'origin</code> property to indicate the syntax came from a use of <code>letrec-syntaxes+values</code>, and it adds a <code>'disappeared-use</code> property to record the erased bindings for use by tools like DrRacket. We can apply <code>syntax-track-origin</code> and <code>internal-definition-context-track</code> to the resulting syntax to add the same properties the expander would:\n</p><pre><code class=\"pygments\"><span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:letrec-syntaxes+values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">e:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">()</span> <span class=\"n\">t:expr</span><span class=\"p\">)</span>\n         <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">ids</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">id</span><span class=\"p\">))]</span>\n                     <span class=\"p\">[</span><span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">e</span><span class=\"p\">))])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">ids</span> <span class=\"n\">e</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">))]</span>\n         <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t*</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">)}</span> <span class=\"o\">#&#39;</span><span class=\"n\">t</span>\n         <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"p\">(</span><span class=\"n\">internal-definition-context-track</span> <span class=\"n\">intdef-ctx*</span> <span class=\"o\">#&#39;</span><span class=\"n\">t*.expansion</span><span class=\"p\">)</span>\n                              <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))]</span></code></pre><p>Now we’ve <em>finally</em> dotted all our i’s and crossed our t’s. While it does take a lot to properly emulate what the macroexpander is doing, the important thing is that it’s actually possible! The end result of all this definition context juggling and property copying is that we’ve effectively managed to move some of the macroexpander’s logic into userspace code, which allows us to manipulate it as we see fit.\n</p><h3><a name=\"connecting-our-custom-language-to-hackett\"></a>Connecting our custom language to Hackett</h3><p>It took a lot of work, but we finally managed to write a custom type language, and while the code is not exactly simple, it’s not actually very long. The entire implementation of our custom type language is less than 80 lines of code:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket/base</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-meta</span> <span class=\"mi\">2</span> <span class=\"n\">racket/base</span>\n                     <span class=\"n\">syntax/parse</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">racket/base</span>\n                     <span class=\"n\">syntax/intdef</span>\n                     <span class=\"n\">threading</span><span class=\"p\">)</span>\n         <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define-syntaxes</span> <span class=\"p\">[</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">quasisyntax/loc/props</span><span class=\"p\">]</span>\n    <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">()</span>\n      <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"n\">name</span> <span class=\"n\">syntax-id</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n          <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">from-stx-expr:expr</span> <span class=\"p\">{</span><span class=\"n\">~describe</span> <span class=\"s2\">\"template\"</span> <span class=\"n\">template</span><span class=\"p\">})</span>\n           <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">from-stx</span> <span class=\"n\">from-stx-expr</span><span class=\"p\">])</span>\n               <span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"nb\">syntax?</span> <span class=\"n\">from-stx</span><span class=\"p\">)</span>\n                 <span class=\"p\">(</span><span class=\"nb\">raise-argument-error</span> <span class=\"o\">&#39;#,</span><span class=\"ss\">name</span> <span class=\"s2\">\"syntax?\"</span> <span class=\"n\">from-stx</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">let*</span> <span class=\"p\">([</span><span class=\"n\">stx</span> <span class=\"p\">(</span><span class=\"o\">#,</span><span class=\"n\">syntax-id</span> <span class=\"n\">template</span><span class=\"p\">)]</span>\n                      <span class=\"p\">[</span><span class=\"n\">stx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-disarm</span> <span class=\"n\">stx</span> <span class=\"no\">#f</span><span class=\"p\">)])</span>\n                 <span class=\"p\">(</span><span class=\"nb\">syntax-rearm</span> <span class=\"p\">(</span><span class=\"nb\">datum-&gt;syntax</span> <span class=\"n\">stx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-e</span> <span class=\"n\">stx*</span><span class=\"p\">)</span> <span class=\"n\">from-stx</span> <span class=\"n\">from-stx</span><span class=\"p\">)</span> <span class=\"n\">stx</span><span class=\"p\">)))]))</span>\n      <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"o\">&#39;</span><span class=\"ss\">syntax/loc/props</span> <span class=\"o\">#&#39;</span><span class=\"k\">syntax</span><span class=\"p\">)</span>\n              <span class=\"p\">(</span><span class=\"n\">make-syntax/loc/props</span> <span class=\"o\">&#39;</span><span class=\"ss\">quasisyntax/loc/props</span> <span class=\"o\">#&#39;</span><span class=\"k\">quasisyntax</span><span class=\"p\">)))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-syntaxes</span> <span class=\"p\">[</span><span class=\"n\">#%type:con</span> <span class=\"n\">#%type:app</span> <span class=\"n\">#%type:forall</span> <span class=\"n\">#%type:qual</span>\n                  <span class=\"n\">#%type:bound-var</span> <span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">#%type:rigid-var</span><span class=\"p\">]</span>\n  <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">type-literal</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">raise-syntax-error</span> <span class=\"no\">#f</span> <span class=\"s2\">\"cannot be used as an expression\"</span> <span class=\"n\">stx</span><span class=\"p\">))])</span>\n    <span class=\"p\">(</span><span class=\"nb\">values</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span>\n            <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span> <span class=\"n\">type-literal</span><span class=\"p\">)))</span>\n\n<span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">type-literal-ids</span>\n    <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:con</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:app</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:forall</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:qual</span>\n          <span class=\"o\">#&#39;</span><span class=\"n\">#%type:bound-var</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"o\">#&#39;</span><span class=\"n\">#%type:rigid-var</span><span class=\"p\">))</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-literal-set</span> <span class=\"n\">type-literals</span>\n    <span class=\"p\">[</span><span class=\"n\">#%type:con</span> <span class=\"n\">#%type:app</span> <span class=\"n\">#%type:forall</span> <span class=\"n\">#%type:qual</span>\n     <span class=\"n\">#%type:bound-var</span> <span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">#%type:rigid-var</span><span class=\"p\">])</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"p\">[</span><span class=\"n\">intdef-ctx</span> <span class=\"no\">#f</span><span class=\"p\">])</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"type\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"k\">_</span> <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">||</span> <span class=\"p\">(</span><span class=\"n\">expanded-type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span>\n                      <span class=\"p\">(</span><span class=\"nb\">local-expand</span> <span class=\"n\">this-syntax</span> <span class=\"o\">&#39;</span><span class=\"ss\">expression</span> <span class=\"n\">type-literal-ids</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)])</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"p\">(</span><span class=\"n\">expanded-type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:description</span> <span class=\"no\">#f</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">expansion</span><span class=\"p\">]</span>\n    <span class=\"kd\">#:commit</span>\n    <span class=\"kd\">#:literal-sets</span> <span class=\"p\">[</span><span class=\"n\">kernel-literals</span> <span class=\"n\">type-literals</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:letrec-syntaxes+values</span> <span class=\"n\">~!</span> <span class=\"p\">([(</span><span class=\"n\">id:id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">e:expr</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">()</span> <span class=\"n\">t:expr</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define</span> <span class=\"n\">intdef-ctx*</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-make-definition-context</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">))</span>\n                   <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"p\">([</span><span class=\"n\">ids</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">id</span><span class=\"p\">))]</span>\n                         <span class=\"p\">[</span><span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"nb\">in-list</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">e</span><span class=\"p\">))])</span>\n                     <span class=\"p\">(</span><span class=\"nb\">syntax-local-bind-syntaxes</span> <span class=\"n\">ids</span> <span class=\"n\">e</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">))]</span>\n             <span class=\"kd\">#:with</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t*</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx*</span><span class=\"p\">)}</span> <span class=\"o\">#&#39;</span><span class=\"n\">t</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">~&gt;</span> <span class=\"p\">(</span><span class=\"n\">internal-definition-context-track</span> <span class=\"n\">intdef-ctx*</span> <span class=\"o\">#&#39;</span><span class=\"n\">t*.expansion</span><span class=\"p\">)</span>\n                                  <span class=\"p\">(</span><span class=\"nb\">syntax-track-origin</span> <span class=\"n\">this-syntax</span> <span class=\"o\">#&#39;</span><span class=\"n\">head</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:con</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:app</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:forall</span> <span class=\"n\">~!</span> <span class=\"n\">x:id</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">t</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">x</span> <span class=\"n\">t.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">head:#%type:qual</span> <span class=\"n\">~!</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">a</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)}</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">b</span> <span class=\"p\">(</span><span class=\"n\">type</span> <span class=\"n\">intdef-ctx</span><span class=\"p\">)})</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"p\">(</span><span class=\"n\">syntax/loc/props</span> <span class=\"n\">this-syntax</span>\n                                <span class=\"p\">(</span><span class=\"n\">head</span> <span class=\"n\">a.expansion</span> <span class=\"n\">b.expansion</span><span class=\"p\">))]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:bound-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:wobbly-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">#%type:rigid-var</span> <span class=\"n\">~!</span> <span class=\"n\">_:id</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">expansion</span> <span class=\"n\">this-syntax</span><span class=\"p\">])</span>\n\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">expand-type</span> <span class=\"p\">(</span><span class=\"n\">syntax-parser</span> <span class=\"p\">[</span><span class=\"n\">t:type</span> <span class=\"o\">#&#39;</span><span class=\"n\">t.expansion</span><span class=\"p\">])))</span></code></pre><p>But what now? Just as Racket fully-expanded programs are useless without a compiler to turn them into something useful, our custom type language doesn’t do anything at all in isolation. As it happens, in the case of the type language, we don’t have a compiler at all—we have a <em>typechecker</em>. The Hackett typechecker consumes fully-expanded types as input and uses them to perform its typechecking process. The actual implementation of Hackett’s typechecker is outside the scope of this blog post, since it’s really an entirely separate problem, but you can probably imagine what such a thing might look like, in an extremely vague, handwavy sense.\n</p><p>But we don’t <em>just</em> need a typechecker. Just as the authors of Racket don’t expect users to write programs using the core forms directly, we also don’t expect users to write their types using the fully-expanded syntax. If we did, all this fancy expansion machinery would be pretty pointless! Hackett provides a custom <code>#%app</code> binding that converts n-ary type applications to nested uses of <code>#%type:app</code>, as well as a nicer <code>forall</code> macro that supports specifying multiple type variables and multiple typeclass constraints all at once. The best part, though, is that these macros can be defined in a completely straightforward way, just as any ordinary Racket macro would be written, and the machinery will work precisely as intended. It’s also perfectly okay to have two different versions of <code>#%app</code>—one for types and one for values—since <a href=\"/blog/2017/10/27/a-space-of-their-own-adding-a-type-namespace-to-hackett/\">Hackett supports multiple namespaces</a>, and each can have its own <code>#%app</code> binding.\n</p><p>The real implementation of Hackett’s type language is a little bit longer than the one in this blog post because it includes some extra definitions to provide custom <code>syntax/parse</code> pattern expanders for matching types and some template metafunctions for producing them, which are used by the typechecker, but if you’d like to see the whole thing, <a href=\"https://github.com/lexi-lambda/hackett/blob/ba64193da38f63dab2523f42c1b7614cdfa8c935/hackett-lib/hackett/private/type-language.rkt\">it’s available on GitHub here</a>.\n</p><h2><a name=\"evaluation-limitations-and-acknowledgements\"></a>Evaluation, limitations, and acknowledgements</h2><p>Reimplementing Hackett’s type language took about a week and a half, about half of which was supplemented by the extra time I had before I started <a href=\"https://twitter.com/lexi_lambda/status/976533916596097024\">my new job</a> this past week. A portion of that time was spent deciding what I actually wanted to do, and a lot of it was spent hunting down fiddly bugs. All told, the rewrite resulted in a net addition of 250 lines of code to the Hackett codebase. However, 350 of the added lines reside in a new, self-contained module dedicated to Hackett’s type language, so the change actually resulted in a net <em>removal</em> of 100 lines from the rest of the codebase, which I consider an organizational win.\n</p><p>As for whether or not the change will accomplish the goals I had in mind, I think signs currently point to a strong likelihood of the answer being yes. The very same night I finalized and merged the changes to the type language, I dusted off an old prototype of typeclass deriving I had not been able to get working due to insufficiencies of the old type representation. Not only was I <a href=\"https://twitter.com/lexi_lambda/status/985051504867446786\">able to get it working</a> quickly and easily, I was able to do it in <a href=\"https://twitter.com/lexi_lambda/status/985052476473856000\">no more than 20 lines of code</a>. While the implementation is not as robust as it should ideally be, nor is it safe or simple enough yet to be easy for Hackett users to write themselves, making the impossible possible is usually a sign of motion in the right direction.\n</p><p>Unfortunately, the technique outlined in this blog post is not completely flawless. Due to its reliance on the <code>local-expand</code> stop list, this technique is incompatible with macros that force recursive expansion using an empty stop list. In the upcoming reimplementation of the Racket macroexpander to be released in Racket 7, this includes <code>syntax-parameterize</code>, which unfortunately means syntax parameters don’t work in the type language. This is a problem, and while it’s not a dealbreaker, it is something that will almost certainly have to be fixed at some point. Fortunately, it isn’t intractable, and I’ve been discussing some potential approaches to fixing the problem, whether via changes to the macroexpander or by making macros like <code>syntax-parameterize</code> cooperate better with things like Hackett’s type language.\n</p><p>Finally, as seems to be the case more and more with my blog posts, I cannot express enough thanks to <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a>, without whose help I would probably not have been able to get everything working (not to mention that the Racket macro system would not exist without Matthew inventing and implementing it nearly singlehandedly). Matthew does an almost unfathomable number of things for Racket already without me pestering him with questions, bug reports, and feature requests, but he’s always patient and helpful all the same. Also, once again, I’d like to thank <a href=\"http://www.ccs.neu.edu/home/ryanc/\">Ryan Culpepper</a> for <a href=\"https://www2.ccs.neu.edu/racket/pubs/dissertation-culpepper.pdf\">his incredible work on constructing tools for the working macro developer</a>, including writing the fantastic <code>syntax/parse</code> library that powers essentially everything I do. Thank you both.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"In the past couple of weeks, I completely rewrote the implementation of Hackett’s type language to improve the integration between the type representation and Racket’s macro system. The new type language effectively implements a way to reuse as much of the Racket macroexpanding infrastructure as possible while expanding a completely custom language, which uses a custom set of core forms. The fundamental technique used to do so is not novel, and it seems to be periodically rediscovered every so often, but it has never been published or documented anywhere, and getting it right involves understanding a great number of subtleties about the Racket macro system. While I cannot entirely eliminate the need to understand those subtleties, in this blog post, I hope to make the secret sauce considerably less secret.\n\nThis blog post is both a case study on how I implemented the expander for Hackett’s new type language and a discussion of how such a technique can apply more generally. Like my previous blog post on Hackett, which covered the implementation of its namespace system, the implementation section of this blog post is highly technical and probably requires significant experience with Racket’s macro system to completely comprehend. However, the surrounding material is written to be more accessible, so even if you are not a Racket programmer, you should hopefully be able to understand the big ideas behind this change.\n\nWhat are core forms?\nBefore we can get started writing custom core forms, we need to understand the meaning of Racket’s plain old core forms. What is a core form? In order to answer that question, we need to think about how Racket’s expansion and compilation model works.\n\nTo start, let’s consider a simple Racket program. Racket programs are organized into modules, which are usually written with a #lang line at the top. In this case, we’ll use #lang racket to keep things simple:\n\n#lang racket\n\n(define (add2 x)\n  (+ x 2))\n\n(add2 3)\nHow does Racket see this program? Well, before it can do anything with it, it must parse the program text, which is known in Racket as reading the program. The #lang line controls how the program is read—some #langs provide parsers that allow syntax that is very different from the parser used for #lang racket—but no matter which reader is used, the result is an s-expression (actually a syntax object, but essentially an s-expression) representing a module. In the case of the above program, the result looks like this:\n\n(module m racket\n  (#%module-begin\n    (define (add2 x)\n      (+ x 2))\n\n    (add2 3)))\nNote the introduction of #%module-begin. Despite the fancy name, this is really just an ordinary macro provided by the racket language. By convention, the reader and expander cooperate to ensure the body of every module is wrapped with #%module-begin; as we’ll see shortly, this allows languages to add functionality that affects the entire contents of the module.\n\nOne the program has been read, it is subsequently expanded by the macroexpander. As the name implies, this is the phase that expands all the macros in a module. What does the above module look like after expansion? Well, it doesn’t look unrecognizable, but it certainly does look different:\n\n(module m racket\n  (#%plain-module-begin\n    (define-values (add2)\n      (lambda (x) (#%plain-app + x '2)))\n\n    (#%plain-app call-with-values\n                 (lambda () (#%plain-app add2 '3))\n                 print-values)))\nLet’s note the things that changed:\n\n\n#%module-begin was replaced with #%plain-module-begin. #%plain-module-begin is a binding that wraps the body of every expanded module, and all definitions of #%module-begin in any language must eventually expand to #%plain-module-begin. However, #lang racket’s #%module-begin doesn’t just expand to #%plain-module-begin, it also wraps bare expressions at the top level of a module so that their results are printed. This is why running the above program prints 5 even though there is no code related to printing in the original program!\n\n\nThe lambda shorthand used with define was converted to an explicit use of lambda, and it was expanded to define-values. In Racket, define and define-syntax are really just macros for define-values and define-syntaxes that only bind a single identifier.\n\n\nAll function applications were tagged explicitly with #%plain-app. This syntactically distinguishes function applications from uses of forms like define-values or lambda. It also allows languages to customize function application by providing their own macros named #%app (just like languages can provide their own macros named #%module-begin that expand to #%plain-module-begin), but that is outside the scope of this blog post.\n\n\nAll literals have been wrapped with quote, so 2 became '2 and 3 became '3.\n\n\nImportantly, the resulting program contains no macros. Such programs are called fully expanded, since all macros have been eliminated and no further expansion can take place.\n\nSo what’s left behind? Well, some of the things in the program are literal data, like the numbers 2 and 3. There are also some variable references, x and add2. Most of the program, however, is built out of primitives like module, #%plain-module-begin, #%plain-app, define-values, and lambda. These primitives are core forms—they are not variables, since they do not represent bindings that contain values at runtime, but they are also not macros, since they cannot be expanded any further.\n\nIn this sense, a fully-expanded program is just like a program in most languages that do not have macros. Core forms in Racket correspond to the syntax of other languages. We can imagine a JavaScript program similar to the above fully-expanded Racket program:\n\nvar add2 =\n  function (x) { return x + 2; };\n\nconsole.log(add2(3));\nJust as this JavaScript program is internally transformed into an AST containing a definition node, a function abstraction node, and some function application nodes, a fully-expanded Racket program represents an AST ready to be sent off to be compiled. The Racket compiler has built-in rules for how to compile core forms like define-values, lambda, and #%plain-app, and the result is optimized Racket bytecode.\n\nIn the remainder of this blog post, as most discussions of macros do, we’ll ignore the read and compile steps of the Racket program pipeline and focus exclusively on the expand step. It’s useful, however, to keep the other steps in mind, since we’re going to be discussing what it means to implement custom core forms, and core forms really only make sense in the context of the subsequent compilation step that consumes them.\n\nRacket’s default core forms\nSo, now that we know what core forms are in an abstract sense, what are they in practice? We’ve already encountered module, #%plain-module-begin, #%plain-app, define-values, lambda, and quote, but there are many more. The full list is available in the section of the Racket reference named Fully Expanded Programs, and I will not list all of them here. In general, they are more or less what you’d expect. The list of Racket’s core forms also includes things like define-syntaxes, if, let-values, letrec-values, begin, quote-syntax, and set!. Fundamentally, these correspond to the basic operations the Racket compiler understands, and it allows the remainder of Racket’s compilation pipeline to ignore the complexities of macroexpansion.\n\nThese forms are fairly versatile, and it’s easy to build high-level abstractions on top of them. For example, #lang racket implements cond as a macro that eventually expands into if, and it implements syntax as a macro that eventually expands into function calls and quote-syntax. The real power comes in the way new macros can be built out of other macros, not just core forms, so Racket’s match can expand into uses of let and cond, and it doesn’t need to concern itself with using let-values and if. For this reason, Racket’s core forms are quite capable of representing any language imaginable, since fully-expanded programs are essentially instructions for the Racket virtual machine, and macros are mini-compilers that can be mixed and matched.\n\nThe need for custom core forms\nWith that in mind, why might we wish to define custom core forms? In fact, what would such a thing even mean? By their very nature, all Racket programs eventually expand into Racket’s core forms; new core forms cannot be added because Racket’s underlying compiler infrastructure is not (currently) extensible. New forms can be added that are defined in terms of other forms, but adding new primitives doesn’t make any sense, since the compiler would not know what to do with them.\n\nDespite this, there are at least two use-cases in which a programmer might wish to customize the set of core forms produced by the macroexpander. Each situation is slightly different, but they both revolve around the same idea.\n\nSupporting multiple backends\nThe most commonly discussed use case for customizing the set of core forms is for languages that wish to use the Racket macroexpander, but target backends that are not the Racket compiler. For example, a user might implement a Racket #lang that describes electronic circuits, and they might even implement a way to execute such a program in Racket, but they might also wish to compile the result to a more traditional hardware description language. Like other languages in the Racket ecosystem, such a language would be made up of a tower of macros built on top of core forms; unlike other languages, the core forms might need to be more abstract than the ones provided by Racket to efficiently compile to other targets.\n\nIn the case of a hardware description language, the custom core forms might include things like input and output for declaring circuit inputs and outputs, and expressions might be built out of hardware operations rather than high-level things like function calls. The Racket macroexpander would expand the input program into the custom set of core forms, at which point an external compiler program could compile the resutling AST in a more traditional way. If the language author wished, they could additionally define implementations of these core forms as Racket macros that eventually expand into Racket, which would allow them to emulate their circuits in Racket at little cost, but this would be a wholly optional step.\n\nEssentially, this use case stems from a desire to reuse Racket’s advanced language-development technology, such as the macroexpander, the module system, and editor tooling, without also committing to using Racket as a runtime, which is not always appropriate for all languages. This use case is not nearly as easy as it ought to be, but it is a common request, and it is possible that future improvements to the Racket toolchain will be designed specifically to address this problem.\n\nCompiling an extensible embedded language\nA second use case for custom core forms is less frequently discussed, but I think it might actually be significantly more common in practice were it available in a form accessible to working macro programmers. In this scenario, users might wish to remain within Racket, but still want to define a custom language that other macros can consume.\n\nThis concept is a little more vague and fuzzily-defined than the case of developing a separate backend, so allow me to propose an example. Imagine a Racket programmer decides to build an embedded DSL for asynchronously producing and consuming events, similar to first-order functional reactive programming. In this case, the DSL is designed to be used in larger Racket programs, so it will eventually expand to Racket’s core forms. However, it’s possible that such a language might wish to enforce static invariants about the network graph, and in doing so, it might be able to produce significantly more optimal Racket code via a compile-time analysis.\n\nPerforming such a compile-time analysis is essentially writing a custom optimizer as part of a macro, which has been done numerous times already within the Racket ecosystem. One of the most prominent examples of such a thing is the match macro, which parses users’ patterns into compile-time data structures, performs a fairly traditional optimization pass designed to efficiently compile pattern matching, and it emits optimized Racket code as a result. This approach works well for fairly contained problems like pattern-matching, but it works less well for entirely new embedded languages that include everything from their own notion of evaluation to their own binding forms.\n\nExisting DSLs of this type are rare, but they do exist. syntax/parse provides an expressive, specialized pattern-matching language designed specifically for matching syntax objects, and it uses a different model from racket/match to be more suitable for that task. It allows backtracking with cuts, an extensible pattern language, an abstraction language for defining reusable parsers that can accept inputs and produce outputs, and fine-grained control over both parsing and binding. While match is essentially just a traditional pattern-matcher, albeit an extensible one, syntax-parse is its own programming language, closer in some ways to Prolog than to Racket.\n\nFor this reason, syntax/parse has an extensive language to do everything from creating new bindings to controlling when and how parsing fails. This language is represented in two ways: an inline pattern language, and an alternate syntax known as pattern directives. Here is an example of pattern directives in action, from my own threading library:\n\n[(_ ex:expr cl:clause remaining:clause ...)\n #:do [(define call (syntax->list #'cl.call))\n       (define-values (pre post)\n         (split-at call (add1 (or (attribute cl.insertion-point) 0))))]\n #:with [pre ...] pre\n #:with [post ...] post\n #:with app/ctx (adjust-outer-context this-syntax #'(pre ... ex post ...) #'cl)\n (adjust-outer-context this-syntax #'(~> app/ctx remaining ...) this-syntax)]\nEach directive is represented by a keyword, in this case #:do and #:with. Each directive has a corresponding keyword in the pattern language, in this case ~do and ~parse. Therefore, the above pattern could equivalently be written this way:\n\n[{~and (_ ex:expr cl:clause remaining:clause ...)\n       {~do (define call (syntax->list #'cl.call))\n            (define-values (pre post)\n              (split-at call (add1 (or (attribute cl.insertion-point) 0))))}\n       {~parse [pre ...] pre}\n       {~parse [post ...] post}\n       {~parse app/ctx (adjust-outer-context this-syntax #'(pre ... ex post ...) #'cl)}}\n (adjust-outer-context this-syntax #'(~> app/ctx remaining ...) this-syntax)]\nThe transformation can go in the other direction, too—each syntax class annotation on each pattern variable can be extracted into the directive language using #:declare, so this is also equivalent:\n\n[(_ ex cl remaining ...)\n #:declare ex expr\n #:declare cl clause\n #:declare remaining clause\n #:do [(define call (syntax->list #'cl.call))\n       (define-values (pre post)\n         (split-at call (add1 (or (attribute cl.insertion-point) 0))))]\n #:with [pre ...] pre\n #:with [post ...] post\n #:with app/ctx (adjust-outer-context this-syntax #'(pre ... ex post ...) #'cl)\n (adjust-outer-context this-syntax #'(~> app/ctx remaining ...) this-syntax)]\nThis is very much a programming language, but it has very different semantics from programming in Racket! Failure to match against a #:with or ~parse pattern causes pattern-matching to backtrack, and though it’s possible to escape to Racket using #:do or ~do, practical uses of syntax/parse really do involve quite a lot of programming in its pattern DSL.\n\nBut the Racket programmer might not find this DSL wholly satisfying. Why? Well, it isn’t extensible! The pattern directives—#:declare, #:do, and #:with, among others—are essentially the core forms of syntax/parse’s pattern-matching language, but new ones cannot be defined. The desire to make this language easy to analyze statically in order to emit optimal pattern-matching code meant its author opted to define the language in terms of a specific grammar rather than a tower of macros.\n\nBut what if syntax/parse could define its own core forms? What if, instead of #:do, #:declare, and #:with being implemented as keyword options specially recognized by the syntax-parse grammar, it defined do, declare, and with as core forms for a new, macro-enabled language? A user of the language could then define a completely ordinary Racket macro and use it with this new language as long as it eventually expanded into the syntax/parse core forms. The implementation of syntax/parse could then invoke the macroexpander to request each clause be expanded into its core forms, perform its static analysis on the result, and finally emit optimized Racket code.\n\nNow, to be fair, syntax/parse is not actually entirely inextensible. While new directives cannot be defined, new patterns can be added through a pattern-expander API that was added to the library after its initial design. However, pattern expanders are still not ideal because they are not ordinary Racket macros—users must explicitly define each pattern expander differently from how they would a macro—and they cannot use existing Racket forms, even ones that would theoretically be compatible with an arbitrary set of core forms.\n\nThe technique described in this blog post avoids all those problems. In the following sections, I’ll show that it’s possible to define an embedded language with a custom set of core forms that works well with the rest of the Racket ecosystem and still permits arbitrary static analysis.\n\nThe need for a custom type language in Hackett\nIn the previous section, I described two use cases for custom core forms. Hackett, in fact, has uses for both of them:\n\n\nHackett can definitely make use of custom core forms to compile to multiple backends. Eventually, it would be nice to compile Hackett to an intermediate language that can target both the Racket runtime and Haskell or GHC Core. This would allow Hackett to take advantage of GHC’s advanced optimizing compiler that already has decades of tuning for a pure, lazy, functional programming language, at the cost of not having access to the rest of Racket’s ecosystem of libraries at runtime.\n\n\nHackett can also make use of custom core forms for an embedded DSL. In this case, that embedded DSL is actually Hackett’s type language.\n\n\nThe second of those two use cases is simpler, and it’s what I ended up implementing first, so it’s what I will focus on in this blog post. Hackett’s type language is fundamentally quite simple, so its set of custom core forms is small as well. Everything in the type language eventually compiles into only seven core forms:\n\n\n(#%type:con id) — Type constructors, like Integer or Maybe. These are one of the fundamental building blocks of Hackett types.\n\n\n(#%type:app type type) — Type application, such as (Maybe Integer). Types are curried, so type constructors that accept multiple arguments are represented by nested uses of #%type:app.\n\n\n(#%type:forall id type) — Universal quantification. This is essentially a binding form, which binds any uses of (#%type:bound-var id) in type.\n\n\n(#%type:qual type type) — Qualified types, aka types with typeclass constraints. Constraints in Hackett, like in GHC, are represented by types, so typeclass names like Eq are bound as type constructors.\n\n\nFinally, Hackett types support three different varieties of type variables:\n\n\n(#%type:bound-var id) — Bound type variables. These are only legal under a corresponding #%type:forall.\n\n\n(#%type:wobbly-var id) — Solver variables, which may unify with any other type as part of the typechecking process.\n\n\n(#%type:rigid-var id) — Rigid variables, aka skolem variables, which only unify with themselves. They represent a unique, anonymous type used to ensure types are suitably polymorphic.\n\n\n\nTo implement our custom core forms in Racket, we need to somehow define them, but how? Intentionally, these should never be expanded, since we want the expander to stop expanding whenever it encounters one of these identifiers. While we can’t encode this directly, we can bind them to macros that do nothing but raise an exception if something attempts to expand them:\n\n(define-syntaxes [#%type:con #%type:app #%type:forall #%type:qual\n                  #%type:bound-var #%type:wobbly-var #%type:rigid-var]\n  (let ([type-literal (λ (stx) (raise-syntax-error #f \"cannot be used as an expression\" stx))])\n    (values type-literal type-literal type-literal type-literal\n            type-literal type-literal type-literal)))\nThis will ensure our core forms are never accidentally expanded, and we’ll instruct the macroexpander to stop whenever it sees one of them via a separate mechanism.\n\nExpanding types in our type language\nWe’ve now defined our core forms, but we’ve intentionally left them meaningless. How do we actually inform the expander about how our types ought to be expanded? While it’s true that we don’t want the core forms themselves to be eliminated, we do want to expand some of their subforms. For example, in the type (#%type:app a b), we want to recursively expand a and b.\n\nIn order to do this, we’ll use the API made available by the expander for manually invoking macroexpansion from within another macro. This API is called local-expand, and it has an option relevant to our needs: the stop list.\n\nOften, local-expand is used to force the expander to completely, recursively expand a form. For example, by using local-expand, we can produce a fragment of a fully-expanded program from a piece of syntax that still includes macros:\n\n(local-expand #'(let ([x 1]) (+ x 2)) 'expression '())\n; => (let-values ([(x) '1]) (#%plain-app + x '2))\nThe third argument to local-expand is the stop list, which controls how deep the expander ought to expand a given form. By providing an empty list, we ask for a complete, recursive expansion. In this case, however, we don’t want a complete expansion! We can inform the expander to stop whenever it sees any of our custom core forms by passing a list of our core form identifiers instead of an empty list:\n\n(begin-for-syntax\n  (define type-literal-ids\n    (list #'#%type:con #'#%type:app #'#%type:forall #'#%type:qual\n          #'#%type:bound-var #'#%type:wobbly-var #'#%type:rigid-var))\n\n  (local-expand #'(#%type:forall x t) 'expression type-literal-ids))\n  ; => (#%type:forall x t)\nOf course, this isn’t very interesting, since it just gives us back exactly what we gave it. It spotted the #%type:forall identifier, which is in our stop list, and immediately halted expansion. It didn’t attempt to continue expanding t since the expander has no way of knowing which pieces of (#%type:forall x t) it should expand! In this case, we want it to recur to expand t, since it should be a type, but not x, since #%type:forall essentially puts x in binding position.\n\nTherefore, we have to get more clever. We need to call local-expand to produce a type, then we have to pattern-match on it and subsequently call local-expand again on any of the pieces of syntax we want to keep expanding. Eventually, we’ll run out of things to expand, and our type will be fully-expanded.\n\nOne good way to do this is to use syntax/parse syntax classes, since they provide a convenient way for other macros to invoke the type expander. To implement our type expander, we’ll use two mutually recursive syntax classes: one to perform the actual expansion using local-expand and a second to pattern-match on the resulting expanded type. For example, here’s what these two classes would look like if they only handled #%type:con and #%type:app:\n\n(begin-for-syntax\n  (define-literal-set type-literals\n    [#%type:con #%type:app #%type:forall #%type:qual\n     #%type:bound-var #%type:wobbly-var #%type:rigid-var])\n\n  (define-syntax-class type\n    #:description \"type\"\n    #:attributes [expansion]\n    [pattern _ #:with :expanded-type\n                      (local-expand this-syntax 'expression type-literal-ids)])\n\n  (define-syntax-class expanded-type\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    #:literal-sets [type-literals]\n    [pattern (#%type:con ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:app ~! a:type b:type)\n             #:attr expansion #'(#%type:app a.expansion b.expansion)]))\nThis blog post is definitely not a syntax/parse tutorial, so I will not explain in detail everything that’s going on here, but the gist of it is that the above code defines two syntax classes, both of which produce a single output attribute named expansion. This attribute contains the fully expanded version of the type currently being parsed. In the #%type:con case, expansion is just this-syntax, which holds the current piece of syntax being parsed. This makes sense, since uses of #%type:con just expand to themselves—expanding (#%type:con Maybe) should not perform any additional expansion on Maybe. This is one of Hackett’s atomic types.\n\nIn contrast, #%type:app does recursively expand its arguments. By annotating its two subforms with :type, the type syntax class will invoke local-expand on each subform, which will in turn use expanded-type to parse the resulting type. This is what implements the expansion loop that will eventually expand each type completely. Once a and b have been expanded, #%type:app reassembles them into a new syntax object using #'(#%type:app a.expansion b.expansion), which replaces their unexpanded versions with their new, expanded versions.\n\nWe can see this behavior by writing a small expand-type function that will expand its argument:\n\n(begin-for-syntax\n  (define expand-type (syntax-parser [t:type #'t.expansion])))\nNow we can use it to observe what happens when we try expanding a type using #%type:app:\n\n(expand-type #'(#%type:app Maybe Integer))\n; => #%type:app: expected type\n;      at: Maybe\n;      in: (#%type:app Maybe Integer)\nOkay, it failed with an error, which is not ideal, but it makes sense. We haven’t actually defined Maybe or Integer anywhere. Let’s do so! We can define them as simple macros that expand into uses of #%type:con, which can be done easily using make-variable-like-transformer from syntax/transformer:\n\n(define-syntax Maybe (make-variable-like-transformer #'(#%type:con Maybe)))\n(define-syntax Integer (make-variable-like-transformer #'(#%type:con Integer)))\nNow, if we try expanding that same type again:\n\n(expand-type #'(#%type:app Maybe Integer))\n; => (#%type:app (#%type:con Maybe) (#%type:con Integer))\n…it works! Neat. Now we just need to add the cases for the remaining forms in our type language:\n\n(begin-for-syntax\n  (define-syntax-class expanded-type\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    #:literal-sets [type-literals]\n    [pattern (#%type:con ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:app ~! a:type b:type)\n             #:attr expansion #'(#%type:app a.expansion b.expansion)]\n    [pattern (#%type:forall ~! x:id t:type)\n             #:attr expansion #'(#%type:forall x t.expansion)]\n    [pattern (#%type:qual ~! a:type b:type)\n             #:attr expansion #'(#%type:qual a.expansion b.expansion)]\n    [pattern (#%type:bound-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:wobbly-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:rigid-var ~! _:id)\n             #:attr expansion this-syntax]))\nThis is pretty good already, and to a first approximation, it’s done! However, it doesn’t actually work as well as we’d really like it to. One of the whole points of doing things this way is to allow other macros like let-syntax to work in types. For example, we ought to be able to create a local type binding with let-syntax and have it just work. Unfortunately, it doesn’t:\n\n(expand-type #'(let-syntax ([Bool (make-variable-like-transformer #'(#%type:con Bool))])\n                 (#%type:app Maybe Bool)))\n; => let-syntax: expected one of these identifiers: `#%type:con', `#%type:app', `#%type:forall', `#%type:qual', `#%type:bound-var', `#%type:wobbly-var', or `#%type:rigid-var'\n;     at: letrec-syntaxes+values\n;     in: (let-syntax ((Bool (make-variable-like-transformer (syntax Bool)))) (#%type:app Maybe Bool))\nWhat went wrong? And why is it complaining about letrec-syntaxes+values? Well, if you read the documentation for local-expand, you’ll find that its behavior is a little more complicated than you might at first believe:\n\nIf stop-ids is [a nonempty list containing more than just module*], then begin, quote, set!, #%plain-lambda, case-lambda, let-values, letrec-values, if, begin0, with-continuation-mark, letrec-syntaxes+values, #%plain-app, #%expression, #%top, and #%variable-reference are implicitly added to stop-ids. Expansion stops when the expander encounters any of the forms in stop-ids, and the result is the partially-expanded form.\n\nThat’s a little strange, isn’t it? I am not completely sure why the behavior works quite this way, though I’m sure backwards compatibility plays a significant part, but while some of the behavior seems unnecessary, the issue with letrec-syntaxes+values (which let-syntax expands to) is a reasonable one. If the expander naïvely expanded letrec-syntaxes+values in the presence of a nonempty stop list, it could cause some significant problems!\n\nAllow me to illustrate with an example. Let’s imagine we are the expander, and we are instructed to expand the following program:\n\n(let-syntax ([Bool (make-variable-like-transformer #'(#%type:con Bool))])\n  (#%type:app Maybe Bool))\nWe see let-syntax, so we start by evaluating the expression on the right hand side of the Bool binding. This produces a transformer expression, so we bind Bool to the transformer in the local environment, then move onto expanding the body. At this point, the expander is looking at this:\n\n; local bindings:\n;   Bool -> #<variable-like-transformer>\n(#%type:app Maybe Bool)\nNow, the identifier in application position is #%type:app, and #%type:app is in the stop list. Therefore, expansion must stop, and it does not attempt to expand any further. But what should the result of expansion be? Well, the let-syntax needs to go away when we expand it—local syntax bindings are erased as part of macroexpansion—so the logical thing to expand into is (#%type:app Maybe Bool). But this is a problem, because when we then go to expand Bool, Bool isn’t in the local binding table anymore! The let-syntax was already erased, and Bool is unbound!\n\nWhen expanding recursively, this isn’t a problem, since the entire expression is guaranteed to be expanded while the local binding is still in the expander’s environment. As soon as we introduce partial expansion, however, we run the risk of a binding getting erased too early. So we’re stuck: we can’t recursively expand, or we’ll expand too much, but we can’t partially expand, since we might expand too little.\n\nConfronted with this problem, there is some good news and some bad news. The good news is that, while the macroexpander can’t help us, we can help the macroexpander by doing some of the necessary bookkeeping for it. We can do this using first-class definition contexts, which allow us to manually extend the local environment when we call local-expand. The bad news is that first-class definition contexts are complicated, and using them properly is a surprisingly subtle problem.\n\nFortunately, I’ve already spent a lot of time figuring out what needs to be done to properly manipulate the necessary definition contexts in this particular situation. The first step is to parameterize our type and expanded-type syntax classes so that we may thread a definition context around as we recursively expand:\n\n(begin-for-syntax\n  (define-syntax-class (type [intdef-ctx #f])\n    #:description \"type\"\n    #:attributes [expansion]\n    [pattern _ #:with {~var || (expanded-type intdef-ctx)}\n                      (local-expand this-syntax 'expression type-literal-ids intdef-ctx)])\n\n  (define-syntax-class (expanded-type intdef-ctx)\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    #:literal-sets [type-literals]\n    [pattern (#%type:con ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:app ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion #'(#%type:app a.expansion b.expansion)]\n    [pattern (#%type:forall ~! x:id {~var t (type intdef-ctx)})\n             #:attr expansion #'(#%type:forall x t.expansion)]\n    [pattern (#%type:qual ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion #'(#%type:qual a.expansion b.expansion)]\n    [pattern (#%type:bound-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:wobbly-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:rigid-var ~! _:id)\n             #:attr expansion this-syntax]))\nNow, we can add an additional case to expanded-type to handle letrec-syntaxes+values, which will explicitly create a new definition context, add bindings to it, and use it when parsing the body:\n\n[pattern (letrec-syntaxes+values ~! ([(id:id ...) e:expr] ...) () t:expr)\n         #:do [(define intdef-ctx* (syntax-local-make-definition-context))\n               (for ([ids (in-list (attribute id))]\n                     [e (in-list (attribute e))])\n                 (syntax-local-bind-syntaxes ids e intdef-ctx*))]\n         #:with {~var t* (type intdef-ctx*)} #'t\n         #:attr expansion #'t*.expansion]\nBut even this isn’t quite right. The problem with this implementation is that it throws away the existing intdef-ctx argument to expanded-type, which means those bindings will be lost as soon as we introduce a new set. To fix this, we have to make the new definition context a child of the previous definition context by passing the old context as an argument to syntax-local-make-definition-context. This will ensure the parent bindings are brought into scope when expanding using the child context:\n\n[pattern (letrec-syntaxes+values ~! ([(id:id ...) e:expr] ...) () t:expr)\n         #:do [(define intdef-ctx* (syntax-local-make-definition-context intdef-ctx))\n               (for ([ids (in-list (attribute id))]\n                     [e (in-list (attribute e))])\n                 (syntax-local-bind-syntaxes ids e intdef-ctx*))]\n         #:with {~var t* (type intdef-ctx*)} #'t\n         #:attr expansion #'t*.expansion]\nWith this in place, our example using let-syntax actually works!\n\n(expand-type #'(let-syntax ([Bool (make-variable-like-transformer #'(#%type:con Bool))])\n                 (#%type:app Maybe Bool)))\n; => (#%type:app (#%type:con Maybe) (#%type:con Bool))\nPretty cool, isn’t it?\n\nPreserving syntax properties and source locations\nWe’ve now managed to essentially implement an expander for our custom language by periodically yielding to the Racket macroexpander, and for the most part, it works. However, our implementation isn’t perfect. The real Racket macroexpander takes great care to preserve source locations and syntax properties on syntax objects wherever possible, which our implementation does not do. Normally we don’t have to worry so much about such things, since the macroexpander automatically copies properties when expanding macros, but since we’re circumventing the expander, we don’t get that luxury. In order to properly preserve this information, we’ll have to be a little more careful.\n\nTo start, we really ought to copy the identifier in application position into the output wherever we can. In addition to preserving source location information and syntax properties, it also preserves the even more visible renamings. For example, if a user imports #%type:app under a different name, like #%type:apply, we should expand to a piece of syntax that still has #%type:apply in application position instead of replacing it with #%type:app.\n\nTo do this, we just need to bind each of the identifiers in application position, then use that binding when we produce output. For example, we would adjust the #%type:app clause to the following:\n\n[pattern (head:#%type:app ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n         #:attr expansion #'(head a.expansion b.expansion)]\nBut even after doing this, some source locations and syntax properties are lost, since we’re still reconstructing the pair from scratch. To ensure we copy everything, we can define two helper macros, syntax/loc/props and quasisyntax/loc/props, which are like syntax/loc and quasisyntax/loc but copy properties in addition to source location information:\n\n(begin-for-syntax\n  (define-syntaxes [syntax/loc/props quasisyntax/loc/props]\n    (let ()\n      (define (make-syntax/loc/props name syntax-id)\n        (syntax-parser\n          [(_ from-stx-expr:expr {~describe \"template\" template})\n           #`(let ([from-stx from-stx-expr])\n               (unless (syntax? from-stx)\n                 (raise-argument-error '#,name \"syntax?\" from-stx))\n               (let* ([stx (#,syntax-id template)]\n                      [stx* (syntax-disarm stx #f)])\n                 (syntax-rearm (datum->syntax stx* (syntax-e stx*) from-stx from-stx) stx)))]))\n      (values (make-syntax/loc/props 'syntax/loc/props #'syntax)\n              (make-syntax/loc/props 'quasisyntax/loc/props #'quasisyntax)))))\nUsing syntax/loc/props, we can be truly thorough about ensuring all properties are preserved:\n\n[pattern (head:#%type:app ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n         #:attr expansion (syntax/loc/props this-syntax\n                            (head a.expansion b.expansion))]\nApplying this to the other relevant clauses, we get an updated version of the expanded-type syntax class:\n\n(begin-for-syntax\n  (define-syntax-class (expanded-type intdef-ctx)\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    #:literal-sets [kernel-literals type-literals]\n    [pattern (letrec-syntaxes+values ~! ([(id:id ...) e:expr] ...) () t:expr)\n             #:do [(define intdef-ctx* (syntax-local-make-definition-context intdef-ctx))\n                   (for ([ids (in-list (attribute id))]\n                         [e (in-list (attribute e))])\n                     (syntax-local-bind-syntaxes ids e intdef-ctx*))]\n             #:with {~var t* (type intdef-ctx*)} #'t\n             #:attr expansion #'t*.expansion]\n    [pattern (#%type:con ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (head:#%type:app ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head a.expansion b.expansion))]\n    [pattern (head:#%type:forall ~! x:id {~var t (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head x t.expansion))]\n    [pattern (head:#%type:qual ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head a.expansion b.expansion))]\n    [pattern (#%type:bound-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:wobbly-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:rigid-var ~! _:id)\n             #:attr expansion this-syntax]))\nNow we’re getting closer, but if you can believe it, even this isn’t good enough. The real expander’s implementation of letrec-syntaxes+values does two things our implementation does not: it copies properties and updates the 'origin property to indicate the syntax came from a use of letrec-syntaxes+values, and it adds a 'disappeared-use property to record the erased bindings for use by tools like DrRacket. We can apply syntax-track-origin and internal-definition-context-track to the resulting syntax to add the same properties the expander would:\n\n[pattern (head:letrec-syntaxes+values ~! ([(id:id ...) e:expr] ...) () t:expr)\n         #:do [(define intdef-ctx* (syntax-local-make-definition-context intdef-ctx))\n               (for ([ids (in-list (attribute id))]\n                     [e (in-list (attribute e))])\n                 (syntax-local-bind-syntaxes ids e intdef-ctx*))]\n         #:with {~var t* (type intdef-ctx*)} #'t\n         #:attr expansion (~> (internal-definition-context-track intdef-ctx* #'t*.expansion)\n                              (syntax-track-origin this-syntax #'head))]\nNow we’ve finally dotted all our i’s and crossed our t’s. While it does take a lot to properly emulate what the macroexpander is doing, the important thing is that it’s actually possible! The end result of all this definition context juggling and property copying is that we’ve effectively managed to move some of the macroexpander’s logic into userspace code, which allows us to manipulate it as we see fit.\n\nConnecting our custom language to Hackett\nIt took a lot of work, but we finally managed to write a custom type language, and while the code is not exactly simple, it’s not actually very long. The entire implementation of our custom type language is less than 80 lines of code:\n\n#lang racket/base\n\n(require (for-meta 2 racket/base\n                     syntax/parse)\n         (for-syntax racket/base\n                     syntax/intdef\n                     threading)\n         syntax/parse/define)\n\n(begin-for-syntax\n  (define-syntaxes [syntax/loc/props quasisyntax/loc/props]\n    (let ()\n      (define (make-syntax/loc/props name syntax-id)\n        (syntax-parser\n          [(_ from-stx-expr:expr {~describe \"template\" template})\n           #`(let ([from-stx from-stx-expr])\n               (unless (syntax? from-stx)\n                 (raise-argument-error '#,name \"syntax?\" from-stx))\n               (let* ([stx (#,syntax-id template)]\n                      [stx* (syntax-disarm stx #f)])\n                 (syntax-rearm (datum->syntax stx* (syntax-e stx*) from-stx from-stx) stx)))]))\n      (values (make-syntax/loc/props 'syntax/loc/props #'syntax)\n              (make-syntax/loc/props 'quasisyntax/loc/props #'quasisyntax)))))\n\n(define-syntaxes [#%type:con #%type:app #%type:forall #%type:qual\n                  #%type:bound-var #%type:wobbly-var #%type:rigid-var]\n  (let ([type-literal (λ (stx) (raise-syntax-error #f \"cannot be used as an expression\" stx))])\n    (values type-literal type-literal type-literal type-literal\n            type-literal type-literal type-literal)))\n\n(begin-for-syntax\n  (define type-literal-ids\n    (list #'#%type:con #'#%type:app #'#%type:forall #'#%type:qual\n          #'#%type:bound-var #'#%type:wobbly-var #'#%type:rigid-var))\n\n  (define-literal-set type-literals\n    [#%type:con #%type:app #%type:forall #%type:qual\n     #%type:bound-var #%type:wobbly-var #%type:rigid-var])\n\n  (define-syntax-class (type [intdef-ctx #f])\n    #:description \"type\"\n    #:attributes [expansion]\n    [pattern _ #:with {~var || (expanded-type intdef-ctx)}\n                      (local-expand this-syntax 'expression type-literal-ids intdef-ctx)])\n\n  (define-syntax-class (expanded-type intdef-ctx)\n    #:description #f\n    #:attributes [expansion]\n    #:commit\n    #:literal-sets [kernel-literals type-literals]\n    [pattern (head:letrec-syntaxes+values ~! ([(id:id ...) e:expr] ...) () t:expr)\n             #:do [(define intdef-ctx* (syntax-local-make-definition-context intdef-ctx))\n                   (for ([ids (in-list (attribute id))]\n                         [e (in-list (attribute e))])\n                     (syntax-local-bind-syntaxes ids e intdef-ctx*))]\n             #:with {~var t* (type intdef-ctx*)} #'t\n             #:attr expansion (~> (internal-definition-context-track intdef-ctx* #'t*.expansion)\n                                  (syntax-track-origin this-syntax #'head))]\n    [pattern (#%type:con ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (head:#%type:app ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head a.expansion b.expansion))]\n    [pattern (head:#%type:forall ~! x:id {~var t (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head x t.expansion))]\n    [pattern (head:#%type:qual ~! {~var a (type intdef-ctx)} {~var b (type intdef-ctx)})\n             #:attr expansion (syntax/loc/props this-syntax\n                                (head a.expansion b.expansion))]\n    [pattern (#%type:bound-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:wobbly-var ~! _:id)\n             #:attr expansion this-syntax]\n    [pattern (#%type:rigid-var ~! _:id)\n             #:attr expansion this-syntax])\n\n  (define expand-type (syntax-parser [t:type #'t.expansion])))\nBut what now? Just as Racket fully-expanded programs are useless without a compiler to turn them into something useful, our custom type language doesn’t do anything at all in isolation. As it happens, in the case of the type language, we don’t have a compiler at all—we have a typechecker. The Hackett typechecker consumes fully-expanded types as input and uses them to perform its typechecking process. The actual implementation of Hackett’s typechecker is outside the scope of this blog post, since it’s really an entirely separate problem, but you can probably imagine what such a thing might look like, in an extremely vague, handwavy sense.\n\nBut we don’t just need a typechecker. Just as the authors of Racket don’t expect users to write programs using the core forms directly, we also don’t expect users to write their types using the fully-expanded syntax. If we did, all this fancy expansion machinery would be pretty pointless! Hackett provides a custom #%app binding that converts n-ary type applications to nested uses of #%type:app, as well as a nicer forall macro that supports specifying multiple type variables and multiple typeclass constraints all at once. The best part, though, is that these macros can be defined in a completely straightforward way, just as any ordinary Racket macro would be written, and the machinery will work precisely as intended. It’s also perfectly okay to have two different versions of #%app—one for types and one for values—since Hackett supports multiple namespaces, and each can have its own #%app binding.\n\nThe real implementation of Hackett’s type language is a little bit longer than the one in this blog post because it includes some extra definitions to provide custom syntax/parse pattern expanders for matching types and some template metafunctions for producing them, which are used by the typechecker, but if you’d like to see the whole thing, it’s available on GitHub here.\n\nEvaluation, limitations, and acknowledgements\nReimplementing Hackett’s type language took about a week and a half, about half of which was supplemented by the extra time I had before I started my new job this past week. A portion of that time was spent deciding what I actually wanted to do, and a lot of it was spent hunting down fiddly bugs. All told, the rewrite resulted in a net addition of 250 lines of code to the Hackett codebase. However, 350 of the added lines reside in a new, self-contained module dedicated to Hackett’s type language, so the change actually resulted in a net removal of 100 lines from the rest of the codebase, which I consider an organizational win.\n\nAs for whether or not the change will accomplish the goals I had in mind, I think signs currently point to a strong likelihood of the answer being yes. The very same night I finalized and merged the changes to the type language, I dusted off an old prototype of typeclass deriving I had not been able to get working due to insufficiencies of the old type representation. Not only was I able to get it working quickly and easily, I was able to do it in no more than 20 lines of code. While the implementation is not as robust as it should ideally be, nor is it safe or simple enough yet to be easy for Hackett users to write themselves, making the impossible possible is usually a sign of motion in the right direction.\n\nUnfortunately, the technique outlined in this blog post is not completely flawless. Due to its reliance on the local-expand stop list, this technique is incompatible with macros that force recursive expansion using an empty stop list. In the upcoming reimplementation of the Racket macroexpander to be released in Racket 7, this includes syntax-parameterize, which unfortunately means syntax parameters don’t work in the type language. This is a problem, and while it’s not a dealbreaker, it is something that will almost certainly have to be fixed at some point. Fortunately, it isn’t intractable, and I’ve been discussing some potential approaches to fixing the problem, whether via changes to the macroexpander or by making macros like syntax-parameterize cooperate better with things like Hackett’s type language.\n\nFinally, as seems to be the case more and more with my blog posts, I cannot express enough thanks to Matthew Flatt, without whose help I would probably not have been able to get everything working (not to mention that the Racket macro system would not exist without Matthew inventing and implementing it nearly singlehandedly). Matthew does an almost unfathomable number of things for Racket already without me pestering him with questions, bug reports, and feature requests, but he’s always patient and helpful all the same. Also, once again, I’d like to thank Ryan Culpepper for his incredible work on constructing tools for the working macro developer, including writing the fantastic syntax/parse library that powers essentially everything I do. Thank you both.","isoDate":"2018-04-15T00:00:00.000Z","timestamp":"4/14/2018"},{"title":"An opinionated guide to Haskell in 2018","pubDate":"2018-02-10T00:00:00.000Z","author":"Alexis King","content":"<article><p>For me, this month marks the end of an era in my life: as of February 2018, I am no longer employed writing Haskell. It’s been a fascinating two years, and while I am excitedly looking forward to what I’ll be doing next, it’s likely I will continue to write Haskell in my spare time. I’ll probably even write it again professionally in the future.\n</p><p>In the meantime, in the interest of both sharing with others the small amount of wisdom I’ve gained and preserving it for my future self, I’ve decided to write a long, rather dry overview of a few select parts of the Haskell workflow I developed and the ecosystem I settled into. This guide is, as the title notes, <em>opinionated</em>—it is what I used in my day-to-day work, nothing more—and I don’t claim that anything here is the only way to write Haskell, nor even the best way. It is merely what I found helpful and productive. Take from it as much or as little as you’d like.\n</p><h2><a name=\"build-tools-and-how-to-use-them\"></a>Build tools and how to use them</h2><p>When it comes to building Haskell, you have options. And frankly, most of them are pretty good. There was a time when <code>cabal-install</code> had a (warranted) reputation for being nearly impossible to use and regularly creating dependency hell, but I don’t think that’s the case anymore (though you <em>do</em> need to be a little careful about how you use it). Sandboxed builds work alright, and <code>cabal new-build</code> and the other <code>cabal new-*</code> commands are even better. That said, the UX of <code>cabal-install</code> is still less-than-stellar, and it has sharp edges, especially for someone coming from an ecosystem without a heavyweight compilation process like JavaScript, Ruby, or Python.\n</p><p>Nix is an alternative way to manage Haskell dependencies, and it seems pretty cool. It has a reputation for being large and complicated, and that reputation does not seem especially unfair, but you get lots of benefits if you’re willing to pay the cost. Unfortunately, I have never used it (though I’ve read a lot about it), so I can’t comment much on it here. Perhaps I’ll try to go all-in with Nix when I purchase my next computer, but for now, my workflow works well enough that I don’t feel compelled to switch.\n</p><p>Personally, I use <code>stack</code> as my Haskell build tool. It’s easy to use, it works out of the box, and while it doesn’t enjoy the same amount of caching as <code>cabal new-build</code> or Nix, it caches most packages, and it also makes things like git-hosted sources incredibly easy, which (as far as I can tell) can’t be done with <code>cabal-install</code> alone.\n</p><p>This section is going to be a guide on how <em>I</em> use <code>stack</code>. If you use <code>cabal-install</code> with or without Nix, great! Those tools seem good, too. This is not an endorsement of <code>stack</code> over the other build tools, just a description of how I use it, the issues I ran into, and my solutions to them.\n</p><h3><a name=\"understanding-stack-s-model-and-avoiding-its-biggest-gotcha\"></a>Understanding <code>stack</code>’s model and avoiding its biggest gotcha</h3><p>Before using <code>stack</code>, there are a few things every programmer should know:\n</p><ul><li><p><code>stack</code> is not a package manager, it is a build tool. It does not manage a set of “installed” packages; it simply builds targets and their dependencies.\n</p></li><li><p>The command to build a target is <code>stack build &lt;target&gt;</code>. Just using <code>stack build</code> on its own will build the current project’s targets.\n</p></li><li><p><strong>You almost certainly do not want to use <code>stack install</code>.</strong>\n</p></li></ul><p>This is the biggest point of confusion I see among new users of <code>stack</code>. After all, when you want to install a package with <code>npm</code>, you type <code>npm install &lt;package&gt;</code>. So a new Haskeller decides to install <code>lens</code>, types <code>stack install lens</code>, and then later tries <code>stack uninstall lens</code>, only to discover that no such command exists. What happened?\n</p><p><code>stack install</code> is not like <code>npm install</code>. <code>stack install</code> is like <code>make install</code>. It is nothing more than an alias for <code>stack build --copy-bins</code>, and <em>all</em> it does is build the target and copy all of its executables into some relatively global location like <code>~/.local/bin</code>. This is usually not what you want.\n</p><p>This design decision is not unique to <code>stack</code>; <code>cabal-install</code> suffers from it as well. One can argue that it isn’t unintuitive because it really is just following what <code>make install</code> conventionally does, and the fact that it happens to conflict with things like <code>npm install</code> or even <code>apt-get install</code> is just a naming clash. I think that argument is a poor one, however, and I think the decision to even include a <code>stack install</code> command was a bad idea.\n</p><p>So, remember: don’t use <code>stack install</code>! <code>stack</code> works best when everything lives inside the current project’s <em>local</em> sandbox, and <code>stack install</code> copies executables into a <em>global</em> location by design. While it might sometimes appear to work, it’s almost always wrong. The <em>only</em> situation in which <code>stack install</code> is the right answer is when you want to install an executable for a use unrelated to Haskell development (that is, something like <code>pandoc</code>) that just so happens to be provided by a Haskell package. <strong>This means no running <code>stack install ghc-mod</code> or <code>stack install intero</code> either, no matter what READMEs might tell you!</strong> Don’t worry: I’ll cover the proper way to install those things later.\n</p><h3><a name=\"actually-building-your-project-with-stack\"></a>Actually building your project with <code>stack</code></h3><p>Okay, so now that you know to never use <code>stack install</code>, what <em>do</em> you use? Well, <code>stack build</code> is probably all you need. Let’s cover some variations of <code>stack build</code> that I use most frequently.\n</p><p>Once you have a <code>stack</code> project, you can build it by simply running <code>stack build</code> within the project directory. However, for local development, this is usually unnecessarily slow because it runs the GHC optimizer. For faster development build times, pass the <code>--fast</code> flag to disable optimizations:\n</p><pre><code>$ stack build --fast\n</code></pre><p>By default, <code>stack</code> builds dependencies with coarse-grained, package-level parallelism, but you can enable more fine-grained, module-level parallel builds by adding <code>--ghc-options=-j</code>. Unfortunately, there are conflicting accounts on whether or not this actually makes things faster or slower in practice, and I haven’t extensively tested to see whether or not this is the case, so I mostly leave it off.\n</p><p>Usually, you also want to build and run the tests along with your code, which you can enable with the <code>--test</code> flag. Additionally, <code>stack test</code> is an alias for <code>stack build --test</code>, so these two commands are equivalent:\n</p><pre><code>$ stack build --fast --test\n$ stack test --fast\n</code></pre><p>Also, it is useful to build documentation as well as code! You can do this by passing the <code>--haddock</code> flag, but unfortunately, I find Haddock sometimes takes an unreasonably long time to run. Therefore, since I usually only care about running Haddock on my dependencies, I usually pass the <code>--haddock-deps</code> flag instead, which prevents having to re-run Haddock every time you build:\n</p><pre><code>$ stack test --fast --haddock-deps\n</code></pre><p>Finally, I usually want to build and test my project in the background whenever my code changes. Fortunately, this can be done easily by using the <code>--file-watch</code> flag, making it easy to incrementally change project code and immediately see results:\n</p><pre><code>$ stack test --fast --haddock-deps --file-watch\n</code></pre><p>This is the command I usually use to develop my Haskell projects.\n</p><h3><a name=\"accessing-local-documentation\"></a>Accessing local documentation</h3><p>While Haskell does not always excel on the documentation front, a small amount of documentation is almost always better than no documentation at all, and I find my dependencies’ documentation to be an invaluable resource while developing. I find many people just look at docs on Hackage or use the hosted instance of Hoogle, but this sometimes leads people astray: they might end up looking at the wrong version of the documentation! Fortunately, there’s an easy solution to this problem, which is to browse the documentation <code>stack</code> installs locally, which is guaranteed to match the version you are using in your current project.\n</p><p>The easiest way to open local documentation for a particular package is to use the <code>stack haddock --open</code> command. For example, to open the documentation for <code>lens</code>, you could use the following command:\n</p><pre><code>$ stack haddock --open lens\n</code></pre><p>This will open the local documentation in your web browser, and you can browse it at your leisure. If you have already built the documentation using the <code>--haddock-deps</code> option I recommended in the previous section, this command should complete almost instantly, but if you haven’t built the documentation yet, you’ll have to wait as <code>stack</code> builds it for you on-demand.\n</p><p>While this is a good start, it isn’t perfect. Ideally, I want to have <em>searchable</em> documentation, and fortunately, this is possible to do by running Hoogle locally. This is easy enough with modern versions of <code>stack</code>, which have built-in Hoogle integration, but it still requires a little bit of per-project setup, since you need to build the Hoogle search index with the following command:\n</p><pre><code>$ stack hoogle -- generate --local\n</code></pre><p>This will install Hoogle into the current project if it isn’t already installed, and it will index your dependencies’ documentation and generate a new Hoogle database. Once you’ve done that, you can start a web server that serves a local Hoogle search page with the following command:\n</p><pre><code>$ stack hoogle -- server --local --port=8080\n</code></pre><p>Navigate to <code>http://localhost:8080</code> in your web browser, and you’ll have a fully-searchable index of all your Haskell packages’ documentation. Isn’t that neat?\n</p><p>Unfortunately, you <em>will</em> have to manually regenerate the Hoogle database when you install new packages and their documentation, which you can do by re-running <code>stack hoogle -- generate --local</code>. Fortunately, regenerating the database doesn’t take very long, as long as you’ve been properly rebuilding the documentation with <code>--haddock-deps</code>.\n</p><h3><a name=\"configuring-your-project\"></a>Configuring your project</h3><p>Every project built with <code>stack</code> is configured with two separate files:\n</p><ul><li><p>The <code>stack.yaml</code> file, which controls which packages are built and what versions to pin your dependencies to.\n</p></li><li><p>The <code>&lt;project&gt;.cabal</code> file <em>or</em> <code>package.yaml</code> file, which specifies build targets, their dependencies, and which GHC options to apply, among other things.\n</p></li></ul><p>The <code>.cabal</code> file is, ultimately, what is used to build your project, but modern versions of <code>stack</code> generate projects that use hpack, which uses an alternate configuration file, the <code>package.yaml</code> file, to generate the <code>.cabal</code> file. This can get a little bit confusing, since it means you have <em>three</em> configuration files in your project, one of which is generated from the other one.\n</p><p>I happen to use and like hpack, so I use a <code>package.yaml</code> file and allow hpack to generate the <code>.cabal</code> file. I have no real love for YAML, and in fact I think custom configuration formats are completely fine, but the primary advantage of hpack is the ability to specify things like GHC options and default language extensions for all targets at once, instead of needing to duplicate them per-target.\n</p><p>You can think of the <code>.cabal</code> or <code>package.yaml</code> file as a specification for <em>how</em> your project is built and <em>what packages</em> it depends on, but the <code>stack.yaml</code> file is a specification of precisely <em>which version</em> of each package should be used and where it should be fetched from. Also, each <code>.cabal</code> file corresponds to precisely <em>one</em> Haskell package (though it may have any number of executable targets), but a <code>stack.yaml</code> file can specify multiple different packages to build, useful for multi-project builds that share a common library. The details here can be a little confusing, more than I am likely going to be able to explain in this blog post, but for the most part, you can get away with the defaults unless you’re doing something fancy.\n</p><h3><a name=\"setting-up-editor-integration\"></a>Setting up editor integration</h3><p>Currently, I use Atom to write Haskell. Atom is not a perfect editor by any means, and it leaves a lot to be desired, but it’s easy to set up, and the Haskell editor integration is decent.\n</p><p>Atom’s editor integration is powered by <code>ghc-mod</code>, a program that uses the GHC API to provide tools to inspect Haskell programs. Installing <code>ghc-mod</code> must be done manually so that Atom’s <code>haskell-ghc-mod</code> package can find it, and this is where a lot of people get tripped up. They run <code>stack install ghc-mod</code>, it installs <code>ghc-mod</code> into <code>~/.local/bin</code>, they put that in their <code>PATH</code>, and things work! …except when a new version of GHC is released a few months later, everything stops working.\n</p><p>As mentioned above, <strong><code>stack install</code> is not what you want</strong>. Tools like <code>ghc-mod</code>, <code>hlint</code>, <code>hoogle</code>, <code>weeder</code>, and <code>intero</code> work best when installed as part of the sandbox, <em>not</em> globally, since that ensures they will match the current GHC version your project is using. This can be done per-project using the ordinary <code>stack build</code> command, so the easiest way to properly install <code>ghc-mod</code> into a <code>stack</code> project is with the following command:\n</p><pre><code>$ stack build ghc-mod\n</code></pre><p>Unfortunately, this means you will need to run that command inside every single <code>stack</code> project individually in order to properly set it up so that <code>stack exec -- ghc-mod</code> will find the correct executable. One way to circumvent this is by using a recently-added <code>stack</code> flag designed for this explicit purpose, <code>--copy-compiler-tool</code>. This is like <code>--copy-bins</code>, but it copies the executables into a <em>compiler-specific location</em>, so a tool built for GHC 8.0.2 will be stored separately from the same tool built for GHC 8.2.2. <code>stack exec</code> arranges for the executables for the current compiler version to end up in the <code>PATH</code>, so you only need to build and install your tools once per compiler version.\n</p><p>Does this kind of suck? Yes, a little bit, but it sucks a whole lot less than all your editor integration breaking every time you switch to a project that uses a different version of GHC. I use the following command in a fresh sandbox when a Stackage LTS comes out for a new version of GHC:\n</p><pre><code>$ stack build --copy-compiler-tool ghc-mod hoogle weeder\n</code></pre><p>This way, I only have to build those tools once, and I don’t worry about rebuilding them again until a the next release of GHC. To verify that things are working properly, you should be able to create a fresh <code>stack</code> project, run a command like this one, and get a similar result:\n</p><pre><code>$ stack exec -- which ghc-mod\n/Users/alexis/.stack/compiler-tools/x86_64-osx/ghc-8.2.2/bin/ghc-mod\n</code></pre><p>Note that this path is scoped to my operating system and my compiler version, but nothing else—no LTS or anything like that.\n</p><h2><a name=\"warning-flags-for-a-safe-build\"></a>Warning flags for a safe build</h2><p>Haskell is a relatively strict language as programming languages go, but in my experience, it isn’t quite strict enough. Many things are not errors that probably ought to be, like orphan instances and inexhaustive pattern matches. Fortunately, GHC provides <em>warnings</em> that catch these problems statically, which fill in the gaps. I recommend using the following flags on all projects to ensure everything is caught:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wcompat\"><code>-Wcompat</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-record-updates\"><code>-Wincomplete-record-updates</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-uni-patterns\"><code>-Wincomplete-uni-patterns</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wredundant-constraints\"><code>-Wredundant-constraints</code></a>\n</p></li></ul><p>The <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a> option turns on <em>most</em> warnings, but (ironically) not all of them. The <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Weverything\"><code>-Weverything</code></a> flag truly turns on <em>all</em> warnings, but some of the warnings left disabled by <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a> really are quite silly, like warning when type signatures on polymorphic local bindings are omitted. Some of them, however, are legitimately useful, so I recommend turning them on explicitly.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wcompat\"><code>-Wcompat</code></a> enables warnings that make your code more robust in the face of future backwards-incompatible changes. These warnings are trivial to fix and serve as free future-proofing, so I see no reason not to turn these warnings on.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-record-updates\"><code>-Wincomplete-record-updates</code></a> and <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-uni-patterns\"><code>-Wincomplete-uni-patterns</code></a> are things I think ought to be enabled by <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a> because they both catch what are essentially partial pattern-matches (and therefore runtime errors waiting to happen). The fact that <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-uni-patterns\"><code>-Wincomplete-uni-patterns</code></a> <em>isn’t</em> enabled by <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a> is so surprising that it can lead to bugs being overlooked, since the extremely similar <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wincomplete-patterns\"><code>-Wincomplete-patterns</code></a> <em>is</em> enabled by <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wall\"><code>-Wall</code></a>.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Wredundant-constraints\"><code>-Wredundant-constraints</code></a> is a useful warning that helps to eliminate unnecessary typeclass constraints on functions, which can sometimes occur if a constraint was previously necessary but ends up becoming redundant due to a change in the function’s behavior.\n</p><p>I put all five of these flags in the <code>.cabal</code> file (or <code>package.yaml</code>), which enables them everywhere, but this alone is unlikely to enforce a warning-free codebase, since the build will still succeed even in the presence of warnings. Therefore, when building projects in CI, I pass the <a href=\"https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-warnings.html#ghc-flag--Werror\"><code>-Werror</code></a> flag (using <code>--ghc-options=-Werror</code> for <code>stack</code>), which treats warnings as errors and halts the build if any warnings are found. This is useful, since it means warnings don’t halt the whole build while developing, making it possible to write some code that has warnings and still run the test suite, but it still enforces that pushed code be warning-free.\n</p><h2><a name=\"any-flavor-you-like\"></a>Any flavor you like</h2><p>Haskell is both a language and a spectrum of languages. It is both a standard and a specific implementation. Haskell 98 and Haskell 2010 are good, small languages, and there are a few different implementations, but when people talk about “Haskell”, unqualified, they’re almost always talking about GHC.\n</p><p>GHC Haskell, in stark contrast to standard Haskell, is neither small nor particularly specific, since GHC ships with <em>dozens</em> of knobs and switches that can be used to configure the language. In theory, this is a little terrifying. How could anyone ever hope to talk about Haskell and agree upon how to write it if there are so many <em>different</em> Haskells, each a little bit distinct? Having a cohesive ecosystem would be completely hopeless.\n</p><p>Fortunately, in practice, this is not nearly as bad as it seems. The majority of GHC extensions are simple switches: a feature is either on or it is off. Turning a feature on rarely affects code that does not use it, so most extensions can be turned on by default, and programmers may simply avoid the features they do not wish to use, just as any programmer in any programming language likely picks a subset of their language’s features to use on a daily basis. Writing Haskell is not different in this regard, only in the sense that it does not allow all features to be used by default; everything from minor syntactic tweaks to entirely new facets of the type system are opt-in.\n</p><p>Frankly, I think the UX around this is terrible. I recognize the desire to implement a standard Haskell, and the old <code>-fglasgow-exts</code> was not an especially elegant solution for people wishing to use nonstandard Haskell, but having to insert <code>LANGUAGE</code> pragmas at the top of every module just to take advantage of the best features GHC has to offer is a burden, and it is unnecessarily intimidating. I think much of the Haskell community finds the use of <code>LANGUAGE</code> pragmas preferable to enabling extensions globally using the <code>default-extensions</code> list in the <code>.cabal</code> file, but I cut across the grain on that issue <em>hard</em>. The vast majority of language extensions I use are extensions I want enabled all the time; a list of them at the top of a module is just distracting noise, and it only serves to bury the extensions I really do want to enable on a module-by-module basis. It also makes it tricky to communicate with a team which extensions are acceptable (or even preferable) and which are discouraged.\n</p><p>My <strong><em>strong</em></strong> recommendation if you decide to write GHC Haskell on a team is to agree as a group to a list of extensions the team is happy with enabling everywhere and putting those extensions in the <code>default-extensions</code> list in the <code>.cabal</code> file. This eliminates clutter, busywork, and the conceptual overhead of remembering which extensions are in favor, and which are discouraged. This is a net win, and it isn’t at all difficult to look in the <code>.cabal</code> file when you want to know which extensions are in use.\n</p><p>Now, with that small digression out of the way, the question becomes precisely which extensions should go into that <code>default-extensions</code> list. I happen to like using most of the features GHC makes available, so I enable a whopping <strong>34</strong> language extensions <em>by default</em>. As of GHC 8.2, here is my list:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XBangPatterns\"><code>BangPatterns</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XConstraintKinds\"><code>ConstraintKinds</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDataKinds\"><code>DataKinds</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDefaultSignatures\"><code>DefaultSignatures</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveFoldable\"><code>DeriveFoldable</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveFunctor\"><code>DeriveFunctor</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveGeneric\"><code>DeriveGeneric</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveLift\"><code>DeriveLift</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveTraversable\"><code>DeriveTraversable</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDerivingStrategies\"><code>DerivingStrategies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XEmptyCase\"><code>EmptyCase</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XExistentialQuantification\"><code>ExistentialQuantification</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleContexts\"><code>FlexibleContexts</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleInstances\"><code>FlexibleInstances</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFunctionalDependencies\"><code>FunctionalDependencies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGeneralizedNewtypeDeriving\"><code>GeneralizedNewtypeDeriving</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XInstanceSigs\"><code>InstanceSigs</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures\"><code>KindSignatures</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XLambdaCase\"><code>LambdaCase</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiParamTypeClasses\"><code>MultiParamTypeClasses</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiWayIf\"><code>MultiWayIf</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XNamedFieldPuns\"><code>NamedFieldPuns</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XPatternSynonyms\"><code>PatternSynonyms</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XRankNTypes\"><code>RankNTypes</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XScopedTypeVariables\"><code>ScopedTypeVariables</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XStandaloneDeriving\"><code>StandaloneDeriving</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTupleSections\"><code>TupleSections</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeApplications\"><code>TypeApplications</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilyDependencies\"><code>TypeFamilyDependencies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeOperators\"><code>TypeOperators</code></a>\n</p></li></ul><p>This is a lot, and a few of them are likely to be more controversial than others. Since I do not imagine everyone will agree with everything in this list, I’ve broken it down into smaller chunks, arranged from what I think ought to be least controversial to most controversial, along with a little bit of justification why each extension is in each category. If you’re interested in coming up with your own list of extensions, the rest of this section is for you.\n</p><h3><a name=\"trivial-lifting-of-standards-imposed-limitations\"></a>Trivial lifting of standards-imposed limitations</h3><p>A few extensions are tiny changes that lift limitations that really have no reason to exist, other than that they are mandated by the standard. I am not sure why these restrictions are in the standard to begin with, other than perhaps a misguided attempt at making the language simpler. These extensions include the following:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XEmptyCase\"><code>EmptyCase</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleContexts\"><code>FlexibleContexts</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleInstances\"><code>FlexibleInstances</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XInstanceSigs\"><code>InstanceSigs</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiParamTypeClasses\"><code>MultiParamTypeClasses</code></a>\n</p></li></ul><p>These extensions have no business <em>not</em> being turned on everywhere. <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleContexts\"><code>FlexibleContexts</code></a> and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleInstances\"><code>FlexibleInstances</code></a> end up being turned on in almost any nontrivial Haskell module, since without them, the typeclass system is pointlessly and artificially limited.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XInstanceSigs\"><code>InstanceSigs</code></a> is extremely useful, completely safe, and has zero downsides.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiParamTypeClasses\"><code>MultiParamTypeClasses</code></a> are almost impossible to avoid, given how many libraries use them, and they are a completely obvious generalization of single-parameter typeclasses. Much like <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleContexts\"><code>FlexibleContexts</code></a> and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFlexibleInstances\"><code>FlexibleInstances</code></a>, I see no real reason to ever leave these disabled.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XEmptyCase\"><code>EmptyCase</code></a> is even stranger to me, since <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XEmptyDataDecls\"><code>EmptyDataDecls</code></a> is in Haskell 2010, so it’s possible to define empty datatypes in standard Haskell but not exhaustively pattern-match on them! This is silly, and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XEmptyCase\"><code>EmptyCase</code></a> should be standard Haskell.\n</p><h3><a name=\"syntactic-conveniences\"></a>Syntactic conveniences</h3><p>A few GHC extensions are little more than trivial, syntactic abbreviations. These things would be tiny macros in a Lisp, but they need to be extensions to the compiler in Haskell:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XLambdaCase\"><code>LambdaCase</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiWayIf\"><code>MultiWayIf</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XNamedFieldPuns\"><code>NamedFieldPuns</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTupleSections\"><code>TupleSections</code></a>\n</p></li></ul><p>All of these extensions are only triggered by explicit use of new syntax, so existing programs will never change behavior when these extensions are introduced.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XLambdaCase\"><code>LambdaCase</code></a> only saves a few characters, but it eliminates the need to come up with a fresh, unique variable name that will only be used once, which is sometimes hard to do and leads to worse names overall. Sometimes, it really is better to leave something unnamed.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMultiWayIf\"><code>MultiWayIf</code></a> isn’t something I find I commonly need, but when I do, it’s nice to have. It’s far easier to read than nested <code>if...then...else</code> chains, and it uses the existing guard syntax already used with function declarations and <code>case...of</code>, so it’s easy to understand, even to those unfamiliar with the extension.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XNamedFieldPuns\"><code>NamedFieldPuns</code></a> avoids headaches and clutter when using Haskell records without the <a href=\"https://www.reddit.com/r/haskell/comments/6jaa5f/recordwildcards_and_binary_parsing/djd5ugj/\">accidental identifier capture issues</a> of <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XRecordWildCards\"><code>RecordWildCards</code></a>. It’s a nice, safe compromise that brings some of the benefits of <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XRecordWildCards\"><code>RecordWildCards</code></a> without any downsides.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTupleSections\"><code>TupleSections</code></a> is a logical generalization of tuple syntax in the same vein as standard operator sections, and it’s quite useful when using applicative notation. I don’t see any reason to not enable it.\n</p><h3><a name=\"extensions-to-the-deriving-mechanism\"></a>Extensions to the deriving mechanism</h3><p>GHC’s typeclass deriving mechanism is one of the things that makes Haskell so pleasant to write, and in fact I think Haskell would be nearly unpalatable to write without it. Boilerplate generation is a good thing, since it defines operations in terms of a single source of truth, and generated code is code you do not need to maintain. There is rarely any reason to write a typeclass instance by hand when the deriving mechanism will write it automatically.\n</p><p>These extensions give GHC’s typeclass deriving mechanism more power without any cost. Therefore, I see no reason <em>not</em> to enable them:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveFoldable\"><code>DeriveFoldable</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveFunctor\"><code>DeriveFunctor</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveGeneric\"><code>DeriveGeneric</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveLift\"><code>DeriveLift</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveTraversable\"><code>DeriveTraversable</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDerivingStrategies\"><code>DerivingStrategies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGeneralizedNewtypeDeriving\"><code>GeneralizedNewtypeDeriving</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XStandaloneDeriving\"><code>StandaloneDeriving</code></a>\n</p></li></ul><p>The first five of these simply extend the list of typeclasses GHC knows how to derive, something that will only ever be triggered if the user explicitly requests GHC derive one of those classes. <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGeneralizedNewtypeDeriving\"><code>GeneralizedNewtypeDeriving</code></a> is quite possibly one of the most important extensions in all of Haskell, since it dramatically improves <code>newtype</code>s’ utility. Wrapper types can inherit instances they need without any boilerplate, and making increased type safety easier and more accessible is always a good thing in my book.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDerivingStrategies\"><code>DerivingStrategies</code></a> is new to GHC 8.2, but it finally presents the functionality of GHC’s <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveAnyClass\"><code>DeriveAnyClass</code></a> extension in a useful way. <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveAnyClass\"><code>DeriveAnyClass</code></a> is useful when used with certain libraries that use <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDefaultSignatures\"><code>DefaultSignatures</code></a> (discussed later) with <code>GHC.Generics</code> to derive instances of classes without the deriving being baked into GHC. Unfortunately, enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveAnyClass\"><code>DeriveAnyClass</code></a> essentially disables the far more useful <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGeneralizedNewtypeDeriving\"><code>GeneralizedNewtypeDeriving</code></a>, so I do <em>not</em> recommend enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDeriveAnyClass\"><code>DeriveAnyClass</code></a>. Fortunately, with <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDerivingStrategies\"><code>DerivingStrategies</code></a>, it’s possible to opt into the <code>anyclass</code> deriving strategy on a case-by-case basis, getting some nice boilerplate reduction in the process.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XStandaloneDeriving\"><code>StandaloneDeriving</code></a> is useful when GHC’s deriving algorithms aren’t <em>quite</em> clever enough to deduce the instance context automatically, so it allows specifying it manually. This is only useful in a few small situations, but it’s nice to have, and there are no downsides to enabling it, so it ought to be turned on.\n</p><h3><a name=\"lightweight-syntactic-adjustments\"></a>Lightweight syntactic adjustments</h3><p>A couple extensions tweak Haskell’s syntax in more substantial ways than things like <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XLambdaCase\"><code>LambdaCase</code></a>, but not in a significant enough way for them to really be at all surprising:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XBangPatterns\"><code>BangPatterns</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures\"><code>KindSignatures</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeOperators\"><code>TypeOperators</code></a>\n</p></li></ul><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XBangPatterns\"><code>BangPatterns</code></a> mirror strictness annotations on datatypes, so they are unlikely to be confusing, and they provide a much more pleasant notation for annotating the strictness of bindings than explicit uses of <code>seq</code>.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures\"><code>KindSignatures</code></a> are also fairly self-explanatory: they’re just like type annotations, but for types instead of values. Writing kind signatures explicitly is usually unnecessary, but they can be helpful for clarity or for annotating phantom types when <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XPolyKinds\"><code>PolyKinds</code></a> is not enabled. Enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures\"><code>KindSignatures</code></a> doesn’t have any adverse effects, so I see no reason not to enable it everywhere.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeOperators\"><code>TypeOperators</code></a> adjusts the syntax of types slightly, allowing operators to be used as type constructors and written infix, which is technically backwards-incompatible, but I’m a little suspicious of anyone using <code>(!@#$)</code> as a type variable (especially since standard Haskell does not allow them to be written infix). This extension is useful with some libraries like <code>natural-transformations</code> that provide infix type constructors, and it makes the type language more consistent with the value language.\n</p><h3><a name=\"polymorphic-string-literals\"></a>Polymorphic string literals</h3><p>I’m putting this extension in a category all of its own, mostly because I don’t think any other Haskell extensions have quite the same set of tradeoffs:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a>\n</p></li></ul><p>For me, <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a> is not optional. Haskell’s infamous “string problem” (discussed in more detail at the end of this blog post) means that <code>String</code> is a linked list of characters, and all code that cares about performance actually uses <code>Text</code>. Manually invoking <code>pack</code> on every single string literal in a program is just noise, and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a> solves that noise.\n</p><p>That said, I actually find I don’t use the polymorphism of string literals very often, and I’d be alright with monomorphic literals if I could make them <em>all</em> have type <code>Text</code>. Unfortunately, there isn’t a way to do this, so <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a> is the next best thing, even if it sometimes causes some unnecessary ambiguities that require type annotations to resolve.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverloadedStrings\"><code>OverloadedStrings</code></a> is an extension that I use so frequently, in so many modules (especially in my test suites) that I would rather keep it on everywhere so I don’t have to care about whether or not it’s enabled in the module I’m currently writing. On the other hand, it certainly isn’t my favorite language extension, either. I wouldn’t go as far as to call it a necessary evil, since I don’t think it’s truly “evil”, but it does seem to be necessary.\n</p><h3><a name=\"simple-extensions-to-aid-type-annotation\"></a>Simple extensions to aid type annotation</h3><p>The following two extensions significantly round out Haskell’s language for referring to types, making it much easier to insert type annotations where necessary (for removing ambiguity or for debugging type errors):\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XScopedTypeVariables\"><code>ScopedTypeVariables</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeApplications\"><code>TypeApplications</code></a>\n</p></li></ul><p>That the behavior of <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XScopedTypeVariables\"><code>ScopedTypeVariables</code></a> is <em>not</em> the default is actually one of the most common gotchas for new Haskellers. Sadly, it can theoretically adjust the behavior of existing Haskell programs, so I cannot include it in the list of trivial changes, but I would argue such programs were probably confusing to begin with, and I have never seen a program in practice that was impacted by that problem. I think leaving <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XScopedTypeVariables\"><code>ScopedTypeVariables</code></a> off is much, much more likely to be confusing than turning it on.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeApplications\"><code>TypeApplications</code></a> is largely unrelated, but I include it in this category because it’s quite useful and cooperates well with <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XScopedTypeVariables\"><code>ScopedTypeVariables</code></a>. Use of <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeApplications\"><code>TypeApplications</code></a> makes instantiation much more lightweight than full-blown type annotations, and once again, it has no downsides if it is enabled and unused (since it is a syntactic addition). I recommend enabling it.\n</p><h3><a name=\"simple-extensions-to-the-haskell-type-system\"></a>Simple extensions to the Haskell type system</h3><p>A few extensions tweak the Haskell type system in ways that I think are simple enough to be self-explanatory, even to people who might not have known they existed. These are as follows:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XConstraintKinds\"><code>ConstraintKinds</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XRankNTypes\"><code>RankNTypes</code></a>\n</p></li></ul><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XConstraintKinds\"><code>ConstraintKinds</code></a> is largely just used to define typeclass aliases, which is both useful and self-explanatory. Unifying the type and constraint language also has the effect of allowing type-level programming with constraints, which is sometimes useful, but far rarer in practice than the aforementioned use case.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XRankNTypes\"><code>RankNTypes</code></a> are uncommon, looking at the average type in a Haskell program, but they’re certainly nice to have when you need them. The idea of pushing <code>forall</code>s further into a type to adjust how variables are quantified is something that I find people find fairly intuitive, especially after seeing them used once or twice, and higher-rank types do crop up regularly, if infrequently.\n</p><h3><a name=\"intermediate-syntactic-adjustments\"></a>Intermediate syntactic adjustments</h3><p>Three syntactic extensions to Haskell are a little bit more advanced than the ones I’ve already covered, and none of them are especially related:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDefaultSignatures\"><code>DefaultSignatures</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XPatternSynonyms\"><code>PatternSynonyms</code></a>\n</p></li></ul><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> is, on the surface, simple. It changes <code>do</code> notation to use <code>Applicative</code> operations where possible, which allows using <code>do</code> notation with applicative functors that are not monads, and it also makes operations potentially more performant when <code>(&lt;*&gt;)</code> can be implemented more efficiently than <code>(&gt;&gt;=)</code>. In theory, it sounds like there are no downsides to enabling this everywhere. However, there are are a few drawbacks that lead me to put it so low on this list:\n</p><ol><li><p>It considerably complicates the desugaring of <code>do</code> blocks, to the point where the algorithm cannot even be easily syntactically documented. In fact, an additional compiler flag, <code>-foptimal-applicative-do</code>, is a way to <em>opt into</em> optimal solutions for <code>do</code> block expansions, tweaking the desugaring algorithm to have an <em>O</em>(<em>n</em><sup>3</sup>) time complexity! This means that the default behavior is guided by a heuristic, and desugaring isn’t even especially predictable. This isn’t necessarily so bad, since it’s really only intended as an optimization when some <code>Monad</code> operations are still necessary, but it does dramatically increase the complexity of one of Haskell’s core forms.\n</p></li><li><p>The desugaring, despite being <em>O</em>(<em>n</em><sup>2</sup>) by default, isn’t even especially clever. It relies on a rather disgusting hack that recognizes <code>return e</code>, <code>return $ e</code>, <code>pure e</code>, or <code>pure $ e</code> expressions <em>syntactically</em>, and it completely gives up if an expression with precisely that shape is not the final statement in a <code>do</code> block. This is a bit awkward, since it effectively turns <code>return</code> and <code>pure</code> into syntax when before they were merely functions, but that isn’t all. It also means that the following <code>do</code> block is <em>not</em> desugared using <code>Applicative</code> operations:\n</p><pre><code class=\"pygments\"><span class=\"kr\">do</span> <span class=\"n\">foo</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n   <span class=\"n\">bar</span> <span class=\"n\">s</span> <span class=\"n\">t</span>\n   <span class=\"n\">baz</span> <span class=\"n\">y</span> <span class=\"n\">z</span></code></pre><p>This will use the normal, monadic desugaring, despite the fact that it is trivially desugared into <code>Applicative</code> operations as <code>foo a b *&gt; bar s t *&gt; baz y z</code>. In order to get <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> to trigger here, the <code>do</code> block must be contorted into the following:\n</p><pre><code class=\"pygments\"><span class=\"kr\">do</span> <span class=\"n\">foo</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n   <span class=\"n\">bar</span> <span class=\"n\">s</span> <span class=\"n\">t</span>\n   <span class=\"n\">r</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">baz</span> <span class=\"n\">y</span> <span class=\"n\">z</span>\n   <span class=\"n\">pure</span> <span class=\"n\">r</span></code></pre><p>This seems like an odd oversight.\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTemplateHaskell\"><code>TemplateHaskell</code></a> doesn’t seem able to cope with <code>do</code> blocks when <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> is enabled. I reported this as <a href=\"https://ghc.haskell.org/trac/ghc/ticket/14471\">an issue on the GHC bug tracker</a>, but it hasn’t received any attention, so it’s not likely to get fixed unless someone takes the initiative to do so.\n</p></li><li><p>Enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> can cause problems with code that may have assumed <code>do</code> would always be monadic, and sometimes, that can cause code that typechecks to lead to an infinite loop at runtime. Specifically, if <code>do</code> notation is used to define <code>(&lt;*&gt;)</code> in terms of <code>(&gt;&gt;=)</code>, enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> will cause the definition of <code>(&lt;*&gt;)</code> to become self-referential and therefore divergent. Fortunately, this issue can be easily mitigated by simply writing <code>(&lt;*&gt;) = ap</code> instead, which is clearer and shorter than the equivalent code using <code>do</code>.\n</p></li></ol><p>Given all these things, it seems <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XApplicativeDo\"><code>ApplicativeDo</code></a> is a little too new in a few places, and it isn’t quite baked. Still, I keep it enabled by default. Why? Well, <em>usually</em> it works fine without any problems, and when I run into issues, I can disable it on a per-module basis by writing <code>{-# LANGUAGE NoApplicativeDo #-}</code>. I still find that keeping it enabled by default is fine the vast majority of the time, I just sometimes need to work around the bugs.\n</p><p>In contrast, <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDefaultSignatures\"><code>DefaultSignatures</code></a> isn’t buggy at all, as far as I can tell, it’s just not usually useful without fairly advanced features like <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> (for type equalities) or <code>GHC.Generics</code>. I mostly use it for <a href=\"/blog/2017/04/28/lifts-for-free-making-mtl-typeclasses-derivable/\">making lifting instances for <code>mtl</code>-style typeclasses easier to write</a>, which I’ve found to be a tiny bit tricky to explain (mostly due to the use of type equalities in the context), but it works well. I don’t see any real reason to leave this disabled, but if you don’t think you’re going to use it anyway, it doesn’t really matter one way or the other.\n</p><p>Finally, <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XPatternSynonyms\"><code>PatternSynonyms</code></a> allow users to extend the pattern language just as they are allowed to extend the value language. Bidirectional pattern synonyms are isomorphisms, and it’s quite useful to allow those isomorphisms to be used with Haskell’s usual pattern-matching syntax. I think this extension is actually quite benign, but I put it so low on this list because it seems infrequently used, and I get the sense most people consider it fairly advanced. I would argue, however, that it’s a very pleasant, useful extension, and it’s no more complicated than a number of the features in Haskell 98.\n</p><h3><a name=\"intermediate-extensions-to-the-haskell-type-system\"></a>Intermediate extensions to the Haskell type system</h3><p>Now we’re getting into the meat of things. Everything up to this point has been, in my opinion, completely self-evident in its usefulness and simplicity. As far as I’m concerned, the extensions in the previous six sections have no business ever being left disabled. Starting in this section, however, I could imagine a valid argument being made either way.\n</p><p>The following three extensions add some complexity to the Haskell type system in return for some added expressive power:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XExistentialQuantification\"><code>ExistentialQuantification</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFunctionalDependencies\"><code>FunctionalDependencies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a>\n</p></li></ul><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XExistentialQuantification\"><code>ExistentialQuantification</code></a> and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> are related, given that the former is subsumed by the latter, but <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> also enables an alternative syntax. Both syntaxes allow packing away a typeclass dictionary or equality constraint that is brought into scope upon a successful pattern-match against a data constructor, something that is sometimes quite useful but certainly a departure from Haskell’s simple ADTs.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFunctionalDependencies\"><code>FunctionalDependencies</code></a> extend multi-parameter typeclasses, and they are almost unavoidable, given their use in the venerable <code>mtl</code> library. Like <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a>, <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFunctionalDependencies\"><code>FunctionalDependencies</code></a> add an additional layer of complexity to the typeclass system in order to express certain things that would otherwise be difficult or impossible.\n</p><p>All of these extensions involve a tradeoff. Enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> also implies <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMonoLocalBinds\"><code>MonoLocalBinds</code></a>, which disables let generalization, one of the most likely ways a program that used to typecheck might subsequently fail to do so. Some might argue that this is a good reason to turn <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> on in a per-module basis, but I disagree: I actually want my language to be fairly consistent, and given that I know I am likely going to want to use <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XGADTs\"><code>GADTs</code></a> <em>somewhere</em>, I want <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XMonoLocalBinds\"><code>MonoLocalBinds</code></a> enabled <em>everywhere</em>, not inconsistently and sporadically.\n</p><p>That aside, all these extensions are relatively safe. They are well-understood, and they are fairly self-contained extensions to the Haskell type system. I think these extensions have a very good power to cost ratio, and I find myself using them regularly (especially <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XFunctionalDependencies\"><code>FunctionalDependencies</code></a>), so I keep them enabled globally.\n</p><h3><a name=\"advanced-extensions-to-the-haskell-type-system\"></a>Advanced extensions to the Haskell type system</h3><p>Finally, we arrive at the last set of extensions in this list. These are the most advanced features Haskell’s type system currently has to offer, and they are likely to be the most controversial to enable globally:\n</p><ul><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDataKinds\"><code>DataKinds</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a>\n</p></li><li><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilyDependencies\"><code>TypeFamilyDependencies</code></a>\n</p></li></ul><p>All of these extensions exist exclusively for the purpose of type-level programming. <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDataKinds\"><code>DataKinds</code></a> allows datatype promotion, creating types that are always uninhabited and therefore can only be used phantom. <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a> allows the definition of type-level functions that map types to other types. Both of these are minor extensions to Haskell’s surface area, but they have rather significant ramifications on the sort of programming that can be done and the way GHC’s typechecker must operate.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a> is an interesting extension because it comes in so many flavors: associated type synonyms, associated datatypes, open and closed type synonym families, and open and closed datatype families. Associated types tend to be easier to grok and easier to use, though they can also be replaced by functional dependencies. Open type families are also quite similar to classes and instances, so they aren’t <em>too</em> tricky to understand. Closed type families, on the other hand, are a rather different beast, and they can be used to do fairly advanced things, <em>especially</em> in combination with <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XDataKinds\"><code>DataKinds</code></a>.\n</p><p>I happen to appreciate GHC’s support for these features, and while I’m hopeful that an eventual <code>DependentHaskell</code> will alleviate many of the existing infelicities with dependently typed programming in GHC, in the meantime, it’s often useful to enjoy what exists where practically applicable. Therefore, I have little problem keeping them enabled, since, like the vast majority of extensions on this list, these extensions merely lift restrictions, not adjust semantics of the language without the extensions enabled. When I am going to write a type family, I am going to turn on <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a>; I see no reason to annotate the modules in which I decide to do so. I do not write an annotation at the top of each module in which I define a typeclass or a datatype, so why should I do so with type families?\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilyDependencies\"><code>TypeFamilyDependencies</code></a> is a little bit different, since it’s a very new extension, and it doesn’t seem to always work as well as I would hope. Still, when it doesn’t work, it fails with a very straightforward error message, and when it works, it is legitimately useful, so I don’t see any real reason to leave it off if <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTypeFamilies\"><code>TypeFamilies</code></a> is enabled.\n</p><h3><a name=\"extensions-intentionally-left-off-this-list\"></a>Extensions intentionally left off this list</h3><p>Given what I’ve said so far, it may seem like I would advocate flipping on absolutely every lever GHC has to offer, but that isn’t actually true. There are a few extensions I quite intentionally do <em>not</em> enable.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XUndecidableInstances\"><code>UndecidableInstances</code></a> is something I turn on semi-frequently, since GHC’s termination heuristic is not terribly advanced, but I turn it on per-module, since it’s useful to know when it’s necessary (and in application code, it rarely is). <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XOverlappingInstances\"><code>OverlappingInstances</code></a> and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XIncoherentInstances\"><code>IncoherentInstances</code></a>, in contrast, are completely banned—not only are they almost always a bad idea, GHC has a better, more fine-grained way to opt into overlapping instances, using the <code>{-# OVERLAPPING #-}</code>, <code>{-# OVERLAPPABLE #-}</code>, and <code>{-# INCOHERENT #-}</code> pragmas.\n</p><p><a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTemplateHaskell\"><code>TemplateHaskell</code></a> and <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XQuasiQuotes\"><code>QuasiQuotes</code></a> are tricky ones. Anecdotes seem to suggest that enabling <a href=\"https://downloads.haskell.org/~ghc/8.2.2/docs/html/users_guide/glasgow_exts.html#ghc-flag--XTemplateHaskell\"><code>TemplateHaskell</code></a> everywhere leads to worse compile times, but after trying this on a few projects and measuring, I wasn’t able to detect any meaningful difference. Unless I manage to come up with some evidence that these extensions actually slow down compile times just by being <em>enabled</em>, even if they aren’t used, then I may add them to my list of globally-enabled extensions, since I use them regularly.\n</p><p>Other extensions I haven’t mentioned are probably things I just don’t use very often and therefore haven’t felt the need to include on this list. It certainly isn’t exhaustive, and I add to it all the time, so I expect I will continue to do so in the future. This is just what I have for now, and if your favorite extension isn’t included, it probably isn’t a negative judgement against that extension. I just didn’t think to mention it.\n</p><h2><a name=\"libraries-a-field-guide\"></a>Libraries: a field guide</h2><p>Now that you’re able to build a Haskell project and have chosen which handpicked flavor of Haskell you are going to write, it’s time to decide which libraries to use. Haskell is an expressive programming language, and the degree to which different libraries can shape the way you structure your code is significant. Picking the right libraries can lead to clean code that’s easy to understand and maintain, but picking the wrong ones can lead to disaster.\n</p><p>Of course, there are <em>thousands</em> of Haskell libraries on Hackage alone, so I cannot hope to cover all of the ones I have ever found useful, and I certainly cannot cover ones that would be useful but I did not have the opportunity to try (of which there are certainly many). This blog post is long enough already, so I’ll just cover a few categories of libraries that I think I can offer interesting commentary on; most libraries can generally speak for themselves.\n</p><h3><a name=\"having-an-effect\"></a>Having an effect</h3><p>One of the first questions Haskell programmers bump into when they begin working on a large application is how they’re going to model effects. Few practical programming languages are pure, but Haskell is one of them, so there’s no getting away from coming up with a way to manage side-effects.\n</p><p>For some applications, Haskell’s built-in solution might be enough: <code>IO</code>. This can work decently for data processing programs that do very minimal amounts of I/O, and the types of side-effects they perform are minimal. For these applications, most of the logic is likely to be pure, which means it’s already easy to reason about and easy to test. For other things, like web applications, it’s more likely that a majority of the program logic is going to be side-effectful by its nature—it may involve making HTTP requests to other services, interacting with a database, and writing to logfiles.\n</p><p>Figuring out how to structure these effects in a type-safe, decoupled, composable way can be tricky, especially since Haskell has so many different solutions. I could not bring myself to choose just one, but I did choose two: the so-called “<code>mtl</code> style” and freer monads.\n</p><p><code>mtl</code> style is so named because it is inspired by the technique of interlocking monadic typeclasses and lifting instances used to model effects using constraints that is used in the <a href=\"https://hackage.haskell.org/package/mtl\"><code>mtl</code></a> library. Here is a small code example of what <code>mtl</code> style typeclasses and handlers look like:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n\n  <span class=\"kr\">default</span> <span class=\"n\">readFile</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m&#39;</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m&#39;</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">readFile</span> <span class=\"n\">a</span>\n\n  <span class=\"kr\">default</span> <span class=\"n\">writeFile</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m&#39;</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m&#39;</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">writeFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">readFile</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">writeFile</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">MaybeT</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">InMemoryFileSystemT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">InMemoryFileSystemT</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"p\">[(</span><span class=\"kt\">FilePath</span><span class=\"p\">,</span> <span class=\"kt\">String</span><span class=\"p\">)]</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">InMemoryFileSystemT</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"kt\">InMemoryFileSystemT</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"n\">vfs</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">get</span>\n    <span class=\"kr\">case</span> <span class=\"n\">lookup</span> <span class=\"n\">path</span> <span class=\"n\">vfs</span> <span class=\"kr\">of</span>\n      <span class=\"kt\">Just</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"n\">contents</span>\n      <span class=\"kt\">Nothing</span> <span class=\"ow\">-&gt;</span> <span class=\"ne\">error</span> <span class=\"p\">(</span><span class=\"s\">\"readFile: no such file \"</span> <span class=\"o\">++</span> <span class=\"n\">path</span><span class=\"p\">)</span>\n\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"n\">contents</span> <span class=\"ow\">=</span> <span class=\"kt\">InMemoryFileSystemT</span> <span class=\"o\">$</span> <span class=\"n\">modify</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">vfs</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"kt\">:</span> <span class=\"n\">delete</span> <span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"n\">vfs</span></code></pre><p>This is the most prevalent way to abstract over effects in Haskell, and it’s been around for a long time. Due to the way it uses the typeclass system, it’s also very fast, since GHC can often specialize and inline the typeclass dictionaries to avoid runtime dictionary passing. The main drawbacks are the amount of boilerplate required and the conceptual difficulty of understanding exactly how monad transformers, monadic typeclasses, and lifting instances all work together to discharge <code>mtl</code> style constraints.\n</p><p>There are various alternatives to <code>mtl</code>’s direct approach to effect composition, most of which are built around the idea of reifying a computation as a data structure and subsequently interpreting it. The most popular of these is the <code>Free</code> monad, a clever technique for deriving a monad from a functor that happens to be useful for modeling programs. Personally, I think <code>Free</code> is overhyped. It’s a cute, mathematically elegant technique, but it involves a lot of boilerplate, and composing effect algebras is still a laborious process. The additional expressive power of <code>Free</code>, namely its ability to choose an interpreter dynamically, at runtime, is rarely necessary or useful, and it adds complexity and reduces performance for few benefits. (And in fact, this is still possible to do with <code>mtl</code> style, it’s just uncommon because there is rarely any need to do so.)\n</p><p>A 2017 blog post entitled <a href=\"https://markkarpov.com/post/free-monad-considered-harmful.html\">Free monad considered harmful</a> discussed <code>Free</code> in comparison with <code>mtl</code> style, and unsurprisingly cast <code>Free</code> in a rather unflattering light. I largely agree with everything outlined in that blog post, so I will not retread its arguments here. I do, however, think that there is another abstraction that <em>is</em> quite useful: the so-called “freer monad” used to implement extensible effects.\n</p><p>Freer moves even further away from worrying about functors and monads, since its effect algebras do not even need to be functors. Instead, freer’s effect algebras are ordinary GADTs, and reusable, composable effect handlers are easily written to consume elements of these datatypes. Unfortunately, the way this works means that GHC is still not clever enough to optimize freer monads as efficiently as <code>mtl</code> style, since it can’t easily detect when the interpreter is chosen statically and use that information to specialize and inline effect implementations, but the cost difference is significantly reduced, and I’ve found that in real application code, the vast majority of the cost does not come from the extra overhead introduced by a more expensive <code>(&gt;&gt;=)</code>.\n</p><p>There are a few different implementations of freer monads, but I, sadly, was not satisfied with any of them, so I decided to contribute to the problem by creating yet another one. My implementation is called <a href=\"https://hackage.haskell.org/package/freer-simple\"><code>freer-simple</code></a>, and it includes a streamlined API with <a href=\"https://hackage.haskell.org/package/freer-simple-1.0.1.1/docs/Control-Monad-Freer.html\">more documentation than any other freer implementation</a>. Writing the above <code>mtl</code> style example using <code>freer-simple</code> is more straightforward:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">FileSystem</span> <span class=\"n\">r</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">ReadFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FileSystem</span> <span class=\"kt\">String</span>\n  <span class=\"kt\">WriteFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FileSystem</span> <span class=\"nb\">()</span>\n\n<span class=\"nf\">readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">Member</span> <span class=\"kt\">FileSystem</span> <span class=\"n\">r</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Eff</span> <span class=\"n\">r</span> <span class=\"kt\">String</span>\n<span class=\"nf\">readFile</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">send</span> <span class=\"o\">$</span> <span class=\"kt\">ReadFile</span> <span class=\"n\">a</span>\n\n<span class=\"nf\">writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">Member</span> <span class=\"kt\">FileSystem</span> <span class=\"n\">r</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Eff</span> <span class=\"n\">r</span> <span class=\"nb\">()</span>\n<span class=\"nf\">writeFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">send</span> <span class=\"o\">$</span> <span class=\"kt\">WriteFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n\n<span class=\"nf\">runFileSystemIO</span> <span class=\"ow\">::</span> <span class=\"kt\">LastMember</span> <span class=\"kt\">IO</span> <span class=\"n\">r</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Eff</span> <span class=\"p\">(</span><span class=\"kt\">FileSystem</span> <span class=\"sc\">&#39;</span><span class=\"err\">: r) ~&gt; Eff r</span>\n<span class=\"nf\">runFileSystemIO</span> <span class=\"ow\">=</span> <span class=\"n\">interpretM</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"kr\">case</span>\n  <span class=\"kt\">ReadFile</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">readFile</span> <span class=\"n\">a</span>\n  <span class=\"kt\">WriteFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">writeFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span>\n\n<span class=\"nf\">runFileSystemInMemory</span> <span class=\"ow\">::</span> <span class=\"p\">[(</span><span class=\"kt\">FilePath</span><span class=\"p\">,</span> <span class=\"kt\">String</span><span class=\"p\">)]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Eff</span> <span class=\"p\">(</span><span class=\"kt\">FileSystem</span> <span class=\"sc\">&#39;</span><span class=\"err\">: effs) ~&gt; Eff effs</span>\n<span class=\"nf\">runFileSystemInMemory</span> <span class=\"n\">initVfs</span> <span class=\"ow\">=</span> <span class=\"n\">runState</span> <span class=\"n\">initVfs</span> <span class=\"o\">.</span> <span class=\"n\">fsToState</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fsToState</span> <span class=\"ow\">::</span> <span class=\"kt\">Eff</span> <span class=\"p\">(</span><span class=\"kt\">FileSystem</span> <span class=\"sc\">&#39;</span><span class=\"err\">: effs) ~&gt; Eff (State [(FilePath, String)]</span><span class=\"sc\"> &#39;</span><span class=\"kt\">:</span> <span class=\"n\">effs</span><span class=\"p\">)</span>\n  <span class=\"n\">fsToState</span> <span class=\"ow\">=</span> <span class=\"n\">reinterpret</span> <span class=\"o\">$</span> <span class=\"kr\">case</span>\n    <span class=\"kt\">ReadFile</span> <span class=\"n\">path</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">get</span> <span class=\"o\">&gt;&gt;=</span> <span class=\"nf\">\\</span><span class=\"n\">vfs</span> <span class=\"ow\">-&gt;</span> <span class=\"kr\">case</span> <span class=\"n\">lookup</span> <span class=\"n\">path</span> <span class=\"n\">vfs</span> <span class=\"kr\">of</span>\n      <span class=\"kt\">Just</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pure</span> <span class=\"n\">contents</span>\n      <span class=\"kt\">Nothing</span> <span class=\"ow\">-&gt;</span> <span class=\"ne\">error</span> <span class=\"p\">(</span><span class=\"s\">\"readFile: no such file \"</span> <span class=\"o\">++</span> <span class=\"n\">path</span><span class=\"p\">)</span>\n    <span class=\"kt\">WriteFile</span> <span class=\"n\">path</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">modify</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">vfs</span> <span class=\"ow\">-&gt;</span>\n      <span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"kt\">:</span> <span class=\"n\">delete</span> <span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"n\">vfs</span></code></pre><p>(It could be simplified further with a little bit of Template Haskell to generate the <code>readFile</code> and <code>writeFile</code> function definitions, but I haven’t gotten around to writing that.)\n</p><p>So which effect system do I recommend? I used to recommend <code>mtl</code> style, but as of only two months ago, I now recommend <code>freer-simple</code>. It’s easier to understand, involves less boilerplate, achieves “good enough” performance, and generally gets out of the way wherever possible. Its API is designed to make it easy to do the sorts of the things you most commonly need to do, and it provides a core set of effects that can be used to build a real-world application.\n</p><p>That said, freer is indisputably relatively new and relatively untested. It has success stories, but <code>mtl</code> style is still the approach used by the majority of the ecosystem. <code>mtl</code> style has more library support, its performance characteristics are better understood, and it is a tried and true way to structure effects in a Haskell application. If you understand it well enough to use it, and you are happy with it in your application, my recommendation is to stick with it. If you find it confusing, however, or you end up running up against its limits, give <code>freer-simple</code> a try.\n</p><h3><a name=\"through-the-looking-glass-to-lens-or-not-to-lens\"></a>Through the looking glass: to lens or not to lens</h3><p>There’s no getting around it: <a href=\"https://hackage.haskell.org/package/lens\"><code>lens</code></a> is a behemoth of a library. For a long time, I wrote Haskell without it, and honestly, it worked out alright. I just wasn’t doing a whole lot of work that involved complicated, deeply-nested data structures, and I didn’t feel the need to bring in a library with such a reputation for having impenetrable operators and an almost equally impenetrable learning curve.\n</p><p>But, after some time, I decided I wanted to take the plunge. So I braced myself for the worst, pulled out my notebook, and started writing some code. To my surprise… it wasn’t that hard. It made sense. Sure, I still don’t know how it works on the inside, and I never did learn the majority of the exports in <code>Control.Lens.Operators</code>, but I had no need to. Lenses were useful in the way I had expected them to be, and so were prisms. One thing led to another, and before long, I understood the relationship between the various optics, the most notable additions to my toolkit being folds and traversals. Sure, the type errors were completely opaque much of the time, but I was able to piece things together with ample type annotations and time spent staring at ill-typed expressions. Before long, I had developed an intuition for <code>lens</code>.\n</p><p>After using it for a while, I retrospected on whether or not I liked it, and honestly, I still can’t decide. Some lensy expressions were straightforward to read and were a pleasant simplification, like this one:\n</p><pre><code class=\"pygments\"><span class=\"nf\">paramSpecs</span> <span class=\"o\">^..</span> <span class=\"n\">folded</span><span class=\"o\">.</span><span class=\"n\">_Required</span></code></pre><p>Others were less obviously improvements, such as this beauty:\n</p><pre><code class=\"pygments\"><span class=\"kt\">M</span><span class=\"o\">.</span><span class=\"n\">fromList</span> <span class=\"o\">$</span> <span class=\"n\">paramSpecs</span> <span class=\"o\">^..</span> <span class=\"n\">folded</span><span class=\"o\">.</span><span class=\"n\">_Optional</span><span class=\"o\">.</span><span class=\"n\">filtered</span> <span class=\"p\">(</span><span class=\"n\">has</span> <span class=\"o\">$</span> <span class=\"n\">_2</span><span class=\"o\">.</span><span class=\"n\">_UsePreviousValue</span><span class=\"p\">)</span></code></pre><p>But operator soup aside, there was something deeper about <code>lens</code> that bothered me, and I just wasn’t sure what. I didn’t know how to articulate my vague feelings until I read a 2014 blog post entitled <a href=\"https://ro-che.info/articles/2014-04-24-lens-unidiomatic\">Lens is unidiomatic Haskell</a>, which includes a point that I think is spot-on:\n</p><blockquote><p>Usually, types in Haskell are rigid. This leads to a distinctive style of composing programs: look at the types and see what fits where. This is impossible with <code>lens</code>, which takes overloading to the level mainstream Haskell probably hasn’t seen before.\n</p><p>We have to learn the new language of the <code>lens</code> combinators and how to compose them, instead of enjoying our knowledge of how to compose Haskell functions. Formally, <code>lens</code> types are Haskell function types, but while with ordinary Haskell functions you immediately see from types whether they can be composed, with <code>lens</code> functions this is very hard in practice.\n</p><p>[…]\n</p><p>Now let me clarify that this doesn’t necessarily mean that <code>lens</code> is a bad library. It’s an <em>unusual</em> library. It’s almost a separate language, with its own idioms, embedded in Haskell.\n</p></blockquote><p>The way <code>lens</code> structures its types deliberately introduces a sort of subtyping relationship—for example, all lenses are traversals and all traversals are folds, but not vice versa—and indeed, knowing this subtyping relationship is essential to working with the library and understanding how to use it. It is helpfully documented with a large diagram on <a href=\"https://hackage.haskell.org/package/lens\">the <code>lens</code> package overview page</a>, and that diagram was most definitely an invaluable resource for me when I was learning how to use the library.\n</p><p>On the surface, this isn’t unreasonable. Subtyping is an enormously useful concept! The only reason Haskell dispenses with it entirely is because it makes type inference notoriously difficult. The subtyping relation between optics is one of the things that makes them so useful, since it allows you to easily compose a lens with a prism and get a traversal out. Unfortunately, the downside of all this is that Haskell does not truly have subtyping, so all of <code>lens</code>’s “types” really must be type aliases for types of roughly the same shape, namely functions. This makes type errors completely <em>baffling</em>, since the errors do not mention the aliases, only the fully-expanded types (which are often rather complicated, and their meaning is not especially clear without knowing how <code>lens</code> works under the hood).\n</p><p>So the above quote is correct: working with <code>lens</code> really <em>is</em> like working in a separate embedded language, but I’m usually okay with that. Embedded, domain-specific languages are good! Unfortunately, in this case, the host language is not very courteous to its guest. Haskell does not appear to be a powerful enough language for <code>lens</code> to be a language in its own right, so it must piggyback on top of Haskell’s error reporting mechanisms, which are insufficient for <code>lens</code> to be a cohesive linguistic abstraction. Just as debugging code by stepping through the assembly it produces (or, perhaps more relevant in 2018, debugging a compile-to-JS language by looking at the emitted JavaScript instead of the source code) makes for an unacceptably leaky language. We would never stand for such a thing in our general-purpose language tooling, and we should demand better even in our embedded languages.\n</p><p>That said, <code>lens</code> is just too useful to ignore. It is a hopelessly leaky abstraction, but it’s still an abstraction, and a powerful one at that. Given my selection of default extensions as evidence, I think it’s clear I have zero qualms with “advanced” Haskell; I will happily use even <code>singletons</code> where it makes sense. Haskell’s various language extensions are sometimes confusing in their own right, but their complexity is usually fundamental to the expressive power they bring. <code>lens</code> has some fundamental complexity, too, but it is mostly difficult for the wrong reasons. Still, while it is not the first library I reach for on every new Haskell project, manipulating nested data without <code>lens</code> is just too unpleasant after tasting the nectar, so I can’t advise against it in good faith.\n</p><p>Sadly, this means I’m a bit wishy-washy when it comes to using <code>lens</code>, but I do have at least one recommendation: if you decide to use <code>lens</code>, it’s better to go all-in. Don’t generate lenses for just a handful of datatypes, do it for <em>all</em> of them. You can definitely stick to a subset of the <code>lens</code> library’s features, but don’t apply it in some functions but not others. Having too many different, equally valid ways of doing things leads to confusion and inconsistency, and inconsistency minimizes code reuse and leads to duplication and spaghetti. Commit to using <code>lens</code>, or don’t use it at all.\n</p><h3><a name=\"mitigating-the-string-problem\"></a>Mitigating the string problem</h3><p>Finally, Haskell has a problem with strings. Namely, <code>String</code> is a type alias for <code>[Char]</code>, a lazy, singly linked list of characters, which is an awful representation of text. Fortunately, the answer to this problem is simple: ban <code>String</code> in your programs.\n</p><p>Use <code>Text</code> everywhere. I don’t really care if you pick strict <code>Text</code> or lazy <code>Text</code>, but pick one and stick to it. Don’t ever use <code>String</code>, and <em>especially</em> don’t ever, <em>ever</em>, <strong><em>ever</em></strong> use <code>ByteString</code> to represent text! There are enormously few legitimate cases for using <code>ByteString</code> in a program that is not explicitly about reading or writing raw data, and even at that level, <code>ByteString</code> should only be used at program boundaries. In that sense, I treat <code>ByteString</code> much the same way I treat <code>IO</code>: push it to the boundaries of your program.\n</p><p>One of Haskell’s core tenets is making illegal states unrepresentable. Strings are not especially useful datatypes for this, since they are sequences of arbitrary length made up of atoms that can be an enormously large number of different things. Still, string types enforce a very useful invariant, a notion of a sequence of human-readable characters. In the presence of Unicode, this is a more valuable abstraction than it might seem, and the days of treating strings as little different from sequences of bytes are over. While strings make a poor replacement for enums, they are quite effective at representing the incredible amount of text humans produce in a staggeringly large number of languages, and they are the right type for that job.\n</p><p><code>ByteString</code>, on the other hand, is essentially never the right type for any job. If a type classifies a set of values, <code>ByteString</code> is no different from <code>Any</code>. It is the structureless type, the all-encompassing blob of bits. A <code>ByteString</code> could hold anything at all—some text, an image, an executable program—and the type system certainly isn’t going to help to answer that question. The only use case I can possibly imagine for passing around a <code>ByteString</code> in your program rather than decoding it into a more precise type is if it truly holds opaque data, e.g. some sort of token or key provided by a third party with no structure guaranteed whatsoever. Still, even this should be wrapped in a <code>newtype</code> so that the type system enforces this opaqueness.\n</p><p>Troublingly, <code>ByteString</code> shows up in many libraries’ APIs where it has no business being. In many cases, this seems to be things where ASCII text is expected, but this is hardly a good reason to willingly accept absolutely anything and everything! Make an <code>ASCII</code> type that forbids non-ASCII characters, and provide a <code>ByteString -&gt; Maybe ASCII</code> function. Alternatively, think harder about your problem in question to properly support Unicode as you almost certainly ought to.\n</p><p>Other places <code>ByteString</code> appears are similarly unfortunate. Base-64 encoding, for example, could be given the wonderfully illustrative type <code>ByteString -&gt; Text</code>, or even <code>ByteString -&gt; ASCII</code>! Such a type makes it immediately clear why base-64 is useful: it allows transforming arbitrary binary data into a reliable textual encoding. If we consider that <code>ByteString</code> is essentially <code>Any</code>, this function has the type <code>Any -&gt; ASCII</code>, which is amazingly powerful! We can convert <em>anything</em> to ASCII text!\n</p><p>Existing libraries, however, just provide the boring, disappointingly inaccurate type <code>ByteString -&gt; ByteString</code>, which is one of the most useless types there is. It is essentially <code>Any -&gt; Any</code>, the meaningless function type. It conveys nothing about what it does, other than that it is pure. Giving a function this type is scarcely better than dynamic typing. Its mere existence is a failure of Haskell library design.\n</p><p>But wait, it gets worse! <code>Data.Text.Encoding</code> exports a function called <code>decodeUtf8</code>, which has type <code>ByteString -&gt; Text</code>. What an incredible function with a captivating type! Whatever could it possibly do? Again, this function’s type is basically <code>Any -&gt; Text</code>, which is remarkable in the power it gives us. Let’s try it out, shall we?\n</p><pre><code>ghci&gt; decodeUtf8 \"\\xc3\\x28\"\n\"*** Exception: Cannot decode byte '\\x28': Data.Text.Internal.Encoding.decodeUtf8: Invalid UTF-8 stream\n</code></pre><p>Oh. Well, that’s a disappointment.\n</p><p>Haskell’s string problem goes deeper than <code>String</code> versus <code>Text</code>; it seems to have wound its way around the collective consciousness of the Haskell community and made it temporarily forget that it cares about types and totality. This isn’t that hard, I swear! I can only express complete befuddlement at how many of these APIs are just completely worthless.\n</p><p>Fortunately, there is a way out, and that way out is <a href=\"https://hackage.haskell.org/package/text-conversions\"><code>text-conversions</code></a>. It is the first Haskell library I ever wrote. It provides <em>type safe</em>, <em>total</em> conversions between <code>Text</code> and various other types, and it is encoding aware. It provides appropriately-typed base-16 and base-64 conversion functions, and is guaranteed to never raise any exceptions. Use it, and apply the Haskell philosophy to your strings, just as you already do for everything else in your program.\n</p><h2><a name=\"closing-thoughts\"></a>Closing thoughts</h2><p><em>Phew.</em>\n</p><p>When I started writing this blog post, it used the phrase “short overview” in the introduction. It is now over ten thousand words long. I think that’s all I have it in me to say for now.\n</p><p>Haskell is a wonderful language built by a remarkable group of people. Its community is often fraught with needlessly inflammatory debates about things like the value of codes of conduct, the evils of Hackage revisions, and precisely how much or how little people ought to care about the monad laws. These flame wars frustrate me to no end, and they sometimes go so far as to make me ashamed to call myself a part of the Haskell community. Many on the “outside” seem to view Haskellers as an elitist, mean-spirited cult, more interested in creating problems for itself than solving them.\n</p><p>That perception is categorically wrong.\n</p><p>I have never been in a community of programmers so dedicated and passionate about applying thought and rigor to building software, then going out and <em>actually doing it</em>. I don’t know anywhere else where a cutting-edge paper on effect systems is discussed by the very same people who are figuring out how to reliably deploy distributed services to AWS. Some people view the Haskell community as masturbatory, and to some extent, they are probably right. One of my primary motivators for writing Haskell is that it is fun and it challenges me intellectually in ways that other languages don’t. But that challenge is not a sign of uselessness, it is a sign that Haskell is <em>so close</em> to letting me do the right thing, to solving the problem the right way, to letting me work without compromises. When I write in most programming languages, I must constantly accept that my program will never be robust in all the ways I want it to be, and I might as well give up before I even start. Haskell’s greatest weakness is that it tempts me to try.\n</p><p>Haskell is imperfect, as it will always be. I doubt I will ever be satisfied by any language or any ecosystem. There will always be more to learn, more to discover, better tools and abstractions to develop. Many of them will not look anything like Haskell; they may not involve formal verification or static types or effect systems at all. Perhaps live programming, structural editors, and runtime hotswapping will finally take over the world, and we will find that the problems we thought we were solving were irrelevant to begin with. I can’t predict the future, and while I’ve found great value in the Haskell school of program construction, I dearly hope that we do not develop such tunnel vision that we cannot see that there may be other ways to solve these problems. Many of the solutions are things we likely have not even begun to think about. Still, whether that happens or not, it is clear to me that Haskell is a point in the design space unlike any other, and we learn almost as much from the things it gets wrong as we do from the things it gets right.\n</p><p>It’s been a wonderful two years, Haskell. I won’t be a stranger.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"For me, this month marks the end of an era in my life: as of February 2018, I am no longer employed writing Haskell. It’s been a fascinating two years, and while I am excitedly looking forward to what I’ll be doing next, it’s likely I will continue to write Haskell in my spare time. I’ll probably even write it again professionally in the future.\n\nIn the meantime, in the interest of both sharing with others the small amount of wisdom I’ve gained and preserving it for my future self, I’ve decided to write a long, rather dry overview of a few select parts of the Haskell workflow I developed and the ecosystem I settled into. This guide is, as the title notes, opinionated—it is what I used in my day-to-day work, nothing more—and I don’t claim that anything here is the only way to write Haskell, nor even the best way. It is merely what I found helpful and productive. Take from it as much or as little as you’d like.\n\nBuild tools and how to use them\nWhen it comes to building Haskell, you have options. And frankly, most of them are pretty good. There was a time when cabal-install had a (warranted) reputation for being nearly impossible to use and regularly creating dependency hell, but I don’t think that’s the case anymore (though you do need to be a little careful about how you use it). Sandboxed builds work alright, and cabal new-build and the other cabal new-* commands are even better. That said, the UX of cabal-install is still less-than-stellar, and it has sharp edges, especially for someone coming from an ecosystem without a heavyweight compilation process like JavaScript, Ruby, or Python.\n\nNix is an alternative way to manage Haskell dependencies, and it seems pretty cool. It has a reputation for being large and complicated, and that reputation does not seem especially unfair, but you get lots of benefits if you’re willing to pay the cost. Unfortunately, I have never used it (though I’ve read a lot about it), so I can’t comment much on it here. Perhaps I’ll try to go all-in with Nix when I purchase my next computer, but for now, my workflow works well enough that I don’t feel compelled to switch.\n\nPersonally, I use stack as my Haskell build tool. It’s easy to use, it works out of the box, and while it doesn’t enjoy the same amount of caching as cabal new-build or Nix, it caches most packages, and it also makes things like git-hosted sources incredibly easy, which (as far as I can tell) can’t be done with cabal-install alone.\n\nThis section is going to be a guide on how I use stack. If you use cabal-install with or without Nix, great! Those tools seem good, too. This is not an endorsement of stack over the other build tools, just a description of how I use it, the issues I ran into, and my solutions to them.\n\nUnderstanding stack’s model and avoiding its biggest gotcha\nBefore using stack, there are a few things every programmer should know:\n\n\nstack is not a package manager, it is a build tool. It does not manage a set of “installed” packages; it simply builds targets and their dependencies.\n\n\nThe command to build a target is stack build <target>. Just using stack build on its own will build the current project’s targets.\n\n\nYou almost certainly do not want to use stack install.\n\n\nThis is the biggest point of confusion I see among new users of stack. After all, when you want to install a package with npm, you type npm install <package>. So a new Haskeller decides to install lens, types stack install lens, and then later tries stack uninstall lens, only to discover that no such command exists. What happened?\n\nstack install is not like npm install. stack install is like make install. It is nothing more than an alias for stack build --copy-bins, and all it does is build the target and copy all of its executables into some relatively global location like ~/.local/bin. This is usually not what you want.\n\nThis design decision is not unique to stack; cabal-install suffers from it as well. One can argue that it isn’t unintuitive because it really is just following what make install conventionally does, and the fact that it happens to conflict with things like npm install or even apt-get install is just a naming clash. I think that argument is a poor one, however, and I think the decision to even include a stack install command was a bad idea.\n\nSo, remember: don’t use stack install! stack works best when everything lives inside the current project’s local sandbox, and stack install copies executables into a global location by design. While it might sometimes appear to work, it’s almost always wrong. The only situation in which stack install is the right answer is when you want to install an executable for a use unrelated to Haskell development (that is, something like pandoc) that just so happens to be provided by a Haskell package. This means no running stack install ghc-mod or stack install intero either, no matter what READMEs might tell you! Don’t worry: I’ll cover the proper way to install those things later.\n\nActually building your project with stack\nOkay, so now that you know to never use stack install, what do you use? Well, stack build is probably all you need. Let’s cover some variations of stack build that I use most frequently.\n\nOnce you have a stack project, you can build it by simply running stack build within the project directory. However, for local development, this is usually unnecessarily slow because it runs the GHC optimizer. For faster development build times, pass the --fast flag to disable optimizations:\n\n$ stack build --fast\n\nBy default, stack builds dependencies with coarse-grained, package-level parallelism, but you can enable more fine-grained, module-level parallel builds by adding --ghc-options=-j. Unfortunately, there are conflicting accounts on whether or not this actually makes things faster or slower in practice, and I haven’t extensively tested to see whether or not this is the case, so I mostly leave it off.\n\nUsually, you also want to build and run the tests along with your code, which you can enable with the --test flag. Additionally, stack test is an alias for stack build --test, so these two commands are equivalent:\n\n$ stack build --fast --test\n$ stack test --fast\n\nAlso, it is useful to build documentation as well as code! You can do this by passing the --haddock flag, but unfortunately, I find Haddock sometimes takes an unreasonably long time to run. Therefore, since I usually only care about running Haddock on my dependencies, I usually pass the --haddock-deps flag instead, which prevents having to re-run Haddock every time you build:\n\n$ stack test --fast --haddock-deps\n\nFinally, I usually want to build and test my project in the background whenever my code changes. Fortunately, this can be done easily by using the --file-watch flag, making it easy to incrementally change project code and immediately see results:\n\n$ stack test --fast --haddock-deps --file-watch\n\nThis is the command I usually use to develop my Haskell projects.\n\nAccessing local documentation\nWhile Haskell does not always excel on the documentation front, a small amount of documentation is almost always better than no documentation at all, and I find my dependencies’ documentation to be an invaluable resource while developing. I find many people just look at docs on Hackage or use the hosted instance of Hoogle, but this sometimes leads people astray: they might end up looking at the wrong version of the documentation! Fortunately, there’s an easy solution to this problem, which is to browse the documentation stack installs locally, which is guaranteed to match the version you are using in your current project.\n\nThe easiest way to open local documentation for a particular package is to use the stack haddock --open command. For example, to open the documentation for lens, you could use the following command:\n\n$ stack haddock --open lens\n\nThis will open the local documentation in your web browser, and you can browse it at your leisure. If you have already built the documentation using the --haddock-deps option I recommended in the previous section, this command should complete almost instantly, but if you haven’t built the documentation yet, you’ll have to wait as stack builds it for you on-demand.\n\nWhile this is a good start, it isn’t perfect. Ideally, I want to have searchable documentation, and fortunately, this is possible to do by running Hoogle locally. This is easy enough with modern versions of stack, which have built-in Hoogle integration, but it still requires a little bit of per-project setup, since you need to build the Hoogle search index with the following command:\n\n$ stack hoogle -- generate --local\n\nThis will install Hoogle into the current project if it isn’t already installed, and it will index your dependencies’ documentation and generate a new Hoogle database. Once you’ve done that, you can start a web server that serves a local Hoogle search page with the following command:\n\n$ stack hoogle -- server --local --port=8080\n\nNavigate to http://localhost:8080 in your web browser, and you’ll have a fully-searchable index of all your Haskell packages’ documentation. Isn’t that neat?\n\nUnfortunately, you will have to manually regenerate the Hoogle database when you install new packages and their documentation, which you can do by re-running stack hoogle -- generate --local. Fortunately, regenerating the database doesn’t take very long, as long as you’ve been properly rebuilding the documentation with --haddock-deps.\n\nConfiguring your project\nEvery project built with stack is configured with two separate files:\n\n\nThe stack.yaml file, which controls which packages are built and what versions to pin your dependencies to.\n\n\nThe <project>.cabal file or package.yaml file, which specifies build targets, their dependencies, and which GHC options to apply, among other things.\n\n\nThe .cabal file is, ultimately, what is used to build your project, but modern versions of stack generate projects that use hpack, which uses an alternate configuration file, the package.yaml file, to generate the .cabal file. This can get a little bit confusing, since it means you have three configuration files in your project, one of which is generated from the other one.\n\nI happen to use and like hpack, so I use a package.yaml file and allow hpack to generate the .cabal file. I have no real love for YAML, and in fact I think custom configuration formats are completely fine, but the primary advantage of hpack is the ability to specify things like GHC options and default language extensions for all targets at once, instead of needing to duplicate them per-target.\n\nYou can think of the .cabal or package.yaml file as a specification for how your project is built and what packages it depends on, but the stack.yaml file is a specification of precisely which version of each package should be used and where it should be fetched from. Also, each .cabal file corresponds to precisely one Haskell package (though it may have any number of executable targets), but a stack.yaml file can specify multiple different packages to build, useful for multi-project builds that share a common library. The details here can be a little confusing, more than I am likely going to be able to explain in this blog post, but for the most part, you can get away with the defaults unless you’re doing something fancy.\n\nSetting up editor integration\nCurrently, I use Atom to write Haskell. Atom is not a perfect editor by any means, and it leaves a lot to be desired, but it’s easy to set up, and the Haskell editor integration is decent.\n\nAtom’s editor integration is powered by ghc-mod, a program that uses the GHC API to provide tools to inspect Haskell programs. Installing ghc-mod must be done manually so that Atom’s haskell-ghc-mod package can find it, and this is where a lot of people get tripped up. They run stack install ghc-mod, it installs ghc-mod into ~/.local/bin, they put that in their PATH, and things work! …except when a new version of GHC is released a few months later, everything stops working.\n\nAs mentioned above, stack install is not what you want. Tools like ghc-mod, hlint, hoogle, weeder, and intero work best when installed as part of the sandbox, not globally, since that ensures they will match the current GHC version your project is using. This can be done per-project using the ordinary stack build command, so the easiest way to properly install ghc-mod into a stack project is with the following command:\n\n$ stack build ghc-mod\n\nUnfortunately, this means you will need to run that command inside every single stack project individually in order to properly set it up so that stack exec -- ghc-mod will find the correct executable. One way to circumvent this is by using a recently-added stack flag designed for this explicit purpose, --copy-compiler-tool. This is like --copy-bins, but it copies the executables into a compiler-specific location, so a tool built for GHC 8.0.2 will be stored separately from the same tool built for GHC 8.2.2. stack exec arranges for the executables for the current compiler version to end up in the PATH, so you only need to build and install your tools once per compiler version.\n\nDoes this kind of suck? Yes, a little bit, but it sucks a whole lot less than all your editor integration breaking every time you switch to a project that uses a different version of GHC. I use the following command in a fresh sandbox when a Stackage LTS comes out for a new version of GHC:\n\n$ stack build --copy-compiler-tool ghc-mod hoogle weeder\n\nThis way, I only have to build those tools once, and I don’t worry about rebuilding them again until a the next release of GHC. To verify that things are working properly, you should be able to create a fresh stack project, run a command like this one, and get a similar result:\n\n$ stack exec -- which ghc-mod\n/Users/alexis/.stack/compiler-tools/x86_64-osx/ghc-8.2.2/bin/ghc-mod\n\nNote that this path is scoped to my operating system and my compiler version, but nothing else—no LTS or anything like that.\n\nWarning flags for a safe build\nHaskell is a relatively strict language as programming languages go, but in my experience, it isn’t quite strict enough. Many things are not errors that probably ought to be, like orphan instances and inexhaustive pattern matches. Fortunately, GHC provides warnings that catch these problems statically, which fill in the gaps. I recommend using the following flags on all projects to ensure everything is caught:\n\n\n-Wall\n\n\n-Wcompat\n\n\n-Wincomplete-record-updates\n\n\n-Wincomplete-uni-patterns\n\n\n-Wredundant-constraints\n\n\nThe -Wall option turns on most warnings, but (ironically) not all of them. The -Weverything flag truly turns on all warnings, but some of the warnings left disabled by -Wall really are quite silly, like warning when type signatures on polymorphic local bindings are omitted. Some of them, however, are legitimately useful, so I recommend turning them on explicitly.\n\n-Wcompat enables warnings that make your code more robust in the face of future backwards-incompatible changes. These warnings are trivial to fix and serve as free future-proofing, so I see no reason not to turn these warnings on.\n\n-Wincomplete-record-updates and -Wincomplete-uni-patterns are things I think ought to be enabled by -Wall because they both catch what are essentially partial pattern-matches (and therefore runtime errors waiting to happen). The fact that -Wincomplete-uni-patterns isn’t enabled by -Wall is so surprising that it can lead to bugs being overlooked, since the extremely similar -Wincomplete-patterns is enabled by -Wall.\n\n-Wredundant-constraints is a useful warning that helps to eliminate unnecessary typeclass constraints on functions, which can sometimes occur if a constraint was previously necessary but ends up becoming redundant due to a change in the function’s behavior.\n\nI put all five of these flags in the .cabal file (or package.yaml), which enables them everywhere, but this alone is unlikely to enforce a warning-free codebase, since the build will still succeed even in the presence of warnings. Therefore, when building projects in CI, I pass the -Werror flag (using --ghc-options=-Werror for stack), which treats warnings as errors and halts the build if any warnings are found. This is useful, since it means warnings don’t halt the whole build while developing, making it possible to write some code that has warnings and still run the test suite, but it still enforces that pushed code be warning-free.\n\nAny flavor you like\nHaskell is both a language and a spectrum of languages. It is both a standard and a specific implementation. Haskell 98 and Haskell 2010 are good, small languages, and there are a few different implementations, but when people talk about “Haskell”, unqualified, they’re almost always talking about GHC.\n\nGHC Haskell, in stark contrast to standard Haskell, is neither small nor particularly specific, since GHC ships with dozens of knobs and switches that can be used to configure the language. In theory, this is a little terrifying. How could anyone ever hope to talk about Haskell and agree upon how to write it if there are so many different Haskells, each a little bit distinct? Having a cohesive ecosystem would be completely hopeless.\n\nFortunately, in practice, this is not nearly as bad as it seems. The majority of GHC extensions are simple switches: a feature is either on or it is off. Turning a feature on rarely affects code that does not use it, so most extensions can be turned on by default, and programmers may simply avoid the features they do not wish to use, just as any programmer in any programming language likely picks a subset of their language’s features to use on a daily basis. Writing Haskell is not different in this regard, only in the sense that it does not allow all features to be used by default; everything from minor syntactic tweaks to entirely new facets of the type system are opt-in.\n\nFrankly, I think the UX around this is terrible. I recognize the desire to implement a standard Haskell, and the old -fglasgow-exts was not an especially elegant solution for people wishing to use nonstandard Haskell, but having to insert LANGUAGE pragmas at the top of every module just to take advantage of the best features GHC has to offer is a burden, and it is unnecessarily intimidating. I think much of the Haskell community finds the use of LANGUAGE pragmas preferable to enabling extensions globally using the default-extensions list in the .cabal file, but I cut across the grain on that issue hard. The vast majority of language extensions I use are extensions I want enabled all the time; a list of them at the top of a module is just distracting noise, and it only serves to bury the extensions I really do want to enable on a module-by-module basis. It also makes it tricky to communicate with a team which extensions are acceptable (or even preferable) and which are discouraged.\n\nMy strong recommendation if you decide to write GHC Haskell on a team is to agree as a group to a list of extensions the team is happy with enabling everywhere and putting those extensions in the default-extensions list in the .cabal file. This eliminates clutter, busywork, and the conceptual overhead of remembering which extensions are in favor, and which are discouraged. This is a net win, and it isn’t at all difficult to look in the .cabal file when you want to know which extensions are in use.\n\nNow, with that small digression out of the way, the question becomes precisely which extensions should go into that default-extensions list. I happen to like using most of the features GHC makes available, so I enable a whopping 34 language extensions by default. As of GHC 8.2, here is my list:\n\n\nApplicativeDo\n\n\nBangPatterns\n\n\nConstraintKinds\n\n\nDataKinds\n\n\nDefaultSignatures\n\n\nDeriveFoldable\n\n\nDeriveFunctor\n\n\nDeriveGeneric\n\n\nDeriveLift\n\n\nDeriveTraversable\n\n\nDerivingStrategies\n\n\nEmptyCase\n\n\nExistentialQuantification\n\n\nFlexibleContexts\n\n\nFlexibleInstances\n\n\nFunctionalDependencies\n\n\nGADTs\n\n\nGeneralizedNewtypeDeriving\n\n\nInstanceSigs\n\n\nKindSignatures\n\n\nLambdaCase\n\n\nMultiParamTypeClasses\n\n\nMultiWayIf\n\n\nNamedFieldPuns\n\n\nOverloadedStrings\n\n\nPatternSynonyms\n\n\nRankNTypes\n\n\nScopedTypeVariables\n\n\nStandaloneDeriving\n\n\nTupleSections\n\n\nTypeApplications\n\n\nTypeFamilies\n\n\nTypeFamilyDependencies\n\n\nTypeOperators\n\n\nThis is a lot, and a few of them are likely to be more controversial than others. Since I do not imagine everyone will agree with everything in this list, I’ve broken it down into smaller chunks, arranged from what I think ought to be least controversial to most controversial, along with a little bit of justification why each extension is in each category. If you’re interested in coming up with your own list of extensions, the rest of this section is for you.\n\nTrivial lifting of standards-imposed limitations\nA few extensions are tiny changes that lift limitations that really have no reason to exist, other than that they are mandated by the standard. I am not sure why these restrictions are in the standard to begin with, other than perhaps a misguided attempt at making the language simpler. These extensions include the following:\n\n\nEmptyCase\n\n\nFlexibleContexts\n\n\nFlexibleInstances\n\n\nInstanceSigs\n\n\nMultiParamTypeClasses\n\n\nThese extensions have no business not being turned on everywhere. FlexibleContexts and FlexibleInstances end up being turned on in almost any nontrivial Haskell module, since without them, the typeclass system is pointlessly and artificially limited.\n\nInstanceSigs is extremely useful, completely safe, and has zero downsides.\n\nMultiParamTypeClasses are almost impossible to avoid, given how many libraries use them, and they are a completely obvious generalization of single-parameter typeclasses. Much like FlexibleContexts and FlexibleInstances, I see no real reason to ever leave these disabled.\n\nEmptyCase is even stranger to me, since EmptyDataDecls is in Haskell 2010, so it’s possible to define empty datatypes in standard Haskell but not exhaustively pattern-match on them! This is silly, and EmptyCase should be standard Haskell.\n\nSyntactic conveniences\nA few GHC extensions are little more than trivial, syntactic abbreviations. These things would be tiny macros in a Lisp, but they need to be extensions to the compiler in Haskell:\n\n\nLambdaCase\n\n\nMultiWayIf\n\n\nNamedFieldPuns\n\n\nTupleSections\n\n\nAll of these extensions are only triggered by explicit use of new syntax, so existing programs will never change behavior when these extensions are introduced.\n\nLambdaCase only saves a few characters, but it eliminates the need to come up with a fresh, unique variable name that will only be used once, which is sometimes hard to do and leads to worse names overall. Sometimes, it really is better to leave something unnamed.\n\nMultiWayIf isn’t something I find I commonly need, but when I do, it’s nice to have. It’s far easier to read than nested if...then...else chains, and it uses the existing guard syntax already used with function declarations and case...of, so it’s easy to understand, even to those unfamiliar with the extension.\n\nNamedFieldPuns avoids headaches and clutter when using Haskell records without the accidental identifier capture issues of RecordWildCards. It’s a nice, safe compromise that brings some of the benefits of RecordWildCards without any downsides.\n\nTupleSections is a logical generalization of tuple syntax in the same vein as standard operator sections, and it’s quite useful when using applicative notation. I don’t see any reason to not enable it.\n\nExtensions to the deriving mechanism\nGHC’s typeclass deriving mechanism is one of the things that makes Haskell so pleasant to write, and in fact I think Haskell would be nearly unpalatable to write without it. Boilerplate generation is a good thing, since it defines operations in terms of a single source of truth, and generated code is code you do not need to maintain. There is rarely any reason to write a typeclass instance by hand when the deriving mechanism will write it automatically.\n\nThese extensions give GHC’s typeclass deriving mechanism more power without any cost. Therefore, I see no reason not to enable them:\n\n\nDeriveFoldable\n\n\nDeriveFunctor\n\n\nDeriveGeneric\n\n\nDeriveLift\n\n\nDeriveTraversable\n\n\nDerivingStrategies\n\n\nGeneralizedNewtypeDeriving\n\n\nStandaloneDeriving\n\n\nThe first five of these simply extend the list of typeclasses GHC knows how to derive, something that will only ever be triggered if the user explicitly requests GHC derive one of those classes. GeneralizedNewtypeDeriving is quite possibly one of the most important extensions in all of Haskell, since it dramatically improves newtypes’ utility. Wrapper types can inherit instances they need without any boilerplate, and making increased type safety easier and more accessible is always a good thing in my book.\n\nDerivingStrategies is new to GHC 8.2, but it finally presents the functionality of GHC’s DeriveAnyClass extension in a useful way. DeriveAnyClass is useful when used with certain libraries that use DefaultSignatures (discussed later) with GHC.Generics to derive instances of classes without the deriving being baked into GHC. Unfortunately, enabling DeriveAnyClass essentially disables the far more useful GeneralizedNewtypeDeriving, so I do not recommend enabling DeriveAnyClass. Fortunately, with DerivingStrategies, it’s possible to opt into the anyclass deriving strategy on a case-by-case basis, getting some nice boilerplate reduction in the process.\n\nStandaloneDeriving is useful when GHC’s deriving algorithms aren’t quite clever enough to deduce the instance context automatically, so it allows specifying it manually. This is only useful in a few small situations, but it’s nice to have, and there are no downsides to enabling it, so it ought to be turned on.\n\nLightweight syntactic adjustments\nA couple extensions tweak Haskell’s syntax in more substantial ways than things like LambdaCase, but not in a significant enough way for them to really be at all surprising:\n\n\nBangPatterns\n\n\nKindSignatures\n\n\nTypeOperators\n\n\nBangPatterns mirror strictness annotations on datatypes, so they are unlikely to be confusing, and they provide a much more pleasant notation for annotating the strictness of bindings than explicit uses of seq.\n\nKindSignatures are also fairly self-explanatory: they’re just like type annotations, but for types instead of values. Writing kind signatures explicitly is usually unnecessary, but they can be helpful for clarity or for annotating phantom types when PolyKinds is not enabled. Enabling KindSignatures doesn’t have any adverse effects, so I see no reason not to enable it everywhere.\n\nTypeOperators adjusts the syntax of types slightly, allowing operators to be used as type constructors and written infix, which is technically backwards-incompatible, but I’m a little suspicious of anyone using (!@#$) as a type variable (especially since standard Haskell does not allow them to be written infix). This extension is useful with some libraries like natural-transformations that provide infix type constructors, and it makes the type language more consistent with the value language.\n\nPolymorphic string literals\nI’m putting this extension in a category all of its own, mostly because I don’t think any other Haskell extensions have quite the same set of tradeoffs:\n\n\nOverloadedStrings\n\n\nFor me, OverloadedStrings is not optional. Haskell’s infamous “string problem” (discussed in more detail at the end of this blog post) means that String is a linked list of characters, and all code that cares about performance actually uses Text. Manually invoking pack on every single string literal in a program is just noise, and OverloadedStrings solves that noise.\n\nThat said, I actually find I don’t use the polymorphism of string literals very often, and I’d be alright with monomorphic literals if I could make them all have type Text. Unfortunately, there isn’t a way to do this, so OverloadedStrings is the next best thing, even if it sometimes causes some unnecessary ambiguities that require type annotations to resolve.\n\nOverloadedStrings is an extension that I use so frequently, in so many modules (especially in my test suites) that I would rather keep it on everywhere so I don’t have to care about whether or not it’s enabled in the module I’m currently writing. On the other hand, it certainly isn’t my favorite language extension, either. I wouldn’t go as far as to call it a necessary evil, since I don’t think it’s truly “evil”, but it does seem to be necessary.\n\nSimple extensions to aid type annotation\nThe following two extensions significantly round out Haskell’s language for referring to types, making it much easier to insert type annotations where necessary (for removing ambiguity or for debugging type errors):\n\n\nScopedTypeVariables\n\n\nTypeApplications\n\n\nThat the behavior of ScopedTypeVariables is not the default is actually one of the most common gotchas for new Haskellers. Sadly, it can theoretically adjust the behavior of existing Haskell programs, so I cannot include it in the list of trivial changes, but I would argue such programs were probably confusing to begin with, and I have never seen a program in practice that was impacted by that problem. I think leaving ScopedTypeVariables off is much, much more likely to be confusing than turning it on.\n\nTypeApplications is largely unrelated, but I include it in this category because it’s quite useful and cooperates well with ScopedTypeVariables. Use of TypeApplications makes instantiation much more lightweight than full-blown type annotations, and once again, it has no downsides if it is enabled and unused (since it is a syntactic addition). I recommend enabling it.\n\nSimple extensions to the Haskell type system\nA few extensions tweak the Haskell type system in ways that I think are simple enough to be self-explanatory, even to people who might not have known they existed. These are as follows:\n\n\nConstraintKinds\n\n\nRankNTypes\n\n\nConstraintKinds is largely just used to define typeclass aliases, which is both useful and self-explanatory. Unifying the type and constraint language also has the effect of allowing type-level programming with constraints, which is sometimes useful, but far rarer in practice than the aforementioned use case.\n\nRankNTypes are uncommon, looking at the average type in a Haskell program, but they’re certainly nice to have when you need them. The idea of pushing foralls further into a type to adjust how variables are quantified is something that I find people find fairly intuitive, especially after seeing them used once or twice, and higher-rank types do crop up regularly, if infrequently.\n\nIntermediate syntactic adjustments\nThree syntactic extensions to Haskell are a little bit more advanced than the ones I’ve already covered, and none of them are especially related:\n\n\nApplicativeDo\n\n\nDefaultSignatures\n\n\nPatternSynonyms\n\n\nApplicativeDo is, on the surface, simple. It changes do notation to use Applicative operations where possible, which allows using do notation with applicative functors that are not monads, and it also makes operations potentially more performant when (<*>) can be implemented more efficiently than (>>=). In theory, it sounds like there are no downsides to enabling this everywhere. However, there are are a few drawbacks that lead me to put it so low on this list:\n\n\nIt considerably complicates the desugaring of do blocks, to the point where the algorithm cannot even be easily syntactically documented. In fact, an additional compiler flag, -foptimal-applicative-do, is a way to opt into optimal solutions for do block expansions, tweaking the desugaring algorithm to have an O(n3) time complexity! This means that the default behavior is guided by a heuristic, and desugaring isn’t even especially predictable. This isn’t necessarily so bad, since it’s really only intended as an optimization when some Monad operations are still necessary, but it does dramatically increase the complexity of one of Haskell’s core forms.\n\n\nThe desugaring, despite being O(n2) by default, isn’t even especially clever. It relies on a rather disgusting hack that recognizes return e, return $ e, pure e, or pure $ e expressions syntactically, and it completely gives up if an expression with precisely that shape is not the final statement in a do block. This is a bit awkward, since it effectively turns return and pure into syntax when before they were merely functions, but that isn’t all. It also means that the following do block is not desugared using Applicative operations:\n\ndo foo a b\n   bar s t\n   baz y z\nThis will use the normal, monadic desugaring, despite the fact that it is trivially desugared into Applicative operations as foo a b *> bar s t *> baz y z. In order to get ApplicativeDo to trigger here, the do block must be contorted into the following:\n\ndo foo a b\n   bar s t\n   r <- baz y z\n   pure r\nThis seems like an odd oversight.\n\n\nTemplateHaskell doesn’t seem able to cope with do blocks when ApplicativeDo is enabled. I reported this as an issue on the GHC bug tracker, but it hasn’t received any attention, so it’s not likely to get fixed unless someone takes the initiative to do so.\n\n\nEnabling ApplicativeDo can cause problems with code that may have assumed do would always be monadic, and sometimes, that can cause code that typechecks to lead to an infinite loop at runtime. Specifically, if do notation is used to define (<*>) in terms of (>>=), enabling ApplicativeDo will cause the definition of (<*>) to become self-referential and therefore divergent. Fortunately, this issue can be easily mitigated by simply writing (<*>) = ap instead, which is clearer and shorter than the equivalent code using do.\n\n\nGiven all these things, it seems ApplicativeDo is a little too new in a few places, and it isn’t quite baked. Still, I keep it enabled by default. Why? Well, usually it works fine without any problems, and when I run into issues, I can disable it on a per-module basis by writing {-# LANGUAGE NoApplicativeDo #-}. I still find that keeping it enabled by default is fine the vast majority of the time, I just sometimes need to work around the bugs.\n\nIn contrast, DefaultSignatures isn’t buggy at all, as far as I can tell, it’s just not usually useful without fairly advanced features like GADTs (for type equalities) or GHC.Generics. I mostly use it for making lifting instances for mtl-style typeclasses easier to write, which I’ve found to be a tiny bit tricky to explain (mostly due to the use of type equalities in the context), but it works well. I don’t see any real reason to leave this disabled, but if you don’t think you’re going to use it anyway, it doesn’t really matter one way or the other.\n\nFinally, PatternSynonyms allow users to extend the pattern language just as they are allowed to extend the value language. Bidirectional pattern synonyms are isomorphisms, and it’s quite useful to allow those isomorphisms to be used with Haskell’s usual pattern-matching syntax. I think this extension is actually quite benign, but I put it so low on this list because it seems infrequently used, and I get the sense most people consider it fairly advanced. I would argue, however, that it’s a very pleasant, useful extension, and it’s no more complicated than a number of the features in Haskell 98.\n\nIntermediate extensions to the Haskell type system\nNow we’re getting into the meat of things. Everything up to this point has been, in my opinion, completely self-evident in its usefulness and simplicity. As far as I’m concerned, the extensions in the previous six sections have no business ever being left disabled. Starting in this section, however, I could imagine a valid argument being made either way.\n\nThe following three extensions add some complexity to the Haskell type system in return for some added expressive power:\n\n\nExistentialQuantification\n\n\nFunctionalDependencies\n\n\nGADTs\n\n\nExistentialQuantification and GADTs are related, given that the former is subsumed by the latter, but GADTs also enables an alternative syntax. Both syntaxes allow packing away a typeclass dictionary or equality constraint that is brought into scope upon a successful pattern-match against a data constructor, something that is sometimes quite useful but certainly a departure from Haskell’s simple ADTs.\n\nFunctionalDependencies extend multi-parameter typeclasses, and they are almost unavoidable, given their use in the venerable mtl library. Like GADTs, FunctionalDependencies add an additional layer of complexity to the typeclass system in order to express certain things that would otherwise be difficult or impossible.\n\nAll of these extensions involve a tradeoff. Enabling GADTs also implies MonoLocalBinds, which disables let generalization, one of the most likely ways a program that used to typecheck might subsequently fail to do so. Some might argue that this is a good reason to turn GADTs on in a per-module basis, but I disagree: I actually want my language to be fairly consistent, and given that I know I am likely going to want to use GADTs somewhere, I want MonoLocalBinds enabled everywhere, not inconsistently and sporadically.\n\nThat aside, all these extensions are relatively safe. They are well-understood, and they are fairly self-contained extensions to the Haskell type system. I think these extensions have a very good power to cost ratio, and I find myself using them regularly (especially FunctionalDependencies), so I keep them enabled globally.\n\nAdvanced extensions to the Haskell type system\nFinally, we arrive at the last set of extensions in this list. These are the most advanced features Haskell’s type system currently has to offer, and they are likely to be the most controversial to enable globally:\n\n\nDataKinds\n\n\nTypeFamilies\n\n\nTypeFamilyDependencies\n\n\nAll of these extensions exist exclusively for the purpose of type-level programming. DataKinds allows datatype promotion, creating types that are always uninhabited and therefore can only be used phantom. TypeFamilies allows the definition of type-level functions that map types to other types. Both of these are minor extensions to Haskell’s surface area, but they have rather significant ramifications on the sort of programming that can be done and the way GHC’s typechecker must operate.\n\nTypeFamilies is an interesting extension because it comes in so many flavors: associated type synonyms, associated datatypes, open and closed type synonym families, and open and closed datatype families. Associated types tend to be easier to grok and easier to use, though they can also be replaced by functional dependencies. Open type families are also quite similar to classes and instances, so they aren’t too tricky to understand. Closed type families, on the other hand, are a rather different beast, and they can be used to do fairly advanced things, especially in combination with DataKinds.\n\nI happen to appreciate GHC’s support for these features, and while I’m hopeful that an eventual DependentHaskell will alleviate many of the existing infelicities with dependently typed programming in GHC, in the meantime, it’s often useful to enjoy what exists where practically applicable. Therefore, I have little problem keeping them enabled, since, like the vast majority of extensions on this list, these extensions merely lift restrictions, not adjust semantics of the language without the extensions enabled. When I am going to write a type family, I am going to turn on TypeFamilies; I see no reason to annotate the modules in which I decide to do so. I do not write an annotation at the top of each module in which I define a typeclass or a datatype, so why should I do so with type families?\n\nTypeFamilyDependencies is a little bit different, since it’s a very new extension, and it doesn’t seem to always work as well as I would hope. Still, when it doesn’t work, it fails with a very straightforward error message, and when it works, it is legitimately useful, so I don’t see any real reason to leave it off if TypeFamilies is enabled.\n\nExtensions intentionally left off this list\nGiven what I’ve said so far, it may seem like I would advocate flipping on absolutely every lever GHC has to offer, but that isn’t actually true. There are a few extensions I quite intentionally do not enable.\n\nUndecidableInstances is something I turn on semi-frequently, since GHC’s termination heuristic is not terribly advanced, but I turn it on per-module, since it’s useful to know when it’s necessary (and in application code, it rarely is). OverlappingInstances and IncoherentInstances, in contrast, are completely banned—not only are they almost always a bad idea, GHC has a better, more fine-grained way to opt into overlapping instances, using the {-# OVERLAPPING #-}, {-# OVERLAPPABLE #-}, and {-# INCOHERENT #-} pragmas.\n\nTemplateHaskell and QuasiQuotes are tricky ones. Anecdotes seem to suggest that enabling TemplateHaskell everywhere leads to worse compile times, but after trying this on a few projects and measuring, I wasn’t able to detect any meaningful difference. Unless I manage to come up with some evidence that these extensions actually slow down compile times just by being enabled, even if they aren’t used, then I may add them to my list of globally-enabled extensions, since I use them regularly.\n\nOther extensions I haven’t mentioned are probably things I just don’t use very often and therefore haven’t felt the need to include on this list. It certainly isn’t exhaustive, and I add to it all the time, so I expect I will continue to do so in the future. This is just what I have for now, and if your favorite extension isn’t included, it probably isn’t a negative judgement against that extension. I just didn’t think to mention it.\n\nLibraries: a field guide\nNow that you’re able to build a Haskell project and have chosen which handpicked flavor of Haskell you are going to write, it’s time to decide which libraries to use. Haskell is an expressive programming language, and the degree to which different libraries can shape the way you structure your code is significant. Picking the right libraries can lead to clean code that’s easy to understand and maintain, but picking the wrong ones can lead to disaster.\n\nOf course, there are thousands of Haskell libraries on Hackage alone, so I cannot hope to cover all of the ones I have ever found useful, and I certainly cannot cover ones that would be useful but I did not have the opportunity to try (of which there are certainly many). This blog post is long enough already, so I’ll just cover a few categories of libraries that I think I can offer interesting commentary on; most libraries can generally speak for themselves.\n\nHaving an effect\nOne of the first questions Haskell programmers bump into when they begin working on a large application is how they’re going to model effects. Few practical programming languages are pure, but Haskell is one of them, so there’s no getting away from coming up with a way to manage side-effects.\n\nFor some applications, Haskell’s built-in solution might be enough: IO. This can work decently for data processing programs that do very minimal amounts of I/O, and the types of side-effects they perform are minimal. For these applications, most of the logic is likely to be pure, which means it’s already easy to reason about and easy to test. For other things, like web applications, it’s more likely that a majority of the program logic is going to be side-effectful by its nature—it may involve making HTTP requests to other services, interacting with a database, and writing to logfiles.\n\nFiguring out how to structure these effects in a type-safe, decoupled, composable way can be tricky, especially since Haskell has so many different solutions. I could not bring myself to choose just one, but I did choose two: the so-called “mtl style” and freer monads.\n\nmtl style is so named because it is inspired by the technique of interlocking monadic typeclasses and lifting instances used to model effects using constraints that is used in the mtl library. Here is a small code example of what mtl style typeclasses and handlers look like:\n\nclass Monad m => MonadFileSystem m where\n  readFile :: FilePath -> m String\n  writeFile :: FilePath -> String -> m ()\n\n  default readFile :: (MonadTrans t, MonadFileSystem m', m ~ t m') => FilePath -> m String\n  readFile a = lift $ readFile a\n\n  default writeFile :: (MonadTrans t, MonadFileSystem m', m ~ t m') => FilePath -> String -> m ()\n  writeFile a b = lift $ writeFile a b\n\ninstance MonadFileSystem IO where\n  readFile = Prelude.readFile\n  writeFile = Prelude.writeFile\n\ninstance MonadFileSystem m => MonadFileSystem (ExceptT e m)\ninstance MonadFileSystem m => MonadFileSystem (MaybeT m)\ninstance MonadFileSystem m => MonadFileSystem (ReaderT r m)\ninstance MonadFileSystem m => MonadFileSystem (StateT s m)\ninstance MonadFileSystem m => MonadFileSystem (WriterT w m)\n\nnewtype InMemoryFileSystemT m a = InMemoryFileSystemT (StateT [(FilePath, String)] m a)\n  deriving (Functor, Applicative, Monad, MonadError e, MonadReader r, MonadWriter w)\n\ninstance Monad m => MonadFileSystem (InMemoryFileSystemT m) where\n  readFile path = InMemoryFileSystemT $ do\n    vfs <- get\n    case lookup path vfs of\n      Just contents -> pure contents\n      Nothing -> error (\"readFile: no such file \" ++ path)\n\n  writeFile path contents = InMemoryFileSystemT $ modify $ \\vfs ->\n    (path, contents) : delete (path, contents) vfs\nThis is the most prevalent way to abstract over effects in Haskell, and it’s been around for a long time. Due to the way it uses the typeclass system, it’s also very fast, since GHC can often specialize and inline the typeclass dictionaries to avoid runtime dictionary passing. The main drawbacks are the amount of boilerplate required and the conceptual difficulty of understanding exactly how monad transformers, monadic typeclasses, and lifting instances all work together to discharge mtl style constraints.\n\nThere are various alternatives to mtl’s direct approach to effect composition, most of which are built around the idea of reifying a computation as a data structure and subsequently interpreting it. The most popular of these is the Free monad, a clever technique for deriving a monad from a functor that happens to be useful for modeling programs. Personally, I think Free is overhyped. It’s a cute, mathematically elegant technique, but it involves a lot of boilerplate, and composing effect algebras is still a laborious process. The additional expressive power of Free, namely its ability to choose an interpreter dynamically, at runtime, is rarely necessary or useful, and it adds complexity and reduces performance for few benefits. (And in fact, this is still possible to do with mtl style, it’s just uncommon because there is rarely any need to do so.)\n\nA 2017 blog post entitled Free monad considered harmful discussed Free in comparison with mtl style, and unsurprisingly cast Free in a rather unflattering light. I largely agree with everything outlined in that blog post, so I will not retread its arguments here. I do, however, think that there is another abstraction that is quite useful: the so-called “freer monad” used to implement extensible effects.\n\nFreer moves even further away from worrying about functors and monads, since its effect algebras do not even need to be functors. Instead, freer’s effect algebras are ordinary GADTs, and reusable, composable effect handlers are easily written to consume elements of these datatypes. Unfortunately, the way this works means that GHC is still not clever enough to optimize freer monads as efficiently as mtl style, since it can’t easily detect when the interpreter is chosen statically and use that information to specialize and inline effect implementations, but the cost difference is significantly reduced, and I’ve found that in real application code, the vast majority of the cost does not come from the extra overhead introduced by a more expensive (>>=).\n\nThere are a few different implementations of freer monads, but I, sadly, was not satisfied with any of them, so I decided to contribute to the problem by creating yet another one. My implementation is called freer-simple, and it includes a streamlined API with more documentation than any other freer implementation. Writing the above mtl style example using freer-simple is more straightforward:\n\ndata FileSystem r where\n  ReadFile :: FilePath -> FileSystem String\n  WriteFile :: FilePath -> String -> FileSystem ()\n\nreadFile :: Member FileSystem r => FilePath -> Eff r String\nreadFile a = send $ ReadFile a\n\nwriteFile :: Member FileSystem r => FilePath -> String -> Eff r ()\nwriteFile a b = send $ WriteFile a b\n\nrunFileSystemIO :: LastMember IO r => Eff (FileSystem ': r) ~> Eff r\nrunFileSystemIO = interpretM $ \\case\n  ReadFile a -> Prelude.readFile a\n  WriteFile a b -> Prelude.writeFile a b\n\nrunFileSystemInMemory :: [(FilePath, String)] -> Eff (FileSystem ': effs) ~> Eff effs\nrunFileSystemInMemory initVfs = runState initVfs . fsToState where\n  fsToState :: Eff (FileSystem ': effs) ~> Eff (State [(FilePath, String)] ': effs)\n  fsToState = reinterpret $ case\n    ReadFile path -> get >>= \\vfs -> case lookup path vfs of\n      Just contents -> pure contents\n      Nothing -> error (\"readFile: no such file \" ++ path)\n    WriteFile path contents -> modify $ \\vfs ->\n      (path, contents) : delete (path, contents) vfs\n(It could be simplified further with a little bit of Template Haskell to generate the readFile and writeFile function definitions, but I haven’t gotten around to writing that.)\n\nSo which effect system do I recommend? I used to recommend mtl style, but as of only two months ago, I now recommend freer-simple. It’s easier to understand, involves less boilerplate, achieves “good enough” performance, and generally gets out of the way wherever possible. Its API is designed to make it easy to do the sorts of the things you most commonly need to do, and it provides a core set of effects that can be used to build a real-world application.\n\nThat said, freer is indisputably relatively new and relatively untested. It has success stories, but mtl style is still the approach used by the majority of the ecosystem. mtl style has more library support, its performance characteristics are better understood, and it is a tried and true way to structure effects in a Haskell application. If you understand it well enough to use it, and you are happy with it in your application, my recommendation is to stick with it. If you find it confusing, however, or you end up running up against its limits, give freer-simple a try.\n\nThrough the looking glass: to lens or not to lens\nThere’s no getting around it: lens is a behemoth of a library. For a long time, I wrote Haskell without it, and honestly, it worked out alright. I just wasn’t doing a whole lot of work that involved complicated, deeply-nested data structures, and I didn’t feel the need to bring in a library with such a reputation for having impenetrable operators and an almost equally impenetrable learning curve.\n\nBut, after some time, I decided I wanted to take the plunge. So I braced myself for the worst, pulled out my notebook, and started writing some code. To my surprise… it wasn’t that hard. It made sense. Sure, I still don’t know how it works on the inside, and I never did learn the majority of the exports in Control.Lens.Operators, but I had no need to. Lenses were useful in the way I had expected them to be, and so were prisms. One thing led to another, and before long, I understood the relationship between the various optics, the most notable additions to my toolkit being folds and traversals. Sure, the type errors were completely opaque much of the time, but I was able to piece things together with ample type annotations and time spent staring at ill-typed expressions. Before long, I had developed an intuition for lens.\n\nAfter using it for a while, I retrospected on whether or not I liked it, and honestly, I still can’t decide. Some lensy expressions were straightforward to read and were a pleasant simplification, like this one:\n\nparamSpecs ^.. folded._Required\nOthers were less obviously improvements, such as this beauty:\n\nM.fromList $ paramSpecs ^.. folded._Optional.filtered (has $ _2._UsePreviousValue)\nBut operator soup aside, there was something deeper about lens that bothered me, and I just wasn’t sure what. I didn’t know how to articulate my vague feelings until I read a 2014 blog post entitled Lens is unidiomatic Haskell, which includes a point that I think is spot-on:\n\nUsually, types in Haskell are rigid. This leads to a distinctive style of composing programs: look at the types and see what fits where. This is impossible with lens, which takes overloading to the level mainstream Haskell probably hasn’t seen before.\n\nWe have to learn the new language of the lens combinators and how to compose them, instead of enjoying our knowledge of how to compose Haskell functions. Formally, lens types are Haskell function types, but while with ordinary Haskell functions you immediately see from types whether they can be composed, with lens functions this is very hard in practice.\n\n[…]\n\nNow let me clarify that this doesn’t necessarily mean that lens is a bad library. It’s an unusual library. It’s almost a separate language, with its own idioms, embedded in Haskell.\n\nThe way lens structures its types deliberately introduces a sort of subtyping relationship—for example, all lenses are traversals and all traversals are folds, but not vice versa—and indeed, knowing this subtyping relationship is essential to working with the library and understanding how to use it. It is helpfully documented with a large diagram on the lens package overview page, and that diagram was most definitely an invaluable resource for me when I was learning how to use the library.\n\nOn the surface, this isn’t unreasonable. Subtyping is an enormously useful concept! The only reason Haskell dispenses with it entirely is because it makes type inference notoriously difficult. The subtyping relation between optics is one of the things that makes them so useful, since it allows you to easily compose a lens with a prism and get a traversal out. Unfortunately, the downside of all this is that Haskell does not truly have subtyping, so all of lens’s “types” really must be type aliases for types of roughly the same shape, namely functions. This makes type errors completely baffling, since the errors do not mention the aliases, only the fully-expanded types (which are often rather complicated, and their meaning is not especially clear without knowing how lens works under the hood).\n\nSo the above quote is correct: working with lens really is like working in a separate embedded language, but I’m usually okay with that. Embedded, domain-specific languages are good! Unfortunately, in this case, the host language is not very courteous to its guest. Haskell does not appear to be a powerful enough language for lens to be a language in its own right, so it must piggyback on top of Haskell’s error reporting mechanisms, which are insufficient for lens to be a cohesive linguistic abstraction. Just as debugging code by stepping through the assembly it produces (or, perhaps more relevant in 2018, debugging a compile-to-JS language by looking at the emitted JavaScript instead of the source code) makes for an unacceptably leaky language. We would never stand for such a thing in our general-purpose language tooling, and we should demand better even in our embedded languages.\n\nThat said, lens is just too useful to ignore. It is a hopelessly leaky abstraction, but it’s still an abstraction, and a powerful one at that. Given my selection of default extensions as evidence, I think it’s clear I have zero qualms with “advanced” Haskell; I will happily use even singletons where it makes sense. Haskell’s various language extensions are sometimes confusing in their own right, but their complexity is usually fundamental to the expressive power they bring. lens has some fundamental complexity, too, but it is mostly difficult for the wrong reasons. Still, while it is not the first library I reach for on every new Haskell project, manipulating nested data without lens is just too unpleasant after tasting the nectar, so I can’t advise against it in good faith.\n\nSadly, this means I’m a bit wishy-washy when it comes to using lens, but I do have at least one recommendation: if you decide to use lens, it’s better to go all-in. Don’t generate lenses for just a handful of datatypes, do it for all of them. You can definitely stick to a subset of the lens library’s features, but don’t apply it in some functions but not others. Having too many different, equally valid ways of doing things leads to confusion and inconsistency, and inconsistency minimizes code reuse and leads to duplication and spaghetti. Commit to using lens, or don’t use it at all.\n\nMitigating the string problem\nFinally, Haskell has a problem with strings. Namely, String is a type alias for [Char], a lazy, singly linked list of characters, which is an awful representation of text. Fortunately, the answer to this problem is simple: ban String in your programs.\n\nUse Text everywhere. I don’t really care if you pick strict Text or lazy Text, but pick one and stick to it. Don’t ever use String, and especially don’t ever, ever, ever use ByteString to represent text! There are enormously few legitimate cases for using ByteString in a program that is not explicitly about reading or writing raw data, and even at that level, ByteString should only be used at program boundaries. In that sense, I treat ByteString much the same way I treat IO: push it to the boundaries of your program.\n\nOne of Haskell’s core tenets is making illegal states unrepresentable. Strings are not especially useful datatypes for this, since they are sequences of arbitrary length made up of atoms that can be an enormously large number of different things. Still, string types enforce a very useful invariant, a notion of a sequence of human-readable characters. In the presence of Unicode, this is a more valuable abstraction than it might seem, and the days of treating strings as little different from sequences of bytes are over. While strings make a poor replacement for enums, they are quite effective at representing the incredible amount of text humans produce in a staggeringly large number of languages, and they are the right type for that job.\n\nByteString, on the other hand, is essentially never the right type for any job. If a type classifies a set of values, ByteString is no different from Any. It is the structureless type, the all-encompassing blob of bits. A ByteString could hold anything at all—some text, an image, an executable program—and the type system certainly isn’t going to help to answer that question. The only use case I can possibly imagine for passing around a ByteString in your program rather than decoding it into a more precise type is if it truly holds opaque data, e.g. some sort of token or key provided by a third party with no structure guaranteed whatsoever. Still, even this should be wrapped in a newtype so that the type system enforces this opaqueness.\n\nTroublingly, ByteString shows up in many libraries’ APIs where it has no business being. In many cases, this seems to be things where ASCII text is expected, but this is hardly a good reason to willingly accept absolutely anything and everything! Make an ASCII type that forbids non-ASCII characters, and provide a ByteString -> Maybe ASCII function. Alternatively, think harder about your problem in question to properly support Unicode as you almost certainly ought to.\n\nOther places ByteString appears are similarly unfortunate. Base-64 encoding, for example, could be given the wonderfully illustrative type ByteString -> Text, or even ByteString -> ASCII! Such a type makes it immediately clear why base-64 is useful: it allows transforming arbitrary binary data into a reliable textual encoding. If we consider that ByteString is essentially Any, this function has the type Any -> ASCII, which is amazingly powerful! We can convert anything to ASCII text!\n\nExisting libraries, however, just provide the boring, disappointingly inaccurate type ByteString -> ByteString, which is one of the most useless types there is. It is essentially Any -> Any, the meaningless function type. It conveys nothing about what it does, other than that it is pure. Giving a function this type is scarcely better than dynamic typing. Its mere existence is a failure of Haskell library design.\n\nBut wait, it gets worse! Data.Text.Encoding exports a function called decodeUtf8, which has type ByteString -> Text. What an incredible function with a captivating type! Whatever could it possibly do? Again, this function’s type is basically Any -> Text, which is remarkable in the power it gives us. Let’s try it out, shall we?\n\nghci> decodeUtf8 \"\\xc3\\x28\"\n\"*** Exception: Cannot decode byte '\\x28': Data.Text.Internal.Encoding.decodeUtf8: Invalid UTF-8 stream\n\nOh. Well, that’s a disappointment.\n\nHaskell’s string problem goes deeper than String versus Text; it seems to have wound its way around the collective consciousness of the Haskell community and made it temporarily forget that it cares about types and totality. This isn’t that hard, I swear! I can only express complete befuddlement at how many of these APIs are just completely worthless.\n\nFortunately, there is a way out, and that way out is text-conversions. It is the first Haskell library I ever wrote. It provides type safe, total conversions between Text and various other types, and it is encoding aware. It provides appropriately-typed base-16 and base-64 conversion functions, and is guaranteed to never raise any exceptions. Use it, and apply the Haskell philosophy to your strings, just as you already do for everything else in your program.\n\nClosing thoughts\nPhew.\n\nWhen I started writing this blog post, it used the phrase “short overview” in the introduction. It is now over ten thousand words long. I think that’s all I have it in me to say for now.\n\nHaskell is a wonderful language built by a remarkable group of people. Its community is often fraught with needlessly inflammatory debates about things like the value of codes of conduct, the evils of Hackage revisions, and precisely how much or how little people ought to care about the monad laws. These flame wars frustrate me to no end, and they sometimes go so far as to make me ashamed to call myself a part of the Haskell community. Many on the “outside” seem to view Haskellers as an elitist, mean-spirited cult, more interested in creating problems for itself than solving them.\n\nThat perception is categorically wrong.\n\nI have never been in a community of programmers so dedicated and passionate about applying thought and rigor to building software, then going out and actually doing it. I don’t know anywhere else where a cutting-edge paper on effect systems is discussed by the very same people who are figuring out how to reliably deploy distributed services to AWS. Some people view the Haskell community as masturbatory, and to some extent, they are probably right. One of my primary motivators for writing Haskell is that it is fun and it challenges me intellectually in ways that other languages don’t. But that challenge is not a sign of uselessness, it is a sign that Haskell is so close to letting me do the right thing, to solving the problem the right way, to letting me work without compromises. When I write in most programming languages, I must constantly accept that my program will never be robust in all the ways I want it to be, and I might as well give up before I even start. Haskell’s greatest weakness is that it tempts me to try.\n\nHaskell is imperfect, as it will always be. I doubt I will ever be satisfied by any language or any ecosystem. There will always be more to learn, more to discover, better tools and abstractions to develop. Many of them will not look anything like Haskell; they may not involve formal verification or static types or effect systems at all. Perhaps live programming, structural editors, and runtime hotswapping will finally take over the world, and we will find that the problems we thought we were solving were irrelevant to begin with. I can’t predict the future, and while I’ve found great value in the Haskell school of program construction, I dearly hope that we do not develop such tunnel vision that we cannot see that there may be other ways to solve these problems. Many of the solutions are things we likely have not even begun to think about. Still, whether that happens or not, it is clear to me that Haskell is a point in the design space unlike any other, and we learn almost as much from the things it gets wrong as we do from the things it gets right.\n\nIt’s been a wonderful two years, Haskell. I won’t be a stranger.","isoDate":"2018-02-10T00:00:00.000Z","timestamp":"2/9/2018"},{"title":"A space of their own: adding a type namespace to Hackett","pubDate":"2017-10-27T00:00:00.000Z","author":"Alexis King","content":"<article><p>As previously discussed on this blog, <a href=\"https://github.com/lexi-lambda/hackett\">my programming language, Hackett</a>, is a fusion of two languages, Haskell and Racket. What happens when two distinctly different programming languages collide? Hackett recently faced that very problem when it came to the question of namespacing: Haskell has two namespaces, one for values and another for types, but Racket is a staunch Lisp-1 with a single namespace for all bindings. Which convention should Hackett adopt?\n</p><p>For now, at least, the answer is that Hackett will emulate Haskell: <strong>Hackett now has two namespaces</strong>. Of course, Hackett is embedded in Racket, so what did it take to add an entirely new namespace to a language that possesses only one? The answer was a little more than I had hoped, but it was still remarkably simple given the problem: after two weeks of hacking, I’ve managed to get something working.\n</p><h2><a name=\"why-two-namespaces\"></a>Why two namespaces?</h2><p>Before delving into the mechanics of how multi-namespace Hackett is implemented, it’s important to understand what Hackett’s namespaces actually are and why they exist in the first place. Its host language, Racket, is a descendant of Scheme, a Lisp derivative that famously chose to only use a single namespace. This means everything—from values to functions to classes—lives in a single namespace in Racket.\n</p><p>This is in stark contrast to Common Lisp, which opts to divide bindings into many namespaces, most notably pushing functions into a separate namespace from other variables. You can see this difference most strikingly when applying higher-order functions. In Racket, Clojure, and Scheme, functions can be passed freely as values:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">first</span> <span class=\"o\">&#39;</span><span class=\"p\">((</span><span class=\"mi\">1</span> <span class=\"ss\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"mi\">2</span> <span class=\"ss\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"mi\">3</span> <span class=\"ss\">c</span><span class=\"p\">)))</span>\n<span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">)</span></code></pre><p>In Common Lisp and other languages with two namespaces, functions may still be passed as values, but the programmer must explicitly <em>annotate</em> when they wish to use a value from a different namespace:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">mapcar</span> <span class=\"nf\">#&#39;</span><span class=\"nb\">car</span> <span class=\"o\">&#39;</span><span class=\"p\">((</span><span class=\"mi\">1</span> <span class=\"nv\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"mi\">2</span> <span class=\"nv\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"mi\">3</span> <span class=\"nv\">c</span><span class=\"p\">)))</span>\n<span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">)</span></code></pre><p>The Common Lisp <code>#'x</code> reader abbreviation is equivalent to <code>(function x)</code>, and <code>function</code> is a special form that references a value in the function namespace.\n</p><p>While this distinction is somewhat arbitrary, it is generally my belief that the Scheme approach was, indeed, the right one. Runtime values are values, whether they are numbers, strings, or functions, and they ought to all be treated as equal citizens. After all, if a programmer wishes to define their own function-like thing, they should not be forced to make their abstraction a second-class citizen merely because it is slightly different from the built-in notion of a function. Higher-order functional programming encourages treating functions as ordinary values, and an arbitrary stratification of the namespace is antithetical to that mental model.\n</p><p>However, Hackett is a little different from all of the aforementioned languages because Hackett has <em>types</em>. Types are rather different from runtime values because they do not exist at all at runtime. One cannot use a type where a value is expected, nor can one use a value where a type is expected, so this distinction is <em>always</em> syntactically unambiguous.<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup> Even if types and values live in separate namespaces, there is no need for a <code>type</code> form a la CL’s <code>function</code> because it can always be determined implicitly.\n</p><p>For this reason, it makes a great deal of sense for Hackett to have separate type and value namespaces, permitting declarations such as the following:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"p\">(</span><span class=\"n\">Tuple</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Tuple</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">))</span></code></pre><p>This defines a binding named <code>Tuple</code> at the type level, which is a <em>type constructor</em> of two arguments that produces a type of kind <code>*</code>,<sup><a id=\"footnote-ref-2-1\" href=\"#footnote-2\">2</a></sup> and another binding named <code>Tuple</code> at the value level, which is a <em>value constructor</em> of two arguments that produces a value of type <code>(Tuple a b)</code>.\n</p><p>But why do we want to overload names in this way, anyway? How hard would it really be to just name the value constructor <code>tuple</code> instead of <code>Tuple</code>? Well, it wouldn’t be hard at all, if it weren’t for the unpleasant ambiguity such a naming convention introduces when pattern-matching. Consider the following code snippet:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">Foo</span> <span class=\"n\">bar</span> <span class=\"p\">(</span><span class=\"n\">baz</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">foo-&gt;integer</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">Foo</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Integer</span><span class=\"p\">}</span>\n  <span class=\"p\">[[</span><span class=\"n\">bar</span>    <span class=\"p\">]</span> <span class=\"mi\">0</span><span class=\"p\">]</span>\n  <span class=\"p\">[[(</span><span class=\"n\">baz</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"n\">y</span><span class=\"p\">])</span></code></pre><p>This works fine. But what happens if the programmer decides to change the name of the <code>bar</code> value?\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">Foo</span> <span class=\"n\">qux</span> <span class=\"p\">(</span><span class=\"n\">baz</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">foo-&gt;integer</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">Foo</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Integer</span><span class=\"p\">}</span>\n  <span class=\"p\">[[</span><span class=\"n\">bar</span>    <span class=\"p\">]</span> <span class=\"mi\">0</span><span class=\"p\">]</span>\n  <span class=\"p\">[[(</span><span class=\"n\">baz</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"n\">y</span><span class=\"p\">])</span></code></pre><p>Can you spot the bug? Disturbingly, this code <em>still compiles</em>! Even though <code>bar</code> is not a member of <code>Foo</code> anymore, it’s still a valid pattern, since names used as patterns match anything, just as the <code>y</code> pattern matches against any integer inside the <code>baz</code> constructor. If Hackett had a pattern redundancy checker, it could at least hopefully catch this mistake, but as things are, this could would silently compile and do the wrong thing: <code>(foo-&gt;integer (baz 42))</code> will still produce <code>0</code>, not <code>42</code>, since the first case always matches.\n</p><p>Haskell escapes this flaw by syntactically distinguishing between patterns and ordinary bindings by requiring all constructors start with an uppercase letter. This means that programmers often want to define data constructors and type constructors with the same name, such as the <code>Tuple</code> example above, which is illegal if a programming language only supports a single namespace.\n</p><p>Although Hackett now supports two namespaces, it does not currently enforce this naming convention, but it seems like an increasingly good idea. Separating the namespaces is the biggest hurdle needed to implement such a feature, and happily, it is now complete. The <code>Tuple</code> example from above is perfectly legal Hackett.\n</p><h2><a name=\"adding-namespaces-to-a-language\"></a>Adding namespaces to a language</h2><p>Hopefully, we now agree that it would be nice if Hackett had two namespaces, but that doesn’t really get us any closer to being able to <em>implement</em> such a feature. At its core, Hackett is still a Racket language, and Racket’s binding structure has no notion of namespaces. How can it possibly support a language with more than one namespace?\n</p><p>Fortunately, Racket is no ordinary language—it is a language with a highly formalized notion of lexical scope, and many of its low-level scope control features are accessible to ordinary programmers. Before we get into the details, however, a forewarning: <strong>the remainder of this blog post is <em>highly technical</em>, and some of it involves some of the more esoteric corners of Racket’s macro system</strong>. This blog post is <em>not</em> representative of most macros written in Racket, nor is it at all necessary to understand these things to be a working Racket or Hackett macrologist. It is certainly not a tutorial on any of these concepts, so if you find it intimidating, there is no shame in skipping the rest of this post! If, however, you think you can handle it, or if you simply want to stare into the sun, by all means, read on.\n</p><h3><a name=\"namespaces-as-scopes\"></a>Namespaces as scopes</h3><p>With that disclaimer out of the way, let’s begin. As of this writing, the current Racket macroexpander uses a scoping model known as <a href=\"https://www.cs.utah.edu/plt/scope-sets/\"><em>sets of scopes</em></a>, which characterizes the binding structure of a program by annotating identifiers with sets of opaque markers known as “scopes”. The details of Racket’s macro system are well outside the scope of this blog post, but essentially, two identifiers with the same name can be made to refer to different bindings by adding a unique scope to each identifier.\n</p><p>Using this system of scopes, it is surprisingly simple to create a system of two namespaces: we only need to arrange for all identifiers in a value position to have a particular scope, which we will call the <em>value scope</em>, and all identifiers in type position must have a different scope, which we will call the <em>type scope</em>. How do we create these scopes and apply them to identifiers? In Racket, we use a function called <a href=\"https://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._make-syntax-introducer%29%29\"><code>make-syntax-introducer</code></a>, which produces a function that encapsulates a fresh scope. This function can be applied to any syntax object (Racket’s structured representation of code that includes lexical binding information) to do one of three things: it can <em>add</em> the scope to all pieces of the syntax object, <em>remove</em> the scope, or <em>flip</em> the scope (that is, add it to pieces of the syntax object that do not have it and remove it from pieces that do have it). In practice, this means we need to call <code>make-syntax-introducer</code> once for each namespace:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">value-introducer</span> <span class=\"p\">(</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">type-introducer</span> <span class=\"p\">(</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">)))</span></code></pre><p>We define these in a <code>begin-for-syntax</code> block because these definitions will be used in our compile-time macros (aka “phase 1”), not in runtime code (aka “phase 0”). Now, we can write some macros that use these introducer functions to apply the proper scopes to their contents:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">begin/value</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">value-introducer</span> <span class=\"n\">stx</span> <span class=\"o\">&#39;</span><span class=\"ss\">add</span><span class=\"p\">))</span>\n                          <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">begin</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">begin/type</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">type-introducer</span> <span class=\"n\">stx</span> <span class=\"o\">&#39;</span><span class=\"ss\">add</span><span class=\"p\">))</span>\n                          <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">begin</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>Each of these two forms is like <code>begin</code>, which is a Racket form that is, for our purposes, essentially a no-op, but it applies <code>value-introducer</code> or <code>type-introducer</code> to add the appropriate scope. We can test that this works by writing a program that uses the two namespaces:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">begin/value</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"ss\">value-x</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">begin/type</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">x</span> <span class=\"o\">&#39;</span><span class=\"ss\">type-x</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">begin/value</span>\n  <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">begin/type</span>\n  <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"n\">x</span><span class=\"p\">))</span></code></pre><p>This program produces the following output:\n</p><pre><code>'value-x\n'type-x\n</code></pre><p>It works! Normally, if you try to define two bindings with the same name in Racket, it will produce a compile-time error, but by assigning them different scopes, we have essentially managed to create two separate namespaces.\n</p><p>However, although this is close, it isn’t <em>quite</em> right. What happens if we nest the two inside each other?\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">begin/value</span>\n  <span class=\"p\">(</span><span class=\"n\">begin/type</span>\n    <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"n\">x</span><span class=\"p\">)))</span></code></pre><pre><code>x: identifier's binding is ambiguous\n  context...:\n   #(189267 module) #(189268 module anonymous-module 0) #(189464 use-site)\n   #(189465 use-site) #(190351 use-site) #(190354 use-site) #(190358 local)\n   #(190359 intdef)\n  matching binding...:\n   #&lt;module-path-index:()&gt;\n   #(189267 module) #(189268 module anonymous-module 0) #(189464 use-site)\n  matching binding...:\n   #&lt;module-path-index:()&gt;\n   #(189267 module) #(189268 module anonymous-module 0) #(189465 use-site)\n</code></pre><p>Oh no! That didn’t work at all. The error is a bit of a scary one, but the top of the error message is essentially accurate: the use of <code>x</code> is <em>ambiguous</em> because it has both scopes on it, so it could refer to either binding. What we really want is for nested uses of <code>begin/value</code> or <code>begin/type</code> to <em>override</em> outer ones, ensuring that a use can only be in a single namespace at a time.\n</p><p>To do this, we simply need to adjust <code>begin/value</code> and <code>begin/type</code> to remove the other scope in addition to adding the appropriate one:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">begin/value</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span>\n                            <span class=\"p\">(</span><span class=\"n\">type-introducer</span> <span class=\"p\">(</span><span class=\"n\">value-introducer</span> <span class=\"n\">stx</span> <span class=\"o\">&#39;</span><span class=\"ss\">add</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">remove</span><span class=\"p\">))</span>\n                          <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">begin</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">begin/type</span> <span class=\"n\">form</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span><span class=\"p\">)</span>\n                            <span class=\"p\">(</span><span class=\"n\">value-introducer</span> <span class=\"p\">(</span><span class=\"n\">type-introducer</span> <span class=\"n\">stx</span> <span class=\"o\">&#39;</span><span class=\"ss\">add</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">remove</span><span class=\"p\">))</span>\n                          <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">form</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">begin</span> <span class=\"n\">form*</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>Now our nested program runs, and it produces <code>'type-x</code>, which is exactly what we want—the “nearest” scope wins.\n</p><p>With just a few lines of code, we’ve managed to implement the two-namespace system Hackett needs: we simply maintain two scopes, one for each namespace, and arrange for all the types to have the type scope applied and everything else to have the value scope applied. Easy, right? Well, not quite. Things start to get a lot more complicated once our programs span more than a single module.\n</p><h3><a name=\"namespaces-that-cross-module-boundaries\"></a>Namespaces that cross module boundaries</h3><p>The system of using two syntax introducers to manage scopes is wonderfully simple as long as all of our programs are contained within a single module, but obviously, that is never true in practice. It is critical that users are able to export both values and types from one module and import them into another, as that is a pretty fundamental feature of any language. This is, unfortunately, where we start to run into problems.\n</p><p>Racket’s notion of hygiene is pervasive, but it is still essentially scoped to a single module. This makes sense, since each module conceptually has its own “module scope”, and it wouldn’t be very helpful to inject a binding from a different module with the <em>other</em> module’s scope—it would be impossible to reference the binding in the importing module. Instead, Racket’s modules essentially export <em>symbols</em>, not identifiers (which, in Racket terminology, are symbols packaged together with their lexical scope). When a Racket module provides a binding named <code>foo</code>, there is no other information attached to that binding. It does not have any scopes attached to it, since it is the <code>require</code> form’s job to attach the correct scopes to imported identifiers.\n</p><p>This completely makes sense for all normal uses of the Racket binding system, but it has unfortunate implications for our namespace system: Racket modules cannot export more than one binding with a given symbolic name!<sup><a id=\"footnote-ref-3-1\" href=\"#footnote-3\">3</a></sup> This won’t work at all, since a Hackett programmer might very well want to export a type and value with the same name from a single module. Indeed, this capability is one of the primary <em>points</em> of having multiple namespaces.\n</p><p>What to do? Sadly, Racket does not have nearly as elegant a solution for this problem, at least not at the time of this writing. Fortunately, hope is not lost. While far from perfect, we can get away with a relatively simple name-mangling scheme to prefix types upon export and unprefix them upon import. Since Racket’s <code>require</code> and <code>provide</code> forms are extensible, it’s even possible to implement this mangling in a completely invisible way.\n</p><p>Currently, the scheme that Hackett uses is to prefix <code>#%hackett-type:</code> onto the beginning of any type exports. This can be defined in terms of a <a href=\"https://docs.racket-lang.org/reference/stxtrans.html#%28tech._provide._pre._transformer%29\"><em>provide pre-transformer</em></a>, which is essentially a macro that cooperates with Racket’s <code>provide</code> form to control the export process. In this case, we can define our <code>type-out</code> provide pre-transformer in terms of <a href=\"https://docs.racket-lang.org/reference/require.html#%28form._%28%28lib._racket%2Fprivate%2Fbase..rkt%29._prefix-out%29%29\"><code>prefix-out</code></a>, a form built-in to Racket that allows prefixing the names of exports:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">type-out</span>\n  <span class=\"p\">(</span><span class=\"n\">make-provide-pre-transformer</span>\n   <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">stx</span> <span class=\"n\">modes</span><span class=\"p\">)</span>\n     <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"n\">stx</span>\n       <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">provide-spec</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n        <span class=\"p\">(</span><span class=\"n\">pre-expand-export</span>\n         <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">prefix-out</span> <span class=\"n\">#%hackett-type:</span>\n                       <span class=\"o\">#,</span><span class=\"p\">(</span><span class=\"n\">type-introducer</span>\n                          <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">combine-out</span> <span class=\"n\">provide-spec</span> <span class=\"k\">...</span><span class=\"p\">)))</span>\n         <span class=\"n\">modes</span><span class=\"p\">)]))))</span></code></pre><p>Note that we call <code>type-introducer</code> in this macro! That’s because we want to ensure that, when a user writes <code>(provide (type-out Foo))</code>, we look for <code>Foo</code> in the module’s type namespace. Of course, once it is provided, all that scoping information is thrown away, but we still need it around so that <code>provide</code> knows <em>which</em> <code>Foo</code> is being provided.\n</p><p>Once we have referenced the correct binding, the use of <code>prefix-out</code> will appropriately add the <code>#%hackett-type:</code> prefix, so the exporting side is already done. Users do need to explicitly write <code>(type-out ....)</code> if they are exporting a particular type-level binding, but this is rarely necessary, since most users use <code>data</code> or <code>class</code> to export datatypes or typeclasses respectively, which can be modified to use <code>type-out</code> internally. Very little user code actually needs to change to support this adjustment.\n</p><p>Handling imports is, comparatively, tricky. When exporting, we can just force the user to annotate which exports are types, but we don’t have that luxury when importing, since it is merely whether or not a binding has the <code>#%hackett-type:</code> prefix that indicates which namespace it should be imported into. This means we’ll need to explicitly iterate through every imported binding and check if it has the prefix or not. If it does, we need to strip it off and add the type namespace; otherwise, we just pass it through unchanged.\n</p><p>Just as we extended <code>provide</code> with a provide pre-transformer, we can extend <code>require</code> using a <a href=\"https://docs.racket-lang.org/reference/stxtrans.html#%28tech._require._transformer%29\"><em>require transformer</em></a>. In code, this entire process looks like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">unmangle-type-name</span> <span class=\"n\">name</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">and~&gt;</span> <span class=\"p\">(</span><span class=\"nb\">regexp-match</span> <span class=\"sr\">#rx\"^#%hackett-type:(.+)$\"</span> <span class=\"n\">name</span><span class=\"p\">)</span> <span class=\"nb\">second</span><span class=\"p\">)))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">unmangle-types-in</span>\n  <span class=\"p\">(</span><span class=\"n\">make-require-transformer</span>\n   <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n     <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">require-spec</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n      <span class=\"kd\">#:do</span> <span class=\"p\">[(</span><span class=\"k\">define-values</span> <span class=\"p\">[</span><span class=\"n\">imports</span> <span class=\"n\">sources</span><span class=\"p\">]</span>\n              <span class=\"p\">(</span><span class=\"n\">expand-import</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">combine-in</span> <span class=\"n\">require-spec</span> <span class=\"k\">...</span><span class=\"p\">)))]</span>\n      <span class=\"p\">(</span><span class=\"nb\">values</span>\n       <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"k\">match-lambda</span>\n              <span class=\"p\">[(</span><span class=\"k\">and</span> <span class=\"n\">i</span> <span class=\"p\">(</span><span class=\"k\">import</span> <span class=\"n\">local-id</span> <span class=\"n\">src-sym</span> <span class=\"n\">src-mod-path</span> <span class=\"n\">mode</span> <span class=\"n\">req-mode</span> <span class=\"n\">orig-mode</span> <span class=\"n\">orig-stx</span><span class=\"p\">))</span>\n               <span class=\"p\">(</span><span class=\"k\">let*</span> <span class=\"p\">([</span><span class=\"n\">local-name</span> <span class=\"p\">(</span><span class=\"nb\">symbol-&gt;string</span> <span class=\"p\">(</span><span class=\"nb\">syntax-e</span> <span class=\"n\">local-id</span><span class=\"p\">))]</span>\n                      <span class=\"p\">[</span><span class=\"n\">unmangled-type-name</span> <span class=\"p\">(</span><span class=\"n\">unmangle-type-name</span> <span class=\"n\">local-name</span><span class=\"p\">)])</span>\n                 <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"n\">unmangled-type-name</span>\n                     <span class=\"p\">(</span><span class=\"k\">let*</span> <span class=\"p\">([</span><span class=\"n\">unmangled-id</span>\n                             <span class=\"p\">(</span><span class=\"nb\">datum-&gt;syntax</span> <span class=\"n\">local-id</span>\n                                            <span class=\"p\">(</span><span class=\"nb\">string-&gt;symbol</span> <span class=\"n\">unmangled-type-name</span><span class=\"p\">)</span>\n                                            <span class=\"n\">local-id</span>\n                                            <span class=\"n\">local-id</span><span class=\"p\">)])</span>\n                       <span class=\"p\">(</span><span class=\"k\">import</span> <span class=\"p\">(</span><span class=\"n\">type-introducer</span> <span class=\"n\">unmangled-id</span><span class=\"p\">)</span>\n                               <span class=\"n\">src-sym</span> <span class=\"n\">src-mod-path</span> <span class=\"n\">mode</span> <span class=\"n\">req-mode</span> <span class=\"n\">orig-mode</span> <span class=\"n\">orig-stx</span><span class=\"p\">))</span>\n                     <span class=\"n\">i</span><span class=\"p\">))])</span>\n            <span class=\"n\">imports</span><span class=\"p\">)</span>\n       <span class=\"n\">sources</span><span class=\"p\">)])))</span></code></pre><p>This is a little intimidating if you are not familiar with the intricacies of Racket’s low-level macro system, but the bulk of the code isn’t as scary as it may seem. It essentially does three things:\n</p><ol><li><p>It iterates over each import and calls <code>unmangle-type-name</code> on the imported symbol. If the result is <code>#f</code>, that means the import does not have the <code>#%hackett-type:</code> prefix, and it can be safely passed through unchanged.\n</p></li><li><p>If <code>unmangle-type-name</code> does <em>not</em> return <code>#f</code>, then it returns the unprefixed name, which is then provided to <code>datum-&gt;syntax</code>, which allows users to forge new identifiers in an <em>unhygienic</em> (or “hygiene-bending”) way. In this case, we want to forge a new identifier with the name we get back from <code>unmangle-type-name</code>, but with the lexical context of the original identifier.\n</p></li><li><p>Finally, we pass the new identifier to <code>type-introducer</code> to properly add the type scope, injecting the fresh binding into the type namespace.\n</p></li></ol><p>With this in place, we now have a way for Hackett users to import and export type bindings, but while it is not much of a burden to write <code>type-out</code> when exporting types, it is unlikely that users will want to write <code>unmangle-types-in</code> around each and every import in their program. For that reason, we can define a slightly modified version of <code>require</code> that implicitly wraps all of its subforms with <code>unmangle-types-in</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"p\">(</span><span class=\"k\">rename-out</span> <span class=\"p\">[</span><span class=\"n\">require/unmangle</span> <span class=\"k\">require</span><span class=\"p\">]))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">require/unmangle</span> <span class=\"n\">require-spec</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"n\">unmangle-types-in</span> <span class=\"n\">require-spec</span><span class=\"p\">)</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>…and we’re done. Now, Hackett modules can properly import and export type-level bindings.\n</p><h3><a name=\"namespaces-plus-submodules-the-devil-s-in-the-details\"></a>Namespaces plus submodules: the devil’s in the details</h3><p>Up until this point, adding namespaces has required some understanding of the nuances of Racket’s macro system, but it hasn’t been particularly difficult to implement. However, getting namespaces right is a bit trickier than it appears. One area where namespaces are less than straightforward is Racket’s system of <em>submodules</em>.\n</p><p>Submodules are a Racket feature that allows the programmer to arbitrarily nest modules. Each file always corresponds to a single outer module, but that module can contain an arbitrary number of submodules. Each submodule can have its own “module language”, which even allows different languages to be mixed within a single file.\n</p><p>Submodules in Racket come in two flavors: <code>module</code> and <code>module*</code>. The difference is what order, semantically, they are defined in. Submodules defined with <code>module</code> are essentially defined <em>before</em> their enclosing module, so they cannot import their enclosing module, but their enclosing module can import them. Modules defined with <code>module*</code> are the logical dual to this: they are defined after their enclosing module, so they can import their enclosing module, but the enclosing module cannot import them.\n</p><p>How do submodules interact with namespaces? Well, for the most part, they work totally fine. This is because submodules are really, for the most part, treated like any other module, so the same machinery that works for ordinary Racket modules works fine with submodules.\n</p><p>However, there is <a href=\"https://docs.racket-lang.org/guide/Module_Syntax.html#%28part._submodules%29\">a special sort of <code>module*</code> submodule that uses <code>#f</code> in place of a module language</a>, which gives a module access to <em>all</em> of its enclosing module’s bindings, even ones that aren’t exported! This is commonly used to create a <code>test</code> submodule that contains unit tests, and functions can be tested in such a submodule even if they are not part of the enclosing module’s public API:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"c1\">; not provided</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">private-add1</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"n\">x</span> <span class=\"mi\">1</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">module*</span> <span class=\"n\">test</span> <span class=\"no\">#f</span>\n  <span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">rackunit</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">check-equal?</span> <span class=\"p\">(</span><span class=\"n\">private-add1</span> <span class=\"mi\">41</span><span class=\"p\">)</span> <span class=\"mi\">42</span><span class=\"p\">))</span></code></pre><p>It would be nice to be able to use these sorts of submodules in Hackett, too, but if we try, we’ll find that types from the enclosing module mysteriously can’t be referenced by the submodule. Why? Well, the issue is in how we naïvely create our type and value introducers:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">value-introducer</span> <span class=\"p\">(</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">type-introducer</span> <span class=\"p\">(</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">)))</span></code></pre><p>Remember that <code>make-syntax-introducer</code> is generative—each time it is called, it produces a function that operates on a fresh scope. This is a problem, since those functions will be re-evaluated on every module <a href=\"https://docs.racket-lang.org/reference/eval-model.html#%28tech._instantiate%29\">instantiation</a>, as ensured by Racket’s <a href=\"https://docs.racket-lang.org/reference/eval-model.html#%28part._separate-compilation%29\">separate compilation guarantee</a>. This means that each module gets its <em>own</em> pair of scopes. This means the body of a <code>module*</code> submodule will have different scopes from its enclosing module, and the enclosing modules bindings will not be accessible.\n</p><p>Fortunately, there is a way to circumvent this. While we cannot directly preserve syntax introducers across module instantiations, we <em>can</em> preserve syntax objects by embedding them in the expanded program, and we can attach scopes to syntax objects. Using <a href=\"https://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._make-syntax-delta-introducer%29%29\"><code>make-syntax-delta-introducer</code></a>, we can create a syntax introducer the adds or removes the <em>difference</em> between scopes on two syntax objects. Pairing this with a little bit of clever indirection, we can arrange for <code>value-introducer</code> and <code>type-introducer</code> to always operate on the same scopes on each module instantiation:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">define-value/type-introducers</span>\n                       <span class=\"n\">value-introducer:id</span> <span class=\"n\">type-introducer:id</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">scopeless-id</span> <span class=\"p\">(</span><span class=\"nb\">datum-&gt;syntax</span> <span class=\"no\">#f</span> <span class=\"o\">&#39;</span><span class=\"ss\">introducer-id</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">value-id</span> <span class=\"p\">((</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">scopeless-id</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"n\">type-id</span> <span class=\"p\">((</span><span class=\"nb\">make-syntax-introducer</span><span class=\"p\">)</span> <span class=\"o\">#&#39;</span><span class=\"n\">scopeless-id</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">value-introducer</span>\n      <span class=\"p\">(</span><span class=\"nb\">make-syntax-delta-introducer</span> <span class=\"o\">#&#39;</span><span class=\"n\">value-id</span> <span class=\"o\">#&#39;</span><span class=\"n\">scopeless-id</span><span class=\"p\">))</span>\n    <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">type-introducer</span>\n      <span class=\"p\">(</span><span class=\"nb\">make-syntax-delta-introducer</span> <span class=\"o\">#&#39;</span><span class=\"n\">type-id</span> <span class=\"o\">#&#39;</span><span class=\"n\">scopeless-id</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-value/type-introducers</span> <span class=\"n\">value-introducer</span> <span class=\"n\">type-introducer</span><span class=\"p\">)</span></code></pre><p>The way this trick works is subtle, but to understand it, it’s important to understand that when a module is compiled, its macro uses are only evaluated once. Subsequent imports of the same module will not re-expand the module. <em>However</em>, code inside <code>begin-for-syntax</code> blocks is still re-evaluated every time the module is instantiated! This means we are <em>not</em> circumventing that re-evaluation directly, we are merely arranging for each re-evaluation to always produce the same result.\n</p><p>We still use <code>make-syntax-introducer</code> to create our two scopes, but critically, we only call <code>make-syntax-introducer</code> inside the <code>define-value/type-introducers</code> macro, which is, again, only run once (when the module is expanded). The resulting compiled module embeds <code>value-id</code> and <code>type-id</code> as syntax objects in the fully-expanded program, so they never change on each module instantiation, and they already contain the appropriate scopes. We can use <code>make-syntax-delta-introducer</code> to convert the “inert” scopes into introducer functions that we can use to apply the scopes to other syntax objects as we see fit.\n</p><p>By guaranteeing each namespace’s scope is always the same, even for different modules, <code>module*</code> submodules now work properly, and they are able to refer to bindings inherited from their enclosing module as desired.\n</p><h3><a name=\"the-final-stretch-making-scribble-documentation-namespace-aware\"></a>The final stretch: making Scribble documentation namespace-aware</h3><p>As discussed in <a href=\"/blog/2017/08/28/hackett-progress-report-documentation-quality-of-life-and-snake/\">my previous blog post</a>, Hackett has comprehensive documentation powered by Racket’s excellent documentation tool, Scribble. Fortunately for Hackett, Scribble is incredibly flexible, and it can absolutely cope with a language with multiple namespaces. Less fortunately, it is clear that Scribble’s built-in documentation forms were not at all designed with multiple namespaces in mind.\n</p><p>In general, documenting such a language is tricky, assuming one wishes all identifiers to be properly hyperlinked to their appropriate definition (which, of course, I do). However, documentation is far more ambiguous than code when attempting to determine which identifiers belong in which namespace. When actually writing Hackett code, forms can always syntactically deduce the appropriate namespace for their subforms and annotate them accordingly, but this is not true in documentation. Indeed, it’s entirely possible that a piece of documentation might include intentionally incorrect code, which cannot be expanded at all!\n</p><p>Haskell’s documentation tool, Haddock, does not appear to attempt to tackle this problem at all—when given an identifier that exists in both namespaces, it will generate a hyperlink to the type, not the value. I do not know if there is a way around this, but if there is, it isn’t documented. This works alright for Haddock because Haskell’s documentation generally contains fewer examples, and Haskell programmers do not expect all examples to be appropriately hyperlinked, so a best-effort approach is accepted. Racket programmers, however, are used to a very high standard of documentation, and incorrectly hyperlinked docs are unacceptable.\n</p><p>To work around this problem, Hackett’s documentation requires that users explicitly annotate which identifiers belong to the type namespace. Identifiers in the type namespace are prefixed with <code>t:</code> upon import, and they are bound to Scribble <a href=\"https://docs.racket-lang.org/scribble/scheme.html#%28tech._element._transformer%29\"><em>element transformers</em></a> that indicate they should be typeset without the <code>t:</code> prefix. Fortunately, Scribble’s documentation forms <em>do</em> understand Racket’s model of lexical scope (mostly), so they can properly distinguish between two identifiers with the same name but different lexical context.\n</p><p>In practice, this means Hackett documentation must now include a proliferation of <code>t:</code> prefixes. For example, here is the code for a typeset REPL interaction:\n</p><pre><code class=\"pygments\"><span class=\"n\">@</span><span class=\"p\">(</span><span class=\"n\">hackett-examples</span>\n  <span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">square</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">t:-&gt;</span> <span class=\"n\">t:Integer</span> <span class=\"n\">t:Integer</span><span class=\"p\">)</span>\n    <span class=\"p\">[[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">x</span> <span class=\"nb\">*</span> <span class=\"n\">x</span><span class=\"p\">}])</span>\n  <span class=\"p\">(</span><span class=\"n\">square</span> <span class=\"mi\">5</span><span class=\"p\">))</span></code></pre><p>Note the use of <code>t:-&gt;</code> and <code>t:Integer</code> instead of <code>-&gt;</code> and <code>Integer</code>. When the documentation is rendered and the example is evaluated, the prefixes are stripped, resulting in properly-typeset Hackett code.\n</p><p>This also means Hackett’s documentation forms have been updated to understand multiple namespaces. Hackett now provides <code>deftype</code> and <code>deftycon</code> forms for documenting types and type constructors, respectively, which will use the additional lexical information attached to <code>t:</code>-prefixed identifiers to properly index documented forms. Similarly, <code>defdata</code> and <code>defclass</code> have been updated with an understanding of types.\n</p><p>The implementation details of these changes is less interesting than the ones made to the code itself, since it mostly just involved tweaking Racket’s implementation of <code>defform</code> slightly to cooperate with the prefixed identifiers. To summarize, Hackett defines a notion of “type binding transformers” that include information about both prefixed and unprefixed versions of types, and Hackett provides documentation forms that consume that information when typesetting. A require transformer converts imported bindings into <code>t:</code>-prefixed ones and attaches the necessary compile-time information to them. It isn’t especially elegant, but it works.\n</p><h2><a name=\"analysis-and-unsolved-problems\"></a>Analysis and unsolved problems</h2><p>When laid out from top to bottom in this blog post, the amount of code it takes to actually implement multiple namespaces in Racket is surprisingly small. In hindsight, it does not feel like two weeks worth of effort, but it would be disingenuous to suggest that any of this was obvious. I tried a variety of different implementation strategies and spent a great deal of time staring at opaque error messages and begging <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a> for help before I got things working properly. Fortunately, with everything in place, the implementation seems reliable, predictable, and useful for Hackett’s users (or, as the case may be, users-to-be).\n</p><p>For the most part, all the machinery behind multiple namespaces is invisible to the average Hackett programmer, and it seems to “just work”. For completeness, however, I must mention one unfortunate exception: remember the work needed to unmangle type names? While it’s true that all imports into Hackett modules are automatically unmangled by the custom <code>require</code> form, types provided by a module’s <em>language</em> are not automatically unmangled. This is because Racket does not currently provide a hook to customize how bindings from a module language are introduced, unlike <code>require</code>’s require transformers.\n</p><p>To circumvent this restriction, <code>#lang hackett</code>’s reader includes a somewhat ad-hoc solution that actually inserts a <code>require</code> into users’ programs that unmangles and imports all the types provided by the module. This mostly works, but due to the way Racket’s imports work, it isn’t possible for Racket programmers to import different types with the same names as Hackett core types; the two bindings will conflict, and there is no way for users to hide these implicitly imported bindings. Whether or not this is actually a common problem remains to be seen. If it is rare, it might be sufficient to introduce an ad-hoc mechanism to hide certain type imports, but it might be better to extend Racket in some way to better support this use-case.\n</p><p>That issue aside, multi-namespace Hackett is now working smoothly. It’s worth nothing that I did not have to do <em>any</em> special work to help Racket’s tooling, such as DrRacket’s Check Syntax tool, understand the binding structure of Hackett programs. Since other tools, such as racket-mode for Emacs, use the same mechanisms under the hood, Racket programmers’ existing tools will be able to properly locate the distinct definition sites for types and values with the same name, another example of how Racket successfully <a href=\"http://www.ccs.neu.edu/home/matthias/manifesto/sec_intern.html\">internalizes extra-linguistic mechanisms</a>.\n</p><p>As closing notes, even if the majority of this blog post was gibberish to you, do note that Hackett has come quite a long way in just the past two months, adding much more than just a separate type namespace. I might try and give a more comprehensive update at a later date, but here’s a quick summary of the meaningful changes for those interested:\n</p><ul><li><p><strong>Multi-parameter typeclasses</strong> are implemented, along with <strong>default typeclass method implementations</strong>.\n</p></li><li><p>Pattern-matching performs basic <strong>exhaustiveness checking</strong>, so unmatched cases are a compile-time error.\n</p></li><li><p>Hackett ships with a <strong>larger standard library</strong>, including an <code>Either</code> type and appropriate functions, an <code>Identity</code> type, a <code>MonadTrans</code> typeclass, and the <code>ReaderT</code> and <code>ErrorT</code> monad transformers.\n</p></li><li><p><strong>More things are documented</strong>, and parts of the documentation are slightly improved. Additionally, <strong>Hackett’s internals are much more heavily commented</strong>, hopefully making the project more accessible to new contributors.\n</p></li><li><p><strong>Parts of the typechecker are dramatically simplified</strong>, improving the mechanisms behind dictionary elaboration and clearing the way for a variety of additional long-term improvements, including multiple compilation targets and a type-aware optimizer.\n</p></li><li><p>As always, various bug fixes.\n</p></li></ul><p>Finally, special mention to two new contributors to Hackett, <a href=\"https://github.com/iitalics\">Milo Turner</a> and <a href=\"https://github.com/Shamrock-Frost\">Brendan Murphy</a>. Also special thanks to <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a> and <a href=\"https://github.com/michaelballantyne\">Michael Ballantyne</a> for helping me overcome two of the trickiest macro-related problems I’ve encountered in Hackett to date. It has now been just over a year since Hackett’s original conception and roughly six months since the first commit of its current implementation, and the speed at which I’ve been able to work would not have been possible without the valuable help of the wonderful Racket community. Here’s hoping this is only the beginning.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>“But what about dependent types?” you may ask. Put simply, Hackett is not dependently typed, and it is not going to be dependently typed. Dependent types are currently being bolted onto Haskell, but Haskell does not have <code>#lang</code>. Racket does. It seems likely that a dependently-typed language would be much more useful as a separate <code>#lang</code>, not a modified version of Hackett, so Hackett can optimize its user experience for what it <em>is</em>, not what it might be someday.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li><li id=\"footnote-2\"><p>Hackett does not actually have a real kind system yet, but pleasantly, this same change will allow <code>*</code> to be used to mean “type” at the kind level and “multiply” at the value level.\n <a href=\"#footnote-ref-2-1\">↩</a></p></li><li id=\"footnote-3\"><p>This isn’t strictly true, as readers familiar with Racket’s macro system may likely be aware that Racket modules export bindings at different “phase levels”, where phase levels above 0 correspond to compile-time macroexpansion phases. Racket modules are allowed to export a single binding per name, <em>per phase</em>, so the same symbolic name can be bound to different things at different phases. This isn’t meaningfully relevant for Hackett, however, since types and values are both exported at phase 0, and there are reasons that must be the case, this phase separation does not make this problem any simpler.\n <a href=\"#footnote-ref-3-1\">↩</a></p></li></ol></article>","contentSnippet":"As previously discussed on this blog, my programming language, Hackett, is a fusion of two languages, Haskell and Racket. What happens when two distinctly different programming languages collide? Hackett recently faced that very problem when it came to the question of namespacing: Haskell has two namespaces, one for values and another for types, but Racket is a staunch Lisp-1 with a single namespace for all bindings. Which convention should Hackett adopt?\n\nFor now, at least, the answer is that Hackett will emulate Haskell: Hackett now has two namespaces. Of course, Hackett is embedded in Racket, so what did it take to add an entirely new namespace to a language that possesses only one? The answer was a little more than I had hoped, but it was still remarkably simple given the problem: after two weeks of hacking, I’ve managed to get something working.\n\nWhy two namespaces?\nBefore delving into the mechanics of how multi-namespace Hackett is implemented, it’s important to understand what Hackett’s namespaces actually are and why they exist in the first place. Its host language, Racket, is a descendant of Scheme, a Lisp derivative that famously chose to only use a single namespace. This means everything—from values to functions to classes—lives in a single namespace in Racket.\n\nThis is in stark contrast to Common Lisp, which opts to divide bindings into many namespaces, most notably pushing functions into a separate namespace from other variables. You can see this difference most strikingly when applying higher-order functions. In Racket, Clojure, and Scheme, functions can be passed freely as values:\n\n> (map first '((1 a) (2 b) (3 c)))\n'(1 2 3)\nIn Common Lisp and other languages with two namespaces, functions may still be passed as values, but the programmer must explicitly annotate when they wish to use a value from a different namespace:\n\n> (mapcar #'car '((1 a) (2 b) (3 c)))\n(1 2 3)\nThe Common Lisp #'x reader abbreviation is equivalent to (function x), and function is a special form that references a value in the function namespace.\n\nWhile this distinction is somewhat arbitrary, it is generally my belief that the Scheme approach was, indeed, the right one. Runtime values are values, whether they are numbers, strings, or functions, and they ought to all be treated as equal citizens. After all, if a programmer wishes to define their own function-like thing, they should not be forced to make their abstraction a second-class citizen merely because it is slightly different from the built-in notion of a function. Higher-order functional programming encourages treating functions as ordinary values, and an arbitrary stratification of the namespace is antithetical to that mental model.\n\nHowever, Hackett is a little different from all of the aforementioned languages because Hackett has types. Types are rather different from runtime values because they do not exist at all at runtime. One cannot use a type where a value is expected, nor can one use a value where a type is expected, so this distinction is always syntactically unambiguous.1 Even if types and values live in separate namespaces, there is no need for a type form a la CL’s function because it can always be determined implicitly.\n\nFor this reason, it makes a great deal of sense for Hackett to have separate type and value namespaces, permitting declarations such as the following:\n\n(data (Tuple a b) (Tuple a b))\nThis defines a binding named Tuple at the type level, which is a type constructor of two arguments that produces a type of kind *,2 and another binding named Tuple at the value level, which is a value constructor of two arguments that produces a value of type (Tuple a b).\n\nBut why do we want to overload names in this way, anyway? How hard would it really be to just name the value constructor tuple instead of Tuple? Well, it wouldn’t be hard at all, if it weren’t for the unpleasant ambiguity such a naming convention introduces when pattern-matching. Consider the following code snippet:\n\n(data Foo bar (baz Integer))\n\n(defn foo->integer : {Foo -> Integer}\n  [[bar    ] 0]\n  [[(baz y)] y])\nThis works fine. But what happens if the programmer decides to change the name of the bar value?\n\n(data Foo qux (baz Integer))\n\n(defn foo->integer : {Foo -> Integer}\n  [[bar    ] 0]\n  [[(baz y)] y])\nCan you spot the bug? Disturbingly, this code still compiles! Even though bar is not a member of Foo anymore, it’s still a valid pattern, since names used as patterns match anything, just as the y pattern matches against any integer inside the baz constructor. If Hackett had a pattern redundancy checker, it could at least hopefully catch this mistake, but as things are, this could would silently compile and do the wrong thing: (foo->integer (baz 42)) will still produce 0, not 42, since the first case always matches.\n\nHaskell escapes this flaw by syntactically distinguishing between patterns and ordinary bindings by requiring all constructors start with an uppercase letter. This means that programmers often want to define data constructors and type constructors with the same name, such as the Tuple example above, which is illegal if a programming language only supports a single namespace.\n\nAlthough Hackett now supports two namespaces, it does not currently enforce this naming convention, but it seems like an increasingly good idea. Separating the namespaces is the biggest hurdle needed to implement such a feature, and happily, it is now complete. The Tuple example from above is perfectly legal Hackett.\n\nAdding namespaces to a language\nHopefully, we now agree that it would be nice if Hackett had two namespaces, but that doesn’t really get us any closer to being able to implement such a feature. At its core, Hackett is still a Racket language, and Racket’s binding structure has no notion of namespaces. How can it possibly support a language with more than one namespace?\n\nFortunately, Racket is no ordinary language—it is a language with a highly formalized notion of lexical scope, and many of its low-level scope control features are accessible to ordinary programmers. Before we get into the details, however, a forewarning: the remainder of this blog post is highly technical, and some of it involves some of the more esoteric corners of Racket’s macro system. This blog post is not representative of most macros written in Racket, nor is it at all necessary to understand these things to be a working Racket or Hackett macrologist. It is certainly not a tutorial on any of these concepts, so if you find it intimidating, there is no shame in skipping the rest of this post! If, however, you think you can handle it, or if you simply want to stare into the sun, by all means, read on.\n\nNamespaces as scopes\nWith that disclaimer out of the way, let’s begin. As of this writing, the current Racket macroexpander uses a scoping model known as sets of scopes, which characterizes the binding structure of a program by annotating identifiers with sets of opaque markers known as “scopes”. The details of Racket’s macro system are well outside the scope of this blog post, but essentially, two identifiers with the same name can be made to refer to different bindings by adding a unique scope to each identifier.\n\nUsing this system of scopes, it is surprisingly simple to create a system of two namespaces: we only need to arrange for all identifiers in a value position to have a particular scope, which we will call the value scope, and all identifiers in type position must have a different scope, which we will call the type scope. How do we create these scopes and apply them to identifiers? In Racket, we use a function called make-syntax-introducer, which produces a function that encapsulates a fresh scope. This function can be applied to any syntax object (Racket’s structured representation of code that includes lexical binding information) to do one of three things: it can add the scope to all pieces of the syntax object, remove the scope, or flip the scope (that is, add it to pieces of the syntax object that do not have it and remove it from pieces that do have it). In practice, this means we need to call make-syntax-introducer once for each namespace:\n\n(begin-for-syntax\n  (define value-introducer (make-syntax-introducer))\n  (define type-introducer (make-syntax-introducer)))\nWe define these in a begin-for-syntax block because these definitions will be used in our compile-time macros (aka “phase 1”), not in runtime code (aka “phase 0”). Now, we can write some macros that use these introducer functions to apply the proper scopes to their contents:\n\n(require syntax/parse/define)\n\n(define-simple-macro (begin/value form ...)\n  #:with [form* ...] (map (λ (stx) (value-introducer stx 'add))\n                          (attribute form))\n  (begin form* ...))\n\n(define-simple-macro (begin/type form ...)\n  #:with [form* ...] (map (λ (stx) (type-introducer stx 'add))\n                          (attribute form))\n  (begin form* ...))\nEach of these two forms is like begin, which is a Racket form that is, for our purposes, essentially a no-op, but it applies value-introducer or type-introducer to add the appropriate scope. We can test that this works by writing a program that uses the two namespaces:\n\n(begin/value\n  (define x 'value-x))\n\n(begin/type\n  (define x 'type-x))\n\n(begin/value\n  (println x))\n\n(begin/type\n  (println x))\nThis program produces the following output:\n\n'value-x\n'type-x\n\nIt works! Normally, if you try to define two bindings with the same name in Racket, it will produce a compile-time error, but by assigning them different scopes, we have essentially managed to create two separate namespaces.\n\nHowever, although this is close, it isn’t quite right. What happens if we nest the two inside each other?\n\n(begin/value\n  (begin/type\n    (println x)))\nx: identifier's binding is ambiguous\n  context...:\n   #(189267 module) #(189268 module anonymous-module 0) #(189464 use-site)\n   #(189465 use-site) #(190351 use-site) #(190354 use-site) #(190358 local)\n   #(190359 intdef)\n  matching binding...:\n   #<module-path-index:()>\n   #(189267 module) #(189268 module anonymous-module 0) #(189464 use-site)\n  matching binding...:\n   #<module-path-index:()>\n   #(189267 module) #(189268 module anonymous-module 0) #(189465 use-site)\n\nOh no! That didn’t work at all. The error is a bit of a scary one, but the top of the error message is essentially accurate: the use of x is ambiguous because it has both scopes on it, so it could refer to either binding. What we really want is for nested uses of begin/value or begin/type to override outer ones, ensuring that a use can only be in a single namespace at a time.\n\nTo do this, we simply need to adjust begin/value and begin/type to remove the other scope in addition to adding the appropriate one:\n\n(define-simple-macro (begin/value form ...)\n  #:with [form* ...] (map (λ (stx)\n                            (type-introducer (value-introducer stx 'add) 'remove))\n                          (attribute form))\n  (begin form* ...))\n\n(define-simple-macro (begin/type form ...)\n  #:with [form* ...] (map (λ (stx)\n                            (value-introducer (type-introducer stx 'add) 'remove))\n                          (attribute form))\n  (begin form* ...))\nNow our nested program runs, and it produces 'type-x, which is exactly what we want—the “nearest” scope wins.\n\nWith just a few lines of code, we’ve managed to implement the two-namespace system Hackett needs: we simply maintain two scopes, one for each namespace, and arrange for all the types to have the type scope applied and everything else to have the value scope applied. Easy, right? Well, not quite. Things start to get a lot more complicated once our programs span more than a single module.\n\nNamespaces that cross module boundaries\nThe system of using two syntax introducers to manage scopes is wonderfully simple as long as all of our programs are contained within a single module, but obviously, that is never true in practice. It is critical that users are able to export both values and types from one module and import them into another, as that is a pretty fundamental feature of any language. This is, unfortunately, where we start to run into problems.\n\nRacket’s notion of hygiene is pervasive, but it is still essentially scoped to a single module. This makes sense, since each module conceptually has its own “module scope”, and it wouldn’t be very helpful to inject a binding from a different module with the other module’s scope—it would be impossible to reference the binding in the importing module. Instead, Racket’s modules essentially export symbols, not identifiers (which, in Racket terminology, are symbols packaged together with their lexical scope). When a Racket module provides a binding named foo, there is no other information attached to that binding. It does not have any scopes attached to it, since it is the require form’s job to attach the correct scopes to imported identifiers.\n\nThis completely makes sense for all normal uses of the Racket binding system, but it has unfortunate implications for our namespace system: Racket modules cannot export more than one binding with a given symbolic name!3 This won’t work at all, since a Hackett programmer might very well want to export a type and value with the same name from a single module. Indeed, this capability is one of the primary points of having multiple namespaces.\n\nWhat to do? Sadly, Racket does not have nearly as elegant a solution for this problem, at least not at the time of this writing. Fortunately, hope is not lost. While far from perfect, we can get away with a relatively simple name-mangling scheme to prefix types upon export and unprefix them upon import. Since Racket’s require and provide forms are extensible, it’s even possible to implement this mangling in a completely invisible way.\n\nCurrently, the scheme that Hackett uses is to prefix #%hackett-type: onto the beginning of any type exports. This can be defined in terms of a provide pre-transformer, which is essentially a macro that cooperates with Racket’s provide form to control the export process. In this case, we can define our type-out provide pre-transformer in terms of prefix-out, a form built-in to Racket that allows prefixing the names of exports:\n\n(define-syntax type-out\n  (make-provide-pre-transformer\n   (λ (stx modes)\n     (syntax-parse stx\n       [(_ provide-spec ...)\n        (pre-expand-export\n         #`(prefix-out #%hackett-type:\n                       #,(type-introducer\n                          #'(combine-out provide-spec ...)))\n         modes)]))))\nNote that we call type-introducer in this macro! That’s because we want to ensure that, when a user writes (provide (type-out Foo)), we look for Foo in the module’s type namespace. Of course, once it is provided, all that scoping information is thrown away, but we still need it around so that provide knows which Foo is being provided.\n\nOnce we have referenced the correct binding, the use of prefix-out will appropriately add the #%hackett-type: prefix, so the exporting side is already done. Users do need to explicitly write (type-out ....) if they are exporting a particular type-level binding, but this is rarely necessary, since most users use data or class to export datatypes or typeclasses respectively, which can be modified to use type-out internally. Very little user code actually needs to change to support this adjustment.\n\nHandling imports is, comparatively, tricky. When exporting, we can just force the user to annotate which exports are types, but we don’t have that luxury when importing, since it is merely whether or not a binding has the #%hackett-type: prefix that indicates which namespace it should be imported into. This means we’ll need to explicitly iterate through every imported binding and check if it has the prefix or not. If it does, we need to strip it off and add the type namespace; otherwise, we just pass it through unchanged.\n\nJust as we extended provide with a provide pre-transformer, we can extend require using a require transformer. In code, this entire process looks like this:\n\n(begin-for-syntax\n  (define (unmangle-type-name name)\n    (and~> (regexp-match #rx\"^#%hackett-type:(.+)$\" name) second)))\n\n(define-syntax unmangle-types-in\n  (make-require-transformer\n   (syntax-parser\n     [(_ require-spec ...)\n      #:do [(define-values [imports sources]\n              (expand-import #'(combine-in require-spec ...)))]\n      (values\n       (map (match-lambda\n              [(and i (import local-id src-sym src-mod-path mode req-mode orig-mode orig-stx))\n               (let* ([local-name (symbol->string (syntax-e local-id))]\n                      [unmangled-type-name (unmangle-type-name local-name)])\n                 (if unmangled-type-name\n                     (let* ([unmangled-id\n                             (datum->syntax local-id\n                                            (string->symbol unmangled-type-name)\n                                            local-id\n                                            local-id)])\n                       (import (type-introducer unmangled-id)\n                               src-sym src-mod-path mode req-mode orig-mode orig-stx))\n                     i))])\n            imports)\n       sources)])))\nThis is a little intimidating if you are not familiar with the intricacies of Racket’s low-level macro system, but the bulk of the code isn’t as scary as it may seem. It essentially does three things:\n\n\nIt iterates over each import and calls unmangle-type-name on the imported symbol. If the result is #f, that means the import does not have the #%hackett-type: prefix, and it can be safely passed through unchanged.\n\n\nIf unmangle-type-name does not return #f, then it returns the unprefixed name, which is then provided to datum->syntax, which allows users to forge new identifiers in an unhygienic (or “hygiene-bending”) way. In this case, we want to forge a new identifier with the name we get back from unmangle-type-name, but with the lexical context of the original identifier.\n\n\nFinally, we pass the new identifier to type-introducer to properly add the type scope, injecting the fresh binding into the type namespace.\n\n\nWith this in place, we now have a way for Hackett users to import and export type bindings, but while it is not much of a burden to write type-out when exporting types, it is unlikely that users will want to write unmangle-types-in around each and every import in their program. For that reason, we can define a slightly modified version of require that implicitly wraps all of its subforms with unmangle-types-in:\n\n(provide (rename-out [require/unmangle require]))\n\n(define-simple-macro (require/unmangle require-spec ...)\n  (require (unmangle-types-in require-spec) ...))\n…and we’re done. Now, Hackett modules can properly import and export type-level bindings.\n\nNamespaces plus submodules: the devil’s in the details\nUp until this point, adding namespaces has required some understanding of the nuances of Racket’s macro system, but it hasn’t been particularly difficult to implement. However, getting namespaces right is a bit trickier than it appears. One area where namespaces are less than straightforward is Racket’s system of submodules.\n\nSubmodules are a Racket feature that allows the programmer to arbitrarily nest modules. Each file always corresponds to a single outer module, but that module can contain an arbitrary number of submodules. Each submodule can have its own “module language”, which even allows different languages to be mixed within a single file.\n\nSubmodules in Racket come in two flavors: module and module*. The difference is what order, semantically, they are defined in. Submodules defined with module are essentially defined before their enclosing module, so they cannot import their enclosing module, but their enclosing module can import them. Modules defined with module* are the logical dual to this: they are defined after their enclosing module, so they can import their enclosing module, but the enclosing module cannot import them.\n\nHow do submodules interact with namespaces? Well, for the most part, they work totally fine. This is because submodules are really, for the most part, treated like any other module, so the same machinery that works for ordinary Racket modules works fine with submodules.\n\nHowever, there is a special sort of module* submodule that uses #f in place of a module language, which gives a module access to all of its enclosing module’s bindings, even ones that aren’t exported! This is commonly used to create a test submodule that contains unit tests, and functions can be tested in such a submodule even if they are not part of the enclosing module’s public API:\n\n#lang racket\n\n; not provided\n(define (private-add1 x)\n  (+ x 1))\n\n(module* test #f\n  (require rackunit)\n  (check-equal? (private-add1 41) 42))\nIt would be nice to be able to use these sorts of submodules in Hackett, too, but if we try, we’ll find that types from the enclosing module mysteriously can’t be referenced by the submodule. Why? Well, the issue is in how we naïvely create our type and value introducers:\n\n(begin-for-syntax\n  (define value-introducer (make-syntax-introducer))\n  (define type-introducer (make-syntax-introducer)))\nRemember that make-syntax-introducer is generative—each time it is called, it produces a function that operates on a fresh scope. This is a problem, since those functions will be re-evaluated on every module instantiation, as ensured by Racket’s separate compilation guarantee. This means that each module gets its own pair of scopes. This means the body of a module* submodule will have different scopes from its enclosing module, and the enclosing modules bindings will not be accessible.\n\nFortunately, there is a way to circumvent this. While we cannot directly preserve syntax introducers across module instantiations, we can preserve syntax objects by embedding them in the expanded program, and we can attach scopes to syntax objects. Using make-syntax-delta-introducer, we can create a syntax introducer the adds or removes the difference between scopes on two syntax objects. Pairing this with a little bit of clever indirection, we can arrange for value-introducer and type-introducer to always operate on the same scopes on each module instantiation:\n\n(define-simple-macro (define-value/type-introducers\n                       value-introducer:id type-introducer:id)\n  #:with scopeless-id (datum->syntax #f 'introducer-id)\n  #:with value-id ((make-syntax-introducer) #'scopeless-id)\n  #:with type-id ((make-syntax-introducer) #'scopeless-id)\n  (begin-for-syntax\n    (define value-introducer\n      (make-syntax-delta-introducer #'value-id #'scopeless-id))\n    (define type-introducer\n      (make-syntax-delta-introducer #'type-id #'scopeless-id))))\n\n(define-value/type-introducers value-introducer type-introducer)\nThe way this trick works is subtle, but to understand it, it’s important to understand that when a module is compiled, its macro uses are only evaluated once. Subsequent imports of the same module will not re-expand the module. However, code inside begin-for-syntax blocks is still re-evaluated every time the module is instantiated! This means we are not circumventing that re-evaluation directly, we are merely arranging for each re-evaluation to always produce the same result.\n\nWe still use make-syntax-introducer to create our two scopes, but critically, we only call make-syntax-introducer inside the define-value/type-introducers macro, which is, again, only run once (when the module is expanded). The resulting compiled module embeds value-id and type-id as syntax objects in the fully-expanded program, so they never change on each module instantiation, and they already contain the appropriate scopes. We can use make-syntax-delta-introducer to convert the “inert” scopes into introducer functions that we can use to apply the scopes to other syntax objects as we see fit.\n\nBy guaranteeing each namespace’s scope is always the same, even for different modules, module* submodules now work properly, and they are able to refer to bindings inherited from their enclosing module as desired.\n\nThe final stretch: making Scribble documentation namespace-aware\nAs discussed in my previous blog post, Hackett has comprehensive documentation powered by Racket’s excellent documentation tool, Scribble. Fortunately for Hackett, Scribble is incredibly flexible, and it can absolutely cope with a language with multiple namespaces. Less fortunately, it is clear that Scribble’s built-in documentation forms were not at all designed with multiple namespaces in mind.\n\nIn general, documenting such a language is tricky, assuming one wishes all identifiers to be properly hyperlinked to their appropriate definition (which, of course, I do). However, documentation is far more ambiguous than code when attempting to determine which identifiers belong in which namespace. When actually writing Hackett code, forms can always syntactically deduce the appropriate namespace for their subforms and annotate them accordingly, but this is not true in documentation. Indeed, it’s entirely possible that a piece of documentation might include intentionally incorrect code, which cannot be expanded at all!\n\nHaskell’s documentation tool, Haddock, does not appear to attempt to tackle this problem at all—when given an identifier that exists in both namespaces, it will generate a hyperlink to the type, not the value. I do not know if there is a way around this, but if there is, it isn’t documented. This works alright for Haddock because Haskell’s documentation generally contains fewer examples, and Haskell programmers do not expect all examples to be appropriately hyperlinked, so a best-effort approach is accepted. Racket programmers, however, are used to a very high standard of documentation, and incorrectly hyperlinked docs are unacceptable.\n\nTo work around this problem, Hackett’s documentation requires that users explicitly annotate which identifiers belong to the type namespace. Identifiers in the type namespace are prefixed with t: upon import, and they are bound to Scribble element transformers that indicate they should be typeset without the t: prefix. Fortunately, Scribble’s documentation forms do understand Racket’s model of lexical scope (mostly), so they can properly distinguish between two identifiers with the same name but different lexical context.\n\nIn practice, this means Hackett documentation must now include a proliferation of t: prefixes. For example, here is the code for a typeset REPL interaction:\n\n@(hackett-examples\n  (defn square : (t:-> t:Integer t:Integer)\n    [[x] {x * x}])\n  (square 5))\nNote the use of t:-> and t:Integer instead of -> and Integer. When the documentation is rendered and the example is evaluated, the prefixes are stripped, resulting in properly-typeset Hackett code.\n\nThis also means Hackett’s documentation forms have been updated to understand multiple namespaces. Hackett now provides deftype and deftycon forms for documenting types and type constructors, respectively, which will use the additional lexical information attached to t:-prefixed identifiers to properly index documented forms. Similarly, defdata and defclass have been updated with an understanding of types.\n\nThe implementation details of these changes is less interesting than the ones made to the code itself, since it mostly just involved tweaking Racket’s implementation of defform slightly to cooperate with the prefixed identifiers. To summarize, Hackett defines a notion of “type binding transformers” that include information about both prefixed and unprefixed versions of types, and Hackett provides documentation forms that consume that information when typesetting. A require transformer converts imported bindings into t:-prefixed ones and attaches the necessary compile-time information to them. It isn’t especially elegant, but it works.\n\nAnalysis and unsolved problems\nWhen laid out from top to bottom in this blog post, the amount of code it takes to actually implement multiple namespaces in Racket is surprisingly small. In hindsight, it does not feel like two weeks worth of effort, but it would be disingenuous to suggest that any of this was obvious. I tried a variety of different implementation strategies and spent a great deal of time staring at opaque error messages and begging Matthew Flatt for help before I got things working properly. Fortunately, with everything in place, the implementation seems reliable, predictable, and useful for Hackett’s users (or, as the case may be, users-to-be).\n\nFor the most part, all the machinery behind multiple namespaces is invisible to the average Hackett programmer, and it seems to “just work”. For completeness, however, I must mention one unfortunate exception: remember the work needed to unmangle type names? While it’s true that all imports into Hackett modules are automatically unmangled by the custom require form, types provided by a module’s language are not automatically unmangled. This is because Racket does not currently provide a hook to customize how bindings from a module language are introduced, unlike require’s require transformers.\n\nTo circumvent this restriction, #lang hackett’s reader includes a somewhat ad-hoc solution that actually inserts a require into users’ programs that unmangles and imports all the types provided by the module. This mostly works, but due to the way Racket’s imports work, it isn’t possible for Racket programmers to import different types with the same names as Hackett core types; the two bindings will conflict, and there is no way for users to hide these implicitly imported bindings. Whether or not this is actually a common problem remains to be seen. If it is rare, it might be sufficient to introduce an ad-hoc mechanism to hide certain type imports, but it might be better to extend Racket in some way to better support this use-case.\n\nThat issue aside, multi-namespace Hackett is now working smoothly. It’s worth nothing that I did not have to do any special work to help Racket’s tooling, such as DrRacket’s Check Syntax tool, understand the binding structure of Hackett programs. Since other tools, such as racket-mode for Emacs, use the same mechanisms under the hood, Racket programmers’ existing tools will be able to properly locate the distinct definition sites for types and values with the same name, another example of how Racket successfully internalizes extra-linguistic mechanisms.\n\nAs closing notes, even if the majority of this blog post was gibberish to you, do note that Hackett has come quite a long way in just the past two months, adding much more than just a separate type namespace. I might try and give a more comprehensive update at a later date, but here’s a quick summary of the meaningful changes for those interested:\n\n\nMulti-parameter typeclasses are implemented, along with default typeclass method implementations.\n\n\nPattern-matching performs basic exhaustiveness checking, so unmatched cases are a compile-time error.\n\n\nHackett ships with a larger standard library, including an Either type and appropriate functions, an Identity type, a MonadTrans typeclass, and the ReaderT and ErrorT monad transformers.\n\n\nMore things are documented, and parts of the documentation are slightly improved. Additionally, Hackett’s internals are much more heavily commented, hopefully making the project more accessible to new contributors.\n\n\nParts of the typechecker are dramatically simplified, improving the mechanisms behind dictionary elaboration and clearing the way for a variety of additional long-term improvements, including multiple compilation targets and a type-aware optimizer.\n\n\nAs always, various bug fixes.\n\n\nFinally, special mention to two new contributors to Hackett, Milo Turner and Brendan Murphy. Also special thanks to Matthew Flatt and Michael Ballantyne for helping me overcome two of the trickiest macro-related problems I’ve encountered in Hackett to date. It has now been just over a year since Hackett’s original conception and roughly six months since the first commit of its current implementation, and the speed at which I’ve been able to work would not have been possible without the valuable help of the wonderful Racket community. Here’s hoping this is only the beginning.\n\n\n“But what about dependent types?” you may ask. Put simply, Hackett is not dependently typed, and it is not going to be dependently typed. Dependent types are currently being bolted onto Haskell, but Haskell does not have #lang. Racket does. It seems likely that a dependently-typed language would be much more useful as a separate #lang, not a modified version of Hackett, so Hackett can optimize its user experience for what it is, not what it might be someday.\n ↩\n\nHackett does not actually have a real kind system yet, but pleasantly, this same change will allow * to be used to mean “type” at the kind level and “multiply” at the value level.\n ↩\n\nThis isn’t strictly true, as readers familiar with Racket’s macro system may likely be aware that Racket modules export bindings at different “phase levels”, where phase levels above 0 correspond to compile-time macroexpansion phases. Racket modules are allowed to export a single binding per name, per phase, so the same symbolic name can be bound to different things at different phases. This isn’t meaningfully relevant for Hackett, however, since types and values are both exported at phase 0, and there are reasons that must be the case, this phase separation does not make this problem any simpler.\n ↩","isoDate":"2017-10-27T00:00:00.000Z","timestamp":"10/26/2017"},{"title":"Hackett progress report: documentation, quality of life, and snake","pubDate":"2017-08-28T00:00:00.000Z","author":"Alexis King","content":"<article><p>Three months ago, <a href=\"/blog/2017/05/27/realizing-hackett-a-metaprogrammable-haskell/\">I wrote a blog post describing my new, prototype implementation of my programming language, Hackett</a>. At the time, some things looked promising—the language already included algebraic datatypes, typeclasses, laziness, and even a mini, proof of concept web server. It was, however, clearly still rather rough around the edges—error messages were poor, features were sometimes brittle, the REPL experience was less than ideal, and there was no documentation to speak of. In the time since, while the language is still experimental, I have tackled a handful of those issues, and I am excited to announce <a href=\"https://pkg-build.racket-lang.org/doc/hackett@hackett-doc/\"><strong>the first (albeit quite incomplete) approach to Hackett’s documentation</strong></a>.\n</p><p>I’d recommend clicking that link above and at least skimming around before reading the rest of this blog post, as its remainder will describe some of the pieces that didn’t end up in the documentation: the development process, the project’s status, a small demo, and some other details from behind the scenes.\n</p><h2><a name=\"a-philosophy-of-documentation\"></a>A philosophy of documentation</h2><p>Racket, as a project, has always had <a href=\"http://docs.racket-lang.org\">wonderful documentation</a>. There are many reasons for this—Racket’s educational origins almost certainly play a part, and it helps that the core packages set the bar high—but one of the biggest reasons is undoubtably <a href=\"http://docs.racket-lang.org/scribble/index.html\">Scribble, the Racket documentation tool</a>. Scribble is, in many ways, the embodiment of the Racket philosophy: it is a user-extensible, fully-featured, domain-specific programming language designed for typesetting, with <a href=\"http://docs.racket-lang.org/scribble/plt-manuals.html\">a powerful library for documenting Racket code</a>. Like the Racket language itself, Scribble comes with a hygienic macro system, and in fact, all Racket libraries are trivially usable from within Scribble documents, if desired. The macro system is used to great effect to provide typesetting forms tailored to the various sorts of things a Racket programmer might wish to document, such as procedures, structures, and macros.\n</p><p>Scribble documents are decoupled from a rendering backend, so a single Scribble document can be rendered to plain text, a PDF, or HTML, but the HTML backend is the most useful for writing docs. Scribble documents themselves use a syntax inspired by (La)TeX’s syntax, but Scribble uses an <code>@</code> character instead of <code>\\</code>. It also generalizes and regularizes TeX in many ways, creating a much more uniform language without nearly so much magic or complexity. Since Scribble’s “at-expressions” are merely an alternate syntax for Racket’s more traditional s-expressions, Scribble documents can be built out of ordinary Racket macros. For example, to document a procedure in Racket, one would use <a href=\"http://docs.racket-lang.org/scribble/doc-forms.html#%28form._%28%28lib._scribble%2Fmanual..rkt%29._defproc%29%29\">the provided <code>defproc</code> form</a>:\n</p><pre><code class=\"pygments\"><span class=\"n\">@defproc</span><span class=\"p\">[(</span><span class=\"nb\">add1</span> <span class=\"p\">[</span><span class=\"n\">z</span> <span class=\"nb\">number?</span><span class=\"p\">])</span> <span class=\"nb\">number?</span><span class=\"p\">]{</span>\n<span class=\"n\">Returns</span> <span class=\"n\">@racket</span><span class=\"p\">[(</span><span class=\"nb\">+</span> <span class=\"n\">z</span> <span class=\"mi\">1</span><span class=\"p\">)]</span><span class=\"o\">.</span><span class=\"p\">}</span></code></pre><p>This syntax may look alien to someone more familiar with traditional, Javadoc-style documentation comments, but the results are quite impressive. The above snippet renders into <a href=\"http://docs.racket-lang.org/reference/generic-numbers.html#%28def._%28%28quote._~23~25kernel%29._add1%29%29\">something like this</a>:\n</p><p><a href=\"http://docs.racket-lang.org/reference/generic-numbers.html#%28def._%28%28quote._~23~25kernel%29._add1%29%29\"></a>\n</p><p>The fact that Scribble documents are fully-fledged <em>programs</em> equips the programmer with a lot of power. One of the most remarkable tools Scribble provides is <a href=\"http://docs.racket-lang.org/scribble/eval.html\">the <code>scribble/example</code> module</a>, a library that performs sandboxed evaluation as part of the rendering process. This allows Scribble documents to include REPL-style examples inline, automatically generated as part of typesetting, always kept up to date from a single source of truth: the implementation. It even provides a special <code>eval:check</code> form that enables <a href=\"https://docs.python.org/3/library/doctest.html\">doctest</a>-like checking, which allows documentation to serve double duty as a test suite.\n</p><p>Of course, Hackett is not Racket, though it shares many similarities. Fortunately, all of Racket is <em>designed</em> with the goal of supporting many different programming languages, and Scribble is no exception. Things like <a href=\"http://docs.racket-lang.org/scribble/eval.html\"><code>scribble/example</code></a> essentially work out of the box with Hackett, and most of <a href=\"http://docs.racket-lang.org/scribble/plt-manuals.html\"><code>scribble/manual</code></a> can be reused. However, what about documenting algebraic datatypes? What about documenting typeclasses? Well, remember: Scribble is extensible. The <code>defproc</code> and <code>defstruct</code> forms are hardly builtins; they are defined as part of the <code>scribble/manual</code> library in terms of Scribble primitives, and <a href=\"https://github.com/lexi-lambda/hackett/blob/f472859cfc03086d39563e5c0eb81dcb2ceb49dc/hackett-doc/scribble/manual/hackett.rkt\">we can do the same</a>.\n</p><p>Hackett’s documentation already defines three new forms, <code>defdata</code>, <code>defclass</code>, and <code>defmethod</code>, for documenting algebraic datatypes, typeclasses, and typeclass methods, respectively. They typeset documentation custom-tailored to Hackett’s needs, so Hackett’s documentation need not be constrained by Racket’s design decisions. For example, one could document the <code>Functor</code> typeclass using <code>defclass</code> like this:\n</p><pre><code class=\"pygments\"><span class=\"n\">@defclass</span><span class=\"p\">[(</span><span class=\"n\">Functor</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n          <span class=\"p\">[</span><span class=\"nb\">map</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">forall</span> <span class=\"p\">[</span><span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">]</span> <span class=\"p\">{(</span><span class=\"n\">a</span> <span class=\"k\">-&gt;</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">f</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">f</span> <span class=\"n\">b</span><span class=\"p\">)})]]{</span>\n\n<span class=\"n\">A</span> <span class=\"k\">class</span> <span class=\"n\">of</span> <span class=\"n\">types</span> <span class=\"n\">that</span> <span class=\"n\">are</span> <span class=\"n\">@deftech</span><span class=\"p\">{</span><span class=\"n\">functors</span><span class=\"p\">}</span><span class=\"o\">,</span> <span class=\"n\">essentially</span> <span class=\"n\">types</span> <span class=\"n\">that</span> <span class=\"k\">provide</span> <span class=\"n\">a</span>\n<span class=\"n\">mapping</span> <span class=\"k\">or</span> <span class=\"n\">“piercing”</span> <span class=\"n\">operation.</span> <span class=\"n\">The</span> <span class=\"n\">@racket</span><span class=\"p\">[</span><span class=\"nb\">map</span><span class=\"p\">]</span> <span class=\"n\">function</span> <span class=\"n\">can</span> <span class=\"n\">be</span> <span class=\"n\">viewed</span> <span class=\"n\">in</span>\n<span class=\"n\">different</span> <span class=\"n\">ways:</span>\n\n<span class=\"k\">...</span><span class=\"p\">}</span></code></pre><p>With only a little more than the above code, <a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28def._%28%28lib._hackett%2Fmain..rkt%29._.Functor%29%29\">Hackett’s documentation includes a beautifully-typeset definition of the <code>Functor</code> typeclass</a>, including examples and rich prose:\n</p><p><a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28def._%28%28lib._hackett%2Fmain..rkt%29._.Functor%29%29\"></a>\n</p><p>Scribble makes Hackett’s documentation shine.\n</p><h3><a name=\"a-tale-of-two-users\"></a>A tale of two users</h3><p>For a programming language, documentation is critical. Once we have grown comfortable with a language, it’s easy to take for granted our ability to work within it, but there is always a learning period, no matter how simple or familiar the language may be. When learning a new language, we often relate the languages’ concepts and features to those which we already know, which is why having a broad vocabulary of languages makes picking up new ones so much easier.\n</p><p>A new user of a language needs a gentle introduction to its features, structured in a logical way, encouraging this period of discovery and internalization. Such an introduction should come equipped with plenty of examples, and it shouldn’t worry itself with being an authoritative reference. Some innocent simplifications are often conducive to learning, and it is unlikely to be helpful to force the full power of a language onto a user all at once.\n</p><p>However, for experienced users, an authoritative reference is <em>exactly</em> what they need. While learners want tutorial-style documentation that encourages experimentation and exploration, working users of a language need something closer to a dictionary or encyclopedia: a way to look up forms and functions by name and find precise definitions, complete explanations, and hopefully a couple of examples. Such a user does not want information to be scattered across multiple chapters of explanatory text; they simply need a focused, targeted, one-stop shop for the information they’re looking for.\n</p><p>This dichotomy is rarely well-served by existing programming language documentation. Most programming languages suffer from either failing entirely to serve both types of users, or doing so in a way that enforces too strong a separation between the styles of documentation. For example:\n</p><ul><li><p>Java ships with a quintessential example of a documentation generator: Javadoc. Java is a good case study because, although its documentation is not particularly good, it still manages to be considerably better than most languages’ docs.\n</p><p><a href=\"https://docs.oracle.com/javase/8/docs/api/\">Java’s API documentation</a> documents its standard library, but it doesn’t document the language. Reference-style language documentation is largely relegated to the Java Language Specification, which is highly technical and rather low-level. It is more readable than the standards for some other languages, but it’s still mostly only useful to language lawyers. For Java, this ends up being mostly okay, largely because Java is a fairly <em>small</em> language that does not often change.\n</p><p>On the other hand, Java’s reference documentation is inconsistent, rarely provides any examples, and certainly does not do a good job of serving new users. Java <em>does</em> provide guide-style documentation in the form of the <a href=\"https://docs.oracle.com/javase/tutorial/\">Java Tutorials</a>, but they are of inconsistent quality.\n</p><p>More importantly, while the Java tutorials link to the API docs, the reverse is <strong>not</strong> true, which is a real disservice. One of the most beautiful things about the web is how information can be extensively cross-linked, and exploring links is many times easier than turning pages of a physical book. Anyone who’s explored topics on Wikipedia for an hour (or more) at a time knows how amazing this can be.\n</p><p>Language documentation isn’t quite the same as an encyclopedia, but it’s a shame that Java’s documentation does not lend itself as easily to curious, open-ended learning. If the API docs frequently linked to relevant portions of the tutorials, then a user could open the Javadoc for a class or method they are using, then quickly jump to the relevant guide. As the documentation is currently organized, this is nearly impossible, and tutorials are only discovered when explicitly looking for them.\n</p></li><li><p>Other languages, such as JavaScript, are in even worse boats than Java when it comes to documentation. For whatever reason, structured documentation of any kind doesn’t seem to have caught on in the JavaScript world, probably largely because no documentation tool ships with the language, and no such tool ever became standard. Whatever the reason, JavaScript libraries’ documentation largely resides in markdown documents spread across version control repositories and various webpages.\n</p><p>The closest thing that JavaScript has to official language documentation, aside from the (largely incomprehensible) language standard, is <a href=\"https://developer.mozilla.org/en-US/\">MDN</a>. MDN’s docs are actually quite good, and they tend to mix lots of examples together with reference-style documentation. They’re indexed and searchable, and they have a great Google search ranking. MDN is easily my go-to place to read about core JavaScript functions.\n</p><p>The trouble, of course, is that MDN only houses documentation for the standard library, and while new standards make it bigger than ever, huge amounts of critical functionality are often offloaded to separate packages. These libraries all have their own standards and styles of documentation, and virtually none of them even compare to MDN.\n</p><p>This means that documentation for JavaScript libraries, even the most popular ones, tends to be all over the map. <a href=\"http://ramdajs.com/docs/\">Ramda’s documentation is nothing but a reference</a>, which makes it easy to look up information about a specific function, but nearly impossible to find anything if you don’t have a specific name to look for. In contrast, <a href=\"http://passportjs.org/docs\">Passport’s docs are essentially <em>only</em> a set of tutorials</a>, which is great for learners, but enormously frustrating if I just want to look up what the heck a specific function or method <em>does</em>. Fortunately, <a href=\"https://facebook.github.io/react/docs/hello-world.html\">there are some libraries, like React</a>, that absolutely <em>nail</em> this, and they have both styles of documentation that are <strong>actually cross-referenced</strong>. Unfortunately, those are mostly the exceptions, not the norm.\n</p></li><li><p><a href=\"https://docs.python.org/3/index.html\">Python’s documentation is interesting</a>, since it includes a set of tutorials alongside the API reference, and it <em>also</em> ships a language reference written for ordinary users. In many ways, it does everything right, but disappointingly, it generally doesn’t link back to the tutorials from the API docs, even though the reverse is true. For example, the section in the tutorial on <code>if</code> links to the section in the reference about <code>if</code>, but nothing goes in the other direction, which is something of a missed opportunity.\n</p></li><li><p><a href=\"https://hackage.haskell.org/package/base\">Haskell manages to be especially bad here</a> (maybe even notoriously bad) despite having an ubiquitous documentation generator, Haddock. Unfortunately, Haddock’s format makes writing prose and examples somewhat unpleasant, and very few packages provide any sort of tutorial. For those that do, the tutorial is often not included in the API docs, a common theme at this point.\n</p><p>It’s generally a bad sign when your documentation tool isn’t even powerful enough to document itself, and <a href=\"https://www.haskell.org/haddock/\">Haddock’s docs are pretty impressively bad, though mostly serviceable if you’re willing to look</a>.\n</p></li></ul><p>The takeaway here is that I just don’t think most languages’ documentation is particularly good, and programmers seem to have gotten so used to this state of affairs that the bar is set disappointingly low. Fortunately, this is another area where Racket delivers. Racket, like Python, ships with <em>two</em> pieces of documentation: the <a href=\"http://docs.racket-lang.org/guide/index.html\">Racket Guide</a> and the <a href=\"http://docs.racket-lang.org/reference/index.html\">Racket Reference</a>. The guide includes over <strong>one hundred thousand</strong> words of explanations and examples, and the reference includes roughly <strong>half a million</strong>. Racket’s documentation is impressive on its own, but what’s equally impressive is how carefully and methodically cross-linked it is. Margin notes often provide links to corresponding sections in the relevant companion manual, so it’s easy to look up a form or function by name, then quickly jump to the section of the guide explaining it.\n</p><p>Hackett is obviously not going to have hundreds of thousands of words worth of documentation in its first few months of existence, but it already has nearly ten thousand, and that’s not nothing. More importantly, it is structured the same way that Racket’s docs are: it’s split into the <a href=\"http://docs.racket-lang.org/hackett/guide.html\">Hackett Guide</a> and the <a href=\"http://docs.racket-lang.org/hackett/reference.html\">Hackett Reference</a>, and the two are cross-referenced as much as possible. Haskell is a notoriously difficult language to learn, but my hope is that does not necessarily <em>need</em> to be the case. Documentation cannot make the language trivial, but my hope is that it can make it a <em>lot</em> more accessible without making it any less useful for power users.\n</p><h2><a name=\"rounding-hackett-s-library-sanding-its-edges\"></a>Rounding Hackett’s library, sanding its edges</h2><p>One of the best things about sitting down and writing documentation—whether it’s for a tool, a library, or a language—is how it forces you, the author, to think about how someone else might perceive the project when seeing it for the first time. This encompasses everything: error messages, ease of installation, completeness of a standard library, friendliness of tooling, etc. Writing Hackett’s documentation forced me to make a <em>lot</em> of improvements, and while very few of them are flashy features, they make Hackett feel much less like a toy and more like a tool.\n</p><p>Hackett currently has no formal changelog because it is considered alpha quality, and its API is still unstable. There is no guarantee that things won’t change at any moment. Still, it’s useful to put together an ad-hoc list of changes made in the past few months. Here’s a very brief summary:\n</p><ul><li><p>Hackett includes a <a href=\"http://docs.racket-lang.org/hackett/reference-datatypes.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._.Double%29%29\"><code>Double</code></a> type for working with IEEE 754 double-precision floating-point numbers.\n</p></li><li><p>Local definitions are supported via the <a href=\"http://docs.racket-lang.org/hackett/reference-syntactic-forms.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._let%29%29\"><code>let</code></a> and <a href=\"http://docs.racket-lang.org/hackett/reference-syntactic-forms.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._letrec%29%29\"><code>letrec</code></a> forms.\n</p></li><li><p>The prelude includes many more functions, especially <a href=\"http://docs.racket-lang.org/hackett/reference-datatypes.html#%28part._reference-lists%29\">functions on lists</a>.\n</p></li><li><p>The Hackett reader has been adjusted to support using <code>.</code> as a bare symbol, since <a href=\"http://docs.racket-lang.org/hackett/reference-datatypes.html#%28def._%28%28lib._hackett%2Fmain..rkt%29._..%29%29\"><code>.</code> is the function composition operator</a>.\n</p></li><li><p>The Hackett REPL supports many more forms, including <a href=\"http://docs.racket-lang.org/hackett/reference-datatypes.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._data%29%29\">ADT</a>, <a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._class%29%29\">class</a>, and <a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28form._%28%28lib._hackett%2Fmain..rkt%29._instance%29%29\">instance</a> definitions. Additionally, the REPL now uses <a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28def._%28%28lib._hackett%2Fmain..rkt%29._.Show%29%29\"><code>Show</code></a> instances to display the results of expressions. To compensate for the inability to print non-<a href=\"http://docs.racket-lang.org/hackett/reference-typeclasses.html#%28def._%28%28lib._hackett%2Fmain..rkt%29._.Show%29%29\"><code>Show</code></a>able things, a new <code>(#:type expr)</code> syntax is permitted to print the type of <em>any</em> expression.\n</p></li><li><p>Missing instance errors are now dramatically improved, now correctly highlighting the source location of expressions that led to the error.\n</p></li></ul><p>Alongside these changes are a variety of internal code improvements that make the Hackett code simpler, more readable, and hopefully more accessible to contributors. Many of the trickiest functions are now <a href=\"https://github.com/lexi-lambda/hackett/blob/f472859cfc03086d39563e5c0eb81dcb2ceb49dc/hackett-lib/hackett/private/base.rkt#L77-L189\">heavily commented</a> with the hope that the codebase won’t be so intimidating to people unfamiliar with Racket or the techniques behind Hackett’s typechecker. I will continue to document the internals of Hackett as I change different places of the codebase, and I have even considered writing a separate Scribble document describing the Hackett internals. It certainly wouldn’t hurt.\n</p><p>One of the most exciting things about documenting Hackett has been realizing just <em>how much</em> already exists. Seriously, if you have gotten to this point in the blog post but haven’t read <a href=\"https://pkg-build.racket-lang.org/doc/hackett@hackett-doc/\">the actual documentation</a> yet, I would encourage you to do so. No longer does the idea of writing real programs in this language feel out of reach; indeed, aside from potential performance problems, the language is likely extremely close to being usable for very simple things. After all, that’s the goal, isn’t it? As I’ve mentioned before, I’m writing Hackett for other people, but I’m also very much writing it for <em>me</em>: it’s a language I’d like to use.\n</p><p>Still, writing a general-purpose programming language is a lot of work, and I’ve known from the start that it isn’t something I can accomplish entirely on my own. While this iteration of work on Hackett is a sort of “documentation release”, it might be more accurate to call it an “accessibility release”. If you’re interested in contributing, I finally feel comfortable encouraging you to get involved!\n</p><h2><a name=\"a-demo-with-pictures\"></a>A demo with pictures</h2><p>Now, if you’re like me, all of this documentation stuff is already pretty exciting. Still, even I view documentation as simply a means to an end, not an end in itself. Documentation is successful when it gets out of the way and makes it possible to write good code that does cool things. Let’s write some, shall we?\n</p><p>Hackett ships with a special package of demo libraries in the aptly-named <code>hackett-demo</code> package, which are essentially simple, lightweight bindings to existing, dynamically-typed Racket libraries. In <a href=\"/blog/2017/05/27/realizing-hackett-a-metaprogrammable-haskell/\">the previous Hackett blog post</a>, I demonstrated the capabilities of <code>hackett/demo/web-server</code>. In this blog post, we’re going to use <code>hackett/demo/pict</code> and <code>hackett/demo/pict/universe</code>, which make it possible to write interactive, graphical programs in Hackett with just a few lines of code!\n</p><p>As always, we’ll start with <code>#lang hackett</code>, and we’ll import the necessary libraries:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">hackett</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">hackett/demo/pict</span>\n         <span class=\"n\">hackett/demo/pict/universe</span><span class=\"p\">)</span></code></pre><p>With that, we can start immediately with a tiny example. Just to see how <code>hackett/demo/pict</code> works, let’s start by rendering a red square. We can do this by writing a <code>main</code> action that calls <code>print-pict</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"n\">print-pict</span> <span class=\"p\">(</span><span class=\"n\">colorize</span> <span class=\"n\">red</span> <span class=\"p\">(</span><span class=\"n\">filled-square</span> <span class=\"mf\">50.0</span><span class=\"p\">))))</span></code></pre><p>If you run the above program in DrRacket, you should see a 50 pixel red square printed into the interactions window!\n</p><p>\n</p><p>Using the REPL, we can inspect the type of <code>print-pict</code>:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"kd\">#:type</span> <span class=\"n\">print-pict</span><span class=\"p\">)</span>\n<span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"k\">-&gt;</span> <span class=\"n\">Pict</span> <span class=\"p\">(</span><span class=\"n\">IO</span> <span class=\"n\">Unit</span><span class=\"p\">))</span></code></pre><p>Unsurprisingly, displaying a picture to the screen needs <code>IO</code>. However, what’s interesting is that the rest of the expression is totally pure. Take a look at the type of <code>filled-square</code>:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"kd\">#:type</span> <span class=\"n\">filled-square</span><span class=\"p\">)</span>\n<span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"k\">-&gt;</span> <span class=\"n\">Double</span> <span class=\"n\">Pict</span><span class=\"p\">)</span></code></pre><p>No <code>IO</code> to be seen! This is because “picts” are entirely <em>pure</em> values that represent images built out of simple shapes, and they can be put together to make more complex images. For example, we can put two squares next to one another:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"n\">print-pict</span> <span class=\"p\">{(</span><span class=\"n\">colorize</span> <span class=\"n\">red</span> <span class=\"p\">(</span><span class=\"n\">filled-square</span> <span class=\"mf\">50.0</span><span class=\"p\">))</span>\n                   <span class=\"n\">hc-append</span>\n                   <span class=\"p\">(</span><span class=\"n\">colorize</span> <span class=\"n\">blue</span> <span class=\"p\">(</span><span class=\"n\">filled-square</span> <span class=\"mf\">50.0</span><span class=\"p\">))}))</span></code></pre><p>This code will print out a red square to the left of a blue one.\n</p><p>\n</p><p>Again, <code>hc-append</code> is a simple, pure function, a binary composition operator that places two picts side by side to produce a new one:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"kd\">#:type</span> <span class=\"n\">hc-append</span><span class=\"p\">)</span>\n<span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"k\">-&gt;</span> <span class=\"n\">Pict</span> <span class=\"p\">(</span><span class=\"k\">-&gt;</span> <span class=\"n\">Pict</span> <span class=\"n\">Pict</span><span class=\"p\">))</span></code></pre><p>Using the various features of this toolkit, not only can we make interesting pictures and diagrams, we can even create a foundation for a game!\n</p><h3><a name=\"implementing-a-snake-clone\"></a>Implementing a snake clone</h3><p>This blog post is not a Hackett tutorial; it is merely a demo. For that reason, I am not going to spend much time explaining how the following program is built. This section is closer to annotated source code than a guide to the <code>pict</code> or <code>universe</code> libraries. Hopefully it’s still illustrative.\n</p><p>We’ll start by writing some type definitions. We’ll need a type to represent 2D points on a grid, as well as a type to represent a cardinal direction (to keep track of which direction the player is moving, for example). We’ll also want an <code>Eq</code> instance for our points.\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">Point</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">Integer</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">Direction</span> <span class=\"n\">d:left</span> <span class=\"n\">d:right</span> <span class=\"n\">d:up</span> <span class=\"n\">d:down</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">instance</span> <span class=\"p\">(</span><span class=\"n\">Eq</span> <span class=\"n\">Point</span><span class=\"p\">)</span>\n  <span class=\"p\">[</span><span class=\"k\">==</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">[(</span><span class=\"n\">point</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">c</span> <span class=\"n\">d</span><span class=\"p\">)]</span> <span class=\"p\">{{</span><span class=\"n\">a</span> <span class=\"k\">==</span> <span class=\"n\">c</span><span class=\"p\">}</span> <span class=\"n\">&amp;&amp;</span> <span class=\"p\">{</span><span class=\"n\">b</span> <span class=\"k\">==</span> <span class=\"n\">d</span><span class=\"p\">}})])</span></code></pre><p>With these two datatypes, we can implement a <code>move</code> function that accepts a point and a direction and produces a new point for an adjacent tile:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">move</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">Direction</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Point</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Point</span><span class=\"p\">}</span>\n  <span class=\"p\">[[</span><span class=\"n\">d:left</span>  <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"p\">{</span><span class=\"n\">x</span> <span class=\"nb\">-</span> <span class=\"mi\">1</span><span class=\"p\">}</span> <span class=\"n\">y</span><span class=\"p\">)]</span>\n  <span class=\"p\">[[</span><span class=\"n\">d:right</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"p\">{</span><span class=\"n\">x</span> <span class=\"nb\">+</span> <span class=\"mi\">1</span><span class=\"p\">}</span> <span class=\"n\">y</span><span class=\"p\">)]</span>\n  <span class=\"p\">[[</span><span class=\"n\">d:up</span>    <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"p\">{</span><span class=\"n\">y</span> <span class=\"nb\">-</span> <span class=\"mi\">1</span><span class=\"p\">})]</span>\n  <span class=\"p\">[[</span><span class=\"n\">d:down</span>  <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)]</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"p\">{</span><span class=\"n\">y</span> <span class=\"nb\">+</span> <span class=\"mi\">1</span><span class=\"p\">})])</span></code></pre><p>The next step is to define a type for our world state. The <code>big-bang</code> library operates using a game loop, with a function to update the state that’s called each “tick”. Our state will need to hold all the information about our game, which in this case, is just three things:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">World-State</span> <span class=\"p\">(</span><span class=\"n\">world-state</span>\n                   <span class=\"n\">Direction</span>    <span class=\"c1\">; snake direction</span>\n                   <span class=\"p\">(</span><span class=\"n\">List</span> <span class=\"n\">Point</span><span class=\"p\">)</span> <span class=\"c1\">; snake blocks</span>\n                   <span class=\"p\">(</span><span class=\"n\">List</span> <span class=\"n\">Point</span><span class=\"p\">)</span> <span class=\"c1\">; food blocks</span>\n                   <span class=\"p\">))</span></code></pre><p>It will also be useful to have a functional setter for the direction, which we’ll have to write ourselves, since Hackett does not (currently) have anything like Haskell’s record syntax:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">set-ws-direction</span> <span class=\"p\">[[</span><span class=\"n\">d</span> <span class=\"p\">(</span><span class=\"n\">world-state</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span><span class=\"p\">)]</span> <span class=\"p\">(</span><span class=\"n\">world-state</span> <span class=\"n\">d</span> <span class=\"n\">b</span> <span class=\"n\">c</span><span class=\"p\">)])</span></code></pre><p>Next, we’ll write some top-level constants that we’ll use in our rendering function, such as the number of tiles in the game board, the size of each tile in pixels, and some simple picts that represent the tiles we’ll use to draw our game:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">board-width</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">board-height</span> <span class=\"mi\">30</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">tile-&gt;absolute</span> <span class=\"p\">{(</span><span class=\"n\">d*</span> <span class=\"mf\">15.0</span><span class=\"p\">)</span> <span class=\"o\">.</span> <span class=\"n\">integer-&gt;double</span><span class=\"p\">})</span>\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">empty-board</span> <span class=\"p\">(</span><span class=\"n\">blank-rect</span> <span class=\"p\">(</span><span class=\"n\">tile-&gt;absolute</span> <span class=\"n\">board-width</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">tile-&gt;absolute</span> <span class=\"n\">board-height</span><span class=\"p\">)))</span>\n\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">block</span> <span class=\"p\">(</span><span class=\"n\">filled-square</span> <span class=\"mf\">13.0</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">food-block</span> <span class=\"p\">(</span><span class=\"n\">colorize</span> <span class=\"n\">red</span> <span class=\"n\">block</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">snake-block</span> <span class=\"p\">(</span><span class=\"n\">colorize</span> <span class=\"n\">black</span> <span class=\"n\">block</span><span class=\"p\">))</span></code></pre><p>Now we can write our actual <code>render</code> function. To do this, we simply need to render each <code>Point</code> in our <code>World-State</code>’s two lists as a block on an <code>empty-board</code>. We’ll write a helper function, <code>render-on-board</code>, which does exactly that:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">render-on-board</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">Pict</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">List</span> <span class=\"n\">Point</span><span class=\"p\">)</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Pict</span><span class=\"p\">}</span>\n  <span class=\"p\">[[</span><span class=\"n\">pict</span> <span class=\"n\">points</span><span class=\"p\">]</span>\n   <span class=\"p\">(</span><span class=\"nb\">foldr</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">[(</span><span class=\"n\">point</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"n\">acc</span><span class=\"p\">]</span>\n            <span class=\"p\">(</span><span class=\"n\">pin-over</span> <span class=\"n\">acc</span> <span class=\"p\">(</span><span class=\"n\">tile-&gt;absolute</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">tile-&gt;absolute</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"n\">pict</span><span class=\"p\">))</span>\n          <span class=\"n\">empty-board</span> <span class=\"n\">points</span><span class=\"p\">)])</span></code></pre><p>This function uses <code>foldr</code> to collect each point and place the provided pict at the right location using <code>pin-over</code> on an empty board. Using <code>render-on-board</code>, we can write the <code>render</code> function in just a couple of lines:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">render</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">World-State</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Pict</span><span class=\"p\">}</span>\n  <span class=\"p\">[[(</span><span class=\"n\">world-state</span> <span class=\"k\">_</span> <span class=\"n\">snake-points</span> <span class=\"n\">food-points</span><span class=\"p\">)]</span>\n   <span class=\"p\">(</span><span class=\"n\">pin-over</span> <span class=\"p\">(</span><span class=\"n\">render-on-board</span> <span class=\"n\">snake-block</span> <span class=\"n\">snake-points</span><span class=\"p\">)</span>\n             <span class=\"mf\">0.0</span> <span class=\"mf\">0.0</span>\n             <span class=\"p\">(</span><span class=\"n\">render-on-board</span> <span class=\"n\">food-block</span> <span class=\"n\">food-points</span><span class=\"p\">))])</span></code></pre><p>Next, we’ll need to handle the update logic. On each tick, the snake should advance by a single tile in the direction it’s currently moving. If it runs into a food tile, it should grow one tile larger, and we need to generate a new food tile elsewhere on the board. To help with that last part, the <code>big-bang</code> library provides a <code>random-integer</code> function, which we can use to write a <code>random-point</code> action:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">random-point</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">IO</span> <span class=\"n\">Point</span><span class=\"p\">)</span>\n  <span class=\"p\">{</span><span class=\"n\">point</span> <span class=\"n\">&lt;$&gt;</span> <span class=\"p\">(</span><span class=\"n\">random-integer</span> <span class=\"mi\">0</span> <span class=\"n\">board-width</span><span class=\"p\">)</span>\n         <span class=\"n\">&lt;*&gt;</span> <span class=\"p\">(</span><span class=\"n\">random-integer</span> <span class=\"mi\">0</span> <span class=\"n\">board-height</span><span class=\"p\">)})</span></code></pre><p>Hackett supports applicative notation using infix operators, so <code>random-point</code> looks remarkably readable. It also runs in <code>IO</code>, since the result is, obviously, random. Fortunately, the <code>on-tick</code> function runs in <code>IO</code> as well (unlike <code>render</code>, which must be completely pure), so we can use <code>random-point</code> when necessary to generate a new food block:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">init!</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">forall</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"p\">{(</span><span class=\"n\">List</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">List</span> <span class=\"n\">a</span><span class=\"p\">)})</span>\n  <span class=\"p\">{</span><span class=\"nb\">reverse</span> <span class=\"o\">.</span> <span class=\"n\">tail!</span> <span class=\"o\">.</span> <span class=\"nb\">reverse</span><span class=\"p\">})</span>\n\n<span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">on-tick</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">World-State</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">IO</span> <span class=\"n\">World-State</span><span class=\"p\">)}</span>\n  <span class=\"p\">[[(</span><span class=\"n\">world-state</span> <span class=\"n\">dir</span> <span class=\"n\">snake-points</span> <span class=\"n\">food-points</span><span class=\"p\">)]</span>\n   <span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">new-snake-point</span> <span class=\"p\">(</span><span class=\"n\">move</span> <span class=\"n\">dir</span> <span class=\"p\">(</span><span class=\"n\">head!</span> <span class=\"n\">snake-points</span><span class=\"p\">))])</span>\n     <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">{</span><span class=\"n\">new-snake-point</span> <span class=\"n\">elem?</span> <span class=\"n\">food-points</span><span class=\"p\">}</span>\n         <span class=\"p\">(</span><span class=\"k\">do</span> <span class=\"p\">[</span><span class=\"n\">new-food-point</span> <span class=\"n\">&lt;-</span> <span class=\"n\">random-point</span><span class=\"p\">]</span>\n             <span class=\"p\">(</span><span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">world-state</span> <span class=\"n\">dir</span> <span class=\"p\">{</span><span class=\"n\">new-snake-point</span> <span class=\"n\">::</span> <span class=\"n\">snake-points</span><span class=\"p\">}</span>\n                                <span class=\"p\">{</span><span class=\"n\">new-food-point</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">delete</span> <span class=\"n\">new-snake-point</span> <span class=\"n\">food-points</span><span class=\"p\">)})))</span>\n         <span class=\"p\">(</span><span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">world-state</span> <span class=\"n\">dir</span> <span class=\"p\">{</span><span class=\"n\">new-snake-point</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">init!</span> <span class=\"n\">snake-points</span><span class=\"p\">)}</span>\n                            <span class=\"n\">food-points</span><span class=\"p\">))))])</span></code></pre><p>This function is the most complicated one in the whole program, but it’s still not terribly complex. It figures out what the snake’s next location is and binds it to <code>new-snake-point</code>, then checks if there is a food block at that location. If there is, it generates a <code>new-food-point</code>, then puts it in the new world state. Otherwise, it removes the last snake point and continues as usual.\n</p><p>The game is already almost completely written. The next step is just to handle key events, which are obviously important for allowing the player to control the snake. Fortunately, this is easy, since we can just use our <code>set-ws-direction</code> function that we wrote earlier:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">defn</span> <span class=\"n\">on-key</span> <span class=\"n\">:</span> <span class=\"p\">{</span><span class=\"n\">KeyEvent</span> <span class=\"k\">-&gt;</span> <span class=\"n\">World-State</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">IO</span> <span class=\"n\">World-State</span><span class=\"p\">)}</span>\n  <span class=\"p\">[[</span><span class=\"n\">ke:left</span> <span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">pure</span> <span class=\"o\">.</span> <span class=\"p\">(</span><span class=\"n\">set-ws-direction</span> <span class=\"n\">d:left</span><span class=\"p\">)}]</span>\n  <span class=\"p\">[[</span><span class=\"n\">ke:right</span><span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">pure</span> <span class=\"o\">.</span> <span class=\"p\">(</span><span class=\"n\">set-ws-direction</span> <span class=\"n\">d:right</span><span class=\"p\">)}]</span>\n  <span class=\"p\">[[</span><span class=\"n\">ke:up</span>   <span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">pure</span> <span class=\"o\">.</span> <span class=\"p\">(</span><span class=\"n\">set-ws-direction</span> <span class=\"n\">d:up</span><span class=\"p\">)}]</span>\n  <span class=\"p\">[[</span><span class=\"n\">ke:down</span> <span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">pure</span> <span class=\"o\">.</span> <span class=\"p\">(</span><span class=\"n\">set-ws-direction</span> <span class=\"n\">d:down</span><span class=\"p\">)}]</span>\n  <span class=\"p\">[[</span><span class=\"k\">_</span>       <span class=\"p\">]</span> <span class=\"p\">{</span><span class=\"n\">pure</span> <span class=\"o\">.</span> <span class=\"n\">id</span><span class=\"p\">}])</span></code></pre><p>The <code>on-key</code> function runs in <code>IO</code>, but we don’t actually need that power, since all of our keypress update logic is completely pure, so we just wrap everything in <code>pure</code>.\n</p><p>We’re almost done now—all we need to do is set up the <em>initial</em> state when the game begins. We’ll write a small binding that creates a world state with the snake in the middle of the board and some random food locations scattered about:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">initial-state</span>\n  <span class=\"p\">(</span><span class=\"k\">do</span> <span class=\"p\">[</span><span class=\"n\">initial-food</span> <span class=\"n\">&lt;-</span> <span class=\"p\">(</span><span class=\"n\">sequence</span> <span class=\"p\">(</span><span class=\"nb\">take</span> <span class=\"mi\">5</span> <span class=\"p\">(</span><span class=\"n\">repeat</span> <span class=\"n\">random-point</span><span class=\"p\">)))]</span>\n      <span class=\"p\">(</span><span class=\"n\">pure</span> <span class=\"p\">(</span><span class=\"n\">world-state</span> <span class=\"n\">d:right</span>\n                         <span class=\"p\">{(</span><span class=\"n\">point</span> <span class=\"mi\">25</span> <span class=\"mi\">15</span><span class=\"p\">)</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"mi\">24</span> <span class=\"mi\">15</span><span class=\"p\">)</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">point</span> <span class=\"mi\">23</span> <span class=\"mi\">15</span><span class=\"p\">)</span> <span class=\"n\">::</span> <span class=\"n\">nil</span><span class=\"p\">}</span>\n                         <span class=\"n\">initial-food</span><span class=\"p\">))))</span></code></pre><p>Notably, we can use the <code>repeat</code> function to create an infinite list of <code>random-point</code> actions, <code>take</code> the first five of them, then call <code>sequence</code> to execute them from left to right. Now, all we have to do is put the pieces together in a <code>main</code> block:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"k\">do</span> <span class=\"p\">[</span><span class=\"n\">state</span> <span class=\"n\">&lt;-</span> <span class=\"n\">initial-state</span><span class=\"p\">]</span>\n          <span class=\"p\">(</span><span class=\"n\">big-bang</span> <span class=\"n\">state</span>\n            <span class=\"kd\">#:to-draw</span> <span class=\"n\">render</span>\n            <span class=\"kd\">#:on-tick</span> <span class=\"n\">on-tick</span> <span class=\"mf\">0.2</span>\n            <span class=\"kd\">#:on-key</span> <span class=\"n\">on-key</span><span class=\"p\">)))</span></code></pre><p>And that’s it! We haven’t implemented any win or loss conditions, but the basics are all there. In 80 lines of code, we’ve implemented a working snake game in Hackett.\n</p><p>\n</p><h2><a name=\"contributing-to-hackett\"></a>Contributing to Hackett</h2><p>If you are excited enough about Hackett to be interested in contributing, your first question is very likely “What can I do?” or “Where do I start?” My answer to that is (perhaps a little unhelpfully): it depends! My general recommendation is to try and write something with Hackett, and if you run into anything that prevents you from accomplishing your goal, look into what would need to be changed to support your program. Having a use case is a great way to come up with useful improvements.\n</p><p>On the other hand, you might not have anything in mind, or you might find Hackett’s scope a little too overwhelming to just jump right in and start contributing. Fortunately, <a href=\"https://github.com/lexi-lambda/hackett/issues\">Hackett has an issue tracker</a>, so feel free to take a look and pick something that looks interesting and achievable. Alternatively, the standard library can always use fleshing out, and quite a lot of that can be written without ever even touching the scary Hackett internals.\n</p><p>Additionally, if you have any questions, please don’t hesitate to ask them! If you have a question about the codebase, get stuck implementing something, or just don’t know where to start, feel free to <a href=\"https://github.com/lexi-lambda/hackett/issues\">open an issue on GitHub</a>, send me a message on the <code>#racket</code> IRC channel on Freenode, or ping me on <a href=\"http://racket-slack.herokuapp.com\">the Racket Slack team</a>.\n</p><h2><a name=\"acknowledgements\"></a>Acknowledgements</h2><p>Speaking of contributors, I’m excited to say that this is the first time I can truly say Hackett includes code written by someone other than me! I want to call attention to <a href=\"https://github.com/gelisam\">Samuel Gélineau, aka gelisam</a>, who is officially the second contributor to Hackett. He helped to implement the new approach the Hackett REPL uses for printing expressions, which ended up being quite useful when implementing some of the other REPL improvements.\n</p><p>Additionally, I want to specially thank <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a>, <a href=\"http://eecs.northwestern.edu/~robby/\">Robby Findler</a>, and <a href=\"http://www.ccs.neu.edu/home/samth/\">Sam Tobin-Hochstadt</a> for being especially responsive and helpful to my many questions about Scribble and the Racket top level. Racket continues to be extremely impressive, both as a project and as a community.\n</p><p>Finally, many thanks to the various people who have expressed interest in the project and continue to push me and ask questions. Working on Hackett is a lot of work—both time and effort—and it’s your continued enthusiasm that inspires me to put in the hours.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Three months ago, I wrote a blog post describing my new, prototype implementation of my programming language, Hackett. At the time, some things looked promising—the language already included algebraic datatypes, typeclasses, laziness, and even a mini, proof of concept web server. It was, however, clearly still rather rough around the edges—error messages were poor, features were sometimes brittle, the REPL experience was less than ideal, and there was no documentation to speak of. In the time since, while the language is still experimental, I have tackled a handful of those issues, and I am excited to announce the first (albeit quite incomplete) approach to Hackett’s documentation.\n\nI’d recommend clicking that link above and at least skimming around before reading the rest of this blog post, as its remainder will describe some of the pieces that didn’t end up in the documentation: the development process, the project’s status, a small demo, and some other details from behind the scenes.\n\nA philosophy of documentation\nRacket, as a project, has always had wonderful documentation. There are many reasons for this—Racket’s educational origins almost certainly play a part, and it helps that the core packages set the bar high—but one of the biggest reasons is undoubtably Scribble, the Racket documentation tool. Scribble is, in many ways, the embodiment of the Racket philosophy: it is a user-extensible, fully-featured, domain-specific programming language designed for typesetting, with a powerful library for documenting Racket code. Like the Racket language itself, Scribble comes with a hygienic macro system, and in fact, all Racket libraries are trivially usable from within Scribble documents, if desired. The macro system is used to great effect to provide typesetting forms tailored to the various sorts of things a Racket programmer might wish to document, such as procedures, structures, and macros.\n\nScribble documents are decoupled from a rendering backend, so a single Scribble document can be rendered to plain text, a PDF, or HTML, but the HTML backend is the most useful for writing docs. Scribble documents themselves use a syntax inspired by (La)TeX’s syntax, but Scribble uses an @ character instead of \\. It also generalizes and regularizes TeX in many ways, creating a much more uniform language without nearly so much magic or complexity. Since Scribble’s “at-expressions” are merely an alternate syntax for Racket’s more traditional s-expressions, Scribble documents can be built out of ordinary Racket macros. For example, to document a procedure in Racket, one would use the provided defproc form:\n\n@defproc[(add1 [z number?]) number?]{\nReturns @racket[(+ z 1)].}\nThis syntax may look alien to someone more familiar with traditional, Javadoc-style documentation comments, but the results are quite impressive. The above snippet renders into something like this:\n\n\n\nThe fact that Scribble documents are fully-fledged programs equips the programmer with a lot of power. One of the most remarkable tools Scribble provides is the scribble/example module, a library that performs sandboxed evaluation as part of the rendering process. This allows Scribble documents to include REPL-style examples inline, automatically generated as part of typesetting, always kept up to date from a single source of truth: the implementation. It even provides a special eval:check form that enables doctest-like checking, which allows documentation to serve double duty as a test suite.\n\nOf course, Hackett is not Racket, though it shares many similarities. Fortunately, all of Racket is designed with the goal of supporting many different programming languages, and Scribble is no exception. Things like scribble/example essentially work out of the box with Hackett, and most of scribble/manual can be reused. However, what about documenting algebraic datatypes? What about documenting typeclasses? Well, remember: Scribble is extensible. The defproc and defstruct forms are hardly builtins; they are defined as part of the scribble/manual library in terms of Scribble primitives, and we can do the same.\n\nHackett’s documentation already defines three new forms, defdata, defclass, and defmethod, for documenting algebraic datatypes, typeclasses, and typeclass methods, respectively. They typeset documentation custom-tailored to Hackett’s needs, so Hackett’s documentation need not be constrained by Racket’s design decisions. For example, one could document the Functor typeclass using defclass like this:\n\n@defclass[(Functor f)\n          [map : (forall [a b] {(a -> b) -> (f a) -> (f b)})]]{\n\nA class of types that are @deftech{functors}, essentially types that provide a\nmapping or “piercing” operation. The @racket[map] function can be viewed in\ndifferent ways:\n\n...}\nWith only a little more than the above code, Hackett’s documentation includes a beautifully-typeset definition of the Functor typeclass, including examples and rich prose:\n\n\n\nScribble makes Hackett’s documentation shine.\n\nA tale of two users\nFor a programming language, documentation is critical. Once we have grown comfortable with a language, it’s easy to take for granted our ability to work within it, but there is always a learning period, no matter how simple or familiar the language may be. When learning a new language, we often relate the languages’ concepts and features to those which we already know, which is why having a broad vocabulary of languages makes picking up new ones so much easier.\n\nA new user of a language needs a gentle introduction to its features, structured in a logical way, encouraging this period of discovery and internalization. Such an introduction should come equipped with plenty of examples, and it shouldn’t worry itself with being an authoritative reference. Some innocent simplifications are often conducive to learning, and it is unlikely to be helpful to force the full power of a language onto a user all at once.\n\nHowever, for experienced users, an authoritative reference is exactly what they need. While learners want tutorial-style documentation that encourages experimentation and exploration, working users of a language need something closer to a dictionary or encyclopedia: a way to look up forms and functions by name and find precise definitions, complete explanations, and hopefully a couple of examples. Such a user does not want information to be scattered across multiple chapters of explanatory text; they simply need a focused, targeted, one-stop shop for the information they’re looking for.\n\nThis dichotomy is rarely well-served by existing programming language documentation. Most programming languages suffer from either failing entirely to serve both types of users, or doing so in a way that enforces too strong a separation between the styles of documentation. For example:\n\n\nJava ships with a quintessential example of a documentation generator: Javadoc. Java is a good case study because, although its documentation is not particularly good, it still manages to be considerably better than most languages’ docs.\n\nJava’s API documentation documents its standard library, but it doesn’t document the language. Reference-style language documentation is largely relegated to the Java Language Specification, which is highly technical and rather low-level. It is more readable than the standards for some other languages, but it’s still mostly only useful to language lawyers. For Java, this ends up being mostly okay, largely because Java is a fairly small language that does not often change.\n\nOn the other hand, Java’s reference documentation is inconsistent, rarely provides any examples, and certainly does not do a good job of serving new users. Java does provide guide-style documentation in the form of the Java Tutorials, but they are of inconsistent quality.\n\nMore importantly, while the Java tutorials link to the API docs, the reverse is not true, which is a real disservice. One of the most beautiful things about the web is how information can be extensively cross-linked, and exploring links is many times easier than turning pages of a physical book. Anyone who’s explored topics on Wikipedia for an hour (or more) at a time knows how amazing this can be.\n\nLanguage documentation isn’t quite the same as an encyclopedia, but it’s a shame that Java’s documentation does not lend itself as easily to curious, open-ended learning. If the API docs frequently linked to relevant portions of the tutorials, then a user could open the Javadoc for a class or method they are using, then quickly jump to the relevant guide. As the documentation is currently organized, this is nearly impossible, and tutorials are only discovered when explicitly looking for them.\n\n\nOther languages, such as JavaScript, are in even worse boats than Java when it comes to documentation. For whatever reason, structured documentation of any kind doesn’t seem to have caught on in the JavaScript world, probably largely because no documentation tool ships with the language, and no such tool ever became standard. Whatever the reason, JavaScript libraries’ documentation largely resides in markdown documents spread across version control repositories and various webpages.\n\nThe closest thing that JavaScript has to official language documentation, aside from the (largely incomprehensible) language standard, is MDN. MDN’s docs are actually quite good, and they tend to mix lots of examples together with reference-style documentation. They’re indexed and searchable, and they have a great Google search ranking. MDN is easily my go-to place to read about core JavaScript functions.\n\nThe trouble, of course, is that MDN only houses documentation for the standard library, and while new standards make it bigger than ever, huge amounts of critical functionality are often offloaded to separate packages. These libraries all have their own standards and styles of documentation, and virtually none of them even compare to MDN.\n\nThis means that documentation for JavaScript libraries, even the most popular ones, tends to be all over the map. Ramda’s documentation is nothing but a reference, which makes it easy to look up information about a specific function, but nearly impossible to find anything if you don’t have a specific name to look for. In contrast, Passport’s docs are essentially only a set of tutorials, which is great for learners, but enormously frustrating if I just want to look up what the heck a specific function or method does. Fortunately, there are some libraries, like React, that absolutely nail this, and they have both styles of documentation that are actually cross-referenced. Unfortunately, those are mostly the exceptions, not the norm.\n\n\nPython’s documentation is interesting, since it includes a set of tutorials alongside the API reference, and it also ships a language reference written for ordinary users. In many ways, it does everything right, but disappointingly, it generally doesn’t link back to the tutorials from the API docs, even though the reverse is true. For example, the section in the tutorial on if links to the section in the reference about if, but nothing goes in the other direction, which is something of a missed opportunity.\n\n\nHaskell manages to be especially bad here (maybe even notoriously bad) despite having an ubiquitous documentation generator, Haddock. Unfortunately, Haddock’s format makes writing prose and examples somewhat unpleasant, and very few packages provide any sort of tutorial. For those that do, the tutorial is often not included in the API docs, a common theme at this point.\n\nIt’s generally a bad sign when your documentation tool isn’t even powerful enough to document itself, and Haddock’s docs are pretty impressively bad, though mostly serviceable if you’re willing to look.\n\n\nThe takeaway here is that I just don’t think most languages’ documentation is particularly good, and programmers seem to have gotten so used to this state of affairs that the bar is set disappointingly low. Fortunately, this is another area where Racket delivers. Racket, like Python, ships with two pieces of documentation: the Racket Guide and the Racket Reference. The guide includes over one hundred thousand words of explanations and examples, and the reference includes roughly half a million. Racket’s documentation is impressive on its own, but what’s equally impressive is how carefully and methodically cross-linked it is. Margin notes often provide links to corresponding sections in the relevant companion manual, so it’s easy to look up a form or function by name, then quickly jump to the section of the guide explaining it.\n\nHackett is obviously not going to have hundreds of thousands of words worth of documentation in its first few months of existence, but it already has nearly ten thousand, and that’s not nothing. More importantly, it is structured the same way that Racket’s docs are: it’s split into the Hackett Guide and the Hackett Reference, and the two are cross-referenced as much as possible. Haskell is a notoriously difficult language to learn, but my hope is that does not necessarily need to be the case. Documentation cannot make the language trivial, but my hope is that it can make it a lot more accessible without making it any less useful for power users.\n\nRounding Hackett’s library, sanding its edges\nOne of the best things about sitting down and writing documentation—whether it’s for a tool, a library, or a language—is how it forces you, the author, to think about how someone else might perceive the project when seeing it for the first time. This encompasses everything: error messages, ease of installation, completeness of a standard library, friendliness of tooling, etc. Writing Hackett’s documentation forced me to make a lot of improvements, and while very few of them are flashy features, they make Hackett feel much less like a toy and more like a tool.\n\nHackett currently has no formal changelog because it is considered alpha quality, and its API is still unstable. There is no guarantee that things won’t change at any moment. Still, it’s useful to put together an ad-hoc list of changes made in the past few months. Here’s a very brief summary:\n\n\nHackett includes a Double type for working with IEEE 754 double-precision floating-point numbers.\n\n\nLocal definitions are supported via the let and letrec forms.\n\n\nThe prelude includes many more functions, especially functions on lists.\n\n\nThe Hackett reader has been adjusted to support using . as a bare symbol, since . is the function composition operator.\n\n\nThe Hackett REPL supports many more forms, including ADT, class, and instance definitions. Additionally, the REPL now uses Show instances to display the results of expressions. To compensate for the inability to print non-Showable things, a new (#:type expr) syntax is permitted to print the type of any expression.\n\n\nMissing instance errors are now dramatically improved, now correctly highlighting the source location of expressions that led to the error.\n\n\nAlongside these changes are a variety of internal code improvements that make the Hackett code simpler, more readable, and hopefully more accessible to contributors. Many of the trickiest functions are now heavily commented with the hope that the codebase won’t be so intimidating to people unfamiliar with Racket or the techniques behind Hackett’s typechecker. I will continue to document the internals of Hackett as I change different places of the codebase, and I have even considered writing a separate Scribble document describing the Hackett internals. It certainly wouldn’t hurt.\n\nOne of the most exciting things about documenting Hackett has been realizing just how much already exists. Seriously, if you have gotten to this point in the blog post but haven’t read the actual documentation yet, I would encourage you to do so. No longer does the idea of writing real programs in this language feel out of reach; indeed, aside from potential performance problems, the language is likely extremely close to being usable for very simple things. After all, that’s the goal, isn’t it? As I’ve mentioned before, I’m writing Hackett for other people, but I’m also very much writing it for me: it’s a language I’d like to use.\n\nStill, writing a general-purpose programming language is a lot of work, and I’ve known from the start that it isn’t something I can accomplish entirely on my own. While this iteration of work on Hackett is a sort of “documentation release”, it might be more accurate to call it an “accessibility release”. If you’re interested in contributing, I finally feel comfortable encouraging you to get involved!\n\nA demo with pictures\nNow, if you’re like me, all of this documentation stuff is already pretty exciting. Still, even I view documentation as simply a means to an end, not an end in itself. Documentation is successful when it gets out of the way and makes it possible to write good code that does cool things. Let’s write some, shall we?\n\nHackett ships with a special package of demo libraries in the aptly-named hackett-demo package, which are essentially simple, lightweight bindings to existing, dynamically-typed Racket libraries. In the previous Hackett blog post, I demonstrated the capabilities of hackett/demo/web-server. In this blog post, we’re going to use hackett/demo/pict and hackett/demo/pict/universe, which make it possible to write interactive, graphical programs in Hackett with just a few lines of code!\n\nAs always, we’ll start with #lang hackett, and we’ll import the necessary libraries:\n\n#lang hackett\n\n(require hackett/demo/pict\n         hackett/demo/pict/universe)\nWith that, we can start immediately with a tiny example. Just to see how hackett/demo/pict works, let’s start by rendering a red square. We can do this by writing a main action that calls print-pict:\n\n(main (print-pict (colorize red (filled-square 50.0))))\nIf you run the above program in DrRacket, you should see a 50 pixel red square printed into the interactions window!\n\nUsing the REPL, we can inspect the type of print-pict:\n\n> (#:type print-pict)\n: (-> Pict (IO Unit))\nUnsurprisingly, displaying a picture to the screen needs IO. However, what’s interesting is that the rest of the expression is totally pure. Take a look at the type of filled-square:\n\n> (#:type filled-square)\n: (-> Double Pict)\nNo IO to be seen! This is because “picts” are entirely pure values that represent images built out of simple shapes, and they can be put together to make more complex images. For example, we can put two squares next to one another:\n\n(main (print-pict {(colorize red (filled-square 50.0))\n                   hc-append\n                   (colorize blue (filled-square 50.0))}))\nThis code will print out a red square to the left of a blue one.\n\nAgain, hc-append is a simple, pure function, a binary composition operator that places two picts side by side to produce a new one:\n\n> (#:type hc-append)\n: (-> Pict (-> Pict Pict))\nUsing the various features of this toolkit, not only can we make interesting pictures and diagrams, we can even create a foundation for a game!\n\nImplementing a snake clone\nThis blog post is not a Hackett tutorial; it is merely a demo. For that reason, I am not going to spend much time explaining how the following program is built. This section is closer to annotated source code than a guide to the pict or universe libraries. Hopefully it’s still illustrative.\n\nWe’ll start by writing some type definitions. We’ll need a type to represent 2D points on a grid, as well as a type to represent a cardinal direction (to keep track of which direction the player is moving, for example). We’ll also want an Eq instance for our points.\n\n(data Point (point Integer Integer))\n(data Direction d:left d:right d:up d:down)\n\n(instance (Eq Point)\n  [== (λ [(point a b) (point c d)] {{a == c} && {b == d}})])\nWith these two datatypes, we can implement a move function that accepts a point and a direction and produces a new point for an adjacent tile:\n\n(defn move : {Direction -> Point -> Point}\n  [[d:left  (point x y)] (point {x - 1} y)]\n  [[d:right (point x y)] (point {x + 1} y)]\n  [[d:up    (point x y)] (point x {y - 1})]\n  [[d:down  (point x y)] (point x {y + 1})])\nThe next step is to define a type for our world state. The big-bang library operates using a game loop, with a function to update the state that’s called each “tick”. Our state will need to hold all the information about our game, which in this case, is just three things:\n\n(data World-State (world-state\n                   Direction    ; snake direction\n                   (List Point) ; snake blocks\n                   (List Point) ; food blocks\n                   ))\nIt will also be useful to have a functional setter for the direction, which we’ll have to write ourselves, since Hackett does not (currently) have anything like Haskell’s record syntax:\n\n(defn set-ws-direction [[d (world-state a b c)] (world-state d b c)])\nNext, we’ll write some top-level constants that we’ll use in our rendering function, such as the number of tiles in the game board, the size of each tile in pixels, and some simple picts that represent the tiles we’ll use to draw our game:\n\n(def board-width 50)\n(def board-height 30)\n(def tile->absolute {(d* 15.0) . integer->double})\n(def empty-board (blank-rect (tile->absolute board-width) (tile->absolute board-height)))\n\n(def block (filled-square 13.0))\n(def food-block (colorize red block))\n(def snake-block (colorize black block))\nNow we can write our actual render function. To do this, we simply need to render each Point in our World-State’s two lists as a block on an empty-board. We’ll write a helper function, render-on-board, which does exactly that:\n\n(defn render-on-board : {Pict -> (List Point) -> Pict}\n  [[pict points]\n   (foldr (λ [(point x y) acc]\n            (pin-over acc (tile->absolute x) (tile->absolute y) pict))\n          empty-board points)])\nThis function uses foldr to collect each point and place the provided pict at the right location using pin-over on an empty board. Using render-on-board, we can write the render function in just a couple of lines:\n\n(defn render : {World-State -> Pict}\n  [[(world-state _ snake-points food-points)]\n   (pin-over (render-on-board snake-block snake-points)\n             0.0 0.0\n             (render-on-board food-block food-points))])\nNext, we’ll need to handle the update logic. On each tick, the snake should advance by a single tile in the direction it’s currently moving. If it runs into a food tile, it should grow one tile larger, and we need to generate a new food tile elsewhere on the board. To help with that last part, the big-bang library provides a random-integer function, which we can use to write a random-point action:\n\n(def random-point : (IO Point)\n  {point <$> (random-integer 0 board-width)\n         <*> (random-integer 0 board-height)})\nHackett supports applicative notation using infix operators, so random-point looks remarkably readable. It also runs in IO, since the result is, obviously, random. Fortunately, the on-tick function runs in IO as well (unlike render, which must be completely pure), so we can use random-point when necessary to generate a new food block:\n\n(def init! : (forall [a] {(List a) -> (List a)})\n  {reverse . tail! . reverse})\n\n(defn on-tick : {World-State -> (IO World-State)}\n  [[(world-state dir snake-points food-points)]\n   (let ([new-snake-point (move dir (head! snake-points))])\n     (if {new-snake-point elem? food-points}\n         (do [new-food-point <- random-point]\n             (pure (world-state dir {new-snake-point :: snake-points}\n                                {new-food-point :: (delete new-snake-point food-points)})))\n         (pure (world-state dir {new-snake-point :: (init! snake-points)}\n                            food-points))))])\nThis function is the most complicated one in the whole program, but it’s still not terribly complex. It figures out what the snake’s next location is and binds it to new-snake-point, then checks if there is a food block at that location. If there is, it generates a new-food-point, then puts it in the new world state. Otherwise, it removes the last snake point and continues as usual.\n\nThe game is already almost completely written. The next step is just to handle key events, which are obviously important for allowing the player to control the snake. Fortunately, this is easy, since we can just use our set-ws-direction function that we wrote earlier:\n\n(defn on-key : {KeyEvent -> World-State -> (IO World-State)}\n  [[ke:left ] {pure . (set-ws-direction d:left)}]\n  [[ke:right] {pure . (set-ws-direction d:right)}]\n  [[ke:up   ] {pure . (set-ws-direction d:up)}]\n  [[ke:down ] {pure . (set-ws-direction d:down)}]\n  [[_       ] {pure . id}])\nThe on-key function runs in IO, but we don’t actually need that power, since all of our keypress update logic is completely pure, so we just wrap everything in pure.\n\nWe’re almost done now—all we need to do is set up the initial state when the game begins. We’ll write a small binding that creates a world state with the snake in the middle of the board and some random food locations scattered about:\n\n(def initial-state\n  (do [initial-food <- (sequence (take 5 (repeat random-point)))]\n      (pure (world-state d:right\n                         {(point 25 15) :: (point 24 15) :: (point 23 15) :: nil}\n                         initial-food))))\nNotably, we can use the repeat function to create an infinite list of random-point actions, take the first five of them, then call sequence to execute them from left to right. Now, all we have to do is put the pieces together in a main block:\n\n(main (do [state <- initial-state]\n          (big-bang state\n            #:to-draw render\n            #:on-tick on-tick 0.2\n            #:on-key on-key)))\nAnd that’s it! We haven’t implemented any win or loss conditions, but the basics are all there. In 80 lines of code, we’ve implemented a working snake game in Hackett.\n\nContributing to Hackett\nIf you are excited enough about Hackett to be interested in contributing, your first question is very likely “What can I do?” or “Where do I start?” My answer to that is (perhaps a little unhelpfully): it depends! My general recommendation is to try and write something with Hackett, and if you run into anything that prevents you from accomplishing your goal, look into what would need to be changed to support your program. Having a use case is a great way to come up with useful improvements.\n\nOn the other hand, you might not have anything in mind, or you might find Hackett’s scope a little too overwhelming to just jump right in and start contributing. Fortunately, Hackett has an issue tracker, so feel free to take a look and pick something that looks interesting and achievable. Alternatively, the standard library can always use fleshing out, and quite a lot of that can be written without ever even touching the scary Hackett internals.\n\nAdditionally, if you have any questions, please don’t hesitate to ask them! If you have a question about the codebase, get stuck implementing something, or just don’t know where to start, feel free to open an issue on GitHub, send me a message on the #racket IRC channel on Freenode, or ping me on the Racket Slack team.\n\nAcknowledgements\nSpeaking of contributors, I’m excited to say that this is the first time I can truly say Hackett includes code written by someone other than me! I want to call attention to Samuel Gélineau, aka gelisam, who is officially the second contributor to Hackett. He helped to implement the new approach the Hackett REPL uses for printing expressions, which ended up being quite useful when implementing some of the other REPL improvements.\n\nAdditionally, I want to specially thank Matthew Flatt, Robby Findler, and Sam Tobin-Hochstadt for being especially responsive and helpful to my many questions about Scribble and the Racket top level. Racket continues to be extremely impressive, both as a project and as a community.\n\nFinally, many thanks to the various people who have expressed interest in the project and continue to push me and ask questions. Working on Hackett is a lot of work—both time and effort—and it’s your continued enthusiasm that inspires me to put in the hours.","isoDate":"2017-08-28T00:00:00.000Z","timestamp":"8/27/2017"},{"title":"User-programmable infix operators in Racket","pubDate":"2017-08-12T00:00:00.000Z","author":"Alexis King","content":"<article><p>Lisps are not known for infix operators, quite the opposite; infix operators generally involve more syntax and parsing than Lispers are keen to support. However, in <a href=\"https://github.com/lexi-lambda/hackett\">Hackett</a>, all functions are curried, and variable-arity functions do not exist. Infix operators are almost necessary for that to be palatable, and though there are other reasons to want them, it may not be obvious how to support them without making the reader considerably more complex.\n</p><p>Fortunately, if we require users to syntactically specify where they wish to use infix expressions, support for infix operators is not only possible, but can support be done <em>without</em> modifying the stock <code>#lang racket</code> reader. Futhermore, the resulting technique makes it possible for fixity information to be specified locally in a way that cooperates nicely with the Racket macro system, allowing the parsing of infix expressions to be manipulated at compile-time by users’ macros.\n</p><h2><a name=\"our-mission\"></a>Our mission</h2><p>Before we embark, let’s clarify our goal. We want to support infix operators in Racket, of course, but that could mean a lot of different things! Let’s start with what we <em>do</em> want:\n</p><ul><li><p>Infix operators should be user-extensible, not limited to a special set of built-in operators.\n</p></li><li><p>Furthermore, operators’ names should not be restricted to a separate “operator” character set. Any valid Lisp identifier should be usable as an infix operator.\n</p></li><li><p>We want to be able to support fixity/associativity annotations. Some operators should associate to the left, like subtraction, but others should associate to the right, like <code>cons</code>. This allows <code>5 - 1 - 2</code> to be parsed as <code>(- (- 5 1) 2)</code>, but <code>5 :: 1 :: nil</code> to be parsed as <code>(:: 5 (:: 1 nil))</code>.\n</p></li></ul><p>These are nice goals, but we also won’t be too ambitious. In order to keep things simple and achievable, we’ll keep the following restrictions:\n</p><ul><li><p>We will <strong>not</strong> permit infix expressions in arbitrary locations, since that would be impossible to parse given how we want to allow users to pick any names for operators they wish. Instead, infix expressions must be wrapped in curly braces, e.g. replacing <code>(+ 1 2)</code> with <code>{1 + 2}</code>.\n</p></li><li><p>Our implementation will <strong>not</strong> support any notion of operator precedence; all operators will have equal precedence, and it will be illegal to mix operators of different associativity in the same expression. Precedence is entirely possible to implement in theory, but it would be considerably more work, so this blog post does not include it.\n</p></li><li><p>All operators will be binary, and we will <strong>not</strong> support unary or mixfix operators. My intuition is that this technique should be able to be generalized to both of those things, but it would be considerably more complicated.\n</p></li></ul><p>With those points in mind, what would the interface for our infix operator library look like for our users? Ideally, something like this:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">prefix-in</span> <span class=\"n\">racket/base/</span> <span class=\"n\">racket/base</span><span class=\"p\">)</span>\n         <span class=\"s2\">\"infix.rkt\"</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">-</span> <span class=\"n\">racket/base/-</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">::</span> <span class=\"nb\">cons</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">right</span><span class=\"p\">)</span>\n\n<span class=\"p\">{{</span><span class=\"mi\">2</span> <span class=\"nb\">-</span> <span class=\"mi\">1</span><span class=\"p\">}</span> <span class=\"n\">::</span> <span class=\"p\">{</span><span class=\"mi\">10</span> <span class=\"nb\">-</span> <span class=\"mi\">3</span><span class=\"p\">}</span> <span class=\"n\">::</span> <span class=\"o\">&#39;</span><span class=\"p\">()}</span>\n<span class=\"c1\">; =&gt; &#39;(1 7)</span></code></pre><p>Let’s get started.\n</p><h2><a name=\"implementing-infix-operators\"></a>Implementing infix operators</h2><p>Now that we know what we want, how do we get there? Well, there are a few pieces to this puzzle. We’ll need to solve a two main problems:\n</p><ol><li><p>How do we “hook into” expressions wrapped with curly braces so that we can perform a desugaring pass?\n</p></li><li><p>How can we associate fixity information with certain operators?\n</p></li></ol><p>We’ll start by tackling the first problem, since its solution will inform the answer to the second. Since we won’t have any fixity information to start with, we’ll just assume that all operators associate left by default.\n</p><p>So, how <em>do</em> we detect if a Racket expression is surrounded by curly braces? Normally, in <code>#lang racket</code>, parentheses, square brackets, and curly braces are all interchangeable. Indeed, if you use curly braces in the REPL, you will find that they are treated <em>exactly</em> the same as parentheses:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"nb\">+</span> <span class=\"mi\">1</span> <span class=\"mi\">2</span><span class=\"p\">}</span>\n<span class=\"mi\">3</span></code></pre><p>If they are treated identically, giving them special behavior might seem hopeless, but don’t despair! Racket is no ordinary programming language, and it provides some tools to help us out here.\n</p><p>Someone who has worked with Lisps before is likely already aware that Lisp source code is a very direct representation of its AST, composed mostly of lists, pairs, symbols, numbers, and strings. In Racket, this is also true, but Racket also wraps these datums in boxes known as <a href=\"http://docs.racket-lang.org/reference/syntax-model.html#%28tech._syntax._object%29\"><em>syntax objects</em></a>. Syntax objects contain extra metadata about the code, most notably its lexical context, necessary for Racket’s hygiene system. However, syntax objects can also contain arbitrary metadata, known as <a href=\"http://docs.racket-lang.org/reference/stxprops.html#%28tech._syntax._property%29\"><em>syntax properties</em></a>. Macros can attach arbitrary values to the syntax objects they produce using syntax properties, and other macros can inspect them. Racket’s <a href=\"http://docs.racket-lang.org/guide/Pairs__Lists__and_Racket_Syntax.html#%28tech._reader%29\"><em>reader</em></a> (the syntax parser that turns program text into Racket syntax objects) also attaches certain syntax properties as part of its parsing process. One of those is named <a href=\"http://docs.racket-lang.org/reference/reader.html#%28idx._%28gentag._30._%28lib._scribblings%2Freference%2Freference..scrbl%29%29%29\"><code>'paren-shape</code></a>.\n</p><p>This syntax property, as the name implies, keeps track of the shape of parentheses in syntax objects. You can see that for yourself by inspecting the property’s value for different syntax objects in the REPL:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"o\">&#39;</span><span class=\"ss\">paren-shape</span><span class=\"p\">)</span>\n<span class=\"no\">#f</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"ss\">paren-shape</span><span class=\"p\">)</span>\n<span class=\"sc\">#\\[</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">syntax-property</span> <span class=\"o\">#&#39;</span><span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">}</span> <span class=\"o\">&#39;</span><span class=\"ss\">paren-shape</span><span class=\"p\">)</span>\n<span class=\"sc\">#\\{</span></code></pre><p>This syntax property gives us the capability to distinguish between syntax objects that use curly braces and those that don’t, which is a step in the right direction, but it still doesn’t give us any hook with which we can change the behavior of certain expressions. Fortunately, there’s something else that can.\n</p><h3><a name=\"customizing-application\"></a>Customizing application</h3><p>Racket is a language <em>designed</em> to be extended, and it provides a variety of hooks in the language for the purposes of tweaking pieces in minor ways. One such hook is named <a href=\"http://docs.racket-lang.org/reference/application.html#%28form._%28%28lib._racket%2Fprivate%2Fbase..rkt%29._~23~25app%29%29\"><code>#%app</code></a>, which is automatically introduced by the macroexpander whenever it encounters a function application. That means it effectively turns this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"mi\">1</span> <span class=\"mi\">2</span><span class=\"p\">)</span></code></pre><p>…into this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">#%app</span> <span class=\"nb\">+</span> <span class=\"mi\">1</span> <span class=\"mi\">2</span><span class=\"p\">)</span></code></pre><p>What’s special about <code>#%app</code> is that the macroexpander will use whichever <code>#%app</code> is in scope in the expression’s lexical context, so if we write our own version of <code>#%app</code>, it will be used instead of the one from <code>#lang racket</code>. This is what we will use to hook into ordinary Racket expressions.\n</p><p>To write our custom version of <code>#%app</code>, we will use the usual tool: Racket’s industrial-strength macro-authoring DSL, <a href=\"http://docs.racket-lang.org/syntax/stxparse.html\"><code>syntax/parse</code></a>. We’ll also use a helper library that provides some tools for pattern-matching on syntax objects with the <code>'paren-shape</code> syntax property, <a href=\"http://docs.racket-lang.org/syntax-classes/index.html#%28mod-path._syntax%2Fparse%2Fclass%2Fparen-shape%29\"><code>syntax/parse/class/paren-shape</code></a>. Using these, we can transform expressions that are surrounded in curly braces differently from how we would transform expressions surrounded by parentheses:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">syntax/parse/class/paren-shape</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">prefix-in</span> <span class=\"n\">racket/base/</span> <span class=\"n\">racket/base</span><span class=\"p\">)</span>\n         <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"k\">#%app</span>\n  <span class=\"p\">[{</span><span class=\"n\">~braces</span> <span class=\"k\">_</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">}</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)])</span></code></pre><p>This code will transform any applications surrounded in curly braces into one that starts with <code>#%infix</code> instead of <code>#%app</code>, so <code>{1 + 2}</code> will become <code>(#%infix 1 + 2)</code>, for example. The identifier <code>#%infix</code> isn’t actually special in any way, it just has a funny name, but we haven’t actually defined <code>#%infix</code> yet, so we need to do that next!\n</p><p>To start, we’ll just handle the simplest case: infix expressions with precisely three subexpressions, like <code>{1 + 2}</code>, should be converted into the equivalent prefix expressions, in this case <code>(+ 1 2)</code>. We can do this with a simple macro:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">#%infix</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">op</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)])</span></code></pre><p>Due to the way Racket propagates syntax properties, we explicitly indicate that the resulting expansion should use the <code>#%app</code> from <code>racket/base</code>, which will avoid any accidental infinite recursion between our <code>#%app</code> and <code>#%infix</code>. With this in place, we can now try our code out in the REPL, and believe it or not, we now support infix expressions with just those few lines of code:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"mi\">1</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"mi\">3</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">+</span> <span class=\"mi\">2</span><span class=\"p\">}</span>\n<span class=\"mi\">3</span></code></pre><p>That’s pretty cool!\n</p><p>Of course, we probably want to support infix applications with more than just a single binary operator, such as <code>{1 + 2 + 3}</code>. We can implement that just by adding another case to <code>#%infix</code> that handles more subforms:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">#%infix</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">op</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)])</span></code></pre><p>…and now, just by adding those two lines, we support arbitrarily-large sequences of infix operators:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">+</span> <span class=\"mi\">2</span> <span class=\"nb\">+</span> <span class=\"mi\">3</span><span class=\"p\">}</span>\n<span class=\"mi\">6</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">+</span> <span class=\"mi\">2</span> <span class=\"nb\">+</span> <span class=\"mi\">3</span> <span class=\"nb\">+</span> <span class=\"mi\">4</span><span class=\"p\">}</span>\n<span class=\"mi\">10</span></code></pre><p>I don’t know about you, but I think being able to do this in less than 20 lines of code is pretty awesome. We can even mix different operators in the same expression:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">+</span> <span class=\"mi\">2</span> <span class=\"nb\">*</span> <span class=\"mi\">3</span> <span class=\"nb\">-</span> <span class=\"mi\">4</span><span class=\"p\">}</span>\n<span class=\"mi\">5</span></code></pre><p>Of course, all of our infix expressions currently assume that all operators associate left, as was our plan. In general, though, there are lots of useful operators that associate right, such as <code>cons</code>, nested <code>-&gt;</code> types or contracts for curried functions, and <code>expt</code>, the exponentiation operator.\n</p><h3><a name=\"tracking-operator-fixity\"></a>Tracking operator fixity</h3><p>Clearly, we need some way to associate operator fixity with certain identifiers, and we need to be able to do it at compile-time. Fortunately, Racket has a very robust mechanism for creating compile-time values. Unfortunately, simply associating metadata with an identifier is a little less convenient than it could be, but there is a general technique that can be done with little boilerplate.\n</p><p>Essentially, Racket (like Scheme) uses a <code>define-syntax</code> form to define macros, which is what <code>define-syntax-parser</code> eventually expands into. However, unlike Scheme, Racket’s <code>define-syntax</code> is not <em>just</em> for defining macros—it’s for defining arbitrary bindings with compile-time (aka “phase 1”) values. Using this, we can define bindings that have entirely arbitrary values at compile-time, including plain data like numbers or strings:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">foo</span> <span class=\"mi\">3</span><span class=\"p\">)</span></code></pre><p>Once a binding has been defined using <code>define-syntax</code>, a macro can look up the value associated with it by using the <a href=\"http://docs.racket-lang.org/reference/stxtrans.html#%28def._%28%28quote._~23~25kernel%29._syntax-local-value%29%29\"><code>syntax-local-value</code></a> function, which returns the compile-time value associated with an identifier:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-value</span> <span class=\"o\">#&#39;</span><span class=\"n\">foo</span><span class=\"p\">)))</span>\n<span class=\"c1\">; =&gt; 3</span></code></pre><p>The cool thing is that <code>syntax-local-value</code> gets the value associated with a specific <em>binding</em>, not a specific name. This means a macro can look up the compile-time value associated with an identifier provided to it as a subform. This is close to what we want, since we could use <code>syntax-local-value</code> to look up something associated with our infix operator bindings, but the trouble is that they would then cease to be usable as ordinary functions. For example, if you try and use the <code>foo</code> binding from the above example as an expression, Racket will complain about an “illegal use of syntax”, which makes sense, because <code>foo</code> is not bound to anything at runtime.\n</p><p>To solve this problem, we can use something of a trick: any compile-time binding that happens to have a procedure as its value will be treated like a macro—that is, using it as an expression will cause the macroexpander to invoke the procedure with a syntax object representing the macro invocation, and the procedure is expected to produce a new syntax object as output. Additionally, Racket programmers can make custom datatypes valid procedures by using the <a href=\"http://docs.racket-lang.org/reference/procedures.html#%28def._%28%28lib._racket%2Fprivate%2Fbase..rkt%29._prop~3aprocedure%29%29\"><code>prop:procedure</code></a> structure type property.\n</p><p>If you are not familiar with the Racket macro system, this probably sounds rather complicated, but in practice, it’s not as confusing as it might seem. The trick here is to create a custom structure type at compile-time that we can use to track operator fixity alongside its runtime binding:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">syntax/transformer</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">infix-operator</span> <span class=\"p\">(</span><span class=\"n\">runtime-binding</span> <span class=\"n\">fixity</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:property</span> <span class=\"nb\">prop:procedure</span>\n    <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">operator</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n      <span class=\"p\">((</span><span class=\"nb\">set!-transformer-procedure</span>\n        <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span>\n         <span class=\"p\">(</span><span class=\"n\">infix-operator-runtime-binding</span> <span class=\"n\">operator</span><span class=\"p\">)))</span>\n       <span class=\"n\">stx</span><span class=\"p\">))))</span></code></pre><p>This is quite the magical incantation, and all the details of what is going on here are outside the scope of this blog post. Essentially, though, we can use values of this structure as a compile-time binding that will act just like the identifier provided for <code>runtime-binding</code>, but we can also include a value of our choosing for <code>fixity</code>. Here’s an example:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">infix-operator</span> <span class=\"o\">#&#39;</span><span class=\"nb\">cons</span> <span class=\"o\">&#39;</span><span class=\"ss\">right</span><span class=\"p\">))</span></code></pre><p>This new <code>::</code> binding will act, in every way, just like <code>cons</code>. If we use it in the REPL, you can see that it acts exactly the same:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">::</span> <span class=\"mi\">1</span> <span class=\"o\">&#39;</span><span class=\"p\">())</span>\n<span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>However, we can also use <code>syntax-local-value</code> to extract this binding’s fixity at compile-time, and that’s what makes it interesting:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"p\">(</span><span class=\"n\">infix-operator-fixity</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-value</span> <span class=\"o\">#&#39;</span><span class=\"n\">::</span><span class=\"p\">))))</span>\n<span class=\"c1\">; =&gt; &#39;right</span></code></pre><p>Using this extra compile-time information, we can adjust our <code>#%infix</code> macro to inspect bindings and determine their fixity, then use that to make decisions about parsing. Just like we used <code>syntax/parse/class/paren-shape</code> to make decisions based on the <code>'paren-shape</code> syntax property, we can use <a href=\"http://docs.racket-lang.org/syntax-classes/index.html#%28mod-path._syntax%2Fparse%2Fclass%2Flocal-value%29\"><code>syntax/parse/class/local-value</code></a> to pattern-match on bindings with a particular compile-time value. We’ll wrap this in a syntax class of our own to make the code easier to read:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">infix-op</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"infix operator\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">fixity</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">op</span> <span class=\"p\">(</span><span class=\"n\">local-value</span> <span class=\"n\">infix-operator?</span><span class=\"p\">)}</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">fixity</span> <span class=\"p\">(</span><span class=\"n\">infix-operator-fixity</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.local-value</span><span class=\"p\">))]))</span></code></pre><p>Now, we can update <code>#%infix</code> to use our new <code>infix-op</code> syntax class:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">#%infix</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">op</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n   <span class=\"kd\">#:when</span> <span class=\"p\">(</span><span class=\"nb\">eq?</span> <span class=\"o\">&#39;</span><span class=\"ss\">left</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.fixity</span><span class=\"p\">))</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">more</span> <span class=\"k\">...</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"kd\">#:when</span> <span class=\"p\">(</span><span class=\"nb\">eq?</span> <span class=\"o\">&#39;</span><span class=\"ss\">right</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.fixity</span><span class=\"p\">))</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">more</span> <span class=\"k\">...</span> <span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">))])</span></code></pre><p>Notably, we now require all operators to be bound to compile-time infix operator values, and we include two conditions via <code>#:when</code> clauses. These clauses check to ensure that the operator in question has the expected fixity before committing to that clause; if the condition fails, then parsing backtracks. Using this new definition of <code>#%infix</code>, we can successfully use <code>::</code> in an infix expression, and it will be parsed with the associativity that we expect:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"n\">::</span> <span class=\"mi\">2</span> <span class=\"n\">::</span> <span class=\"mi\">3</span> <span class=\"n\">::</span> <span class=\"o\">&#39;</span><span class=\"p\">()}</span>\n<span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"mi\">2</span> <span class=\"mi\">3</span><span class=\"p\">)</span></code></pre><p>Exciting!\n</p><h3><a name=\"a-nicer-interface-for-defining-infix-operators\"></a>A nicer interface for defining infix operators</h3><p>We currently have to define infix operators by explicitly using <code>define-syntax</code>, but this is not a very good interface. Users of infix syntax probably don’t want to have to understand the internal workings of the infix operator implementation, so we just need to define one final macro to consider this done: the <code>define-infix-operator</code> form from the example at the very beginning of this blog post.\n</p><p>Fortunately, this macro is absolutely trivial to write. In fact, we can do it in a mere three lines of code, since it’s very minor sugar over the <code>define-syntax</code> definitions we were already writing:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">op:id</span> <span class=\"n\">value:id</span>\n                       <span class=\"kd\">#:fixity</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">fixity</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">left</span><span class=\"p\">}</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">right</span><span class=\"p\">}}})</span>\n  <span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">op</span> <span class=\"p\">(</span><span class=\"n\">infix-operator</span> <span class=\"o\">#&#39;</span><span class=\"n\">value</span> <span class=\"o\">&#39;</span><span class=\"ss\">fixity</span><span class=\"p\">)))</span></code></pre><p>With this in hand, we can define some infix operators with a much nicer syntax:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">+</span> <span class=\"n\">racket/base/+</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">-</span> <span class=\"n\">racket/base/-</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">*</span> <span class=\"n\">racket/base/*</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">/</span> <span class=\"n\">racket/base//</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">^</span> <span class=\"nb\">expt</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">right</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">::</span> <span class=\"nb\">cons</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">right</span><span class=\"p\">)</span></code></pre><p>With these simple definitions, we can write some very nice mathematical expressions that use infix syntax, in ordinary <code>#lang racket</code>:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">+</span> <span class=\"mi\">2</span> <span class=\"nb\">-</span> <span class=\"mi\">4</span><span class=\"p\">}</span>\n<span class=\"mi\">-1</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">2</span> <span class=\"n\">^</span> <span class=\"mi\">2</span> <span class=\"n\">^</span> <span class=\"mi\">3</span><span class=\"p\">}</span>\n<span class=\"mi\">256</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">{{</span><span class=\"mi\">2</span> <span class=\"n\">^</span> <span class=\"mi\">2</span><span class=\"p\">}</span> <span class=\"n\">^</span> <span class=\"mi\">3</span><span class=\"p\">}</span>\n<span class=\"mi\">64</span></code></pre><p>And you know what’s most amazing about this? The entire thing is <strong>only 50 lines of code</strong>. Here is the entire implementation of infix operators from this blog post in a single code block, with absolutely nothing hidden or omitted:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"p\">(</span><span class=\"k\">for-syntax</span> <span class=\"n\">syntax/parse/class/local-value</span>\n                     <span class=\"n\">syntax/parse/class/paren-shape</span>\n                     <span class=\"n\">syntax/transformer</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">prefix-in</span> <span class=\"n\">racket/base/</span> <span class=\"n\">racket/base</span><span class=\"p\">)</span>\n         <span class=\"n\">syntax/parse/define</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">infix-operator</span> <span class=\"p\">(</span><span class=\"n\">runtime-binding</span> <span class=\"n\">fixity</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:property</span> <span class=\"nb\">prop:procedure</span>\n    <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">operator</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n      <span class=\"p\">((</span><span class=\"nb\">set!-transformer-procedure</span>\n        <span class=\"p\">(</span><span class=\"n\">make-variable-like-transformer</span>\n         <span class=\"p\">(</span><span class=\"n\">infix-operator-runtime-binding</span> <span class=\"n\">operator</span><span class=\"p\">)))</span>\n       <span class=\"n\">stx</span><span class=\"p\">)))</span>\n\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">infix-op</span>\n    <span class=\"kd\">#:description</span> <span class=\"s2\">\"infix operator\"</span>\n    <span class=\"kd\">#:attributes</span> <span class=\"p\">[</span><span class=\"n\">fixity</span><span class=\"p\">]</span>\n    <span class=\"p\">[</span><span class=\"n\">pattern</span> <span class=\"p\">{</span><span class=\"n\">~var</span> <span class=\"n\">op</span> <span class=\"p\">(</span><span class=\"n\">local-value</span> <span class=\"n\">infix-operator?</span><span class=\"p\">)}</span>\n             <span class=\"kd\">#:attr</span> <span class=\"n\">fixity</span> <span class=\"p\">(</span><span class=\"n\">infix-operator-fixity</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.local-value</span><span class=\"p\">))]))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"k\">#%app</span>\n  <span class=\"p\">[{</span><span class=\"n\">~braces</span> <span class=\"k\">_</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">}</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)])</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-syntax-parser</span> <span class=\"n\">#%infix</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">racket/base/#%app</span> <span class=\"n\">op</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n   <span class=\"kd\">#:when</span> <span class=\"p\">(</span><span class=\"nb\">eq?</span> <span class=\"o\">&#39;</span><span class=\"ss\">left</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.fixity</span><span class=\"p\">))</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">more</span> <span class=\"k\">...</span><span class=\"p\">)]</span>\n  <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">more</span> <span class=\"k\">...</span> <span class=\"n\">a</span> <span class=\"n\">op:infix-op</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n   <span class=\"kd\">#:when</span> <span class=\"p\">(</span><span class=\"nb\">eq?</span> <span class=\"o\">&#39;</span><span class=\"ss\">right</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">op.fixity</span><span class=\"p\">))</span>\n   <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">more</span> <span class=\"k\">...</span> <span class=\"p\">(</span><span class=\"n\">#%infix</span> <span class=\"n\">a</span> <span class=\"n\">op</span> <span class=\"n\">b</span><span class=\"p\">))])</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-simple-macro</span> <span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">op:id</span> <span class=\"n\">value:id</span>\n                       <span class=\"kd\">#:fixity</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">fixity</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">left</span><span class=\"p\">}</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">right</span><span class=\"p\">}}})</span>\n  <span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">op</span> <span class=\"p\">(</span><span class=\"n\">infix-operator</span> <span class=\"o\">#&#39;</span><span class=\"n\">value</span> <span class=\"o\">&#39;</span><span class=\"ss\">fixity</span><span class=\"p\">)))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">+</span> <span class=\"n\">racket/base/+</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">-</span> <span class=\"n\">racket/base/-</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">*</span> <span class=\"n\">racket/base/*</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"nb\">/</span> <span class=\"n\">racket/base//</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">left</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">^</span> <span class=\"nb\">expt</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">right</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">define-infix-operator</span> <span class=\"n\">::</span> <span class=\"nb\">cons</span> <span class=\"kd\">#:fixity</span> <span class=\"n\">right</span><span class=\"p\">)</span></code></pre><p>Racket is a hell of a programming language.\n</p><h2><a name=\"applications-limitations-and-implications\"></a>Applications, limitations, and implications</h2><p>This blog post has outlined a complete, useful model for infix operators, and it is now hopefully clear how they work, but many of the most interesting properties of this implementation are probably not obvious. As far as I can make out, this embedding of infix operators into a macro system is novel, and I am <em>almost certain</em> that the way this implementation tracks fixity information is unique. One of the most interesting capabilities gained from this choice of implementation is the ability for macros to define infix operators and control their fixity, even <em>locally</em>.\n</p><p>What does this mean? Well, remember that infix operators are just special syntax bindings. Racket includes a variety of forms for binding or adjusting macros locally, such as <code>let-syntax</code> and <code>syntax-parameterize</code>. Using these tools, it would be entirely possible to implement a <code>with-fixity</code> macro, that could adjust the fixity of an operator within a syntactic block. This could be used, for example, to make <code>/</code> right associative within a block of code:\n</p><pre><code class=\"pygments\"><span class=\"nb\">&gt;</span> <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">/</span> <span class=\"mi\">2</span> <span class=\"nb\">/</span> <span class=\"mi\">3</span><span class=\"p\">}</span>\n<span class=\"m\">1/6</span>\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">with-fixity</span> <span class=\"p\">([</span><span class=\"nb\">/</span> <span class=\"n\">right</span><span class=\"p\">])</span>\n    <span class=\"p\">{</span><span class=\"mi\">1</span> <span class=\"nb\">/</span> <span class=\"mi\">2</span> <span class=\"nb\">/</span> <span class=\"mi\">3</span><span class=\"p\">})</span>\n<span class=\"mi\">1</span> <span class=\"m\">1/2</span></code></pre><p>In fact, this macro is hardly theoretical, since it could be implemented in a trivial 7 lines, simply expanding to uses of <code>splicing-let</code> and <code>splicing-let-syntax</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-simple-macro</span>\n  <span class=\"p\">(</span><span class=\"n\">with-fixity</span> <span class=\"p\">([</span><span class=\"n\">op:id</span> <span class=\"p\">{</span><span class=\"n\">~and</span> <span class=\"n\">fixity</span> <span class=\"p\">{</span><span class=\"n\">~or</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">left</span><span class=\"p\">}</span> <span class=\"p\">{</span><span class=\"n\">~datum</span> <span class=\"n\">right</span><span class=\"p\">}}}]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n    <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n  <span class=\"kd\">#:with</span> <span class=\"p\">[</span><span class=\"n\">op-tmp</span> <span class=\"k\">...</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">generate-temporaries</span> <span class=\"o\">#&#39;</span><span class=\"p\">[</span><span class=\"n\">op</span> <span class=\"k\">...</span><span class=\"p\">])</span>\n  <span class=\"p\">(</span><span class=\"n\">splicing-let</span> <span class=\"p\">([</span><span class=\"n\">op-tmp</span> <span class=\"n\">op</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">splicing-let-syntax</span> <span class=\"p\">([</span><span class=\"n\">op</span> <span class=\"p\">(</span><span class=\"n\">infix-operator</span> <span class=\"o\">#&#39;</span><span class=\"n\">op-tmp</span> <span class=\"o\">&#39;</span><span class=\"ss\">fixity</span><span class=\"p\">)]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n      <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">)))</span></code></pre><p>This is not especially useful given the current set of infix operator features, but it’s easy to imagine how useful it could be in a system that also supported a notion of precedence. It is not entirely uncommon to encounter certain expressions that could be more cleanly expressed with a local set of operator precedence rules, perhaps described as a set of relations <em>between</em> operators rather than a global table of magic precedence numbers. With traditional approaches to infix operators, parsing such code would be difficult without a very rigid syntactic structure, but this technique makes it easy.\n</p><p>As mentioned at the beginning of this blog post, this technique is also not merely a novelty—as of now, I am actively using this in <a href=\"https://github.com/lexi-lambda/hackett\">Hackett</a> to support infix operators with all of the features outlined here. The Hackett implementation is a little bit fancier than the one in this blog post, since it works harder to produce better error messages. It explicitly disallows mixing left associative and right associative operators in the same expression, so it does some additional validation as part of expansion, and it arranges for source location information to be copied onto the result. It also make a different design decision to allow <em>any</em> expression to serve as an infix operator, assuming left associativity if no fixity annotation is available.\n</p><p>If you’re interested in the code behind the additional steps Hackett takes to make infix operators more usable and complete, take a look at <a href=\"https://github.com/lexi-lambda/hackett/blob/0d177d00a9ee96f30dd76761f1cb86f15830779f/hackett-lib/hackett/private/infix.rkt\">this file for the definition of infix bindings</a>, as well as <a href=\"https://github.com/lexi-lambda/hackett/blob/0d177d00a9ee96f30dd76761f1cb86f15830779f/hackett-lib/hackett/private/kernel.rkt#L80-L101\">this file for the defintion of infix application</a>. My hope is to eventually add support for some sort of precedence information, though who knows—maybe infix operators will be easier to reason about if the rules are kept extremely simple. I am also considering adding support for so-called “operator sections” at some point, which would allow things like <code>{_ - 1}</code> to serve as a shorthand for <code>(lambda [x] {x - 1})</code>, but I haven’t yet decided if I like the tradeoffs involved.\n</p><p>It’s possible that this implementation of infix operators might also be useful in languages in the Racket ecosystem besides Hackett. However, I’m not sure it makes a ton of sense in <code>#lang racket</code> without modifications, as variadic functions subsume many of the cases where infix operators are needed in Haskell. If there is a clamoring for this capability, I would be happy to consider extracting the functionality into a library, but as of right now, I don’t have any plans to do so.\n</p><p>Finally, the main point of this blog post is to showcase how easy it is to do things in Racket that would be impossible in most languages and difficult even in most Lisps. It also helps to show off how Hackett is already benefitting from those capabilities: while this particular feature is built-in to <code>#lang hackett</code>, there’s no reason something similar but more powerful couldn’t be built as a separate library by a <em>user</em> of Hackett. Even as Hackett’s author, I think that’s exciting, since makes it possible for users to experiment with improvements to the language on their own. Some of those improvements may eventually be rolled into the core language or standard library, but many of them can likely live effectively in separate libraries, accessible on-demand to those who need them. After all, that’s one of Racket’s most important promises—languages as libraries—and it’s why Hackett is a part of the Racket ecosystem.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Lisps are not known for infix operators, quite the opposite; infix operators generally involve more syntax and parsing than Lispers are keen to support. However, in Hackett, all functions are curried, and variable-arity functions do not exist. Infix operators are almost necessary for that to be palatable, and though there are other reasons to want them, it may not be obvious how to support them without making the reader considerably more complex.\n\nFortunately, if we require users to syntactically specify where they wish to use infix expressions, support for infix operators is not only possible, but can support be done without modifying the stock #lang racket reader. Futhermore, the resulting technique makes it possible for fixity information to be specified locally in a way that cooperates nicely with the Racket macro system, allowing the parsing of infix expressions to be manipulated at compile-time by users’ macros.\n\nOur mission\nBefore we embark, let’s clarify our goal. We want to support infix operators in Racket, of course, but that could mean a lot of different things! Let’s start with what we do want:\n\n\nInfix operators should be user-extensible, not limited to a special set of built-in operators.\n\n\nFurthermore, operators’ names should not be restricted to a separate “operator” character set. Any valid Lisp identifier should be usable as an infix operator.\n\n\nWe want to be able to support fixity/associativity annotations. Some operators should associate to the left, like subtraction, but others should associate to the right, like cons. This allows 5 - 1 - 2 to be parsed as (- (- 5 1) 2), but 5 :: 1 :: nil to be parsed as (:: 5 (:: 1 nil)).\n\n\nThese are nice goals, but we also won’t be too ambitious. In order to keep things simple and achievable, we’ll keep the following restrictions:\n\n\nWe will not permit infix expressions in arbitrary locations, since that would be impossible to parse given how we want to allow users to pick any names for operators they wish. Instead, infix expressions must be wrapped in curly braces, e.g. replacing (+ 1 2) with {1 + 2}.\n\n\nOur implementation will not support any notion of operator precedence; all operators will have equal precedence, and it will be illegal to mix operators of different associativity in the same expression. Precedence is entirely possible to implement in theory, but it would be considerably more work, so this blog post does not include it.\n\n\nAll operators will be binary, and we will not support unary or mixfix operators. My intuition is that this technique should be able to be generalized to both of those things, but it would be considerably more complicated.\n\n\nWith those points in mind, what would the interface for our infix operator library look like for our users? Ideally, something like this:\n\n#lang racket\n\n(require (prefix-in racket/base/ racket/base)\n         \"infix.rkt\")\n\n(define-infix-operator - racket/base/- #:fixity left)\n(define-infix-operator :: cons #:fixity right)\n\n{{2 - 1} :: {10 - 3} :: '()}\n; => '(1 7)\nLet’s get started.\n\nImplementing infix operators\nNow that we know what we want, how do we get there? Well, there are a few pieces to this puzzle. We’ll need to solve a two main problems:\n\n\nHow do we “hook into” expressions wrapped with curly braces so that we can perform a desugaring pass?\n\n\nHow can we associate fixity information with certain operators?\n\n\nWe’ll start by tackling the first problem, since its solution will inform the answer to the second. Since we won’t have any fixity information to start with, we’ll just assume that all operators associate left by default.\n\nSo, how do we detect if a Racket expression is surrounded by curly braces? Normally, in #lang racket, parentheses, square brackets, and curly braces are all interchangeable. Indeed, if you use curly braces in the REPL, you will find that they are treated exactly the same as parentheses:\n\n> {+ 1 2}\n3\nIf they are treated identically, giving them special behavior might seem hopeless, but don’t despair! Racket is no ordinary programming language, and it provides some tools to help us out here.\n\nSomeone who has worked with Lisps before is likely already aware that Lisp source code is a very direct representation of its AST, composed mostly of lists, pairs, symbols, numbers, and strings. In Racket, this is also true, but Racket also wraps these datums in boxes known as syntax objects. Syntax objects contain extra metadata about the code, most notably its lexical context, necessary for Racket’s hygiene system. However, syntax objects can also contain arbitrary metadata, known as syntax properties. Macros can attach arbitrary values to the syntax objects they produce using syntax properties, and other macros can inspect them. Racket’s reader (the syntax parser that turns program text into Racket syntax objects) also attaches certain syntax properties as part of its parsing process. One of those is named 'paren-shape.\n\nThis syntax property, as the name implies, keeps track of the shape of parentheses in syntax objects. You can see that for yourself by inspecting the property’s value for different syntax objects in the REPL:\n\n> (syntax-property #'(1 2 3) 'paren-shape)\n#f\n> (syntax-property #'[1 2 3] 'paren-shape)\n#\\[\n> (syntax-property #'{1 2 3} 'paren-shape)\n#\\{\nThis syntax property gives us the capability to distinguish between syntax objects that use curly braces and those that don’t, which is a step in the right direction, but it still doesn’t give us any hook with which we can change the behavior of certain expressions. Fortunately, there’s something else that can.\n\nCustomizing application\nRacket is a language designed to be extended, and it provides a variety of hooks in the language for the purposes of tweaking pieces in minor ways. One such hook is named #%app, which is automatically introduced by the macroexpander whenever it encounters a function application. That means it effectively turns this:\n\n(+ 1 2)\n…into this:\n\n(#%app + 1 2)\nWhat’s special about #%app is that the macroexpander will use whichever #%app is in scope in the expression’s lexical context, so if we write our own version of #%app, it will be used instead of the one from #lang racket. This is what we will use to hook into ordinary Racket expressions.\n\nTo write our custom version of #%app, we will use the usual tool: Racket’s industrial-strength macro-authoring DSL, syntax/parse. We’ll also use a helper library that provides some tools for pattern-matching on syntax objects with the 'paren-shape syntax property, syntax/parse/class/paren-shape. Using these, we can transform expressions that are surrounded in curly braces differently from how we would transform expressions surrounded by parentheses:\n\n#lang racket\n\n(require (for-syntax syntax/parse/class/paren-shape)\n         (prefix-in racket/base/ racket/base)\n         syntax/parse/define)\n\n(define-syntax-parser #%app\n  [{~braces _ arg ...}\n   #'(#%infix arg ...)]\n  [(_ arg ...)\n   #'(racket/base/#%app arg ...)])\nThis code will transform any applications surrounded in curly braces into one that starts with #%infix instead of #%app, so {1 + 2} will become (#%infix 1 + 2), for example. The identifier #%infix isn’t actually special in any way, it just has a funny name, but we haven’t actually defined #%infix yet, so we need to do that next!\n\nTo start, we’ll just handle the simplest case: infix expressions with precisely three subexpressions, like {1 + 2}, should be converted into the equivalent prefix expressions, in this case (+ 1 2). We can do this with a simple macro:\n\n(define-syntax-parser #%infix\n  [(_ a op b)\n   #'(racket/base/#%app op a b)])\nDue to the way Racket propagates syntax properties, we explicitly indicate that the resulting expansion should use the #%app from racket/base, which will avoid any accidental infinite recursion between our #%app and #%infix. With this in place, we can now try our code out in the REPL, and believe it or not, we now support infix expressions with just those few lines of code:\n\n> (+ 1 2)\n3\n> {1 + 2}\n3\nThat’s pretty cool!\n\nOf course, we probably want to support infix applications with more than just a single binary operator, such as {1 + 2 + 3}. We can implement that just by adding another case to #%infix that handles more subforms:\n\n(define-syntax-parser #%infix\n  [(_ a op b)\n   #'(racket/base/#%app op a b)]\n  [(_ a op b more ...)\n   #'(#%infix (#%infix a op b) more ...)])\n…and now, just by adding those two lines, we support arbitrarily-large sequences of infix operators:\n\n> {1 + 2 + 3}\n6\n> {1 + 2 + 3 + 4}\n10\nI don’t know about you, but I think being able to do this in less than 20 lines of code is pretty awesome. We can even mix different operators in the same expression:\n\n> {1 + 2 * 3 - 4}\n5\nOf course, all of our infix expressions currently assume that all operators associate left, as was our plan. In general, though, there are lots of useful operators that associate right, such as cons, nested -> types or contracts for curried functions, and expt, the exponentiation operator.\n\nTracking operator fixity\nClearly, we need some way to associate operator fixity with certain identifiers, and we need to be able to do it at compile-time. Fortunately, Racket has a very robust mechanism for creating compile-time values. Unfortunately, simply associating metadata with an identifier is a little less convenient than it could be, but there is a general technique that can be done with little boilerplate.\n\nEssentially, Racket (like Scheme) uses a define-syntax form to define macros, which is what define-syntax-parser eventually expands into. However, unlike Scheme, Racket’s define-syntax is not just for defining macros—it’s for defining arbitrary bindings with compile-time (aka “phase 1”) values. Using this, we can define bindings that have entirely arbitrary values at compile-time, including plain data like numbers or strings:\n\n(define-syntax foo 3)\nOnce a binding has been defined using define-syntax, a macro can look up the value associated with it by using the syntax-local-value function, which returns the compile-time value associated with an identifier:\n\n(begin-for-syntax\n  (println (syntax-local-value #'foo)))\n; => 3\nThe cool thing is that syntax-local-value gets the value associated with a specific binding, not a specific name. This means a macro can look up the compile-time value associated with an identifier provided to it as a subform. This is close to what we want, since we could use syntax-local-value to look up something associated with our infix operator bindings, but the trouble is that they would then cease to be usable as ordinary functions. For example, if you try and use the foo binding from the above example as an expression, Racket will complain about an “illegal use of syntax”, which makes sense, because foo is not bound to anything at runtime.\n\nTo solve this problem, we can use something of a trick: any compile-time binding that happens to have a procedure as its value will be treated like a macro—that is, using it as an expression will cause the macroexpander to invoke the procedure with a syntax object representing the macro invocation, and the procedure is expected to produce a new syntax object as output. Additionally, Racket programmers can make custom datatypes valid procedures by using the prop:procedure structure type property.\n\nIf you are not familiar with the Racket macro system, this probably sounds rather complicated, but in practice, it’s not as confusing as it might seem. The trick here is to create a custom structure type at compile-time that we can use to track operator fixity alongside its runtime binding:\n\n(require (for-syntax syntax/transformer))\n\n(begin-for-syntax\n  (struct infix-operator (runtime-binding fixity)\n    #:property prop:procedure\n    (λ (operator stx)\n      ((set!-transformer-procedure\n        (make-variable-like-transformer\n         (infix-operator-runtime-binding operator)))\n       stx))))\nThis is quite the magical incantation, and all the details of what is going on here are outside the scope of this blog post. Essentially, though, we can use values of this structure as a compile-time binding that will act just like the identifier provided for runtime-binding, but we can also include a value of our choosing for fixity. Here’s an example:\n\n(define-syntax :: (infix-operator #'cons 'right))\nThis new :: binding will act, in every way, just like cons. If we use it in the REPL, you can see that it acts exactly the same:\n\n> (:: 1 '())\n'(1)\nHowever, we can also use syntax-local-value to extract this binding’s fixity at compile-time, and that’s what makes it interesting:\n\n(begin-for-syntax\n  (println (infix-operator-fixity (syntax-local-value #'::))))\n; => 'right\nUsing this extra compile-time information, we can adjust our #%infix macro to inspect bindings and determine their fixity, then use that to make decisions about parsing. Just like we used syntax/parse/class/paren-shape to make decisions based on the 'paren-shape syntax property, we can use syntax/parse/class/local-value to pattern-match on bindings with a particular compile-time value. We’ll wrap this in a syntax class of our own to make the code easier to read:\n\n(begin-for-syntax\n  (define-syntax-class infix-op\n    #:description \"infix operator\"\n    #:attributes [fixity]\n    [pattern {~var op (local-value infix-operator?)}\n             #:attr fixity (infix-operator-fixity (attribute op.local-value))]))\nNow, we can update #%infix to use our new infix-op syntax class:\n\n(define-syntax-parser #%infix\n  [(_ a op:infix-op b)\n   #'(racket/base/#%app op a b)]\n  [(_ a op:infix-op b more ...)\n   #:when (eq? 'left (attribute op.fixity))\n   #'(#%infix (#%infix a op b) more ...)]\n  [(_ more ... a op:infix-op b)\n   #:when (eq? 'right (attribute op.fixity))\n   #'(#%infix more ... (#%infix a op b))])\nNotably, we now require all operators to be bound to compile-time infix operator values, and we include two conditions via #:when clauses. These clauses check to ensure that the operator in question has the expected fixity before committing to that clause; if the condition fails, then parsing backtracks. Using this new definition of #%infix, we can successfully use :: in an infix expression, and it will be parsed with the associativity that we expect:\n\n> {1 :: 2 :: 3 :: '()}\n'(1 2 3)\nExciting!\n\nA nicer interface for defining infix operators\nWe currently have to define infix operators by explicitly using define-syntax, but this is not a very good interface. Users of infix syntax probably don’t want to have to understand the internal workings of the infix operator implementation, so we just need to define one final macro to consider this done: the define-infix-operator form from the example at the very beginning of this blog post.\n\nFortunately, this macro is absolutely trivial to write. In fact, we can do it in a mere three lines of code, since it’s very minor sugar over the define-syntax definitions we were already writing:\n\n(define-simple-macro (define-infix-operator op:id value:id\n                       #:fixity {~and fixity {~or {~datum left} {~datum right}}})\n  (define-syntax op (infix-operator #'value 'fixity)))\nWith this in hand, we can define some infix operators with a much nicer syntax:\n\n(define-infix-operator + racket/base/+ #:fixity left)\n(define-infix-operator - racket/base/- #:fixity left)\n(define-infix-operator * racket/base/* #:fixity left)\n(define-infix-operator / racket/base// #:fixity left)\n\n(define-infix-operator ^ expt #:fixity right)\n(define-infix-operator :: cons #:fixity right)\nWith these simple definitions, we can write some very nice mathematical expressions that use infix syntax, in ordinary #lang racket:\n\n> {1 + 2 - 4}\n-1\n> {2 ^ 2 ^ 3}\n256\n> {{2 ^ 2} ^ 3}\n64\nAnd you know what’s most amazing about this? The entire thing is only 50 lines of code. Here is the entire implementation of infix operators from this blog post in a single code block, with absolutely nothing hidden or omitted:\n\n#lang racket\n\n(require (for-syntax syntax/parse/class/local-value\n                     syntax/parse/class/paren-shape\n                     syntax/transformer)\n         (prefix-in racket/base/ racket/base)\n         syntax/parse/define)\n\n(begin-for-syntax\n  (struct infix-operator (runtime-binding fixity)\n    #:property prop:procedure\n    (λ (operator stx)\n      ((set!-transformer-procedure\n        (make-variable-like-transformer\n         (infix-operator-runtime-binding operator)))\n       stx)))\n\n  (define-syntax-class infix-op\n    #:description \"infix operator\"\n    #:attributes [fixity]\n    [pattern {~var op (local-value infix-operator?)}\n             #:attr fixity (infix-operator-fixity (attribute op.local-value))]))\n\n(define-syntax-parser #%app\n  [{~braces _ arg ...}\n   #'(#%infix arg ...)]\n  [(_ arg ...)\n   #'(racket/base/#%app arg ...)])\n\n(define-syntax-parser #%infix\n  [(_ a op:infix-op b)\n   #'(racket/base/#%app op a b)]\n  [(_ a op:infix-op b more ...)\n   #:when (eq? 'left (attribute op.fixity))\n   #'(#%infix (#%infix a op b) more ...)]\n  [(_ more ... a op:infix-op b)\n   #:when (eq? 'right (attribute op.fixity))\n   #'(#%infix more ... (#%infix a op b))])\n\n(define-simple-macro (define-infix-operator op:id value:id\n                       #:fixity {~and fixity {~or {~datum left} {~datum right}}})\n  (define-syntax op (infix-operator #'value 'fixity)))\n\n(define-infix-operator + racket/base/+ #:fixity left)\n(define-infix-operator - racket/base/- #:fixity left)\n(define-infix-operator * racket/base/* #:fixity left)\n(define-infix-operator / racket/base// #:fixity left)\n\n(define-infix-operator ^ expt #:fixity right)\n(define-infix-operator :: cons #:fixity right)\nRacket is a hell of a programming language.\n\nApplications, limitations, and implications\nThis blog post has outlined a complete, useful model for infix operators, and it is now hopefully clear how they work, but many of the most interesting properties of this implementation are probably not obvious. As far as I can make out, this embedding of infix operators into a macro system is novel, and I am almost certain that the way this implementation tracks fixity information is unique. One of the most interesting capabilities gained from this choice of implementation is the ability for macros to define infix operators and control their fixity, even locally.\n\nWhat does this mean? Well, remember that infix operators are just special syntax bindings. Racket includes a variety of forms for binding or adjusting macros locally, such as let-syntax and syntax-parameterize. Using these tools, it would be entirely possible to implement a with-fixity macro, that could adjust the fixity of an operator within a syntactic block. This could be used, for example, to make / right associative within a block of code:\n\n> {1 / 2 / 3}\n1/6\n> (with-fixity ([/ right])\n    {1 / 2 / 3})\n1 1/2\nIn fact, this macro is hardly theoretical, since it could be implemented in a trivial 7 lines, simply expanding to uses of splicing-let and splicing-let-syntax:\n\n(define-simple-macro\n  (with-fixity ([op:id {~and fixity {~or {~datum left} {~datum right}}}] ...)\n    body ...)\n  #:with [op-tmp ...] (generate-temporaries #'[op ...])\n  (splicing-let ([op-tmp op] ...)\n    (splicing-let-syntax ([op (infix-operator #'op-tmp 'fixity)] ...)\n      body ...)))\nThis is not especially useful given the current set of infix operator features, but it’s easy to imagine how useful it could be in a system that also supported a notion of precedence. It is not entirely uncommon to encounter certain expressions that could be more cleanly expressed with a local set of operator precedence rules, perhaps described as a set of relations between operators rather than a global table of magic precedence numbers. With traditional approaches to infix operators, parsing such code would be difficult without a very rigid syntactic structure, but this technique makes it easy.\n\nAs mentioned at the beginning of this blog post, this technique is also not merely a novelty—as of now, I am actively using this in Hackett to support infix operators with all of the features outlined here. The Hackett implementation is a little bit fancier than the one in this blog post, since it works harder to produce better error messages. It explicitly disallows mixing left associative and right associative operators in the same expression, so it does some additional validation as part of expansion, and it arranges for source location information to be copied onto the result. It also make a different design decision to allow any expression to serve as an infix operator, assuming left associativity if no fixity annotation is available.\n\nIf you’re interested in the code behind the additional steps Hackett takes to make infix operators more usable and complete, take a look at this file for the definition of infix bindings, as well as this file for the defintion of infix application. My hope is to eventually add support for some sort of precedence information, though who knows—maybe infix operators will be easier to reason about if the rules are kept extremely simple. I am also considering adding support for so-called “operator sections” at some point, which would allow things like {_ - 1} to serve as a shorthand for (lambda [x] {x - 1}), but I haven’t yet decided if I like the tradeoffs involved.\n\nIt’s possible that this implementation of infix operators might also be useful in languages in the Racket ecosystem besides Hackett. However, I’m not sure it makes a ton of sense in #lang racket without modifications, as variadic functions subsume many of the cases where infix operators are needed in Haskell. If there is a clamoring for this capability, I would be happy to consider extracting the functionality into a library, but as of right now, I don’t have any plans to do so.\n\nFinally, the main point of this blog post is to showcase how easy it is to do things in Racket that would be impossible in most languages and difficult even in most Lisps. It also helps to show off how Hackett is already benefitting from those capabilities: while this particular feature is built-in to #lang hackett, there’s no reason something similar but more powerful couldn’t be built as a separate library by a user of Hackett. Even as Hackett’s author, I think that’s exciting, since makes it possible for users to experiment with improvements to the language on their own. Some of those improvements may eventually be rolled into the core language or standard library, but many of them can likely live effectively in separate libraries, accessible on-demand to those who need them. After all, that’s one of Racket’s most important promises—languages as libraries—and it’s why Hackett is a part of the Racket ecosystem.","isoDate":"2017-08-12T00:00:00.000Z","timestamp":"8/11/2017"},{"title":"Unit testing effectful Haskell with monad-mock","pubDate":"2017-06-29T00:00:00.000Z","author":"Alexis King","content":"<article><p>Nearly eight months ago, <a href=\"/blog/2016/10/03/using-types-to-unit-test-in-haskell/\">I wrote a blog post about unit testing effectful Haskell code</a> using a library called test-fixture. That library has served us well, but it wasn’t as easy to use as I would have liked, and it worked better with certain patterns than others. Since then, I’ve learned more about Haskell and more about testing, and I’m pleased to announce that I am releasing an entirely new testing library, <a href=\"https://hackage.haskell.org/package/monad-mock\">monad-mock</a>.\n</p><h2><a name=\"a-first-glance-at-monad-mock\"></a>A first glance at monad-mock</h2><p>The monad-mock library is, first and foremost, designed to be <em>easy</em>. It doesn’t ask much from you, and it requires almost zero boilerplate.\n</p><p>The first step is to write an mtl-style interface that encodes an effect you want to mock. For example, you might want to test some code that interacts with the filesystem:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>Now you just have to write your code as normal. For demonstration purposes, here’s a function that defines copying a file in terms of <code>readFile</code> and <code>writeFile</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">copyFile</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n<span class=\"nf\">copyFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">contents</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">readFile</span> <span class=\"n\">a</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">b</span> <span class=\"n\">contents</span></code></pre><p>Making this function work on the real filesystem is trivial, since we just need to define an instance of <code>MonadFileSystem</code> for <code>IO</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">readFile</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">writeFile</span></code></pre><p>But how do we test this? Well, we <em>could</em> run some real code in <code>IO</code>, which might not be so bad for such a simple function, but this seems like a bad idea. For one thing, a bad implementation of <code>copyFile</code> could do some pretty horrible things if it misbehaved and decided to overwrite important files, and if you’re constantly running a test suite whenever a file changes, it’s easy to imagine causing a lot of damage. Running tests against the real filesystem also makes tests slower and harder to parallelize, and it only gets much worse once you are doing more complex effects than interacting with the filesystem.\n</p><p>Using monad-mock, we can test this function in just a couple of lines of code:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">Control.Exception</span> <span class=\"p\">(</span><span class=\"nf\">evaluate</span><span class=\"p\">)</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.Mock</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.Mock.TH</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Data.Function</span> <span class=\"p\">((</span><span class=\"o\">&amp;</span><span class=\"p\">))</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Test.Hspec</span>\n\n<span class=\"nf\">makeMock</span> <span class=\"s\">\"FileSystemAction\"</span> <span class=\"p\">[</span><span class=\"n\">ts</span><span class=\"o\">|</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"o\">|</span><span class=\"p\">]</span>\n\n<span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"copyFile\"</span> <span class=\"o\">$</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reads a file and writes its contents to another file\"</span> <span class=\"o\">$</span>\n    <span class=\"n\">evaluate</span> <span class=\"o\">$</span> <span class=\"n\">copyFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"s\">\"bar.txt\"</span>\n      <span class=\"o\">&amp;</span> <span class=\"n\">runMock</span> <span class=\"p\">[</span> <span class=\"kt\">ReadFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"kt\">:-&gt;</span> <span class=\"s\">\"contents\"</span>\n                <span class=\"p\">,</span> <span class=\"kt\">WriteFile</span> <span class=\"s\">\"bar.txt\"</span> <span class=\"s\">\"contents\"</span> <span class=\"kt\">:-&gt;</span> <span class=\"nb\">()</span> <span class=\"p\">]</span></code></pre><p>That’s it!\n</p><p>The last two lines of the above snippet are the real interesting bits, which specify the actions that are expected to be executed, and it couples them with their results. You will find that if you tweak the list in any way, such as reordering the actions, eliminating one or both of them, or adding an additional action to the end, the test will fail. We could even turn this into a property-based test that generated arbitrary file paths and file contents.\n</p><p>Admittedly, in this trivial example, the mock is a little silly, since converting this into a property-based test would demonstrate how much we’ve basically just reimplemented the function in our test. However, once our function starts to do somewhat more complicated things, then our tests become more meaningful. Here’s a similar function that only copies a file if it is nonempty:\n</p><pre><code class=\"pygments\"><span class=\"nf\">copyNonemptyFile</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n<span class=\"nf\">copyNonemptyFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">contents</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">readFile</span> <span class=\"n\">a</span>\n  <span class=\"n\">unless</span> <span class=\"p\">(</span><span class=\"n\">null</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"o\">$</span>\n    <span class=\"n\">writeFile</span> <span class=\"n\">b</span> <span class=\"n\">contents</span></code></pre><p>This function has some logic which is very clearly <em>not</em> expressed in its type, and it would be difficult to encode that information into the type in a safe way. Fortunately, we can guarantee that it works by writing some tests:\n</p><pre><code class=\"pygments\"><span class=\"nf\">describe</span> <span class=\"s\">\"copyNonemptyFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"copies a file with contents\"</span> <span class=\"o\">$</span>\n    <span class=\"n\">evaluate</span> <span class=\"o\">$</span> <span class=\"n\">copyNonemptyFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"s\">\"bar.txt\"</span>\n      <span class=\"o\">&amp;</span> <span class=\"n\">runMock</span> <span class=\"p\">[</span> <span class=\"kt\">ReadFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"kt\">:-&gt;</span> <span class=\"s\">\"contents\"</span>\n                <span class=\"p\">,</span> <span class=\"kt\">WriteFile</span> <span class=\"s\">\"bar.txt\"</span> <span class=\"s\">\"contents\"</span> <span class=\"kt\">:-&gt;</span> <span class=\"nb\">()</span> <span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"does nothing with an empty file\"</span> <span class=\"o\">$</span>\n    <span class=\"n\">evaluate</span> <span class=\"o\">$</span> <span class=\"n\">copyNonemptyFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"s\">\"bar.txt\"</span>\n      <span class=\"o\">&amp;</span> <span class=\"n\">runMock</span> <span class=\"p\">[</span> <span class=\"kt\">ReadFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"kt\">:-&gt;</span> <span class=\"s\">\"\"</span> <span class=\"p\">]</span></code></pre><p>These tests are much more useful, and they have some actual value to them. Imagine we had accidentally written <code>when</code> instead of <code>unless</code>, an easy typo to make. Our tests would fail with some useful error messages:\n</p><pre><code>1) copyNonemptyFile copies a file with contents\n     uncaught exception: runMockT: expected the following unexecuted actions to be run:\n       WriteFile \"bar.txt\" \"contents\"\n\n2) copyNonemptyFile does nothing with an empty file\n     uncaught exception: runMockT: expected end of program, called writeFile\n       given action: WriteFile \"bar.txt\" \"\"\n</code></pre><p>You now know enough to write tests with monad-mock.\n</p><h2><a name=\"why-unit-test\"></a>Why unit test?</h2><p>When the issue of testing is brought up in Haskell, it is often treated with a certain distaste by a portion of the community. There are some points I’ve seen a number of times, and though they take different forms, they boil down to two ideas:\n</p><ol><li><p>“Haskell code does not need tests because the type system can prove correctness.”\n</p></li><li><p>“Testing in Haskell is trivial because it is a pure language, and testing pure functions is easy.”\n</p></li></ol><p>I’ve been writing Haskell professionally for over a year now, and I can happily say that there <em>is</em> some truth to both of those things! When my Haskell code typechecks, I feel a confidence in it that I would not feel were I using a language with a less powerful type system. Furthermore, Haskell encourages a “pure core, impure shell” approach to system design that makes testing many things pleasant and straightforward, and it completely eliminates the worry of subtle nondeterminism leaking into tests.\n</p><p>That said, Haskell is not a proof assistant, and its type system cannot guarantee everything, especially for code that operates on the boundaries of what Haskell can control. For much the same reason, I find that my pure code is the code I am <em>least</em> likely to need to test, since it is also the code with the strongest type safety guarantees, operating on types in my application’s domain. In contrast, the effectful code is often what I find the most value in extensively testing, since it often contains the most subtle complexity, and it is frequently difficult or even impossible to encode into types.\n</p><p>Haskell has the power to provide remarkably strong correctness guarantees with a surprisingly small amount of effort by using a combination of tests and types, using each to accommodate for the other’s weaknesses and playing to each technique’s strengths. Some code is test-driven, other code is type-driven. Most code ends up being a mix of both. Testing is just a tool like any other, and it’s nice to feel confident in one’s ability to effectively structure code in a decoupled, testable manner.\n</p><h2><a name=\"why-mock\"></a>Why mock?</h2><p>Even if you accept that testing is good, the question of whether or not to <em>mock</em> is a subtler issue. To some people, “unit testing” is synonymous with mocks. This is emphatically not true, and in fact, overly aggressive mocking is one of the best ways to make your test suite completely worthless. The monad-mock approach to mocking is a bit more principled than mocking in many dynamic, object-oriented languages, but it comes with many of the same drawbacks: mocks couple your tests to your implementation in ways that make them less valuable and less meaningful.\n</p><p>For the <code>MonadFileSystem</code> example above, I would actually probably <em>not</em> use a mock. Instead, I would use a <strong>fake</strong>, in-memory filesystem implementation:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">FakeFileSystemT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">FakeFileSystemT</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"p\">[(</span><span class=\"kt\">FilePath</span><span class=\"p\">,</span> <span class=\"kt\">String</span><span class=\"p\">)]</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">)</span>\n\n<span class=\"nf\">fakeFileSystemT</span> <span class=\"ow\">::</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">[(</span><span class=\"kt\">FilePath</span><span class=\"p\">,</span> <span class=\"kt\">String</span><span class=\"p\">)]</span>\n                <span class=\"ow\">-&gt;</span> <span class=\"kt\">FakeFileSystemT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"p\">[(</span><span class=\"kt\">FilePath</span><span class=\"p\">,</span> <span class=\"kt\">String</span><span class=\"p\">)])</span>\n<span class=\"nf\">fakeFileSystemT</span> <span class=\"n\">fs</span> <span class=\"p\">(</span><span class=\"kt\">FakeFileSystemT</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">second</span> <span class=\"n\">sort</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"n\">runStateT</span> <span class=\"n\">x</span> <span class=\"n\">fs</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">FakeFileSystemT</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"kt\">FakeFileSystemT</span> <span class=\"o\">$</span> <span class=\"n\">get</span> <span class=\"o\">&gt;&gt;=</span> <span class=\"nf\">\\</span><span class=\"n\">fs</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">lookup</span> <span class=\"n\">path</span> <span class=\"n\">fs</span> <span class=\"o\">&amp;</span>\n    <span class=\"n\">maybe</span> <span class=\"p\">(</span><span class=\"n\">fail</span> <span class=\"o\">$</span> <span class=\"s\">\"readFile: no such file ‘\"</span> <span class=\"o\">++</span> <span class=\"n\">path</span> <span class=\"o\">++</span> <span class=\"s\">\"’\"</span><span class=\"p\">)</span> <span class=\"n\">return</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"n\">contents</span> <span class=\"ow\">=</span> <span class=\"kt\">FakeFileSystemT</span> <span class=\"o\">.</span> <span class=\"n\">modify</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">fs</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">,</span> <span class=\"n\">contents</span><span class=\"p\">)</span> <span class=\"kt\">:</span> <span class=\"n\">filter</span> <span class=\"p\">((</span><span class=\"o\">/=</span> <span class=\"n\">path</span><span class=\"p\">)</span> <span class=\"o\">.</span> <span class=\"n\">fst</span><span class=\"p\">)</span> <span class=\"n\">fs</span></code></pre><p>The above snippet demonstrates how easy it is to define a <code>MonadFileSystem</code> implementation in terms of <code>StateT</code>, and while this may seem like a lot of boilerplate, it really isn’t. You have to write a fake <em>once</em> per interface, and the above block is a minuscule twelve lines of code. With this technique, you are still able to write tests that depend on the state of the filesystem before and after running the implementation, but you decouple yourself from the precise process of getting there:\n</p><pre><code class=\"pygments\"><span class=\"nf\">describe</span> <span class=\"s\">\"copyNonemptyFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"copies a file with contents\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"p\">(</span><span class=\"nb\">()</span><span class=\"p\">,</span> <span class=\"n\">fs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">runIdentity</span> <span class=\"o\">$</span> <span class=\"n\">copyNonemptyFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"s\">\"bar.txt\"</span>\n          <span class=\"o\">&amp;</span> <span class=\"n\">fakeFileSystemT</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"contents\"</span><span class=\"p\">)</span> <span class=\"p\">]</span>\n    <span class=\"n\">fs</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"bar.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"contents\"</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"contents\"</span><span class=\"p\">)</span> <span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"does nothing with an empty file\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"p\">(</span><span class=\"nb\">()</span><span class=\"p\">,</span> <span class=\"n\">fs</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">runIdentity</span> <span class=\"o\">$</span> <span class=\"n\">copyNonemptyFile</span> <span class=\"s\">\"foo.txt\"</span> <span class=\"s\">\"bar.txt\"</span>\n          <span class=\"o\">&amp;</span> <span class=\"n\">fakeFileSystemT</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"\"</span><span class=\"p\">)</span> <span class=\"p\">]</span>\n    <span class=\"n\">fs</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"\"</span><span class=\"p\">)</span> <span class=\"p\">]</span></code></pre><p>This is better than using a mock, and I would highly recommend doing it if you can! However, a lot of real applications have to interact with services of much greater complexity than an idealized filesystem, and creating that sort of in-memory fake is not always practical. One such situation might be interacting with AWS CloudFormation, for example:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadAWS</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">createStack</span> <span class=\"ow\">::</span> <span class=\"kt\">StackName</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">StackTemplate</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">AWSError</span> <span class=\"kt\">StackId</span><span class=\"p\">)</span>\n  <span class=\"n\">listStacks</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">AWSError</span> <span class=\"p\">[</span><span class=\"kt\">StackSummaries</span><span class=\"p\">])</span>\n  <span class=\"n\">describeStack</span> <span class=\"ow\">::</span> <span class=\"kt\">StackId</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">AWSError</span> <span class=\"kt\">StackInfo</span><span class=\"p\">)</span>\n  <span class=\"c1\">-- and so on...</span></code></pre><p>AWS is a very complex system, and it can do dozens of different things (and fail in dozens of different ways) based on an equally complex set of inputs. For example, in the above API, <code>createStack</code> needs to parse its template, which can be YAML or JSON, in order to determine which of many possible errors and behaviors can be produced, both on the initial call and on subsequent ones.\n</p><p>Creating a fake implementation of <em>AWS</em> is hardly feasible, and this is where a mock can be useful. By simply writing <code>makeMock \"AWSAction\" [ts| MonadAWS |]</code>, we can test functions that interact with AWS in a pure way without necessarily needing to replicate all of its complexity.\n</p><h3><a name=\"isolating-mocks\"></a>Isolating mocks</h3><p>Of course, tests that use mocks provide less value than tests that use “smarter” fakes, since they are far more tightly coupled to the implementation, and it’s dramatically more likely that you will need to change the tests when you change the logic. To avoid this, it can be helpful to create multiple interfaces to the same thing: a high-level interface and a low-level one. If our above <code>MonadAWS</code> is a low-level interface, we could create a high-level counterpart that does precisely what our application needs:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadDeploy</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">executeDeployment</span> <span class=\"ow\">::</span> <span class=\"kt\">Deployment</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">DeployError</span> <span class=\"nb\">()</span><span class=\"p\">)</span></code></pre><p>When running our application “for real”, we would use <code>MonadAWS</code> to implement <code>MonadDeploy</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">executeDeploymentImpl</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadAWS</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Deployment</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">DeployError</span> <span class=\"nb\">()</span><span class=\"p\">)</span>\n<span class=\"nf\">executeDeploymentImpl</span> <span class=\"ow\">=</span> <span class=\"o\">...</span></code></pre><p>The nice thing about this is we can actually test <code>executeDeploymentImpl</code> using a <code>MonadAWS</code> mock, so we can still have unit test coverage of the code on the boundaries of our system! Additionally, by containing the mock to a single place, we can test the rest of our code using a smarter fake implementation of <code>MonadDeploy</code>, helping to decouple our code from AWS’s complex API and improve the reliability and usefulness of our test suite.\n</p><p>They key point here is that mocking is just a small piece of the larger testing puzzle in <em>any</em> language, and that is just as true in Haskell. An overemphasis on mocking is an easy way to end up with a test suite that feels useless, probably because it is. Use mocks as a technique to insulate your application from the complexity in others’ APIs, then use more domain-specific testing techniques and type-level assertions to ensure the correctness of your logic.\n</p><h2><a name=\"how-monad-mock-works\"></a>How monad-mock works</h2><p>If you’ve read this far and are convinced that monad-mock is useful, you may safely stop reading now. However, if you are interested in the details of what it actually does and what makes it tick, the rest of this blog post is going to focus on how the implementation works and how it compares to other techniques.\n</p><p>The centerpiece of monad-mock’s API is its monad transformer, <code>MockT</code>, which is a type constructor that accepts three types:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">MockT</span> <span class=\"p\">(</span><span class=\"n\">f</span> <span class=\"ow\">::</span> <span class=\"o\">*</span> <span class=\"ow\">-&gt;</span> <span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"ow\">::</span> <span class=\"o\">*</span> <span class=\"ow\">-&gt;</span> <span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"ow\">::</span> <span class=\"o\">*</span><span class=\"p\">)</span></code></pre><p>The <code>m</code> and <code>a</code> type variables obviously correspond to the usual monad transformer arguments, which represent the underlying monad and the result of the monadic computation, respectively. The <code>f</code> variable is more interesting, since it’s what makes <code>MockT</code> work at all, and it isn’t even a type: it’s a type constructor with kind <code>* -&gt; *</code>. What does it mean?\n</p><p>Looking at the type signature of <code>runMockT</code> gives us a little bit more information about what that <code>f</code> actually represents:\n</p><pre><code class=\"pygments\"><span class=\"nf\">runMockT</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">Action</span> <span class=\"n\">f</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">[</span><span class=\"kt\">WithResult</span> <span class=\"n\">f</span><span class=\"p\">]</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">MockT</span> <span class=\"n\">f</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>This type signature provides two pieces of key information:\n</p><ol><li><p>The <code>f</code> parameter is constrained by the <code>Action f</code> constraint.\n</p></li><li><p>Running a mocked computation requires supplying a list of <code>WithResult f</code> values. This list corresponds to the list of expectations provided to <code>runMock</code> in earlier examples.\n</p></li></ol><p>To understand both of these things, it helps to examine the definition of an actual datatype that can have an <code>Action</code> instance. For the filesystem example, the action datatype looks like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">FileSystemAction</span> <span class=\"n\">r</span> <span class=\"kr\">where</span>\n  <span class=\"kt\">ReadFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FileSystemAction</span> <span class=\"kt\">String</span>\n  <span class=\"kt\">WriteFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">FileSystemAction</span> <span class=\"nb\">()</span></code></pre><p>Notice how each constructor clearly corresponds to one of the methods of <code>MonadFileSystem</code>, with a type to match. Now the purpose of the type provided to the <code>FileSystemAction</code> constructor (in this case <code>r</code>) should hopefully become clear: it represents the type of the value <em>produced</em> by each method. Also note that the type is completely phantom—it does not appear in negative position in any of the constructors.\n</p><p>With this in mind, we can take a look at the definition of <code>WithResult</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">WithResult</span> <span class=\"n\">f</span> <span class=\"kr\">where</span>\n  <span class=\"p\">(</span><span class=\"kt\">:-&gt;</span><span class=\"p\">)</span> <span class=\"ow\">::</span> <span class=\"n\">f</span> <span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">WithResult</span> <span class=\"n\">f</span></code></pre><p>This is what defines the <code>(:-&gt;)</code> constructor from earlier in the blog post, and you can see that it effectively just represents a tuple of an action and a value of its associated result. It’s completely type-safe, since it ensures the result matches the type argument to the action.\n</p><p>Finally, this brings us to the <code>Action</code> class, which is not complex, but is unfortunately necessary:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Action</span> <span class=\"n\">f</span> <span class=\"kr\">where</span>\n  <span class=\"n\">eqAction</span> <span class=\"ow\">::</span> <span class=\"n\">f</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"kt\">:~:</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n  <span class=\"n\">showAction</span> <span class=\"ow\">::</span> <span class=\"n\">f</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span></code></pre><p>Notice that these methods are effectively just <code>(==)</code> and <code>show</code>, lifted to type constructors of kind <code>* -&gt; *</code>. One significant difference is that <code>eqAction</code> produces <code>Maybe (a :~: b)</code> instead of <code>Bool</code>, where <code>(:~:)</code> is from <code>Data.Type.Equality</code>. This is a type equality witness, which means a successful equality between two values allows the compiler to be sure that the two <em>types</em> are equal. This is necessary for the implementation of <code>runMockT</code> due to the phantom type in actions—in order to convince GHC that we can properly return the result of a mocked action, we need to assure it that the value we’re going to return is actually of the proper type.\n</p><p>Implementing this typeclass is not particularly burdensome, but it’s entirely boilerplate, so even if you want to define your own action type (that is, you don’t want to use <code>makeMock</code>), you can use the <code>deriveAction</code> function from <code>Control.Monad.Mock.TH</code> to derive an <code>Action</code> instance on an existing datatype.\n</p><h3><a name=\"connecting-the-mock-to-its-class\"></a>Connecting the mock to its class</h3><p>Now that we have an action with which to mock a class, we need to actually define an instance of that class for <code>MockT</code>. For this process, monad-mock provides a <code>mockAction</code> function with the following type:\n</p><pre><code class=\"pygments\"><span class=\"nf\">mockAction</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">Action</span> <span class=\"n\">f</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">MockT</span> <span class=\"n\">f</span> <span class=\"n\">m</span> <span class=\"n\">r</span></code></pre><p>This function accepts two arguments: the name of the method being mocked and the action that represents the current call. This is easier to illustrate with an actual instance of <code>MonadFileSystem</code> using <code>MockT</code> and our <code>FileSystemAction</code> type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFileSystem</span> <span class=\"p\">(</span><span class=\"kt\">MockT</span> <span class=\"kt\">FileSystemAction</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"n\">mockAction</span> <span class=\"s\">\"readFile\"</span> <span class=\"p\">(</span><span class=\"kt\">ReadFile</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">=</span> <span class=\"n\">mockAction</span> <span class=\"s\">\"writeFile\"</span> <span class=\"p\">(</span><span class=\"kt\">WriteFile</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span></code></pre><p>This allows <code>readFile</code> and <code>writeFile</code> to defer to the mock, and providing the names of the functions as strings helps monad-mock to produce useful error messages upon failure. Internally, <code>MockT</code> is a <code>StateT</code> that keeps track of a list of <code>WithResult f</code> values as its state. Each call to the mock checks the action against the internal list of calls, and if they match, it returns the associated result. Otherwise, it throws an exception.\n</p><p>This scheme is simple, but it seems to work remarkably well. There are some obvious enhancements that will probably be eventually necessary, like allowing action results that run in the underlying monad <code>m</code> in order to support things like <code>throwError</code> from <code>MonadError</code>, but so far, it hasn’t been necessary for what we’ve been using it for. Certain tricky signatures defy this simple technique, such as signatures where a monadic action appears in a negative position (that is, the signatures you need things like <a href=\"https://hackage.haskell.org/package/monad-control\">monad-control</a> or <a href=\"https://hackage.haskell.org/package/monad-unlift\">monad-unlift</a> for), but we’ve found that most of our effects don’t have any reason to include such signatures.\n</p><h2><a name=\"a-brief-comparison-with-free-r-monads\"></a>A brief comparison with free(r) monads</h2><p>At this point, astute readers will likely be thinking about free monads, which parts of this technique greatly resemble. The representation of actions as GADTs is especially similar to <a href=\"https://hackage.haskell.org/package/freer\">freer</a>, which does something extremely similar. Indeed, you can think of this technique as something that combines a freer-style representation with mtl-style classes. Given that freer already does this, you might ask yourself what the point is.\n</p><p>If you are already sold on free monads, monad-mock may very well be uninteresting to you. From the perspective of theoretical novelty, monad-mock is not anything new or different. However, there are a variety of practical reasons to prefer mtl over free, and it’s nice to see how easy it is to enjoy the testing benefits of free without too much extra effort.\n</p><p>An in-depth comparison between mtl and free is well outside the scope of this blog post. However, the key point is that this technique <em>only</em> affects test code, so the real runtime implementation will not be affected in any way. This means you can take advantage of the performance benefits and ecosystem support of mtl without sacrificing simple, expressive testing.\n</p><h2><a name=\"conclusion\"></a>Conclusion</h2><p>To cap things off, I want to emphasize monad-mock’s role as a single part of a larger initiative we’ve been making for the better part of the past eighteen months. Haskell is a language with ever-evolving techniques and style, and it’s sometimes dizzying to figure out how to use all the pieces together to develop robust, maintainable applications. While monad-mock might not be anything drastically different from existing testing techniques, my hope is that it can provide an opinionated mechanism to make testing easy and accessible, even for complex interactions with other services and systems.\n</p><p>I’ve made an effort to make it abundantly clear in this blog post that monad-mock is <em>not</em> a silver bullet to testing, and in fact, I would prefer other techniques for ensuring correctness whenever possible. Even so, mocking is a nice tool to have in your toolbox, and it’s a good fallback to get even the worst APIs under test coverage.\n</p><p>If you want to try out monad-mock for yourself, <a href=\"https://hackage.haskell.org/package/monad-mock\">take a look at the documentation on Hackage</a> and start playing around! It’s still early software, so it’s not the most proven or featureful, but we’ve managed to get mileage out of it already, all the same. If you find any problems, have a use case it does not support, or just find something about it unclear, please do not hesitate to <a href=\"https://github.com/cjdev/monad-mock\">open an issue on the GitHub repository</a>—we obviously can’t fix issues we don’t know about.\n</p><p>Thanks as always to the many people who have contributed ideas that have shaped my philosophy and approach to testing and have helped provide the tools that make this library work. Happy testing!\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Nearly eight months ago, I wrote a blog post about unit testing effectful Haskell code using a library called test-fixture. That library has served us well, but it wasn’t as easy to use as I would have liked, and it worked better with certain patterns than others. Since then, I’ve learned more about Haskell and more about testing, and I’m pleased to announce that I am releasing an entirely new testing library, monad-mock.\n\nA first glance at monad-mock\nThe monad-mock library is, first and foremost, designed to be easy. It doesn’t ask much from you, and it requires almost zero boilerplate.\n\nThe first step is to write an mtl-style interface that encodes an effect you want to mock. For example, you might want to test some code that interacts with the filesystem:\n\nclass Monad m => MonadFileSystem m where\n  readFile :: FilePath -> m String\n  writeFile :: FilePath -> String -> m ()\nNow you just have to write your code as normal. For demonstration purposes, here’s a function that defines copying a file in terms of readFile and writeFile:\n\ncopyFile :: MonadFileSystem m => FilePath -> FilePath -> m ()\ncopyFile a b = do\n  contents <- readFile a\n  writeFile b contents\nMaking this function work on the real filesystem is trivial, since we just need to define an instance of MonadFileSystem for IO:\n\ninstance MonadFileSystem IO where\n  readFile = Prelude.readFile\n  writeFile = Prelude.writeFile\nBut how do we test this? Well, we could run some real code in IO, which might not be so bad for such a simple function, but this seems like a bad idea. For one thing, a bad implementation of copyFile could do some pretty horrible things if it misbehaved and decided to overwrite important files, and if you’re constantly running a test suite whenever a file changes, it’s easy to imagine causing a lot of damage. Running tests against the real filesystem also makes tests slower and harder to parallelize, and it only gets much worse once you are doing more complex effects than interacting with the filesystem.\n\nUsing monad-mock, we can test this function in just a couple of lines of code:\n\nimport Control.Exception (evaluate)\nimport Control.Monad.Mock\nimport Control.Monad.Mock.TH\nimport Data.Function ((&))\nimport Test.Hspec\n\nmakeMock \"FileSystemAction\" [ts| MonadFileSystem |]\n\nspec = describe \"copyFile\" $\n  it \"reads a file and writes its contents to another file\" $\n    evaluate $ copyFile \"foo.txt\" \"bar.txt\"\n      & runMock [ ReadFile \"foo.txt\" :-> \"contents\"\n                , WriteFile \"bar.txt\" \"contents\" :-> () ]\nThat’s it!\n\nThe last two lines of the above snippet are the real interesting bits, which specify the actions that are expected to be executed, and it couples them with their results. You will find that if you tweak the list in any way, such as reordering the actions, eliminating one or both of them, or adding an additional action to the end, the test will fail. We could even turn this into a property-based test that generated arbitrary file paths and file contents.\n\nAdmittedly, in this trivial example, the mock is a little silly, since converting this into a property-based test would demonstrate how much we’ve basically just reimplemented the function in our test. However, once our function starts to do somewhat more complicated things, then our tests become more meaningful. Here’s a similar function that only copies a file if it is nonempty:\n\ncopyNonemptyFile :: MonadFileSystem m => FilePath -> FilePath -> m ()\ncopyNonemptyFile a b = do\n  contents <- readFile a\n  unless (null contents) $\n    writeFile b contents\nThis function has some logic which is very clearly not expressed in its type, and it would be difficult to encode that information into the type in a safe way. Fortunately, we can guarantee that it works by writing some tests:\n\ndescribe \"copyNonemptyFile\" $ do\n  it \"copies a file with contents\" $\n    evaluate $ copyNonemptyFile \"foo.txt\" \"bar.txt\"\n      & runMock [ ReadFile \"foo.txt\" :-> \"contents\"\n                , WriteFile \"bar.txt\" \"contents\" :-> () ]\n\n  it \"does nothing with an empty file\" $\n    evaluate $ copyNonemptyFile \"foo.txt\" \"bar.txt\"\n      & runMock [ ReadFile \"foo.txt\" :-> \"\" ]\nThese tests are much more useful, and they have some actual value to them. Imagine we had accidentally written when instead of unless, an easy typo to make. Our tests would fail with some useful error messages:\n\n1) copyNonemptyFile copies a file with contents\n     uncaught exception: runMockT: expected the following unexecuted actions to be run:\n       WriteFile \"bar.txt\" \"contents\"\n\n2) copyNonemptyFile does nothing with an empty file\n     uncaught exception: runMockT: expected end of program, called writeFile\n       given action: WriteFile \"bar.txt\" \"\"\n\nYou now know enough to write tests with monad-mock.\n\nWhy unit test?\nWhen the issue of testing is brought up in Haskell, it is often treated with a certain distaste by a portion of the community. There are some points I’ve seen a number of times, and though they take different forms, they boil down to two ideas:\n\n\n“Haskell code does not need tests because the type system can prove correctness.”\n\n\n“Testing in Haskell is trivial because it is a pure language, and testing pure functions is easy.”\n\n\nI’ve been writing Haskell professionally for over a year now, and I can happily say that there is some truth to both of those things! When my Haskell code typechecks, I feel a confidence in it that I would not feel were I using a language with a less powerful type system. Furthermore, Haskell encourages a “pure core, impure shell” approach to system design that makes testing many things pleasant and straightforward, and it completely eliminates the worry of subtle nondeterminism leaking into tests.\n\nThat said, Haskell is not a proof assistant, and its type system cannot guarantee everything, especially for code that operates on the boundaries of what Haskell can control. For much the same reason, I find that my pure code is the code I am least likely to need to test, since it is also the code with the strongest type safety guarantees, operating on types in my application’s domain. In contrast, the effectful code is often what I find the most value in extensively testing, since it often contains the most subtle complexity, and it is frequently difficult or even impossible to encode into types.\n\nHaskell has the power to provide remarkably strong correctness guarantees with a surprisingly small amount of effort by using a combination of tests and types, using each to accommodate for the other’s weaknesses and playing to each technique’s strengths. Some code is test-driven, other code is type-driven. Most code ends up being a mix of both. Testing is just a tool like any other, and it’s nice to feel confident in one’s ability to effectively structure code in a decoupled, testable manner.\n\nWhy mock?\nEven if you accept that testing is good, the question of whether or not to mock is a subtler issue. To some people, “unit testing” is synonymous with mocks. This is emphatically not true, and in fact, overly aggressive mocking is one of the best ways to make your test suite completely worthless. The monad-mock approach to mocking is a bit more principled than mocking in many dynamic, object-oriented languages, but it comes with many of the same drawbacks: mocks couple your tests to your implementation in ways that make them less valuable and less meaningful.\n\nFor the MonadFileSystem example above, I would actually probably not use a mock. Instead, I would use a fake, in-memory filesystem implementation:\n\nnewtype FakeFileSystemT m a = FakeFileSystemT (StateT [(FilePath, String)] m a)\n  deriving (Functor, Applicative, Monad)\n\nfakeFileSystemT :: Monad m => [(FilePath, String)]\n                -> FakeFileSystemT m a -> m (a, [(FilePath, String)])\nfakeFileSystemT fs (FakeFileSystemT x) = second sort <$> runStateT x fs\n\ninstance Monad m => MonadFileSystem (FakeFileSystemT m) where\n  readFile path = FakeFileSystemT $ get >>= \\fs -> lookup path fs &\n    maybe (fail $ \"readFile: no such file ‘\" ++ path ++ \"’\") return\n  writeFile path contents = FakeFileSystemT . modify $ \\fs ->\n    (path, contents) : filter ((/= path) . fst) fs\nThe above snippet demonstrates how easy it is to define a MonadFileSystem implementation in terms of StateT, and while this may seem like a lot of boilerplate, it really isn’t. You have to write a fake once per interface, and the above block is a minuscule twelve lines of code. With this technique, you are still able to write tests that depend on the state of the filesystem before and after running the implementation, but you decouple yourself from the precise process of getting there:\n\ndescribe \"copyNonemptyFile\" $ do\n  it \"copies a file with contents\" $ do\n    let ((), fs) = runIdentity $ copyNonemptyFile \"foo.txt\" \"bar.txt\"\n          & fakeFileSystemT [ (\"foo.txt\", \"contents\") ]\n    fs `shouldBe` [ (\"bar.txt\", \"contents\"), (\"foo.txt\", \"contents\") ]\n\n  it \"does nothing with an empty file\" $ do\n    let ((), fs) = runIdentity $ copyNonemptyFile \"foo.txt\" \"bar.txt\"\n          & fakeFileSystemT [ (\"foo.txt\", \"\") ]\n    fs `shouldBe` [ (\"foo.txt\", \"\") ]\nThis is better than using a mock, and I would highly recommend doing it if you can! However, a lot of real applications have to interact with services of much greater complexity than an idealized filesystem, and creating that sort of in-memory fake is not always practical. One such situation might be interacting with AWS CloudFormation, for example:\n\nclass Monad m => MonadAWS m where\n  createStack :: StackName -> StackTemplate -> m (Either AWSError StackId)\n  listStacks :: m (Either AWSError [StackSummaries])\n  describeStack :: StackId -> m (Either AWSError StackInfo)\n  -- and so on...\nAWS is a very complex system, and it can do dozens of different things (and fail in dozens of different ways) based on an equally complex set of inputs. For example, in the above API, createStack needs to parse its template, which can be YAML or JSON, in order to determine which of many possible errors and behaviors can be produced, both on the initial call and on subsequent ones.\n\nCreating a fake implementation of AWS is hardly feasible, and this is where a mock can be useful. By simply writing makeMock \"AWSAction\" [ts| MonadAWS |], we can test functions that interact with AWS in a pure way without necessarily needing to replicate all of its complexity.\n\nIsolating mocks\nOf course, tests that use mocks provide less value than tests that use “smarter” fakes, since they are far more tightly coupled to the implementation, and it’s dramatically more likely that you will need to change the tests when you change the logic. To avoid this, it can be helpful to create multiple interfaces to the same thing: a high-level interface and a low-level one. If our above MonadAWS is a low-level interface, we could create a high-level counterpart that does precisely what our application needs:\n\nclass Monad m => MonadDeploy m where\n  executeDeployment :: Deployment -> m (Either DeployError ())\nWhen running our application “for real”, we would use MonadAWS to implement MonadDeploy:\n\nexecuteDeploymentImpl :: MonadAWS m => Deployment -> m (Either DeployError ())\nexecuteDeploymentImpl = ...\nThe nice thing about this is we can actually test executeDeploymentImpl using a MonadAWS mock, so we can still have unit test coverage of the code on the boundaries of our system! Additionally, by containing the mock to a single place, we can test the rest of our code using a smarter fake implementation of MonadDeploy, helping to decouple our code from AWS’s complex API and improve the reliability and usefulness of our test suite.\n\nThey key point here is that mocking is just a small piece of the larger testing puzzle in any language, and that is just as true in Haskell. An overemphasis on mocking is an easy way to end up with a test suite that feels useless, probably because it is. Use mocks as a technique to insulate your application from the complexity in others’ APIs, then use more domain-specific testing techniques and type-level assertions to ensure the correctness of your logic.\n\nHow monad-mock works\nIf you’ve read this far and are convinced that monad-mock is useful, you may safely stop reading now. However, if you are interested in the details of what it actually does and what makes it tick, the rest of this blog post is going to focus on how the implementation works and how it compares to other techniques.\n\nThe centerpiece of monad-mock’s API is its monad transformer, MockT, which is a type constructor that accepts three types:\n\nnewtype MockT (f :: * -> *) (m :: * -> *) (a :: *)\nThe m and a type variables obviously correspond to the usual monad transformer arguments, which represent the underlying monad and the result of the monadic computation, respectively. The f variable is more interesting, since it’s what makes MockT work at all, and it isn’t even a type: it’s a type constructor with kind * -> *. What does it mean?\n\nLooking at the type signature of runMockT gives us a little bit more information about what that f actually represents:\n\nrunMockT :: (Action f, Monad m) => [WithResult f] -> MockT f m a -> m a\nThis type signature provides two pieces of key information:\n\n\nThe f parameter is constrained by the Action f constraint.\n\n\nRunning a mocked computation requires supplying a list of WithResult f values. This list corresponds to the list of expectations provided to runMock in earlier examples.\n\n\nTo understand both of these things, it helps to examine the definition of an actual datatype that can have an Action instance. For the filesystem example, the action datatype looks like this:\n\ndata FileSystemAction r where\n  ReadFile :: FilePath -> FileSystemAction String\n  WriteFile :: FilePath -> String -> FileSystemAction ()\nNotice how each constructor clearly corresponds to one of the methods of MonadFileSystem, with a type to match. Now the purpose of the type provided to the FileSystemAction constructor (in this case r) should hopefully become clear: it represents the type of the value produced by each method. Also note that the type is completely phantom—it does not appear in negative position in any of the constructors.\n\nWith this in mind, we can take a look at the definition of WithResult:\n\ndata WithResult f where\n  (:->) :: f r -> r -> WithResult f\nThis is what defines the (:->) constructor from earlier in the blog post, and you can see that it effectively just represents a tuple of an action and a value of its associated result. It’s completely type-safe, since it ensures the result matches the type argument to the action.\n\nFinally, this brings us to the Action class, which is not complex, but is unfortunately necessary:\n\nclass Action f where\n  eqAction :: f a -> f b -> Maybe (a :~: b)\n  showAction :: f a -> String\nNotice that these methods are effectively just (==) and show, lifted to type constructors of kind * -> *. One significant difference is that eqAction produces Maybe (a :~: b) instead of Bool, where (:~:) is from Data.Type.Equality. This is a type equality witness, which means a successful equality between two values allows the compiler to be sure that the two types are equal. This is necessary for the implementation of runMockT due to the phantom type in actions—in order to convince GHC that we can properly return the result of a mocked action, we need to assure it that the value we’re going to return is actually of the proper type.\n\nImplementing this typeclass is not particularly burdensome, but it’s entirely boilerplate, so even if you want to define your own action type (that is, you don’t want to use makeMock), you can use the deriveAction function from Control.Monad.Mock.TH to derive an Action instance on an existing datatype.\n\nConnecting the mock to its class\nNow that we have an action with which to mock a class, we need to actually define an instance of that class for MockT. For this process, monad-mock provides a mockAction function with the following type:\n\nmockAction :: (Action f, Monad m) => String -> f r -> MockT f m r\nThis function accepts two arguments: the name of the method being mocked and the action that represents the current call. This is easier to illustrate with an actual instance of MonadFileSystem using MockT and our FileSystemAction type:\n\ninstance Monad m => MonadFileSystem (MockT FileSystemAction m) where\n  readFile a = mockAction \"readFile\" (ReadFile a)\n  writeFile a b = mockAction \"writeFile\" (WriteFile a b)\nThis allows readFile and writeFile to defer to the mock, and providing the names of the functions as strings helps monad-mock to produce useful error messages upon failure. Internally, MockT is a StateT that keeps track of a list of WithResult f values as its state. Each call to the mock checks the action against the internal list of calls, and if they match, it returns the associated result. Otherwise, it throws an exception.\n\nThis scheme is simple, but it seems to work remarkably well. There are some obvious enhancements that will probably be eventually necessary, like allowing action results that run in the underlying monad m in order to support things like throwError from MonadError, but so far, it hasn’t been necessary for what we’ve been using it for. Certain tricky signatures defy this simple technique, such as signatures where a monadic action appears in a negative position (that is, the signatures you need things like monad-control or monad-unlift for), but we’ve found that most of our effects don’t have any reason to include such signatures.\n\nA brief comparison with free(r) monads\nAt this point, astute readers will likely be thinking about free monads, which parts of this technique greatly resemble. The representation of actions as GADTs is especially similar to freer, which does something extremely similar. Indeed, you can think of this technique as something that combines a freer-style representation with mtl-style classes. Given that freer already does this, you might ask yourself what the point is.\n\nIf you are already sold on free monads, monad-mock may very well be uninteresting to you. From the perspective of theoretical novelty, monad-mock is not anything new or different. However, there are a variety of practical reasons to prefer mtl over free, and it’s nice to see how easy it is to enjoy the testing benefits of free without too much extra effort.\n\nAn in-depth comparison between mtl and free is well outside the scope of this blog post. However, the key point is that this technique only affects test code, so the real runtime implementation will not be affected in any way. This means you can take advantage of the performance benefits and ecosystem support of mtl without sacrificing simple, expressive testing.\n\nConclusion\nTo cap things off, I want to emphasize monad-mock’s role as a single part of a larger initiative we’ve been making for the better part of the past eighteen months. Haskell is a language with ever-evolving techniques and style, and it’s sometimes dizzying to figure out how to use all the pieces together to develop robust, maintainable applications. While monad-mock might not be anything drastically different from existing testing techniques, my hope is that it can provide an opinionated mechanism to make testing easy and accessible, even for complex interactions with other services and systems.\n\nI’ve made an effort to make it abundantly clear in this blog post that monad-mock is not a silver bullet to testing, and in fact, I would prefer other techniques for ensuring correctness whenever possible. Even so, mocking is a nice tool to have in your toolbox, and it’s a good fallback to get even the worst APIs under test coverage.\n\nIf you want to try out monad-mock for yourself, take a look at the documentation on Hackage and start playing around! It’s still early software, so it’s not the most proven or featureful, but we’ve managed to get mileage out of it already, all the same. If you find any problems, have a use case it does not support, or just find something about it unclear, please do not hesitate to open an issue on the GitHub repository—we obviously can’t fix issues we don’t know about.\n\nThanks as always to the many people who have contributed ideas that have shaped my philosophy and approach to testing and have helped provide the tools that make this library work. Happy testing!","isoDate":"2017-06-29T00:00:00.000Z","timestamp":"6/28/2017"},{"title":"Realizing Hackett, a metaprogrammable Haskell","pubDate":"2017-05-27T00:00:00.000Z","author":"Alexis King","content":"<article><p><a href=\"/blog/2017/01/02/rascal-a-haskell-with-more-parentheses/\">Almost five months ago, I wrote a blog post about my new programming language, Hackett</a>, a fanciful sketch of a programming language from a far-off land with Haskell’s type system and Racket’s macros. At that point in time, I had a little prototype that barely worked, that I barely understood, and was a little bit of a technical dead-end. People saw the post, they got excited, but development sort of stopped.\n</p><p>Then, almost two months ago, I took a second stab at the problem in earnest. I read a lot, I asked a lot of people for help, and eventually I got something sort of working. Suddenly, <a href=\"https://github.com/lexi-lambda/hackett\">Hackett is not only real, it’s working, and you can try it out yourself</a>!\n</p><h2><a name=\"a-first-look-at-hackett\"></a>A first look at Hackett</h2><p>Hackett is still very new, very experimental, and an enormous work in progress. However, that doesn’t mean it’s useless! Hackett is already a remarkably capable programming language. Let’s take a quick tour.\n</p><p>As Racket law decrees it, every Hackett program must begin with <code>#lang</code>. We can start with the appropriate incantation:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">hackett</span></code></pre><p>If you’re using DrRacket or racket-mode with background expansion enabled, then congratulations: the typechecker is online. We can begin by writing a well-typed, albeit boring program:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">hackett</span>\n\n<span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"s2\">\"Hello, world!\"</span><span class=\"p\">))</span></code></pre><p>In Hackett, a use of <code>main</code> at the top level indicates that running the module as a program should execute some <code>IO</code> action. In this case, <code>println</code> is a function of type <code>{String -&gt; (IO Unit)}</code>. Just like Haskell, Hackett is pure, and the runtime will figure out how to actually run an <code>IO</code> value. If you run the above program, you will notice that it really does print out <code>Hello, world!</code>, exactly as we would like.\n</p><p>Of course, hello world programs are boring—so imperative! We are functional programmers, and we have our <em>own</em> class of equally boring programs we must write when learning a new language. How about some Fibonacci numbers?\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">hackett</span>\n\n<span class=\"p\">(</span><span class=\"n\">def</span> <span class=\"n\">fibs</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">List</span> <span class=\"n\">Integer</span><span class=\"p\">)</span>\n  <span class=\"p\">{</span><span class=\"mi\">0</span> <span class=\"n\">::</span> <span class=\"mi\">1</span> <span class=\"n\">::</span> <span class=\"p\">(</span><span class=\"n\">zip-with</span> <span class=\"nb\">+</span> <span class=\"n\">fibs</span> <span class=\"p\">(</span><span class=\"n\">tail!</span> <span class=\"n\">fibs</span><span class=\"p\">))})</span>\n\n<span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"p\">(</span><span class=\"n\">show</span> <span class=\"p\">(</span><span class=\"nb\">take</span> <span class=\"mi\">10</span> <span class=\"n\">fibs</span><span class=\"p\">))))</span></code></pre><p>Again, Hackett is just like Haskell in that it is <em>lazy</em>, so we can construct an infinite list of Fibonacci numbers, and the runtime will happily do nothing at all. When we call <code>take</code>, we realize the first ten numbers in the list, and when you run the program, you should see them printed out, clear as day!\n</p><p>But these programs are boring. Printing strings and laziness may have been novel when you first learned about them, but if you’re reading this blog post, my bet is that you probably <em>aren’t</em> new to programming. How about something more interesting, <strong>like a web server</strong>?\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">hackett</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">hackett/demo/web-server</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">data</span> <span class=\"n\">Greeting</span> <span class=\"p\">(</span><span class=\"n\">greeting</span> <span class=\"n\">String</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">instance</span> <span class=\"p\">(</span><span class=\"n\">-&gt;Body</span> <span class=\"n\">Greeting</span><span class=\"p\">)</span>\n  <span class=\"p\">[</span><span class=\"n\">-&gt;body</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">[(</span><span class=\"n\">greeting</span> <span class=\"n\">name</span><span class=\"p\">)]</span> <span class=\"p\">{</span><span class=\"s2\">\"Hello, \"</span> <span class=\"n\">++</span> <span class=\"n\">name</span> <span class=\"n\">++</span> <span class=\"s2\">\"!\"</span><span class=\"p\">})])</span>\n\n<span class=\"p\">(</span><span class=\"n\">defserver</span> <span class=\"n\">run-server</span>\n  <span class=\"p\">[</span><span class=\"n\">GET</span> <span class=\"s2\">\"/\"</span>               <span class=\"k\">-&gt;</span> <span class=\"n\">String</span>   <span class=\"k\">=&gt;</span> <span class=\"s2\">\"Hello, world!\"</span><span class=\"p\">]</span>\n  <span class=\"p\">[</span><span class=\"n\">GET</span> <span class=\"s2\">\"greet\"</span> <span class=\"k\">-&gt;</span> <span class=\"n\">String</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Greeting</span> <span class=\"k\">=&gt;</span> <span class=\"n\">greeting</span><span class=\"p\">])</span>\n\n<span class=\"p\">(</span><span class=\"n\">main</span> <span class=\"p\">(</span><span class=\"k\">do</span> <span class=\"p\">(</span><span class=\"nb\">println</span> <span class=\"s2\">\"Running server on port 8080.\"</span><span class=\"p\">)</span>\n          <span class=\"p\">(</span><span class=\"n\">run-server</span> <span class=\"mi\">8080</span><span class=\"p\">)))</span></code></pre><pre><code class=\"pygments\">$ racket my-server.rkt\nRunning server on port <span class=\"m\">8080</span>.\n^Z\n$ <span class=\"nb\">bg</span>\n$ curl <span class=\"s1\">&#39;http://localhost:8080/greet/Alexis&#39;</span>\nHello, Alexis!</code></pre><p><strong>Welcome to Hackett.</strong>\n</p><h2><a name=\"what-is-hackett\"></a>What is Hackett?</h2><p>Excited yet? I hope so. I certainly am.\n</p><p>Before you get a little <em>too</em> excited, however, let me make a small disclaimer: the above program, while quite real, is a demo. It is certainly not a production web framework, and it actually just uses the Racket web server under the hood. It does not handle very many things right now. You cannot use it to build your super awesome webapp, and even if you could, I would not recommend attempting to do so.\n</p><p>All that said, it is a <em>real</em> tech demo, and it shows off the potential for Hackett to do some pretty cool things. While the server implementation is just reusing Racket’s dynamically typed web server, the Hackett interface to it is 100% statically typed, and the above example shows off a host of features:\n</p><ul><li><p><strong>Algebraic datatypes.</strong> Hackett has support for basic ADTs, including recursive datatypes (though not yet mutually recursive datatypes).\n</p></li><li><p><strong>Typeclasses.</strong> The demo web server uses a <code>-&gt;Body</code> typeclass to render server responses, and this module implements a <code>-&gt;Body</code> instance for the custom <code>Greeting</code> datatype.\n</p></li><li><p><strong>Macros.</strong> The <code>defserver</code> macro provides a concise, readable, <em>type safe</em> way to define a simple, RESTful web server. It defines two endpoints, a homepage and a greeting, and the latter parses a segment from the URL.\n</p></li><li><p><strong>Static typechecking.</strong> Obviously. If you try and change the homepage endpoint to produce a number instead of a string, you will get a type error! Alternatively, try removing the <code>-&gt;Body</code> instance and see what happens.\n</p></li><li><p><strong>Infix operators.</strong> In Hackett, <code>{</code> curly braces <code>}</code> enter <em>infix mode</em>, which permits arbitrary infix operators. Most Lisps have variadic functions, so infix operators are not strictly necessary, but Hackett only supports curried, single-argument functions, so infix operators are some especially sweet sugar.\n</p></li><li><p><strong>Pure, monadic I/O.</strong> The <code>println</code> and <code>run-server</code> functions both produce <code>(IO Unit)</code>, and <code>IO</code> is a monad. <code>do</code> notation is provided as a macro, and it works with any type that implements the <code>Monad</code> typeclass.\n</p></li></ul><p>All these features are already implemented, and they really work! Of course, you might look at this list and be a little confused: sure, there are macros, but all these other things are firmly Haskellisms. If you thought that, you’d be quite right! <strong>Hackett is much closer to Haskell than Racket, even though it is syntactically a Lisp.</strong> Keep this guiding principal in mind as you read this blog post or explore Hackett. Where Haskell and Racket conflict, Hackett usually prefers Haskell.\n</p><p>For a bit more information about what Hackett is and what it aims to be, <a href=\"/blog/2017/01/02/rascal-a-haskell-with-more-parentheses/\">check out my blog post from a few months ago</a> from back when Hackett was called Rascal. I won’t reiterate everything I said there, but I do want to give a bit of a status update, explain what I’ve been working on, and hopefully give you some idea about where Hackett is going.\n</p><h2><a name=\"the-story-so-far-and-getting-to-hackett-0-1\"></a>The story so far, and getting to Hackett 0.1</h2><p>In September of 2016, I attended <a href=\"http://con.racket-lang.org/2016/\">(sixth RacketCon)</a>, where I saw a <a href=\"https://www.youtube.com/watch?v=j5Hauz6cewM\">pretty incredible and extremely exciting talk</a> about implementing type systems as macros. Finally, I could realize my dream of having an elegant Lisp with a safe, reliable macro system and a powerful, expressive type system! Unfortunately, reality ensued, and I remembered I didn’t actually know any type theory.\n</p><p>Therefore, in October, I started to learn about type systems, and I began to read through Pierce’s Types and Programming Languages, then tried to learn the things I would need to understand Haskell’s type system. I learned about Hindley-Milner and basic typeclasses, and I tried to apply these things to the Type Systems as Macros approach. Throughout October, I hacked and I hacked, and by the end of the month, I stood back and admired my handiwork!\n</p><p>…it <em>sort of</em> worked?\n</p><p>The trouble was that I found myself stuck. I wasn’t sure how to proceed. My language had bugs, programs sometimes did things I didn’t understand, the typechecker was clearly unsound, and there didn’t seem to be an obvious path forward. Other things in my life became distracting or difficult, and I didn’t have the energy to work on it anymore, so I stopped. I put Hackett (then Rascal) on the shelf for a couple months, only to finally return to it in late December.\n</p><p>At the beginning of January, I decided it would be helpful to be public about what I was working on, so I wrote a blog post! Feedback was positive, overwhelmingly so, and while it was certainly encouraging, I suddenly felt nervous about expectations I had not realized I was setting. Could I really build this? Did I have the knowledge or the time? At that point, I didn’t really, so work stalled.\n</p><p>Fortunately, in early April, some things started to become clear. I took another look at Hackett, and I knew I needed to reimplement it from the ground up. I also knew that I needed a different technique, but this time, I knew a bit more about where to find it. I got some help from <a href=\"http://www.ccs.neu.edu/home/samth/\">Sam Tobin-Hochstadt</a> and put together <a href=\"https://gist.github.com/lexi-lambda/045ba782c8a0d915bd8abf97167d3bb5\">an implementation of Pierce and Turner’s Local Type Inference</a>. Unfortunately, it didn’t really provide the amount of type inference I was looking for, but fortunately, implementing it helped me figure out how to understand the rather more complicated (though very impressive) <a href=\"http://www.cs.cmu.edu/~joshuad/papers/bidir/\">Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism</a>. After that, things just sort of started falling into place:\n</p><ul><li><p>First, I <a href=\"https://github.com/lexi-lambda/higher-rank\">implemented the Complete and Easy paper in Haskell</a>, including building a little parser and interpreter. That helped me actually understand the paper, and Haskell really is a rather wonderful language for doing such a thing.\n</p></li><li><p>Three days later, I <a href=\"https://github.com/lexi-lambda/racket-higher-rank\">ported the Haskell implementation to Racket</a>, using (and somewhat abusing) the Type Systems as Macros techniques. It wasn’t the prettiest, but it seemed to work, and that was rather encouraging.\n</p></li><li><p>After that, however, I got a little stuck again, as I wasn’t sure how to generalize what I had. I was also incredibly busy with my day job, and I wasn’t able to really make progress for a few weeks. In early May, however, I decided to <a href=\"https://twitter.com/lexi_lambda/status/865026650487967744\">take a vacation</a> for a week, and with some time to focus, I <a href=\"https://github.com/lexi-lambda/higher-rank/tree/algebraic\">souped up the Haskell implementation with products and sums</a>. This was progress!\n</p></li><li><p>The <em>following day</em> I managed to make <a href=\"https://github.com/lexi-lambda/racket-higher-rank/tree/type-constructors\">similar changes to the Racket implementation</a>, but rather than add anonymous products and sums, I added arbitrary type constructors.\n</p></li><li><p>A couple days later and with more than a bit of help from <a href=\"http://functorial.com\">Phil Freeman</a>, I <a href=\"https://github.com/lexi-lambda/hackett/commit/1fd7fc905b93f68e39b9d01fedc4fb52aa44c4c4\">rebranded the Racket implementation as Hackett, Mk II</a>, and I started working towards turning it into a real programming language.\n</p></li></ul><p><em>Less than three weeks later</em>, and I have a programming language with everything from laziness and typeclasses to a tiny, proof-of-concept web server with <a href=\"https://twitter.com/lexi_lambda/status/867617563206758400\">editor support</a>. The future of Hackett looks bright, and though there’s a <em>lot</em> of work left before I will be even remotely satisfied with it, I am excited and reassured that it already seems to be bearing some fruit.\n</p><p>So what’s left? Is Hackett ready for an initial release? Can you start writing programs in it today? Well, unfortunately, the answer is mostly <strong>no</strong>, at least if you want those programs to be at all reliable in a day or two. If everything looks so cheery, though, what’s left? What is Hackett still missing?\n</p><h3><a name=\"what-hackett-still-isn-t\"></a>What Hackett still <em>isn’t</em></h3><p>I have a laundry list of features I want for Hackett. I want GADTs, indexed type families, newtype deriving, and a compiler that can target multiple backends. These things, however, are not essential. You can probably imagine writing useful software without any of them. Before I can try to tackle those, I first need to tackle some of the bits of the foundation that simply don’t exist yet (or have at least been badly neglected).\n</p><p>Fortunately, these things are not insurmountable, nor are they necessarily especially hard. They’re things like default class methods, static detection and prevention of orphan instances, exhaustiveness checking for pattern-matching, and a real kind system. That’s right—right now, Hackett’s type system is effectively dynamically typed, and even though you can write a higher-kinded type, there is no such thing as a “kind error”.\n</p><p>Other things are simply necessary quality of life improvements before Hackett can become truly usable. Type errors are currently rather atrocious, though they could certainly be worse. Additionally, typechecking currently just halts whenever it encounters a type error, and it makes no attempt to generate more than one type error at a time. Derivation of simple instances like <code>Show</code> and <code>Eq</code> is important, and it will also likely pave the way for a more general form of typeclass deriving (since it can most certainly be implemented via macros), so it’s uncharted territory that still needs to be explored.\n</p><p>Bits of plumbing are still exposed in places, whether it’s unexpected behavior when interoperating with Racket or errors sometimes reported in terms of internal forms. Local bindings are, if you can believe it, still entirely unimplemented, so <code>let</code> and <code>letrec</code> need to be written up. The standard library needs fleshing out, and certain bits of code need to be cleaned up and slotted into the right place.\n</p><p>Oh, and of course, <strong>the whole thing needs to be documented</strong>. That in and of itself is probably a pretty significant project, especially since there’s a good chance I’ll want to figure out how to best make use of Scribble for a language that’s a little bit different from Racket.\n</p><p>All in all, there’s a lot of work to be done! I am eager to make it happen, but I also work a full-time job, and I don’t have it in me to continue at the pace I’ve been working at for the past couple of weeks. Still, if you’re interested in the project, stay tuned and keep an eye on it—if all goes as planned, I hope to make it truly useful before too long.\n</p><h2><a name=\"answering-some-questions\"></a>Answering some questions</h2><p>It’s possible that this blog post does not seem like much; after all, it’s not terribly long. However, if you’re anything like me, there’s a good chance you are interested enough to have some questions! Obviously, I cannot anticipate all your questions and answer them here in advance, but I will try my best.\n</p><h3><a name=\"can-i-try-hackett\"></a>Can I try Hackett?</h3><p>Yes! With the caveat that it’s alpha software in every sense of the word: undocumented, not especially user friendly, and completely unstable. However, if you <em>do</em> want to give it a try, it isn’t difficult: just install Racket, then run <code>raco pkg install hackett</code>. Open DrRacket and write <code>#lang hackett</code> at the top of the module, then start playing around.\n</p><p>Also, note that the demo web server used in the example at the top of this blog post is <em>not</em> included when you install the <code>hackett</code> package. If you want to try that out, you’ll have to run <code>raco pkg install hackett-demo</code> to install the demo package as well.\n</p><h3><a name=\"are-there-any-examples-of-hackett-code\"></a>Are there any examples of Hackett code?</h3><p>Unfortunately, not a lot right now, aside from the tiny examples in this blog post. However, if you are already familiar with Haskell, the syntax likely won’t be hard to pick up. Reading the Hackett source code is not especially recommended, given that it is filled with implementation details. However, if you are interested, reading the module where most of the prelude is defined isn’t so bad. You can <a href=\"https://github.com/lexi-lambda/hackett/blob/6ceeac05e3d2a4b2dacd39163744baf239cf65a4/hackett-lib/hackett/private/prim/base.rkt\">find it on GitHub here</a>, or you can open the <code>hackett/private/prim/base</code> module on a local installation.\n</p><h3><a name=\"how-can-i-learn-more-ask-questions-about-hackett\"></a>How can I learn more / ask questions about Hackett?</h3><p>Feel free to ping me and ask me questions! I may not always be able to get back to you immediately, but if you hang around, I will eventually send you a response. The best ways to contact me are via the #racket IRC channel on Freenode, the snek Slack community (<a href=\"http://snek.jneen.net\">which you can sign up for here</a>), sending me <a href=\"https://twitter.com/lexi_lambda\">a DM on Twitter</a>, opening <a href=\"https://github.com/lexi-lambda/hackett/issues\">an issue on the GitHub repo</a>, or even just <a href=\"mailto:lexi.lambda@gmail.com\">sending me an email</a> (though I’m usually a bit slower to respond to the latter).\n</p><h3><a name=\"how-can-i-help\"></a>How can I help?</h3><p>Probably the easiest way to help out is to try Hackett for yourself and <a href=\"https://github.com/lexi-lambda/hackett/issues\">report any bugs or infelicities you run into</a>. Of course, many issues right now are known, there’s just so much to do that I haven’t had the chance to clean everything up. For that reason, the most effective way to contribute is probably to pick an existing issue and try and implement it yourself, but I wouldn’t be surprised if most people found the existing implementation a little intimidating.\n</p><p>If you <em>are</em> interested in helping out, I’d be happy to give you some pointers and answer some questions, since it would be extremely nice to have some help. Please feel free to contact me using any of the methods mentioned in the previous section, and I’ll try and help you find something you could work on.\n</p><h3><a name=\"how-does-hackett-compare-to-x-why-doesn-t-hackett-support-y\"></a>How does Hackett compare to <em>X</em> / why doesn’t Hackett support <em>Y</em>?</h3><p>These tend to be complex questions, and I don’t always have comprehensive answers for them, especially since the language is evolving so quickly. Still, if you want to ask me about this, feel free to just send the question to me directly. In my experience, it’s usually better to have a conversation about this sort of thing rather than just answering in one big comparison, since there’s usually a fair amount of nuance.\n</p><h3><a name=\"when-will-hackett-be-ready-for-me-to-use\"></a>When will Hackett be ready for me to use?</h3><p>I don’t know.\n</p><p>Obviously, there is a lot left to implement, that is certainly true, but there’s more to it than that. If all goes well, I don’t see any reason why Hackett can’t be early beta quality by the end of this year, even if it doesn’t support all of the goodies necessary to achieve perfection (which, of course, it never really can).\n</p><p>However, there are other things to consider, too. The Racket package system is currently flawed in ways that make rapidly iterating on Hackett hard, since it is extremely difficult (if not impossible) to make backwards-incompatible changes without potentially breaking someone’s program (even if they don’t update anything about their dependencies)! This is a solvable problem, but it would take some work modifying various elements of the package system and build tools, so that might need to get done before I can recommend Hackett in good faith.\n</p><h2><a name=\"appendix\"></a>Appendix</h2><p>It would be unfair not to mention all the people that have made Hackett possible. I cannot list them all here, but I want to give special thanks to <a href=\"http://www.ccs.neu.edu/home/stchang/\">Stephen Chang</a>, <a href=\"http://www.cs.ubc.ca/~joshdunf/\">Joshua Dunfield</a>, <a href=\"http://eecs.northwestern.edu/~robby/\">Robby Findler</a>, <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a>, <a href=\"http://functorial.com\">Phil Freeman</a>, <a href=\"http://www.ccs.neu.edu/home/types/\">Ben Greenman</a>, <a href=\"https://github.com/AlexKnauth\">Alex Knauth</a>, <a href=\"http://www.cl.cam.ac.uk/~nk480/\">Neelakantan Krishnaswami</a>, and <a href=\"http://www.ccs.neu.edu/home/samth/\">Sam Tobin-Hochstadt</a>. I’d also like to thank everyone involved in the Racket and Haskell projects as a whole, as well as everyone who has expressed interest and encouragement about what I’ve been working on.\n</p><p>As a final point, just for fun, I thought I’d keep track of all the albums I’ve been listening to while working on Hackett, just in the past few weeks. It is <a href=\"/blog/2017/01/05/rascal-is-now-hackett-plus-some-answers-to-questions/#whats-in-a-name\">on theme with the name</a>, after all. This list is not completely exhaustive, as I’m sure some slipped through the cracks, but you can thank the following artists for helping me power through a few of the hills in Hackett’s implementation:\n</p><ul><li><p>The Beach Boys — Pet Sounds\n</p></li><li><p>Boards of Canada — Music Has The Right To Children, Geogaddi\n</p></li><li><p>Bruce Springsteen — Born to Run\n</p></li><li><p>King Crimson — In the Court of the Crimson King, Larks’ Tongues in Aspic, Starless and Bible Black, Red, Discipline\n</p></li><li><p>Genesis — Nursery Cryme, Foxtrot, Selling England by the Pound, The Lamb Lies Down on Broadway, A Trick of the Tail\n</p></li><li><p>Mahavishnu Orchestra — Birds of Fire\n</p></li><li><p>Metric — Fantasies, Synthetica, Pagans in Vegas\n</p></li><li><p>Muse — Origin of Symmetry, Absolution, The Resistance\n</p></li><li><p>Peter Gabriel — Peter Gabriel I, II, III, IV / Security, Us, Up\n</p></li><li><p>Pink Floyd — Wish You Were Here\n</p></li><li><p>Supertramp — Breakfast In America\n</p></li><li><p>The Protomen — The Protomen, Act II: The Father of Death\n</p></li><li><p>Talking Heads — Talking Heads: 77, More Songs About Buildings and Food, Fear of Music, Remain in Light\n</p></li><li><p>Yes — Fragile, Relayer, Going For The One\n</p></li></ul><p>And of course, <em>Voyage of the Acolyte</em>, by <strong>Steve Hackett</strong>.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Almost five months ago, I wrote a blog post about my new programming language, Hackett, a fanciful sketch of a programming language from a far-off land with Haskell’s type system and Racket’s macros. At that point in time, I had a little prototype that barely worked, that I barely understood, and was a little bit of a technical dead-end. People saw the post, they got excited, but development sort of stopped.\n\nThen, almost two months ago, I took a second stab at the problem in earnest. I read a lot, I asked a lot of people for help, and eventually I got something sort of working. Suddenly, Hackett is not only real, it’s working, and you can try it out yourself!\n\nA first look at Hackett\nHackett is still very new, very experimental, and an enormous work in progress. However, that doesn’t mean it’s useless! Hackett is already a remarkably capable programming language. Let’s take a quick tour.\n\nAs Racket law decrees it, every Hackett program must begin with #lang. We can start with the appropriate incantation:\n\n#lang hackett\nIf you’re using DrRacket or racket-mode with background expansion enabled, then congratulations: the typechecker is online. We can begin by writing a well-typed, albeit boring program:\n\n#lang hackett\n\n(main (println \"Hello, world!\"))\nIn Hackett, a use of main at the top level indicates that running the module as a program should execute some IO action. In this case, println is a function of type {String -> (IO Unit)}. Just like Haskell, Hackett is pure, and the runtime will figure out how to actually run an IO value. If you run the above program, you will notice that it really does print out Hello, world!, exactly as we would like.\n\nOf course, hello world programs are boring—so imperative! We are functional programmers, and we have our own class of equally boring programs we must write when learning a new language. How about some Fibonacci numbers?\n\n#lang hackett\n\n(def fibs : (List Integer)\n  {0 :: 1 :: (zip-with + fibs (tail! fibs))})\n\n(main (println (show (take 10 fibs))))\nAgain, Hackett is just like Haskell in that it is lazy, so we can construct an infinite list of Fibonacci numbers, and the runtime will happily do nothing at all. When we call take, we realize the first ten numbers in the list, and when you run the program, you should see them printed out, clear as day!\n\nBut these programs are boring. Printing strings and laziness may have been novel when you first learned about them, but if you’re reading this blog post, my bet is that you probably aren’t new to programming. How about something more interesting, like a web server?\n\n#lang hackett\n\n(require hackett/demo/web-server)\n\n(data Greeting (greeting String))\n\n(instance (->Body Greeting)\n  [->body (λ [(greeting name)] {\"Hello, \" ++ name ++ \"!\"})])\n\n(defserver run-server\n  [GET \"/\"               -> String   => \"Hello, world!\"]\n  [GET \"greet\" -> String -> Greeting => greeting])\n\n(main (do (println \"Running server on port 8080.\")\n          (run-server 8080)))\n$ racket my-server.rkt\nRunning server on port 8080.\n^Z\n$ bg\n$ curl 'http://localhost:8080/greet/Alexis'\nHello, Alexis!\nWelcome to Hackett.\n\nWhat is Hackett?\nExcited yet? I hope so. I certainly am.\n\nBefore you get a little too excited, however, let me make a small disclaimer: the above program, while quite real, is a demo. It is certainly not a production web framework, and it actually just uses the Racket web server under the hood. It does not handle very many things right now. You cannot use it to build your super awesome webapp, and even if you could, I would not recommend attempting to do so.\n\nAll that said, it is a real tech demo, and it shows off the potential for Hackett to do some pretty cool things. While the server implementation is just reusing Racket’s dynamically typed web server, the Hackett interface to it is 100% statically typed, and the above example shows off a host of features:\n\n\nAlgebraic datatypes. Hackett has support for basic ADTs, including recursive datatypes (though not yet mutually recursive datatypes).\n\n\nTypeclasses. The demo web server uses a ->Body typeclass to render server responses, and this module implements a ->Body instance for the custom Greeting datatype.\n\n\nMacros. The defserver macro provides a concise, readable, type safe way to define a simple, RESTful web server. It defines two endpoints, a homepage and a greeting, and the latter parses a segment from the URL.\n\n\nStatic typechecking. Obviously. If you try and change the homepage endpoint to produce a number instead of a string, you will get a type error! Alternatively, try removing the ->Body instance and see what happens.\n\n\nInfix operators. In Hackett, { curly braces } enter infix mode, which permits arbitrary infix operators. Most Lisps have variadic functions, so infix operators are not strictly necessary, but Hackett only supports curried, single-argument functions, so infix operators are some especially sweet sugar.\n\n\nPure, monadic I/O. The println and run-server functions both produce (IO Unit), and IO is a monad. do notation is provided as a macro, and it works with any type that implements the Monad typeclass.\n\n\nAll these features are already implemented, and they really work! Of course, you might look at this list and be a little confused: sure, there are macros, but all these other things are firmly Haskellisms. If you thought that, you’d be quite right! Hackett is much closer to Haskell than Racket, even though it is syntactically a Lisp. Keep this guiding principal in mind as you read this blog post or explore Hackett. Where Haskell and Racket conflict, Hackett usually prefers Haskell.\n\nFor a bit more information about what Hackett is and what it aims to be, check out my blog post from a few months ago from back when Hackett was called Rascal. I won’t reiterate everything I said there, but I do want to give a bit of a status update, explain what I’ve been working on, and hopefully give you some idea about where Hackett is going.\n\nThe story so far, and getting to Hackett 0.1\nIn September of 2016, I attended (sixth RacketCon), where I saw a pretty incredible and extremely exciting talk about implementing type systems as macros. Finally, I could realize my dream of having an elegant Lisp with a safe, reliable macro system and a powerful, expressive type system! Unfortunately, reality ensued, and I remembered I didn’t actually know any type theory.\n\nTherefore, in October, I started to learn about type systems, and I began to read through Pierce’s Types and Programming Languages, then tried to learn the things I would need to understand Haskell’s type system. I learned about Hindley-Milner and basic typeclasses, and I tried to apply these things to the Type Systems as Macros approach. Throughout October, I hacked and I hacked, and by the end of the month, I stood back and admired my handiwork!\n\n…it sort of worked?\n\nThe trouble was that I found myself stuck. I wasn’t sure how to proceed. My language had bugs, programs sometimes did things I didn’t understand, the typechecker was clearly unsound, and there didn’t seem to be an obvious path forward. Other things in my life became distracting or difficult, and I didn’t have the energy to work on it anymore, so I stopped. I put Hackett (then Rascal) on the shelf for a couple months, only to finally return to it in late December.\n\nAt the beginning of January, I decided it would be helpful to be public about what I was working on, so I wrote a blog post! Feedback was positive, overwhelmingly so, and while it was certainly encouraging, I suddenly felt nervous about expectations I had not realized I was setting. Could I really build this? Did I have the knowledge or the time? At that point, I didn’t really, so work stalled.\n\nFortunately, in early April, some things started to become clear. I took another look at Hackett, and I knew I needed to reimplement it from the ground up. I also knew that I needed a different technique, but this time, I knew a bit more about where to find it. I got some help from Sam Tobin-Hochstadt and put together an implementation of Pierce and Turner’s Local Type Inference. Unfortunately, it didn’t really provide the amount of type inference I was looking for, but fortunately, implementing it helped me figure out how to understand the rather more complicated (though very impressive) Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism. After that, things just sort of started falling into place:\n\n\nFirst, I implemented the Complete and Easy paper in Haskell, including building a little parser and interpreter. That helped me actually understand the paper, and Haskell really is a rather wonderful language for doing such a thing.\n\n\nThree days later, I ported the Haskell implementation to Racket, using (and somewhat abusing) the Type Systems as Macros techniques. It wasn’t the prettiest, but it seemed to work, and that was rather encouraging.\n\n\nAfter that, however, I got a little stuck again, as I wasn’t sure how to generalize what I had. I was also incredibly busy with my day job, and I wasn’t able to really make progress for a few weeks. In early May, however, I decided to take a vacation for a week, and with some time to focus, I souped up the Haskell implementation with products and sums. This was progress!\n\n\nThe following day I managed to make similar changes to the Racket implementation, but rather than add anonymous products and sums, I added arbitrary type constructors.\n\n\nA couple days later and with more than a bit of help from Phil Freeman, I rebranded the Racket implementation as Hackett, Mk II, and I started working towards turning it into a real programming language.\n\n\nLess than three weeks later, and I have a programming language with everything from laziness and typeclasses to a tiny, proof-of-concept web server with editor support. The future of Hackett looks bright, and though there’s a lot of work left before I will be even remotely satisfied with it, I am excited and reassured that it already seems to be bearing some fruit.\n\nSo what’s left? Is Hackett ready for an initial release? Can you start writing programs in it today? Well, unfortunately, the answer is mostly no, at least if you want those programs to be at all reliable in a day or two. If everything looks so cheery, though, what’s left? What is Hackett still missing?\n\nWhat Hackett still isn’t\nI have a laundry list of features I want for Hackett. I want GADTs, indexed type families, newtype deriving, and a compiler that can target multiple backends. These things, however, are not essential. You can probably imagine writing useful software without any of them. Before I can try to tackle those, I first need to tackle some of the bits of the foundation that simply don’t exist yet (or have at least been badly neglected).\n\nFortunately, these things are not insurmountable, nor are they necessarily especially hard. They’re things like default class methods, static detection and prevention of orphan instances, exhaustiveness checking for pattern-matching, and a real kind system. That’s right—right now, Hackett’s type system is effectively dynamically typed, and even though you can write a higher-kinded type, there is no such thing as a “kind error”.\n\nOther things are simply necessary quality of life improvements before Hackett can become truly usable. Type errors are currently rather atrocious, though they could certainly be worse. Additionally, typechecking currently just halts whenever it encounters a type error, and it makes no attempt to generate more than one type error at a time. Derivation of simple instances like Show and Eq is important, and it will also likely pave the way for a more general form of typeclass deriving (since it can most certainly be implemented via macros), so it’s uncharted territory that still needs to be explored.\n\nBits of plumbing are still exposed in places, whether it’s unexpected behavior when interoperating with Racket or errors sometimes reported in terms of internal forms. Local bindings are, if you can believe it, still entirely unimplemented, so let and letrec need to be written up. The standard library needs fleshing out, and certain bits of code need to be cleaned up and slotted into the right place.\n\nOh, and of course, the whole thing needs to be documented. That in and of itself is probably a pretty significant project, especially since there’s a good chance I’ll want to figure out how to best make use of Scribble for a language that’s a little bit different from Racket.\n\nAll in all, there’s a lot of work to be done! I am eager to make it happen, but I also work a full-time job, and I don’t have it in me to continue at the pace I’ve been working at for the past couple of weeks. Still, if you’re interested in the project, stay tuned and keep an eye on it—if all goes as planned, I hope to make it truly useful before too long.\n\nAnswering some questions\nIt’s possible that this blog post does not seem like much; after all, it’s not terribly long. However, if you’re anything like me, there’s a good chance you are interested enough to have some questions! Obviously, I cannot anticipate all your questions and answer them here in advance, but I will try my best.\n\nCan I try Hackett?\nYes! With the caveat that it’s alpha software in every sense of the word: undocumented, not especially user friendly, and completely unstable. However, if you do want to give it a try, it isn’t difficult: just install Racket, then run raco pkg install hackett. Open DrRacket and write #lang hackett at the top of the module, then start playing around.\n\nAlso, note that the demo web server used in the example at the top of this blog post is not included when you install the hackett package. If you want to try that out, you’ll have to run raco pkg install hackett-demo to install the demo package as well.\n\nAre there any examples of Hackett code?\nUnfortunately, not a lot right now, aside from the tiny examples in this blog post. However, if you are already familiar with Haskell, the syntax likely won’t be hard to pick up. Reading the Hackett source code is not especially recommended, given that it is filled with implementation details. However, if you are interested, reading the module where most of the prelude is defined isn’t so bad. You can find it on GitHub here, or you can open the hackett/private/prim/base module on a local installation.\n\nHow can I learn more / ask questions about Hackett?\nFeel free to ping me and ask me questions! I may not always be able to get back to you immediately, but if you hang around, I will eventually send you a response. The best ways to contact me are via the #racket IRC channel on Freenode, the snek Slack community (which you can sign up for here), sending me a DM on Twitter, opening an issue on the GitHub repo, or even just sending me an email (though I’m usually a bit slower to respond to the latter).\n\nHow can I help?\nProbably the easiest way to help out is to try Hackett for yourself and report any bugs or infelicities you run into. Of course, many issues right now are known, there’s just so much to do that I haven’t had the chance to clean everything up. For that reason, the most effective way to contribute is probably to pick an existing issue and try and implement it yourself, but I wouldn’t be surprised if most people found the existing implementation a little intimidating.\n\nIf you are interested in helping out, I’d be happy to give you some pointers and answer some questions, since it would be extremely nice to have some help. Please feel free to contact me using any of the methods mentioned in the previous section, and I’ll try and help you find something you could work on.\n\nHow does Hackett compare to X / why doesn’t Hackett support Y?\nThese tend to be complex questions, and I don’t always have comprehensive answers for them, especially since the language is evolving so quickly. Still, if you want to ask me about this, feel free to just send the question to me directly. In my experience, it’s usually better to have a conversation about this sort of thing rather than just answering in one big comparison, since there’s usually a fair amount of nuance.\n\nWhen will Hackett be ready for me to use?\nI don’t know.\n\nObviously, there is a lot left to implement, that is certainly true, but there’s more to it than that. If all goes well, I don’t see any reason why Hackett can’t be early beta quality by the end of this year, even if it doesn’t support all of the goodies necessary to achieve perfection (which, of course, it never really can).\n\nHowever, there are other things to consider, too. The Racket package system is currently flawed in ways that make rapidly iterating on Hackett hard, since it is extremely difficult (if not impossible) to make backwards-incompatible changes without potentially breaking someone’s program (even if they don’t update anything about their dependencies)! This is a solvable problem, but it would take some work modifying various elements of the package system and build tools, so that might need to get done before I can recommend Hackett in good faith.\n\nAppendix\nIt would be unfair not to mention all the people that have made Hackett possible. I cannot list them all here, but I want to give special thanks to Stephen Chang, Joshua Dunfield, Robby Findler, Matthew Flatt, Phil Freeman, Ben Greenman, Alex Knauth, Neelakantan Krishnaswami, and Sam Tobin-Hochstadt. I’d also like to thank everyone involved in the Racket and Haskell projects as a whole, as well as everyone who has expressed interest and encouragement about what I’ve been working on.\n\nAs a final point, just for fun, I thought I’d keep track of all the albums I’ve been listening to while working on Hackett, just in the past few weeks. It is on theme with the name, after all. This list is not completely exhaustive, as I’m sure some slipped through the cracks, but you can thank the following artists for helping me power through a few of the hills in Hackett’s implementation:\n\n\nThe Beach Boys — Pet Sounds\n\n\nBoards of Canada — Music Has The Right To Children, Geogaddi\n\n\nBruce Springsteen — Born to Run\n\n\nKing Crimson — In the Court of the Crimson King, Larks’ Tongues in Aspic, Starless and Bible Black, Red, Discipline\n\n\nGenesis — Nursery Cryme, Foxtrot, Selling England by the Pound, The Lamb Lies Down on Broadway, A Trick of the Tail\n\n\nMahavishnu Orchestra — Birds of Fire\n\n\nMetric — Fantasies, Synthetica, Pagans in Vegas\n\n\nMuse — Origin of Symmetry, Absolution, The Resistance\n\n\nPeter Gabriel — Peter Gabriel I, II, III, IV / Security, Us, Up\n\n\nPink Floyd — Wish You Were Here\n\n\nSupertramp — Breakfast In America\n\n\nThe Protomen — The Protomen, Act II: The Father of Death\n\n\nTalking Heads — Talking Heads: 77, More Songs About Buildings and Food, Fear of Music, Remain in Light\n\n\nYes — Fragile, Relayer, Going For The One\n\n\nAnd of course, Voyage of the Acolyte, by Steve Hackett.","isoDate":"2017-05-27T00:00:00.000Z","timestamp":"5/26/2017"},{"title":"Lifts for free: making mtl typeclasses derivable","pubDate":"2017-04-28T00:00:00.000Z","author":"Alexis King","content":"<article><p>Perhaps the most important abstraction a Haskell programmer must understand to effectively write modern Haskell code, beyond the level of the monad, is the <em>monad transformer</em>, a way to compose monads together in a limited fashion. One frustrating downside to monad transformers is a proliferation of <code>lift</code>s, which explicitly indicate which monad in a transformer “stack” a particular computation should run in. Fortunately, the venerable <a href=\"https://hackage.haskell.org/package/mtl\">mtl</a> provides typeclasses that make this lifting mostly automatic, using typeclass machinery to insert <code>lift</code> where appropriate.\n</p><p>Less fortunately, the mtl approach does not actually eliminate <code>lift</code> entirely, it simply moves it from use sites to instances. This requires a small zoo of extraordinarily boilerplate-y instances, most of which simply implement each typeclass method using <code>lift</code>. While we cannot eliminate the instances entirely without somewhat dangerous techniques like <a href=\"https://downloads.haskell.org/~ghc/8.0.2/docs/html/users_guide/glasgow_exts.html#overlapping-instances\">overlapping instances</a>, we <em>can</em> automatically derive them using features of modern GHC, eliminating the truly unnecessary boilerplate.\n</p><h2><a name=\"the-problem-with-mtl-style-typeclasses\"></a>The problem with mtl-style typeclasses</h2><p>To understand what problem it is exactly that we’re trying to solve, we first need to take a look at an actual mtl-style typeclass. I am going to start with an mtl-<em>style</em> typeclass, rather than an actual typeclass in the mtl, due to slight complications with mtl’s actual typeclasses that we’ll get into later. Instead, let’s start with a somewhat boring typeclass, which we’ll call <code>MonadExit</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">System.Exit</span> <span class=\"p\">(</span><span class=\"kt\">ExitCode</span><span class=\"p\">)</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">::</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>This is a simple typeclass that abstracts over the concept of early exit, given an exit code. The most obvious implementation of this typeclass is over <code>IO</code>, which will actually exit the program:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"k\">qualified</span> <span class=\"nn\">System.Exit</span> <span class=\"k\">as</span> <span class=\"n\">IO</span> <span class=\"p\">(</span><span class=\"n\">exitWith</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"kt\">IO</span><span class=\"o\">.</span><span class=\"n\">exitWith</span></code></pre><p>One of the cool things about these typeclasses, though, is that we don’t have to have just one implementation. We could also write a pure implementation of <code>MonadExit</code>, which would simply short-circuit the current computation and return the <code>ExitCode</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">ExitCode</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"kt\">Left</span></code></pre><p>Instead of simply having an instance on a concrete monad, though, we probably want to be able to use this in a larger monad stack, so we can define an <code>ExitT</code> monad transformer that can be inserted into any monad transformer stack:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE GeneralizedNewtypeDeriving #-}</span>\n\n<span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.Except</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span><span class=\"p\">,</span> <span class=\"nf\">runExceptT</span><span class=\"p\">,</span> <span class=\"nf\">throwError</span><span class=\"p\">)</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.Trans</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span><span class=\"p\">)</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">ExitT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">ExitT</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"kt\">ExitCode</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadTrans</span><span class=\"p\">)</span>\n\n<span class=\"nf\">runExitT</span> <span class=\"ow\">::</span> <span class=\"kt\">ExitT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">ExitCode</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"nf\">runExitT</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">runExceptT</span> <span class=\"n\">x</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"kt\">ExitT</span> <span class=\"o\">.</span> <span class=\"n\">throwError</span></code></pre><p>With this in place, we can write actual programs using our <code>ExitT</code> monad transformer:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">runExitT</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n        <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">putStrLn</span> <span class=\"s\">\"hello\"</span>\n        <span class=\"n\">exitWith</span> <span class=\"p\">(</span><span class=\"kt\">ExitFailure</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">lift</span> <span class=\"o\">$</span> <span class=\"n\">putStrLn</span> <span class=\"s\">\"world\"</span>\n<span class=\"nf\">hello</span>\n<span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"kt\">ExitFailure</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>This is pretty cool! Unfortunately, experienced readers will see the rather large problem with what we have so far. Specifically, it won’t actually work if we try and wrap <code>ExitT</code> in another monad transformer:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">logIn</span> <span class=\"n\">password</span> <span class=\"ow\">=</span> <span class=\"n\">runExitT</span> <span class=\"o\">$</span> <span class=\"n\">flip</span> <span class=\"n\">runReaderT</span> <span class=\"n\">password</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n        <span class=\"n\">password</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">ask</span>\n        <span class=\"n\">unless</span> <span class=\"p\">(</span><span class=\"n\">password</span> <span class=\"o\">==</span> <span class=\"s\">\"password1234\"</span><span class=\"p\">)</span> <span class=\"o\">$</span> <span class=\"c1\">-- super secure password</span>\n          <span class=\"n\">exitWith</span> <span class=\"p\">(</span><span class=\"kt\">ExitFailure</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">return</span> <span class=\"s\">\"access granted\"</span>\n\n<span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">logIn</span> <span class=\"s\">\"not the right password\"</span>\n<span class=\"o\">&lt;</span><span class=\"n\">interactive</span><span class=\"o\">&gt;:</span> <span class=\"ne\">error</span><span class=\"kt\">:</span>\n    <span class=\"err\">•</span> <span class=\"kt\">No</span> <span class=\"kr\">instance</span> <span class=\"n\">for</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"p\">[</span><span class=\"kt\">Char</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">m0</span><span class=\"p\">)))</span>\n        <span class=\"n\">arising</span> <span class=\"n\">from</span> <span class=\"n\">a</span> <span class=\"n\">use</span> <span class=\"kr\">of</span> <span class=\"err\">‘</span><span class=\"n\">it</span><span class=\"err\">’</span>\n    <span class=\"err\">•</span> <span class=\"kt\">In</span> <span class=\"n\">a</span> <span class=\"n\">stmt</span> <span class=\"kr\">of</span> <span class=\"n\">an</span> <span class=\"n\">interactive</span> <span class=\"kt\">GHCi</span> <span class=\"n\">command</span><span class=\"kt\">:</span> <span class=\"n\">print</span> <span class=\"n\">it</span></code></pre><p>The error message is relatively self-explanatory if you are familiar with mtl error messages: there is no <code>MonadExit</code> instance for <code>ReaderT</code>. This makes sense, since we only defined a <code>MonadExit</code> instance for <em><code>ExitT</code></em>, nothing else. Fortunately, the instance for <code>ReaderT</code> is completely trivial, since we just need to use <code>lift</code> to delegate to the next monad in the stack:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span></code></pre><p>Now that the delegating instance is set up, we can actually use our <code>logIn</code> function:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">logIn</span> <span class=\"s\">\"not the right password\"</span>\n<span class=\"kt\">Left</span> <span class=\"p\">(</span><span class=\"kt\">ExitFailure</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nf\">ghci</span><span class=\"o\">&gt;</span> <span class=\"n\">logIn</span> <span class=\"s\">\"password1234\"</span>\n<span class=\"kt\">Right</span> <span class=\"s\">\"access granted\"</span></code></pre><h3><a name=\"an-embarrassment-of-instances\"></a>An embarrassment of instances</h3><p>We’ve managed to make our program work properly now, but we’ve still only defined the delegating instance for <code>ReaderT</code>. What if someone wants to use <code>ExitT</code> with <code>WriterT</code>? Or <code>StateT</code>? Or any of <code>ExceptT</code>, <code>RWST</code>, or <code>ContT</code>? Well, we have to define instances for each and every one of them, and as it turns out, the instances are all identical!\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span>\n\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">RWST</span> <span class=\"n\">r</span> <span class=\"n\">w</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ContT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span></code></pre><p>This is bad enough on its own, but this is actually the <em>simplest</em> case: a typeclass with a single method which is trivially lifted through any other monad transformer. Another thing we’ve glossed over is actually defining all the delegating instances for the <em>other</em> mtl typeclasses on <code>ExitT</code> itself. Fortunately, we can derive these ones with <code>GeneralizedNewtypeDeriving</code>, since <code>ExceptT</code> has already done most of the work for us:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">ExitT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">ExitT</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"kt\">ExitCode</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span> <span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadIO</span> <span class=\"c1\">-- base</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadBase</span> <span class=\"kt\">IO</span> <span class=\"c1\">-- transformers-base</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadTrans</span><span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"c1\">-- mtl</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadThrow</span><span class=\"p\">,</span> <span class=\"kt\">MonadCatch</span><span class=\"p\">,</span> <span class=\"kt\">MonadMask</span> <span class=\"c1\">-- exceptions</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadTransControl</span><span class=\"p\">,</span> <span class=\"kt\">MonadBaseControl</span> <span class=\"kt\">IO</span> <span class=\"c1\">-- monad-control</span>\n           <span class=\"p\">)</span></code></pre><p>Unfortunately, we have to write the <code>MonadError</code> instance manually if we want it, since we don’t want to pick up the instance from <code>ExceptT</code>, but rather wish to defer to the underlying monad. This means writing some truly horrid delegation code:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">throwError</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">throwError</span>\n\n  <span class=\"n\">catchError</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"kt\">ExitT</span> <span class=\"o\">.</span> <span class=\"kt\">ExceptT</span> <span class=\"o\">$</span> <span class=\"n\">catchError</span> <span class=\"p\">(</span><span class=\"n\">runExceptT</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">e</span> <span class=\"ow\">-&gt;</span>\n    <span class=\"kr\">let</span> <span class=\"p\">(</span><span class=\"kt\">ExitT</span> <span class=\"n\">x&#39;</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">f</span> <span class=\"n\">e</span> <span class=\"kr\">in</span> <span class=\"n\">runExceptT</span> <span class=\"n\">x&#39;</span></code></pre><p>(Notably, this is so awful because <code>catchError</code> is more complex than the simple <code>exitWith</code> method we’ve studied so far, which is why we’re starting with a simpler typeclass. We’ll get more into this later, as promised.)\n</p><p>This huge number of instances is sometimes referred to as the “n<sup>2</sup> instances” problem, since it requires every monad transformer have an instance of every single mtl-style typeclass. Fortunately, in practice, this proliferation is often less horrible than it might seem, mostly because deriving helps a lot. However, remember that if <code>ExitT</code> <em>weren’t</em> a simple wrapper around an existing monad transformer, we wouldn’t be able to derive the instances at all! Instead, we’d have to write them all out by hand, just like we did with all the <code>MonadExit</code> instances.\n</p><p>It’s a shame that these typeclass instances can’t be derived in a more general way, allowing derivation for arbitrary monad transformers instead of simply requiring the newtype deriving machinery. As it turns out, with clever use of modern GHC features, we actually <strong>can</strong>. It’s not even all that hard.\n</p><h2><a name=\"default-instances-with-default-signatures\"></a>Default instances with default signatures</h2><p>It’s not hard to see that our <code>MonadExit</code> instances are all exactly the same: just <code>lift . exitWith</code>. Why is that, though? Well, every instance is an instance on a monad transformer over a monad that is already an instance of <code>MonadExit</code>. In fact, we can express this in a type signature, and we can extract <code>lift . exitWith</code> into a separate function:\n</p><pre><code class=\"pygments\"><span class=\"nf\">defaultExitWith</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n<span class=\"nf\">defaultExitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span></code></pre><p>However, writing <code>defaultExitWith</code> really isn’t any easier than writing <code>lift . exitWith</code>, so this deduplication doesn’t really buy us anything. However, it <em>does</em> indicate that we could write a default implementation of <code>exitWith</code> if we could require just a little bit more from the implementing type. With <a href=\"https://downloads.haskell.org/~ghc/8.0.2/docs/html/users_guide/glasgow_exts.html#default-method-signatures\">GHC’s <code>DefaultSignatures</code> extension</a>, we can do precisely that.\n</p><p>The idea is that we can write a separate type signature for a default implementation of <code>exitWith</code>, which can be more specific than the type signature for <code>exitWith</code> in general. This allows us to use our <code>defaultExitWith</code> implementation more or less directly:\n</p><pre><code class=\"pygments\"><span class=\"cm\">{-# LANGUAGE DefaultSignatures #-}</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">::</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n\n  <span class=\"kr\">default</span> <span class=\"n\">exitWith</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m1</span> <span class=\"nb\">()</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span></code></pre><p>We have to use <code>m1</code> instead of <code>m</code>, since type variables in the instance head are always scoped, and the names would conflict. However, this creates another problem, since our specialized type signature replaces <code>m</code> with <code>t m1</code>, which won’t quite work (as GHC can’t automatically figure out they should be the same). Instead, we can use <code>m</code> in the type signature, then just add a type equality constraint ensuring that <code>m</code> and <code>t m1</code> must be the same type:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">::</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n\n  <span class=\"kr\">default</span> <span class=\"n\">exitWith</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"n\">exitWith</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">exitWith</span></code></pre><p>Now we can write all of our simple instances without even needing to write a real implementation! All of the instance bodies can be empty:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">RWST</span> <span class=\"n\">r</span> <span class=\"n\">w</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadExit</span> <span class=\"p\">(</span><span class=\"kt\">ContT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>While this doesn’t completely alleviate the pain of writing instances, it’s definitely an improvement over what we had before. With <a href=\"https://downloads.haskell.org/~ghc/8.2.1-rc1/docs/html/users_guide/glasgow_exts.html#deriving-strategies\">GHC 8.2’s new <code>DerivingStrategies</code> extension</a>, it becomes especially beneficial when defining entirely new transformers that should also have <code>ExitT</code> instances, since they can be derived with <code>DeriveAnyClass</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">ParserT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">ParserT</span> <span class=\"p\">(</span><span class=\"kt\">Text</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">Text</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"p\">)))</span>\n  <span class=\"kr\">deriving</span> <span class=\"n\">anyclass</span> <span class=\"p\">(</span><span class=\"kt\">MonadExit</span><span class=\"p\">)</span></code></pre><p>This is pretty wonderful.\n</p><p>Given that only <code>MonadExit</code> supports being derived in this way, we sadly still need to implement the other, more standard mtl-style typeclasses ourselves, like <code>MonadIO</code>, <code>MonadBase</code>, <code>MonadReader</code>, <code>MonadWriter</code>, etc. However, what if all of those classes provided the same convenient default signatures that our <code>MonadExit</code> does? If that were the case, then we could write something like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">ParserT</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">ParserT</span> <span class=\"p\">(</span><span class=\"kt\">Text</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">Text</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"p\">)))</span>\n  <span class=\"kr\">deriving</span> <span class=\"n\">anyclass</span> <span class=\"p\">(</span> <span class=\"kt\">MonadIO</span><span class=\"p\">,</span> <span class=\"kt\">MonadBase</span> <span class=\"n\">b</span>\n                    <span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span>\n                    <span class=\"p\">,</span> <span class=\"kt\">MonadThrow</span><span class=\"p\">,</span> <span class=\"kt\">MonadCatch</span><span class=\"p\">,</span> <span class=\"kt\">MonadMask</span>\n                    <span class=\"p\">,</span> <span class=\"kt\">MonadExit</span>\n                    <span class=\"p\">)</span></code></pre><p>Compared to having to write all those instances by hand, this would be a pretty enormous difference. Unfortunately, many of these typeclasses are not quite as simple as our <code>MonadExit</code>, and we’d have to be a bit more clever to make them derivable.\n</p><h2><a name=\"making-mtl-s-classes-derivable\"></a>Making mtl’s classes derivable</h2><p>Our <code>MonadExit</code> class was extremely simple, since it only had a single method with a particularly simple type signature. For reference, this was the type of our generic <code>exitWith</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">exitWith</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadExit</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">ExitCode</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>Let’s now turn our attention to <code>MonadReader</code>. At first blush, this typeclass should not be any trickier to implement than <code>MonadExit</code>, since the types of <code>ask</code> and <code>reader</code> are both quite simple:\n</p><pre><code class=\"pygments\"><span class=\"nf\">ask</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">r</span>\n<span class=\"nf\">reader</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>However, the type of the other method, <code>local</code>, throws a bit of a wrench in our plans. It has the following type signature:\n</p><pre><code class=\"pygments\"><span class=\"nf\">local</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>Why is this so much more complicated? Well, the key is in the second argument, which has the type <code>m a</code>. That’s not something that can be simply <code>lift</code>ed away! Try it yourself: try to write a <code>MonadReader</code> instance for some monad transformer. It’s not as easy as it looks!\n</p><p>We can illustrate the problem by creating our own version of <code>MonadReader</code> and implementing it for something like <code>ExceptT</code> ourselves. We can start with the trivial methods first:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span> <span class=\"kr\">where</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">r</span>\n  <span class=\"n\">local</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">reader</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">ask</span>\n  <span class=\"n\">reader</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">reader</span></code></pre><p>However, implementing <code>local</code> is harder. Let’s specialize the type signature to <code>ExceptT</code> to make it more clear why:\n</p><pre><code class=\"pygments\"><span class=\"nf\">local</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>Our base monad, <code>m</code>, implements <code>local</code>, but we have to convert the first argument from <code>ExceptT e m a</code> into <code>m (Either e a)</code> first, run it through <code>local</code> in <code>m</code>, then wrap it back up in <code>ExceptT</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">ask</span>\n  <span class=\"n\">reader</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">reader</span>\n  <span class=\"n\">local</span> <span class=\"n\">f</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"kt\">ExceptT</span> <span class=\"o\">$</span> <span class=\"n\">local</span> <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"n\">runExceptT</span> <span class=\"n\">x</span><span class=\"p\">)</span></code></pre><p>This operation is actually a mapping operation of sorts, since we’re mapping <code>local f</code> over <code>x</code>. For that reason, this can be rewritten using the <code>mapExceptT</code> function provided from <code>Control.Monad.Except</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">ask</span>\n  <span class=\"n\">reader</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">reader</span>\n  <span class=\"n\">local</span> <span class=\"ow\">=</span> <span class=\"n\">mapExceptT</span> <span class=\"o\">.</span> <span class=\"n\">local</span></code></pre><p>If you implement <code>MonadReader</code> instances for other transformers, like <code>StateT</code> and <code>WriterT</code>, you’ll find that the instances are exactly the same <em>except</em> for <code>mapExceptT</code>, which is replaced with <code>mapStateT</code> and <code>mapWriterT</code>, respectively. This is sort of obnoxious, given that we want to figure out how to create a generic version of <code>local</code> that works with any monad transformer, but this requires concrete information about which monad we’re in. Obviously, the power <code>MonadTrans</code> gives us is not enough to make this generic. Fortunately, there is a typeclass which does: <a href=\"http://hackage.haskell.org/package/monad-control-1.0.1.0/docs/Control-Monad-Trans-Control.html#t:MonadTransControl\"><code>MonadTransControl</code></a> from the <code>monad-control</code> package.\n</p><p>Using <code>MonadTransControl</code>, we can write a generic <code>mapT</code> function that maps over an arbitrary monad transformer with a <code>MonadTransControl</code> instance:\n</p><pre><code class=\"pygments\"><span class=\"nf\">mapT</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">Monad</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span> <span class=\"p\">(</span><span class=\"n\">t</span> <span class=\"n\">m</span><span class=\"p\">),</span> <span class=\"kt\">MonadTransControl</span> <span class=\"n\">t</span><span class=\"p\">)</span>\n     <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">StT</span> <span class=\"n\">t</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">StT</span> <span class=\"n\">t</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n     <span class=\"ow\">-&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n     <span class=\"ow\">-&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m</span> <span class=\"n\">b</span>\n<span class=\"nf\">mapT</span> <span class=\"n\">f</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"n\">liftWith</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"n\">run</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"o\">&gt;&gt;=</span> <span class=\"n\">restoreT</span> <span class=\"o\">.</span> <span class=\"n\">return</span></code></pre><p>This type signature may look complicated (and, well, it is), but the idea is that the <code>StT</code> associated type family encapsulates the monadic state that <code>t</code> introduces. For example, for <code>ExceptT</code>, <code>StT (ExceptT e) a</code> is <code>Either e a</code>. For <code>StateT</code>, <code>StT (StateT s) a</code> is <code>(a, s)</code>. Some transformers, like <code>ReaderT</code>, have no state, so <code>StT (ReaderT r) a</code> is just <code>a</code>.\n</p><p>I will not go into the precise mechanics of how <code>MonadTransControl</code> works in this blog post, but it doesn’t matter significantly; the point is that we can now use <code>mapT</code> to create a generic implementation of <code>local</code> for use with <code>DefaultSignatures</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span> <span class=\"kr\">where</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">r</span>\n  <span class=\"kr\">default</span> <span class=\"n\">ask</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">r</span>\n  <span class=\"n\">ask</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">ask</span>\n\n  <span class=\"n\">local</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"kr\">default</span> <span class=\"n\">local</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTransControl</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">local</span> <span class=\"ow\">=</span> <span class=\"n\">mapT</span> <span class=\"o\">.</span> <span class=\"n\">local</span>\n\n  <span class=\"n\">reader</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">reader</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"n\">f</span> <span class=\"o\">&lt;$&gt;</span> <span class=\"n\">ask</span></code></pre><p>Once more, we now get instances of our typeclass, in this case <code>MonadReader</code>, <strong>for free</strong>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadReader</span> <span class=\"n\">r</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>It’s also worth noting that we <em>don’t</em> get a <code>ContT</code> instance for free, even though <code>ContT</code> has a <code>MonadReader</code> instance in mtl. Unlike the other monad transformers mtl provides, <code>ContT</code> does not have a <code>MonadTransControl</code> instance because it cannot be generally mapped over. While a <code>mapContT</code> function does exist, its signature is more restricted:\n</p><pre><code class=\"pygments\"><span class=\"nf\">mapContT</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"n\">r</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">ContT</span> <span class=\"n\">k</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">ContT</span> <span class=\"n\">k</span> <span class=\"n\">r</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>It happens that <code>local</code> can still be implemented for <code>ContT</code>, so it can still have a <code>MonadReader</code> instance, but it cannot be derived in the same way as it can for the other transformers. Still, in practice, I’ve found that most user-defined transformers do not have such complex control flow, so they can safely be instances of <code>MonadTransControl</code>, and they get this deriving for free.\n</p><h3><a name=\"extending-this-technique-to-other-mtl-typeclasses\"></a>Extending this technique to other mtl typeclasses</h3><p>The default instances for the other mtl typeclasses are slightly different from the one for <code>MonadReader</code>, but for the most part, the same general technique applies. Here’s a derivable <code>MonadError</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">e</span> <span class=\"kr\">where</span>\n  <span class=\"n\">throwError</span> <span class=\"ow\">::</span> <span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"kr\">default</span> <span class=\"n\">throwError</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">throwError</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">throwError</span>\n\n  <span class=\"n\">catchError</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"kr\">default</span> <span class=\"n\">catchError</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTransControl</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">e</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">catchError</span> <span class=\"n\">x</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"n\">liftWith</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">catchError</span> <span class=\"p\">(</span><span class=\"n\">run</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">run</span> <span class=\"o\">.</span> <span class=\"n\">f</span><span class=\"p\">))</span> <span class=\"o\">&gt;&gt;=</span> <span class=\"n\">restoreT</span> <span class=\"o\">.</span> <span class=\"n\">return</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadError</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"kt\">RWST</span> <span class=\"n\">r</span> <span class=\"n\">w</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>The <code>MonadState</code> interface turns out to be extremely simple, so it doesn’t even need <code>MonadTransControl</code> at all:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">s</span> <span class=\"kr\">where</span>\n  <span class=\"n\">get</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">s</span>\n  <span class=\"kr\">default</span> <span class=\"n\">get</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">s</span>\n  <span class=\"n\">get</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"n\">get</span>\n\n  <span class=\"n\">put</span> <span class=\"ow\">::</span> <span class=\"n\">s</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"kr\">default</span> <span class=\"n\">put</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">s</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"n\">put</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">put</span>\n\n  <span class=\"n\">state</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">s</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">))</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">state</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">s</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">get</span>\n    <span class=\"kr\">let</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">s&#39;</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">f</span> <span class=\"n\">s</span>\n    <span class=\"n\">put</span> <span class=\"n\">s&#39;</span>\n    <span class=\"n\">return</span> <span class=\"n\">a</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n<span class=\"kr\">instance</span> <span class=\"p\">(</span><span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadState</span> <span class=\"n\">s</span> <span class=\"p\">(</span><span class=\"kt\">WriterT</span> <span class=\"n\">w</span> <span class=\"n\">m</span><span class=\"p\">)</span></code></pre><p>Everything seems to be going well! However, not everything is quite so simple.\n</p><h3><a name=\"a-monadwriter-diversion\"></a>A <code>MonadWriter</code> diversion</h3><p>Unexpectedly, <code>MonadWriter</code> turns out to be by far the trickiest of the bunch. It’s not too hard to create default implementations for most of the methods of the typeclass:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"p\">(</span><span class=\"kt\">Monoid</span> <span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span> <span class=\"n\">m</span> <span class=\"o\">|</span> <span class=\"n\">m</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">w</span> <span class=\"kr\">where</span>\n  <span class=\"n\">writer</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"kr\">default</span> <span class=\"n\">writer</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n  <span class=\"n\">writer</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">writer</span>\n\n  <span class=\"n\">tell</span> <span class=\"ow\">::</span> <span class=\"n\">w</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"kr\">default</span> <span class=\"n\">tell</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTrans</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">w</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"n\">tell</span> <span class=\"ow\">=</span> <span class=\"n\">lift</span> <span class=\"o\">.</span> <span class=\"n\">tell</span>\n\n  <span class=\"n\">listen</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n  <span class=\"kr\">default</span> <span class=\"n\">listen</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTransControl</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n  <span class=\"n\">listen</span> <span class=\"n\">x</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftWith</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">listen</span> <span class=\"p\">(</span><span class=\"n\">run</span> <span class=\"n\">x</span><span class=\"p\">))</span>\n    <span class=\"n\">y&#39;</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">restoreT</span> <span class=\"p\">(</span><span class=\"n\">return</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n    <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">y&#39;</span><span class=\"p\">,</span> <span class=\"n\">w</span><span class=\"p\">)</span></code></pre><p>However, <code>MonadWriter</code> has a fourth method, <code>pass</code>, which has a particularly tricky type signature:\n</p><pre><code class=\"pygments\"><span class=\"nf\">pass</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>As far as I can tell, this is not possible to generalize using <code>MonadTransControl</code> alone, since it would require inspection of the result of the monadic argument (that is, it would require a function from <code>StT t (a, b) -&gt; (StT t a, b)</code>), which is not possible in general. My gut is that this could likely also be generalized with a slightly more powerful abstraction than <code>MonadTransControl</code>, but it is not immediately obvious to me what that abstraction should be.\n</p><p>One extremely simple way to make this possible would be to design something to serve this specific use case:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">RunSplit</span> <span class=\"n\">t</span> <span class=\"ow\">=</span> <span class=\"n\">forall</span> <span class=\"n\">m</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"o\">.</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">StT</span> <span class=\"n\">t</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"kt\">Maybe</span> <span class=\"n\">b</span><span class=\"p\">)</span>\n<span class=\"kr\">class</span> <span class=\"kt\">MonadTransControl</span> <span class=\"n\">t</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadTransSplit</span> <span class=\"n\">t</span> <span class=\"kr\">where</span>\n  <span class=\"n\">liftWithSplit</span> <span class=\"ow\">::</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"p\">(</span><span class=\"kt\">RunSplit</span> <span class=\"n\">t</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">t</span> <span class=\"n\">m</span> <span class=\"n\">a</span></code></pre><p>Instances of <code>MonadTransSplit</code> would basically just provide a way to pull out bits of the result, if possible:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadTransSplit</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">liftWithSplit</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"n\">liftWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"n\">fmap</span> <span class=\"n\">split</span> <span class=\"o\">.</span> <span class=\"n\">run</span><span class=\"p\">)</span>\n    <span class=\"kr\">where</span> <span class=\"n\">split</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"kt\">Just</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadTransSplit</span> <span class=\"p\">(</span><span class=\"kt\">ExceptT</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">liftWithSplit</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"n\">liftWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"n\">fmap</span> <span class=\"n\">split</span> <span class=\"o\">.</span> <span class=\"n\">run</span><span class=\"p\">)</span>\n    <span class=\"kr\">where</span> <span class=\"n\">split</span> <span class=\"p\">(</span><span class=\"kt\">Left</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"kt\">Left</span> <span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"kt\">Nothing</span><span class=\"p\">)</span>\n          <span class=\"n\">split</span> <span class=\"p\">(</span><span class=\"kt\">Right</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">))</span> <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"kt\">Right</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"kt\">Just</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadTransSplit</span> <span class=\"p\">(</span><span class=\"kt\">StateT</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">liftWithSplit</span> <span class=\"n\">f</span> <span class=\"ow\">=</span> <span class=\"n\">liftWith</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"n\">fmap</span> <span class=\"n\">split</span> <span class=\"o\">.</span> <span class=\"n\">run</span><span class=\"p\">)</span>\n    <span class=\"kr\">where</span> <span class=\"n\">split</span> <span class=\"p\">((</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">),</span> <span class=\"n\">s</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"p\">((</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">),</span> <span class=\"kt\">Just</span> <span class=\"n\">y</span><span class=\"p\">)</span></code></pre><p>Then, using this, it would be possible to write a generic version of <code>pass</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">default</span> <span class=\"n\">pass</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">MonadTransSplit</span> <span class=\"n\">t</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">w</span> <span class=\"n\">m1</span><span class=\"p\">,</span> <span class=\"n\">m</span> <span class=\"o\">~</span> <span class=\"n\">t</span> <span class=\"n\">m1</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">w</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"n\">a</span>\n<span class=\"nf\">pass</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">r</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftWithSplit</span> <span class=\"o\">$</span> <span class=\"nf\">\\</span><span class=\"n\">run</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">pass</span> <span class=\"o\">$</span> <span class=\"n\">run</span> <span class=\"n\">m</span> <span class=\"o\">&gt;&gt;=</span> <span class=\"nf\">\\</span><span class=\"kr\">case</span>\n    <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"kt\">Just</span> <span class=\"n\">f</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"kt\">Nothing</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n  <span class=\"n\">restoreT</span> <span class=\"p\">(</span><span class=\"n\">return</span> <span class=\"n\">r</span><span class=\"p\">)</span></code></pre><p>However, this seems pretty overkill for just one particular method, given that I have no idea if <code>MonadTransSplit</code> would be useful <em>anywhere</em> else. One interesting thing about going down this rabbit hole, though, is that I learned that <code>pass</code> has some somewhat surprising behavior when mixed with transformers like <code>ExceptT</code> or <code>MaybeT</code>, if you don’t carefully consider how it works. It’s a strange method with a somewhat strange interface, so I don’t think I have a satisfactory conclusion about <code>MonadWriter</code> yet.\n</p><h2><a name=\"regrouping-and-stepping-back\"></a>Regrouping and stepping back</h2><p>Alright, that was a lot of fairly intense, potentially confusing code. What the heck did we actually accomplish? Well, we got a couple of things:\n</p><ol><li><p>First, we developed a technique for writing simple mtl-style typeclasses that are derivable using <code>DeriveAnyClass</code> (or simply writing an empty instance declaration). We used a <code>MonadExit</code> class as a proof of concept, but really, the technique is applicable to most mtl-style typeclasses that represent simple effects (including, for example, <code>MonadIO</code>).\n</p><p>This technique is useful in isolation, even if you completely disregard the rest of the blog post. For an example where I recently applied it in real code, see <a href=\"https://github.com/cjdev/monad-persist/blob/1ce8568d881da3171f8689dd65f4f2df5f6dd313/library/Control/Monad/Persist.hs#L226-L271\">the default signatures provided with <code>MonadPersist</code> from the <code>monad-persist</code> library</a>, which make <a href=\"https://github.com/cjdev/monad-persist/blob/1ce8568d881da3171f8689dd65f4f2df5f6dd313/library/Control/Monad/Persist.hs#L506-L513\">defining instances completely trivial</a>. If you use mtl-style typeclasses in your own application to model effects, I don’t see much of a reason <em>not</em> to use this technique.\n</p></li><li><p>After <code>MonadExit</code>, we applied the same technique to the mtl-provided typeclasses <code>MonadReader</code>, <code>MonadError</code>, and <code>MonadState</code>. These are a bit trickier, since the first two need <code>MonadTransControl</code> in addition to the  usual <code>MonadTrans</code>.\n</p><p>Whether or not this sort of thing should actually be added to mtl itself probably remains to be seen. For the simplest typeclass, <code>MonadState</code>, it seems like there probably aren’t many downsides, but given the difficulty implementing it for <code>MonadWriter</code> (or, heaven forbid, <code>MonadCont</code>, which I didn’t even seriously take a look at for this blog post), it doesn’t seem like an obvious win. Consistency is important.\n</p><p>Another downside that I sort of glossed over is possibly even more significant from a practical point of view: adding default signatures to <code>MonadReader</code> would require the removal of the default implementation of <code>ask</code> that is provided by the existing library (which implements <code>ask</code> in terms of <code>reader</code>). This would be backwards-incompatible, so it’d be difficult to change, even if people wanted to do it. Still, it’s interesting to consider what these typeclasses might look like if they were designed today.\n</p></li></ol><p>Overall, these techniques are not a silver bullet for deriving mtl-style typeclasses, nor do they eliminate the n<sup>2</sup> instances problem that mtl style suffers from. That said, they <em>do</em> significantly reduce boilerplate and clutter in the simplest cases, and they demonstrate how modern Haskell’s hierarchy of typeclasses provides a lot of power, both to describe quite abstract concepts and to alleviate the need to write code by hand.\n</p><p>I will continue to experiment with the ideas described in this blog post, and I’m sure some more pros and cons will surface as I explore the design space. If you have any suggestions for how to deal with “the <code>MonadWriter</code> problem”, I’d be very interested to hear them! In the meantime, consider using the technique in your application code when writing effectful, monadic typeclasses.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Perhaps the most important abstraction a Haskell programmer must understand to effectively write modern Haskell code, beyond the level of the monad, is the monad transformer, a way to compose monads together in a limited fashion. One frustrating downside to monad transformers is a proliferation of lifts, which explicitly indicate which monad in a transformer “stack” a particular computation should run in. Fortunately, the venerable mtl provides typeclasses that make this lifting mostly automatic, using typeclass machinery to insert lift where appropriate.\n\nLess fortunately, the mtl approach does not actually eliminate lift entirely, it simply moves it from use sites to instances. This requires a small zoo of extraordinarily boilerplate-y instances, most of which simply implement each typeclass method using lift. While we cannot eliminate the instances entirely without somewhat dangerous techniques like overlapping instances, we can automatically derive them using features of modern GHC, eliminating the truly unnecessary boilerplate.\n\nThe problem with mtl-style typeclasses\nTo understand what problem it is exactly that we’re trying to solve, we first need to take a look at an actual mtl-style typeclass. I am going to start with an mtl-style typeclass, rather than an actual typeclass in the mtl, due to slight complications with mtl’s actual typeclasses that we’ll get into later. Instead, let’s start with a somewhat boring typeclass, which we’ll call MonadExit:\n\nimport System.Exit (ExitCode)\n\nclass Monad m => MonadExit m where\n  exitWith :: ExitCode -> m ()\nThis is a simple typeclass that abstracts over the concept of early exit, given an exit code. The most obvious implementation of this typeclass is over IO, which will actually exit the program:\n\nimport qualified System.Exit as IO (exitWith)\n\ninstance MonadExit IO where\n  exitWith = IO.exitWith\nOne of the cool things about these typeclasses, though, is that we don’t have to have just one implementation. We could also write a pure implementation of MonadExit, which would simply short-circuit the current computation and return the ExitCode:\n\ninstance MonadExit (Either ExitCode) where\n  exitWith = Left\nInstead of simply having an instance on a concrete monad, though, we probably want to be able to use this in a larger monad stack, so we can define an ExitT monad transformer that can be inserted into any monad transformer stack:\n\n{-# LANGUAGE GeneralizedNewtypeDeriving #-}\n\nimport Control.Monad.Except (ExceptT, runExceptT, throwError)\nimport Control.Monad.Trans (MonadTrans)\n\nnewtype ExitT m a = ExitT (ExceptT ExitCode m a)\n  deriving (Functor, Applicative, Monad, MonadTrans)\n\nrunExitT :: ExitT m a -> m (Either ExitCode a)\nrunExitT (ExitT x) = runExceptT x\n\ninstance Monad m => MonadExit (ExitT m) where\n  exitWith = ExitT . throwError\nWith this in place, we can write actual programs using our ExitT monad transformer:\n\nghci> runExitT $ do\n        lift $ putStrLn \"hello\"\n        exitWith (ExitFailure 1)\n        lift $ putStrLn \"world\"\nhello\nLeft (ExitFailure 1)\nThis is pretty cool! Unfortunately, experienced readers will see the rather large problem with what we have so far. Specifically, it won’t actually work if we try and wrap ExitT in another monad transformer:\n\nghci> logIn password = runExitT $ flip runReaderT password $ do\n        password <- ask\n        unless (password == \"password1234\") $ -- super secure password\n          exitWith (ExitFailure 1)\n        return \"access granted\"\n\nghci> logIn \"not the right password\"\n<interactive>: error:\n    • No instance for (MonadExit (ReaderT [Char] (ExitT m0)))\n        arising from a use of ‘it’\n    • In a stmt of an interactive GHCi command: print it\nThe error message is relatively self-explanatory if you are familiar with mtl error messages: there is no MonadExit instance for ReaderT. This makes sense, since we only defined a MonadExit instance for ExitT, nothing else. Fortunately, the instance for ReaderT is completely trivial, since we just need to use lift to delegate to the next monad in the stack:\n\ninstance MonadExit m => MonadExit (ReaderT r m) where\n  exitWith = lift . exitWith\nNow that the delegating instance is set up, we can actually use our logIn function:\n\nghci> logIn \"not the right password\"\nLeft (ExitFailure 1)\nghci> logIn \"password1234\"\nRight \"access granted\"\nAn embarrassment of instances\nWe’ve managed to make our program work properly now, but we’ve still only defined the delegating instance for ReaderT. What if someone wants to use ExitT with WriterT? Or StateT? Or any of ExceptT, RWST, or ContT? Well, we have to define instances for each and every one of them, and as it turns out, the instances are all identical!\n\ninstance (MonadExit m, Monoid w) => MonadExit (WriterT w m) where\n  exitWith = lift . exitWith\n\ninstance MonadExit m => MonadExit (StateT s m) where\n  exitWith = lift . exitWith\n\ninstance (MonadExit m, Monoid w) => MonadExit (RWST r w s m) where\n  exitWith = lift . exitWith\n\ninstance MonadExit m => MonadExit (ExceptT e m) where\n  exitWith = lift . exitWith\n\ninstance MonadExit m => MonadExit (ContT r m) where\n  exitWith = lift . exitWith\nThis is bad enough on its own, but this is actually the simplest case: a typeclass with a single method which is trivially lifted through any other monad transformer. Another thing we’ve glossed over is actually defining all the delegating instances for the other mtl typeclasses on ExitT itself. Fortunately, we can derive these ones with GeneralizedNewtypeDeriving, since ExceptT has already done most of the work for us:\n\nnewtype ExitT m a = ExitT (ExceptT ExitCode m a)\n  deriving ( Functor, Applicative, Monad, MonadIO -- base\n           , MonadBase IO -- transformers-base\n           , MonadTrans, MonadReader r, MonadWriter w, MonadState s -- mtl\n           , MonadThrow, MonadCatch, MonadMask -- exceptions\n           , MonadTransControl, MonadBaseControl IO -- monad-control\n           )\nUnfortunately, we have to write the MonadError instance manually if we want it, since we don’t want to pick up the instance from ExceptT, but rather wish to defer to the underlying monad. This means writing some truly horrid delegation code:\n\ninstance MonadError e m => MonadError e (ExitT m) where\n  throwError = lift . throwError\n\n  catchError (ExitT x) f = ExitT . ExceptT $ catchError (runExceptT x) $ \\e ->\n    let (ExitT x') = f e in runExceptT x'\n(Notably, this is so awful because catchError is more complex than the simple exitWith method we’ve studied so far, which is why we’re starting with a simpler typeclass. We’ll get more into this later, as promised.)\n\nThis huge number of instances is sometimes referred to as the “n2 instances” problem, since it requires every monad transformer have an instance of every single mtl-style typeclass. Fortunately, in practice, this proliferation is often less horrible than it might seem, mostly because deriving helps a lot. However, remember that if ExitT weren’t a simple wrapper around an existing monad transformer, we wouldn’t be able to derive the instances at all! Instead, we’d have to write them all out by hand, just like we did with all the MonadExit instances.\n\nIt’s a shame that these typeclass instances can’t be derived in a more general way, allowing derivation for arbitrary monad transformers instead of simply requiring the newtype deriving machinery. As it turns out, with clever use of modern GHC features, we actually can. It’s not even all that hard.\n\nDefault instances with default signatures\nIt’s not hard to see that our MonadExit instances are all exactly the same: just lift . exitWith. Why is that, though? Well, every instance is an instance on a monad transformer over a monad that is already an instance of MonadExit. In fact, we can express this in a type signature, and we can extract lift . exitWith into a separate function:\n\ndefaultExitWith :: (MonadTrans t, MonadExit m) => ExitCode -> t m ()\ndefaultExitWith = lift . exitWith\nHowever, writing defaultExitWith really isn’t any easier than writing lift . exitWith, so this deduplication doesn’t really buy us anything. However, it does indicate that we could write a default implementation of exitWith if we could require just a little bit more from the implementing type. With GHC’s DefaultSignatures extension, we can do precisely that.\n\nThe idea is that we can write a separate type signature for a default implementation of exitWith, which can be more specific than the type signature for exitWith in general. This allows us to use our defaultExitWith implementation more or less directly:\n\n{-# LANGUAGE DefaultSignatures #-}\n\nclass Monad m => MonadExit m where\n  exitWith :: ExitCode -> m ()\n\n  default exitWith :: (MonadTrans t, MonadExit m1) => ExitCode -> t m1 ()\n  exitWith = lift . exitWith\nWe have to use m1 instead of m, since type variables in the instance head are always scoped, and the names would conflict. However, this creates another problem, since our specialized type signature replaces m with t m1, which won’t quite work (as GHC can’t automatically figure out they should be the same). Instead, we can use m in the type signature, then just add a type equality constraint ensuring that m and t m1 must be the same type:\n\nclass Monad m => MonadExit m where\n  exitWith :: ExitCode -> m ()\n\n  default exitWith :: (MonadTrans t, MonadExit m1, m ~ t m1) => ExitCode -> m ()\n  exitWith = lift . exitWith\nNow we can write all of our simple instances without even needing to write a real implementation! All of the instance bodies can be empty:\n\ninstance MonadExit m => MonadExit (ReaderT r m)\ninstance (MonadExit m, Monoid w) => MonadExit (WriterT w m)\ninstance MonadExit m => MonadExit (StateT s m)\ninstance (MonadExit m, Monoid w) => MonadExit (RWST r w s m)\ninstance MonadExit m => MonadExit (ExceptT e m)\ninstance MonadExit m => MonadExit (ContT r m)\nWhile this doesn’t completely alleviate the pain of writing instances, it’s definitely an improvement over what we had before. With GHC 8.2’s new DerivingStrategies extension, it becomes especially beneficial when defining entirely new transformers that should also have ExitT instances, since they can be derived with DeriveAnyClass:\n\nnewtype ParserT m a = ParserT (Text -> m (Maybe (Text, a)))\n  deriving anyclass (MonadExit)\nThis is pretty wonderful.\n\nGiven that only MonadExit supports being derived in this way, we sadly still need to implement the other, more standard mtl-style typeclasses ourselves, like MonadIO, MonadBase, MonadReader, MonadWriter, etc. However, what if all of those classes provided the same convenient default signatures that our MonadExit does? If that were the case, then we could write something like this:\n\nnewtype ParserT m a = ParserT (Text -> m (Maybe (Text, a)))\n  deriving anyclass ( MonadIO, MonadBase b\n                    , MonadReader r, MonadWriter w, MonadState s\n                    , MonadThrow, MonadCatch, MonadMask\n                    , MonadExit\n                    )\nCompared to having to write all those instances by hand, this would be a pretty enormous difference. Unfortunately, many of these typeclasses are not quite as simple as our MonadExit, and we’d have to be a bit more clever to make them derivable.\n\nMaking mtl’s classes derivable\nOur MonadExit class was extremely simple, since it only had a single method with a particularly simple type signature. For reference, this was the type of our generic exitWith:\n\nexitWith :: MonadExit m => ExitCode -> m ()\nLet’s now turn our attention to MonadReader. At first blush, this typeclass should not be any trickier to implement than MonadExit, since the types of ask and reader are both quite simple:\n\nask :: MonadReader r m => m r\nreader :: MonadReader r m => (r -> a) -> m a\nHowever, the type of the other method, local, throws a bit of a wrench in our plans. It has the following type signature:\n\nlocal :: MonadReader r m => (r -> r) -> m a -> m a\nWhy is this so much more complicated? Well, the key is in the second argument, which has the type m a. That’s not something that can be simply lifted away! Try it yourself: try to write a MonadReader instance for some monad transformer. It’s not as easy as it looks!\n\nWe can illustrate the problem by creating our own version of MonadReader and implementing it for something like ExceptT ourselves. We can start with the trivial methods first:\n\nclass Monad m => MonadReader r m | m -> r where\n  ask :: m r\n  local :: (r -> r) -> m a -> m a\n  reader :: (r -> a) -> m a\n\ninstance MonadReader r m => MonadReader r (ExceptT e m) where\n  ask = lift ask\n  reader = lift . reader\nHowever, implementing local is harder. Let’s specialize the type signature to ExceptT to make it more clear why:\n\nlocal :: MonadReader r m => (r -> r) -> ExceptT e m a -> ExceptT e m a\nOur base monad, m, implements local, but we have to convert the first argument from ExceptT e m a into m (Either e a) first, run it through local in m, then wrap it back up in ExceptT:\n\ninstance MonadReader r m => MonadReader r (ExceptT e m) where\n  ask = lift ask\n  reader = lift . reader\n  local f x = ExceptT $ local f (runExceptT x)\nThis operation is actually a mapping operation of sorts, since we’re mapping local f over x. For that reason, this can be rewritten using the mapExceptT function provided from Control.Monad.Except:\n\ninstance MonadReader r m => MonadReader r (ExceptT e m) where\n  ask = lift ask\n  reader = lift . reader\n  local = mapExceptT . local\nIf you implement MonadReader instances for other transformers, like StateT and WriterT, you’ll find that the instances are exactly the same except for mapExceptT, which is replaced with mapStateT and mapWriterT, respectively. This is sort of obnoxious, given that we want to figure out how to create a generic version of local that works with any monad transformer, but this requires concrete information about which monad we’re in. Obviously, the power MonadTrans gives us is not enough to make this generic. Fortunately, there is a typeclass which does: MonadTransControl from the monad-control package.\n\nUsing MonadTransControl, we can write a generic mapT function that maps over an arbitrary monad transformer with a MonadTransControl instance:\n\nmapT :: (Monad m, Monad (t m), MonadTransControl t)\n     => (m (StT t a) -> m (StT t b))\n     -> t m a\n     -> t m b\nmapT f x = liftWith (\\run -> f (run x)) >>= restoreT . return\nThis type signature may look complicated (and, well, it is), but the idea is that the StT associated type family encapsulates the monadic state that t introduces. For example, for ExceptT, StT (ExceptT e) a is Either e a. For StateT, StT (StateT s) a is (a, s). Some transformers, like ReaderT, have no state, so StT (ReaderT r) a is just a.\n\nI will not go into the precise mechanics of how MonadTransControl works in this blog post, but it doesn’t matter significantly; the point is that we can now use mapT to create a generic implementation of local for use with DefaultSignatures:\n\nclass Monad m => MonadReader r m | m -> r where\n  ask :: m r\n  default ask :: (MonadTrans t, MonadReader r m1, m ~ t m1) => m r\n  ask = lift ask\n\n  local :: (r -> r) -> m a -> m a\n  default local :: (MonadTransControl t, MonadReader r m1, m ~ t m1) => (r -> r) -> m a -> m a\n  local = mapT . local\n\n  reader :: (r -> a) -> m a\n  reader f = f <$> ask\nOnce more, we now get instances of our typeclass, in this case MonadReader, for free:\n\ninstance MonadReader r m => MonadReader r (ExceptT e m)\ninstance (MonadReader r m, Monoid w) => MonadReader r (WriterT w m)\ninstance MonadReader r m => MonadReader r (StateT s m)\nIt’s also worth noting that we don’t get a ContT instance for free, even though ContT has a MonadReader instance in mtl. Unlike the other monad transformers mtl provides, ContT does not have a MonadTransControl instance because it cannot be generally mapped over. While a mapContT function does exist, its signature is more restricted:\n\nmapContT :: (m r -> m r) -> ContT k r m a -> ContT k r m a\nIt happens that local can still be implemented for ContT, so it can still have a MonadReader instance, but it cannot be derived in the same way as it can for the other transformers. Still, in practice, I’ve found that most user-defined transformers do not have such complex control flow, so they can safely be instances of MonadTransControl, and they get this deriving for free.\n\nExtending this technique to other mtl typeclasses\nThe default instances for the other mtl typeclasses are slightly different from the one for MonadReader, but for the most part, the same general technique applies. Here’s a derivable MonadError:\n\nclass Monad m => MonadError e m | m -> e where\n  throwError :: e -> m a\n  default throwError :: (MonadTrans t, MonadError e m1, m ~ t m1) => e -> m a\n  throwError = lift . throwError\n\n  catchError :: m a -> (e -> m a) -> m a\n  default catchError :: (MonadTransControl t, MonadError e m1, m ~ t m1) => m a -> (e -> m a) -> m a\n  catchError x f = liftWith (\\run -> catchError (run x) (run . f)) >>= restoreT . return\n\ninstance MonadError e m => MonadError e (ReaderT r m)\ninstance (MonadError e m, Monoid w) => MonadError e (WriterT w m)\ninstance MonadError e m => MonadError e (StateT s m)\ninstance (MonadError e m, Monoid w) => MonadError e (RWST r w s m)\nThe MonadState interface turns out to be extremely simple, so it doesn’t even need MonadTransControl at all:\n\nclass Monad m => MonadState s m | m -> s where\n  get :: m s\n  default get :: (MonadTrans t, MonadState s m1, m ~ t m1) => m s\n  get = lift get\n\n  put :: s -> m ()\n  default put :: (MonadTrans t, MonadState s m1, m ~ t m1) => s -> m ()\n  put = lift . put\n\n  state :: (s -> (a, s)) -> m a\n  state f = do\n    s <- get\n    let (a, s') = f s\n    put s'\n    return a\n\ninstance MonadState s m => MonadState s (ExceptT e m)\ninstance MonadState s m => MonadState s (ReaderT r m)\ninstance (MonadState s m, Monoid w) => MonadState s (WriterT w m)\nEverything seems to be going well! However, not everything is quite so simple.\n\nA MonadWriter diversion\nUnexpectedly, MonadWriter turns out to be by far the trickiest of the bunch. It’s not too hard to create default implementations for most of the methods of the typeclass:\n\nclass (Monoid w, Monad m) => MonadWriter w m | m -> w where\n  writer :: (a, w) -> m a\n  default writer :: (MonadTrans t, MonadWriter w m1, m ~ t m1) => (a, w) -> m a\n  writer = lift . writer\n\n  tell :: w -> m ()\n  default tell :: (MonadTrans t, MonadWriter w m1, m ~ t m1) => w -> m ()\n  tell = lift . tell\n\n  listen :: m a -> m (a, w)\n  default listen :: (MonadTransControl t, MonadWriter w m1, m ~ t m1) => m a -> m (a, w)\n  listen x = do\n    (y, w) <- liftWith (\\run -> listen (run x))\n    y' <- restoreT (return y)\n    return (y', w)\nHowever, MonadWriter has a fourth method, pass, which has a particularly tricky type signature:\n\npass :: m (a, w -> w) -> m a\nAs far as I can tell, this is not possible to generalize using MonadTransControl alone, since it would require inspection of the result of the monadic argument (that is, it would require a function from StT t (a, b) -> (StT t a, b)), which is not possible in general. My gut is that this could likely also be generalized with a slightly more powerful abstraction than MonadTransControl, but it is not immediately obvious to me what that abstraction should be.\n\nOne extremely simple way to make this possible would be to design something to serve this specific use case:\n\ntype RunSplit t = forall m a b. Monad m => t m (a, b) -> m (StT t a, Maybe b)\nclass MonadTransControl t => MonadTransSplit t where\n  liftWithSplit :: Monad m => (RunSplit t -> m a) -> t m a\nInstances of MonadTransSplit would basically just provide a way to pull out bits of the result, if possible:\n\ninstance MonadTransSplit (ReaderT r) where\n  liftWithSplit f = liftWith $ \\run -> f (fmap split . run)\n    where split (x, y) = (x, Just y)\n\ninstance MonadTransSplit (ExceptT e) where\n  liftWithSplit f = liftWith $ \\run -> f (fmap split . run)\n    where split (Left e) = (Left e, Nothing)\n          split (Right (x, y)) = (Right x, Just y)\n\ninstance MonadTransSplit (StateT s) where\n  liftWithSplit f = liftWith $ \\run -> f (fmap split . run)\n    where split ((x, y), s) = ((x, s), Just y)\nThen, using this, it would be possible to write a generic version of pass:\n\ndefault pass :: (MonadTransSplit t, MonadWriter w m1, m ~ t m1) => m (a, w -> w) -> m a\npass m = do\n  r <- liftWithSplit $ \\run -> pass $ run m >>= \\case\n    (x, Just f) -> return (x, f)\n    (x, Nothing) -> return (x, id)\n  restoreT (return r)\nHowever, this seems pretty overkill for just one particular method, given that I have no idea if MonadTransSplit would be useful anywhere else. One interesting thing about going down this rabbit hole, though, is that I learned that pass has some somewhat surprising behavior when mixed with transformers like ExceptT or MaybeT, if you don’t carefully consider how it works. It’s a strange method with a somewhat strange interface, so I don’t think I have a satisfactory conclusion about MonadWriter yet.\n\nRegrouping and stepping back\nAlright, that was a lot of fairly intense, potentially confusing code. What the heck did we actually accomplish? Well, we got a couple of things:\n\n\nFirst, we developed a technique for writing simple mtl-style typeclasses that are derivable using DeriveAnyClass (or simply writing an empty instance declaration). We used a MonadExit class as a proof of concept, but really, the technique is applicable to most mtl-style typeclasses that represent simple effects (including, for example, MonadIO).\n\nThis technique is useful in isolation, even if you completely disregard the rest of the blog post. For an example where I recently applied it in real code, see the default signatures provided with MonadPersist from the monad-persist library, which make defining instances completely trivial. If you use mtl-style typeclasses in your own application to model effects, I don’t see much of a reason not to use this technique.\n\n\nAfter MonadExit, we applied the same technique to the mtl-provided typeclasses MonadReader, MonadError, and MonadState. These are a bit trickier, since the first two need MonadTransControl in addition to the  usual MonadTrans.\n\nWhether or not this sort of thing should actually be added to mtl itself probably remains to be seen. For the simplest typeclass, MonadState, it seems like there probably aren’t many downsides, but given the difficulty implementing it for MonadWriter (or, heaven forbid, MonadCont, which I didn’t even seriously take a look at for this blog post), it doesn’t seem like an obvious win. Consistency is important.\n\nAnother downside that I sort of glossed over is possibly even more significant from a practical point of view: adding default signatures to MonadReader would require the removal of the default implementation of ask that is provided by the existing library (which implements ask in terms of reader). This would be backwards-incompatible, so it’d be difficult to change, even if people wanted to do it. Still, it’s interesting to consider what these typeclasses might look like if they were designed today.\n\n\nOverall, these techniques are not a silver bullet for deriving mtl-style typeclasses, nor do they eliminate the n2 instances problem that mtl style suffers from. That said, they do significantly reduce boilerplate and clutter in the simplest cases, and they demonstrate how modern Haskell’s hierarchy of typeclasses provides a lot of power, both to describe quite abstract concepts and to alleviate the need to write code by hand.\n\nI will continue to experiment with the ideas described in this blog post, and I’m sure some more pros and cons will surface as I explore the design space. If you have any suggestions for how to deal with “the MonadWriter problem”, I’d be very interested to hear them! In the meantime, consider using the technique in your application code when writing effectful, monadic typeclasses.","isoDate":"2017-04-28T00:00:00.000Z","timestamp":"4/27/2017"},{"title":"Rascal is now Hackett, plus some answers to questions","pubDate":"2017-01-05T00:00:00.000Z","author":"Alexis King","content":"<article><p>Since I published <a href=\"/blog/2017/01/02/rascal-a-haskell-with-more-parentheses/\">my blog post introducing Rascal</a>, I’ve gotten some <em>amazing</em> feedback, more than I had ever anticipated! One of the things that was pointed out, though, is that <a href=\"http://www.rascal-mpl.org\">Rascal is a language that already exists</a>. Given that the name “Rascal” came from a mixture of “Racket” and “Haskell”, I always had an alternative named planned, and that’s “Hackett”. So, to avoid confusion as much as possible, <a href=\"https://github.com/lexi-lambda/hackett\"><strong>Rascal is now known as Hackett</strong></a>.\n</p><p>With that out of the way, I also want to answer some of the other questions I received, both to hopefully clear up some confusion and to have something I can point to if I get the same questions in the future.\n</p><h2><a name=\"what-s-in-a-name\"></a>What’s in a name?</h2><p>First, a little trivia.\n</p><p>I’ve already mentioned that the old “Rascal” name was based on the names “Racket” and “Haskell”, which is true. However, it had a slightly deeper meaning, too: the name fit a tradition of naming languages in the Scheme family after somewhat nefarious things, such as “Gambit”, “Guile”, “Larceny”, and “Racket” itself. The name goes back a little bit further to the Planner programming language; Scheme was originally called Schemer, but it was (no joke) shorted due to filename length restrictions.\n</p><p>Still, my language isn’t really a Scheme, so the weak connection wasn’t terribly relevant. Curious readers might be wondering if there’s any deeper meaning to the name “Hackett” than a mixture of the two language names. In fact, there is. Hackett is affectionately named after the <a href=\"https://en.wikipedia.org/wiki/Steve_Hackett\">Genesis progressive rock guitarist, Steve Hackett</a>, one of my favorite musicians. The fact that the name is a homophone with “hack-it” is another convenient coincidence.\n</p><p>Perhaps not the most interesting thing in this blog post, but there it is.\n</p><h2><a name=\"why-racket-why-not-haskell\"></a>Why Racket? Why <em>not</em> Haskell?</h2><p>One of the most common questions I received is why I used Racket as the implementation language instead of Haskell. This is a decent question, and I think it likely stems at least in part from an item of common confusion: <strong>Racket is actually two things, a programming language and a programming language platform</strong>. The fact that the two things have the same name is probably not ideal, but it’s what we’ve got.\n</p><p>Racket-the-language is obviously the primary language used on the Racket platform, but there’s actually surprisingly little need for that to be the case; it’s simply the language that is worked on the most. Much of the Racket tooling, including the compiler, macroexpander, and IDE, are actually totally language agnostic. If someone came along and wrote a language that got more popular than <code>#lang racket</code>, then there wouldn’t really be anything hardcoded into any existing tooling that would give the impression that <code>#lang racket</code> was ever the more “dominant” language, aside from the name.\n</p><p>For this reason, Racket is ideal for implementing new programming languages, moreso than pretty much any other platform out there. The talk I linked to in the previous blog post, <a href=\"https://www.youtube.com/watch?v=TfehOLha-18\">Languages in an Afternoon</a>, describes this unique capability. It’s short, only ~15 minutes, but if you’re not into videos, I can try and explain why Racket is so brilliant for this sort of thing.\n</p><p>By leveraging the Racket platform instead of implementing my language from scratch, I get the following things pretty much for free:\n</p><ol><li><p>I get a JIT compiler for my code, and I don’t have to implement a compiler myself.\n</p></li><li><p>I also get a package manager that can cooperate with Hackett code to deliver Hackett modules.\n</p></li><li><p>I get a documentation system that is fully indexed and automatically locally installed when you install Hackett or any package written in Hackett, and that documentation is automatically integrated with the editor.\n</p></li><li><p>The DrRacket IDE can be used out of the box with Hackett code, it automatically does syntax highlighting and indenting, and it even provides interactive tools for inspecting bindings (something that I demo in my aforementioned talk).\n</p></li><li><p>If you don’t want to use DrRacket, you can use the <a href=\"https://github.com/greghendershott/racket-mode\">racket-mode</a> major mode for Emacs, which uses the same sets of tools that DrRacket uses under the hood, so you get most of the same DrRacket goodies without sacrificing Emacs’s power of customization.\n</p></li></ol><p>Reimplementing all of that in another language would take years of work, and I haven’t even mentioned Racket’s module system and macroexpander, which are the underpinnings of Hackett. GHC’s typechecker is likely roughly as complex as Racket’s macroexpander combined with its module system, but I am not currently implementing GHC’s typechecker, since I do not need all of OutsideIn(X)’s features, just Haskell 98 + some extensions.\n</p><p>In contrast, I truly do need all of the Racket macroexpander to implement Hackett, since the <em>Type Systems as Macros</em> paper uses pretty much every trick the Racket macro system has to offer to implement typechecking as macroexpansion. For those reasons, implementing the Racket macroexpander <strong>alone</strong> in Haskell would likely be monumentally more work than implementing a Hindley-Milner typechecker in Racket, so it doesn’t really make sense to use Haskell for that job.\n</p><h3><a name=\"actually-running-hackett-code\"></a>Actually running Hackett code</h3><p>Now, it’s worth noting that GHC is much more efficient as a compiler than Racket is, for a whole host of reasons. However, since typechecking and macroexpansion are inherently strictly compile-time phases, it turns out to be totally feasible to run the typechecker/macroexpander in Racket (since in Hackett, the two things are one and the same), then compile the resulting fully-expanded, well-typed code to GHC Core. That could then be handed off to GHC itself and compiled using the full power of the GHC optimizer and compiler toolchain.\n</p><p>This would be no small amount of work, but it seems theoretically possible, so eventually it’s something I’d love to look into. There are various complexities to making it work, but I think it would let me get the best of both worlds without reinventing the wheel, so it’s something I want long-term.\n</p><p>There’s also the question of how “native” Hackett code would be, were it compiled to GHC Core. Would Hackett code be able to use Haskell libraries, and vice versa? My guess is that the answer is “yes, with some glue”. It probably wouldn’t be possible to do it completely seamlessly, because Hackett provides type information at macroexpansion time that likely wouldn’t exist in the same form in GHC. It might be possible to do some incredibly clever bridging to be able to use Haskell libraries in Hackett almost directly, but the inverse might not be true if a library’s interface depends on macros.\n</p><h2><a name=\"how-do-template-haskell-quasiquoters-compete-with-macros\"></a>How do Template Haskell quasiquoters compete with macros?</h2><p>Quasiquoters have a number of drawbacks, but the two main ones are complexity and lack of composition.\n</p><p>S-expressions happen to be simple, and this means s-expression macros have two lovely properties: they’re easy to write, given good libraries (Racket has <a href=\"http://docs.racket-lang.org/syntax/stxparse.html\"><code>syntax/parse</code></a>), and they’re easy for tools to understand. Quasiquoters force implementors to write their own parsers from raw strings of characters, which is quite a heavy burden, and it usually means those syntaxes are confusing and brittle. To give a good example, consider <a href=\"http://www.yesodweb.com/book/persistent#persistent_code_generation\">persistent’s quasiquoters</a>: they look <em>sort of</em> like Haskell data declarations, but they’re not really, and I honestly have no idea what their actual syntax really is. It feels pretty finicky, though. In contrast, an s-expression based version of the same syntax would basically look just like the usual datatype declaration form, plus perhaps some extra goodies.\n</p><p>Additionally, s-expression macros <em>compose</em>, and this should probably be valued more than anything else. If you’re writing code that doesn’t compose, it’s usually a bad sign. So much of functional programming is about writing small, reusable pieces of code that can be composed together, and macros are no different. Racket’s <code>match</code>, for example, is an expression, and it contains expressions, so <code>match</code> can be nested within itself, as well as other arbitrary macros that produce expressions. Similarly, many Racket macros can be extended, which is possible due to having such uniform syntax.\n</p><p>Making macros “stand out” is an issue of some subjectivity, but in my experience such a fear of macros tends to stem from a familiarity with bad macro systems (which, to be fair, is almost all of them) and poor tooling. I’ve found that, in practice, most of the reasons people want to know “is this a macro??” is because macros are scary black boxes and people want to know which things to be suspicious of.\n</p><p>Really, though, one of the reasons macros are complicated isn’t knowing which things are macros, but it’s knowing <em>which identifiers are uses and which identifiers are bindings</em>, and things like that. Just knowing that something is a macro use doesn’t actually help at all there—the syntax won’t tell you. <a href=\"http://i.imgur.com/HvYee19.png\">Solve that problem with tools that address the problem head on, not by making a syntax that makes macros second-class citizens.</a> One of the reasons I used the phrase “syntactic abstractions” in my previous blog post is because you specifically want them to be <strong>abstractions</strong>. If you have to think of a macro in terms of the thing it expands to then it isn’t a very watertight abstraction. You don’t think about Haskell pattern-matching in terms of what the patterns compile to, you just use them. Macros should be (and can be) just as fluid.\n</p><h2><a name=\"how-can-i-help\"></a>How can I help?</h2><p>Right now, what I really need is someone who understands type system implementation. You don’t need to be up to date on what’s cutting edge—I’m not implementing anything nearly as complicated as GADTs or dependent types yet—you just need to understand how to implement Haskell 98. If you have that knowledge and you’re interested in helping, even if it just means answering some of my questions, please contact me via email, IRC (the #racket channel on Freenode is a good place for now), or Slack (I’m active in the snek Slack community, <a href=\"http://snek.jneen.net\">which you can sign up for here</a>).\n</p><p>If you aren’t familiar with those things, but you’re still interested in helping out, there’s definitely plenty of work that needs doing. If you want to find somewhere you can pitch in, contacting me via any of the above means is totally fine, and I can point you in the right direction. Even if you just want to be a guinea pig, that’s useful.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Since I published my blog post introducing Rascal, I’ve gotten some amazing feedback, more than I had ever anticipated! One of the things that was pointed out, though, is that Rascal is a language that already exists. Given that the name “Rascal” came from a mixture of “Racket” and “Haskell”, I always had an alternative named planned, and that’s “Hackett”. So, to avoid confusion as much as possible, Rascal is now known as Hackett.\n\nWith that out of the way, I also want to answer some of the other questions I received, both to hopefully clear up some confusion and to have something I can point to if I get the same questions in the future.\n\nWhat’s in a name?\nFirst, a little trivia.\n\nI’ve already mentioned that the old “Rascal” name was based on the names “Racket” and “Haskell”, which is true. However, it had a slightly deeper meaning, too: the name fit a tradition of naming languages in the Scheme family after somewhat nefarious things, such as “Gambit”, “Guile”, “Larceny”, and “Racket” itself. The name goes back a little bit further to the Planner programming language; Scheme was originally called Schemer, but it was (no joke) shorted due to filename length restrictions.\n\nStill, my language isn’t really a Scheme, so the weak connection wasn’t terribly relevant. Curious readers might be wondering if there’s any deeper meaning to the name “Hackett” than a mixture of the two language names. In fact, there is. Hackett is affectionately named after the Genesis progressive rock guitarist, Steve Hackett, one of my favorite musicians. The fact that the name is a homophone with “hack-it” is another convenient coincidence.\n\nPerhaps not the most interesting thing in this blog post, but there it is.\n\nWhy Racket? Why not Haskell?\nOne of the most common questions I received is why I used Racket as the implementation language instead of Haskell. This is a decent question, and I think it likely stems at least in part from an item of common confusion: Racket is actually two things, a programming language and a programming language platform. The fact that the two things have the same name is probably not ideal, but it’s what we’ve got.\n\nRacket-the-language is obviously the primary language used on the Racket platform, but there’s actually surprisingly little need for that to be the case; it’s simply the language that is worked on the most. Much of the Racket tooling, including the compiler, macroexpander, and IDE, are actually totally language agnostic. If someone came along and wrote a language that got more popular than #lang racket, then there wouldn’t really be anything hardcoded into any existing tooling that would give the impression that #lang racket was ever the more “dominant” language, aside from the name.\n\nFor this reason, Racket is ideal for implementing new programming languages, moreso than pretty much any other platform out there. The talk I linked to in the previous blog post, Languages in an Afternoon, describes this unique capability. It’s short, only ~15 minutes, but if you’re not into videos, I can try and explain why Racket is so brilliant for this sort of thing.\n\nBy leveraging the Racket platform instead of implementing my language from scratch, I get the following things pretty much for free:\n\n\nI get a JIT compiler for my code, and I don’t have to implement a compiler myself.\n\n\nI also get a package manager that can cooperate with Hackett code to deliver Hackett modules.\n\n\nI get a documentation system that is fully indexed and automatically locally installed when you install Hackett or any package written in Hackett, and that documentation is automatically integrated with the editor.\n\n\nThe DrRacket IDE can be used out of the box with Hackett code, it automatically does syntax highlighting and indenting, and it even provides interactive tools for inspecting bindings (something that I demo in my aforementioned talk).\n\n\nIf you don’t want to use DrRacket, you can use the racket-mode major mode for Emacs, which uses the same sets of tools that DrRacket uses under the hood, so you get most of the same DrRacket goodies without sacrificing Emacs’s power of customization.\n\n\nReimplementing all of that in another language would take years of work, and I haven’t even mentioned Racket’s module system and macroexpander, which are the underpinnings of Hackett. GHC’s typechecker is likely roughly as complex as Racket’s macroexpander combined with its module system, but I am not currently implementing GHC’s typechecker, since I do not need all of OutsideIn(X)’s features, just Haskell 98 + some extensions.\n\nIn contrast, I truly do need all of the Racket macroexpander to implement Hackett, since the Type Systems as Macros paper uses pretty much every trick the Racket macro system has to offer to implement typechecking as macroexpansion. For those reasons, implementing the Racket macroexpander alone in Haskell would likely be monumentally more work than implementing a Hindley-Milner typechecker in Racket, so it doesn’t really make sense to use Haskell for that job.\n\nActually running Hackett code\nNow, it’s worth noting that GHC is much more efficient as a compiler than Racket is, for a whole host of reasons. However, since typechecking and macroexpansion are inherently strictly compile-time phases, it turns out to be totally feasible to run the typechecker/macroexpander in Racket (since in Hackett, the two things are one and the same), then compile the resulting fully-expanded, well-typed code to GHC Core. That could then be handed off to GHC itself and compiled using the full power of the GHC optimizer and compiler toolchain.\n\nThis would be no small amount of work, but it seems theoretically possible, so eventually it’s something I’d love to look into. There are various complexities to making it work, but I think it would let me get the best of both worlds without reinventing the wheel, so it’s something I want long-term.\n\nThere’s also the question of how “native” Hackett code would be, were it compiled to GHC Core. Would Hackett code be able to use Haskell libraries, and vice versa? My guess is that the answer is “yes, with some glue”. It probably wouldn’t be possible to do it completely seamlessly, because Hackett provides type information at macroexpansion time that likely wouldn’t exist in the same form in GHC. It might be possible to do some incredibly clever bridging to be able to use Haskell libraries in Hackett almost directly, but the inverse might not be true if a library’s interface depends on macros.\n\nHow do Template Haskell quasiquoters compete with macros?\nQuasiquoters have a number of drawbacks, but the two main ones are complexity and lack of composition.\n\nS-expressions happen to be simple, and this means s-expression macros have two lovely properties: they’re easy to write, given good libraries (Racket has syntax/parse), and they’re easy for tools to understand. Quasiquoters force implementors to write their own parsers from raw strings of characters, which is quite a heavy burden, and it usually means those syntaxes are confusing and brittle. To give a good example, consider persistent’s quasiquoters: they look sort of like Haskell data declarations, but they’re not really, and I honestly have no idea what their actual syntax really is. It feels pretty finicky, though. In contrast, an s-expression based version of the same syntax would basically look just like the usual datatype declaration form, plus perhaps some extra goodies.\n\nAdditionally, s-expression macros compose, and this should probably be valued more than anything else. If you’re writing code that doesn’t compose, it’s usually a bad sign. So much of functional programming is about writing small, reusable pieces of code that can be composed together, and macros are no different. Racket’s match, for example, is an expression, and it contains expressions, so match can be nested within itself, as well as other arbitrary macros that produce expressions. Similarly, many Racket macros can be extended, which is possible due to having such uniform syntax.\n\nMaking macros “stand out” is an issue of some subjectivity, but in my experience such a fear of macros tends to stem from a familiarity with bad macro systems (which, to be fair, is almost all of them) and poor tooling. I’ve found that, in practice, most of the reasons people want to know “is this a macro??” is because macros are scary black boxes and people want to know which things to be suspicious of.\n\nReally, though, one of the reasons macros are complicated isn’t knowing which things are macros, but it’s knowing which identifiers are uses and which identifiers are bindings, and things like that. Just knowing that something is a macro use doesn’t actually help at all there—the syntax won’t tell you. Solve that problem with tools that address the problem head on, not by making a syntax that makes macros second-class citizens. One of the reasons I used the phrase “syntactic abstractions” in my previous blog post is because you specifically want them to be abstractions. If you have to think of a macro in terms of the thing it expands to then it isn’t a very watertight abstraction. You don’t think about Haskell pattern-matching in terms of what the patterns compile to, you just use them. Macros should be (and can be) just as fluid.\n\nHow can I help?\nRight now, what I really need is someone who understands type system implementation. You don’t need to be up to date on what’s cutting edge—I’m not implementing anything nearly as complicated as GADTs or dependent types yet—you just need to understand how to implement Haskell 98. If you have that knowledge and you’re interested in helping, even if it just means answering some of my questions, please contact me via email, IRC (the #racket channel on Freenode is a good place for now), or Slack (I’m active in the snek Slack community, which you can sign up for here).\n\nIf you aren’t familiar with those things, but you’re still interested in helping out, there’s definitely plenty of work that needs doing. If you want to find somewhere you can pitch in, contacting me via any of the above means is totally fine, and I can point you in the right direction. Even if you just want to be a guinea pig, that’s useful.","isoDate":"2017-01-05T00:00:00.000Z","timestamp":"1/4/2017"},{"title":"Rascal: a Haskell with more parentheses","pubDate":"2017-01-02T00:00:00.000Z","author":"Alexis King","content":"<article><blockquote><p><strong>Note</strong>: since the writing of this blog post, Rascal has been renamed to Hackett. You can read about why in <a href=\"/blog/2017/01/05/rascal-is-now-hackett-plus-some-answers-to-questions/\">the followup blog post</a>.\n</p></blockquote><p>“Hey! You got your Haskell in my Racket!”\n</p><p>“No, you got <em>your</em> Racket in <em>my</em> Haskell!”\n</p><p>Welcome to the <a href=\"https://github.com/lexi-lambda/hackett\">Rascal</a> programming language.\n</p><h2><a name=\"why-rascal\"></a>Why Rascal?</h2><p>Why yet <em>another</em> programming language? Anyone who knows me knows that I already have two programming languages that I <em>really</em> like: Haskell and Racket. Really, I think they’re both great! Each brings some things to the table that aren’t really available in any other programming language I’ve ever used.\n</p><p>Haskell, in many ways, is a programming language that fits my mental model of how to structure programs better than any other programming language I’ve used. Some people would vehemently disagree, and it seems that there is almost certainly some heavy subjectivity in how people think about programming. I think Haskell’s model is awesome once you get used to it, though, but this blog post is not really going to try and convince you why you should care about Haskell (though that <em>is</em> something I want to write at some point). What you <em>should</em> understand, though, is that to me, Haskell is pretty close to what I want in a programming language.\n</p><p>At the same time, though, Haskell has problems, and a lot of that revolves around its story for metaprogramming. “Metaprogramming” is another M word that people seem to be very afraid of, and for good reason: most metaprogramming systems are ad-hoc, unsafe, unpredictable footguns that require delicate care to use properly, and <em>even then</em> the resulting code is brittle and difficult to understand. Haskell doesn’t suffer from this problem as much as some languages, but it isn’t perfect by any means: Haskell has at least two different metaprogramming systems (generics and Template Haskell) that are designed for different tasks, but they’re both limited in scope and both tend to be pretty complicated to use.\n</p><p>Discussing the merits and drawbacks of Haskell’s various metaprogramming capabilities is also outside the scope of this blog post, but there’s one <em>fact</em> that I want to bring up, which is that <strong>Haskell does not provide any mechanism for adding syntactic abstractions to the language</strong>. What do I mean by this? Well, in order to understand what a “syntactic abstraction” is and why you should care about it, I want to shift gears a little and take a look at why Racket is so amazing.\n</p><h3><a name=\"a-programmable-programming-language-theory-and-practice\"></a>A programmable programming language: theory and practice</h3><p>I feel confident in saying that Racket has <em>the</em> most advanced macro system in the world, and it is pretty much unparalleled in that space. There are many languages with powerful type systems, but Racket is more or less alone in many of the niches it occupies. Racket has a large number of innovations that I don’t know of in any other programming language, and a significant portion of them focus on making Racket a <a href=\"http://www.ccs.neu.edu/home/matthias/manifesto/\">programmable programming language, a language for building languages</a>.\n</p><p>This lofty goal is backed up by decades of research, providing Racket with an unparalleled toolkit for creating languages that can communicate, be extended, and even cooperate with tooling to provide introspection and error diagnostics. Working in Haskell feels like carefully designing a mould that cleanly and precisely fits your domain, carefully carving, cutting, and whittling. In contrast, working with Racket feels like moulding your domain until it looks the way <em>you</em> want it to look, poking and prodding at a pliable substrate. The sheer <em>ease</em> of it all is impossible for me to convey in words, so <a href=\"https://twitter.com/andmkent_/status/724036694773628930\">you will have to see it for yourself</a>.\n</p><p>All this stuff is super abstract, though. What does it mean for practical programming, and why should you care? Well, I’m not going to try and sell you if you’re extremely skeptical, but if you’re interested, <a href=\"https://www.youtube.com/watch?v=TfehOLha-18\">I gave a talk on some of Racket’s linguistic capabilities last year called <em>Languages in an Afternoon</em></a>. If you’re curious, give it a watch, and you might find yourself (hopefully) a little impressed. If you prefer reading, well, I have some <a href=\"/blog/2015/12/21/adts-in-typed-racket-with-macros/\">blog posts</a> on this very blog that <a href=\"/blog/2015/08/30/managing-application-configuration-with-envy/\">demonstrate what Racket can do</a>.\n</p><p>The basic idea, though, is that by having a simple syntax and a powerful macro system with a formalization of lexical scope, users can effectively invent entirely new language constructs as ordinary libraries, constructs that would have to be core forms in other programming languages. For example, Racket supports pattern-matching, but it isn’t built into the compiler: it’s simply implemented in the <code>racket/match</code> module distributed with Racket. Not only is it defined in ordinary Racket code, it’s actually <em>extensible</em>, so users can add their own pattern-matching forms that cooperate with <code>match</code>.\n</p><p>This is the power of a macro system to produce “syntactic abstractions”, things that can transform the way a user thinks of the code they’re writing. Racket has the unique capability of making these abstractions both easy to write and watertight, so instead of being a scary tool you have to handle with extreme care, you can easily whip up a powerful, user-friendly embedded domain specific language in a matter of <em>minutes</em>, and it’ll be safe, provide error reporting for misuse, and cooperate with existing tooling pretty much out of the box.\n</p><h3><a name=\"fusing-haskell-and-racket\"></a>Fusing Haskell and Racket</h3><p>So, let’s assume that we <em>do</em> want Haskell’s strong type system and that we <em>also</em> want a powerful metaprogramming model that permits syntactic extensions. What would that look like? Well, one way we could do it is to put one in front of the other: macro expansion is, by nature, a compile-time pass, so we could stick a macroexpander in front of the typechecker. This leads to a simple technique: first, macroexpand the program to erase the macros, then typecheck it and erase the types, then send the resulting code off to be compiled. This technique has the following properties:\n</p><ol><li><p>First of all, <strong>it’s easy to implement</strong>. Racket’s macroexpander, while complex, is well-documented in academic literature and works extremely well in practice. In fact, this strategy has already been implemented! Typed Racket, the gradually-typed sister language of Racket, expands every program before typechecking. It would be possible to effectively create a “Lisp-flavored Haskell” by using this technique, and it might not even be that hard.\n</p></li><li><p>Unfortunately, there’s a huge problem with this approach: <strong>type information is not available at macroexpansion time</strong>. This is the real dealbreaker with the “expand, then typecheck” model, since static type information is some of the most useful information possibly available to a macro writer. In an ideal world, macros should not only have access to type information, they should be able to manipulate it and metaprogram the typechecker as necessary, but if macroexpansion is a separate phase from typechecking, then that information simply doesn’t exist yet.\n</p></li></ol><p>For me, the second option is unacceptable. I am <em>not</em> satisfied by a “Lisp-flavored Haskell”; I want my types and macros to be able to cooperate and communicate with each other. The trouble, though, is that solving that problem is really, really hard! For a couple years now, I’ve been wishing this ideal language existed, but I’ve had no idea how to make it actually work. Template Haskell implements a highly restricted system of interweaving typechecking and splice evaluation, but it effectively does it by running the typechecker and the splice expander alternately, splitting the source into chunks and typechecking them one at a time. This works okay for Template Haskell, but for the more powerful macro system I am looking for, it wouldn’t scale.\n</p><p>There’s something a little bit curious, though, about the problem as I just described it. The processes of “macroexpanding the program to erase the macros” and “typechecking the program to erase the types” sound awfully similar. It seems like maybe these are two sides of the same coin, and it would be wonderful if we could encode one in terms of the other, effectively turning the two passes into a single, unified pass. Unfortunately, while this sounds great, I had no idea how to do this (and it didn’t help that I really had no idea how existing type systems were actually implemented).\n</p><p>Fortunately, last year, Stephen Chang, Alex Knauth, and Ben Greenman put together a rather exciting paper called <a href=\"http://www.ccs.neu.edu/home/stchang/popl2017/\"><em>Type Systems as Macros</em></a>, which does precisely what I just described, and it delivers it all in a remarkably simple and elegant presentation. The idea is to “distribute” the task of typechecking over the individual forms of the language, leveraging existing macro communication facilities avaiable in the Racket macroexpander to propagate type information as macros are expanded. To me, it was exactly what I was looking for, and I almost immediately started playing with it and seeing what I could do with it.\n</p><p>The result is <a href=\"https://github.com/lexi-lambda/hackett\"><em>Rascal</em></a>, a programming language built in the Racket ecosystem that attempts to implement a Haskell-like type system.\n</p><h2><a name=\"a-first-peek-at-rascal\"></a>A first peek at Rascal</h2><p>Rascal is a very new programming language I’ve only been working on over the past few months. It is extremely experimental, riddled with bugs, half-baked, and may turn your computer into scrambled eggs. Still, while I might not recommend that you actually <em>use</em> it just yet, I want to try and share what it is I’m working on, since I’d bet at least a few other people will find it interesting, too.\n</p><p>First, let me say this up front: <strong>Rascal is probably a lot closer to Haskell than Racket</strong>. That might come as a surprise, given that Rascal has very Lisp-y syntax, it’s written in Racket, and it runs on the Racket platform, but semantically, Rascal is mostly just Haskell 98. This is important, because it may come as a surprise, given that there are so few statically typed Lisps, but there’s obviously no inherent reason that Lisps need to be dynamically typed. They just seem to have mostly evolved that way.\n</p><p>Taking a look at a snippet of Rascal code, it’s easy to see that the language doesn’t work quite like a traditional Lisp, though:<sup><a id=\"footnote-ref-1-1\" href=\"#footnote-1\">1</a></sup>\n</p><pre><code>(def+ map-every-other : (forall [a] {{a -&gt; a} -&gt; (List a) -&gt; (List a)})\n  [_ nil            -&gt; nil]\n  [_ {x :: nil}     -&gt; {x :: nil}]\n  [f {x :: y :: ys} -&gt; {x :: (f y) :: (map-every-other f ys)}])\n</code></pre><p>This is a Lisp with all the goodies you would expect out of Haskell: static types, parametric polymorphism, automatically curried functions, algebraic datatypes, pattern-matching, infix operators, and of course, <em>typeclasses</em>. Yes, with Rascal you can have your monads in all their statically dispatched glory:\n</p><pre><code>(data (Maybe a)\n  (just a)\n  nothing)\n\n(instance (Monad Maybe)\n  [join (case-lambda\n          [(just (just x)) (just x)]\n          [_               nothing])])\n</code></pre><p>So far, though, this really <em>is</em> just “Haskell with parentheses”. As alluded to above, however, Rascal is a bit more than that.\n</p><h3><a name=\"core-forms-can-be-implemented-as-derived-concepts\"></a>Core forms can be implemented as derived concepts</h3><p>Rascal’s type system is currently very simple, being nothing more than Hindley-Milner plus ad-hoc polymorphism in the form of typeclasses. Something interesting to note about it is that it does not implement ADTs or pattern-matching anywhere in the core! In fact, ADTs are defined as two macros <code>data</code> and <code>case</code>, in an entirely separate module, which can be imported just like any other library.\n</p><p>The main <code>rascal</code> language provides ADTs by default, of course, but it would be perfectly possible to produce a <code>rascal/kernel</code> language which does not include them at all. In this particular case, it seems unlikely that Rascal programmers would want their own implementation of ADTs, but it’s an interesting proof of concept, and it hints at other “core” features that could be implemented using macros.\n</p><p>Simple syntactic transformations are, of course, trivially defined as macros. Haskell <code>do</code> notation is defined as <a href=\"https://github.com/lexi-lambda/hackett/blob/87d001a82c86fb66544d25c37ffba9be1ac63464/rascal-lib/rascal/monad.rkt#L48-L58\">an eleven-line macro in <code>rascal/monad</code></a>, and GHC’s useful <code>LambdaCase</code> extension is also possible to implement without modifying Rascal at all. This is useful, because there are many syntactic shorthands that are extremely useful to implement, but don’t make any sense to be in GHC because they are specific to certain libraries or applications. Racket’s macro system makes those not only possible, but actually pretty easy.\n</p><p>While the extent of what is possible to implement as derived forms remains to be seen, many useful GHC features seem quite possible to implement without touching the core language, including things like <code>GeneralizedNewtypeDeriving</code> and other generic deriving mechanisms like <code>GHC.Generics</code>, <code>DeriveGeneric</code>, and <code>DeriveAnyClass</code>.\n</p><h3><a name=\"the-language-is-not-enough\"></a>The language is not enough</h3><p>No language is perfect. Most people would agree with this, but I would take it a step further: no language is even sufficient! This makes a lot of sense, given that general-purpose programming languages are designed to do <em>everything</em>, and it’s impossible to do everything well.\n</p><p>Haskell programmers know this, and they happily endorse the creation of embedded domain specific languages. These are fantastic, and we need more of them. Things like <a href=\"http://hackage.haskell.org/package/servant\">servant</a> let me write a third of the code I might otherwise need to, and the most readable code is the code you didn’t have to write in the first place. DSLs are good.\n</p><p>Unfortunately, building DSLs is traditionally difficult, largely in part because building embedded DSLs means figuring out a way to encode your domain into your host language of choice. Sometimes, your domain simply does not elegantly map to your host language’s syntax or semantics, and you have to come up with a compromise. This is easy to see with servant, which, while it does a remarkably good job, still has to resort to some very clever type magic to create some semblance of an API description in Haskell types:\n</p><pre><code>type UserAPI = \"users\" :&gt; Get '[JSON] [User]\n          :&lt;|&gt; \"users\" :&gt; ReqBody '[JSON] User :&gt; Post '[JSON] User\n          :&lt;|&gt; \"users\" :&gt; Capture \"userid\" Integer\n                       :&gt; Get '[JSON] User\n          :&lt;|&gt; \"users\" :&gt; Capture \"userid\" Integer\n                       :&gt; ReqBody '[JSON] User\n                       :&gt; Put '[JSON] User\n</code></pre><p>The above code is <em>remarkably</em> readable for what it is, but what if we didn’t have to worry about working within the constraints of Haskell’s syntax? What if we could design a syntax that was truly the best for the job? Perhaps we would come up with something like this:\n</p><pre><code>(define-api User-API\n  #:content-types [JSON]\n  [GET  \"users\"                    =&gt; (List User)]\n  [POST \"users\"                    =&gt; User -&gt; User]\n  [GET  \"users\" [userid : Integer] =&gt; User]\n  [PUT  \"users\" [userid : Integer] =&gt; User -&gt; User])\n</code></pre><p>This would be extremely easy to write with Racket’s macro-writing utilities, and it could even be made extensible. This could also avoid having to do the complicated typeclass trickery servant has to perform to then generate code from the above specification, since it would be much easier to just generate the necessary code directly (which still maintaining type safety).\n</p><p>In addition to the type-level hacks that Haskell programmers often have to pull in order to make these kinds of fancy DSLs work, free monads tend to be used to create domain-specific languages. This works okay for some DSLs, but remember that when you use a free monad, you are effectively writing a <em>runtime interpreter</em> for your language! Macros, on the other hand, are compiled, and you get ability to <em>compile</em> your DSL to code that can be optimized by all the existing facilities of the compiler toolchain.\n</p><h2><a name=\"rascal-is-embryonic\"></a>Rascal is embryonic</h2><p>I’m pretty excited about Rascal. I think that it could have the potential to do some pretty interesting things, and I have some ideas in my head for how having macros in a Haskell-like language could change things. I also think that, based on what I’ve seen so far, having both macros and a Haskell-like type system could give rise to <em>completely</em> different programming paradigms than exist in either Haskell or Racket today. My gut tells me that this is a case where the whole might actually be greater than the sum of its parts.\n</p><p>That said, Rascal doesn’t really exist yet. Yes, <a href=\"https://github.com/lexi-lambda/hackett\">there is a GitHub repository</a>, and it has some code in it that does… something. Unfortunately, the code is also currently extremely buggy, to the point of being borderline broken, and it’s also in such early stages that you can’t really do <em>anything</em> interesting with it, aside from some tiny toy programs.\n</p><p>As I have worked on Rascal, I’ve come to a somewhat unfortunate conclusion, which is that I really have almost zero interest in implementing type systems. I felt that way before I started the project, but I was hoping that maybe once I got into them, I would find them more interesting. Unfortunately, as much as I love working with powerful type systems (and really, I adore working with Haskell and using all the fancy features GHC provides), I find implementing the software that makes them tick completely dull.\n</p><p>Still, I’m willing to invest the time to get something that I can use. Even so, resources for practical type system implementation are scarce. I want to thank <a href=\"https://web.cecs.pdx.edu/~mpj/\">Mark P Jones</a> for his wonderful resource <a href=\"https://web.cecs.pdx.edu/~mpj/thih/\">Typing Haskell in Haskell</a>, without which getting to where I am now would likely have been impossible. I also want to thank <a href=\"http://www.stephendiehl.com\">Stephen Diehl</a> for his wonderful <a href=\"http://dev.stephendiehl.com/fun/\">Write You a Haskell</a> series, which was also wonderfully useful to study, even if it is unfinished and doesn’t cover anything beyond ML just yet.\n</p><p>Even with these wonderful resources, I’ve come to the realization that <strong>I probably can’t do all of this on my own</strong>. I consider myself pretty familiar with macros and macro expanders at this point, but I don’t know much about type systems (at least not their implementation), and I could absolutely use some help. So if you’re interested in Rascal and think you might be able to pitch in, please: I would appreciate even the littlest bits of help or guidance!\n</p><p>In the meantime, I will try to keep picking away at Rascal in the small amount of free time I currently have. Thanks, as always, to all the amazing people who have contributed to the tools I’ve been using for this project: special thanks to the authors of <em>Type Systems as Macros</em> for their help as well as the people I mentioned just above, and also to all of the people who have built Racket and Haskell and made them what they are today. Without them, Rascal would most definitely not exist.\n</p><ol class=\"footnotes\"><li id=\"footnote-1\"><p>Note that most of the Rascal code in this blog post probably doesn’t actually work on the current Rascal implementation. Pretty much all of it can be implemented in the current implementation, the syntax just isn’t quite as nice yet.\n <a href=\"#footnote-ref-1-1\">↩</a></p></li></ol></article>","contentSnippet":"Note: since the writing of this blog post, Rascal has been renamed to Hackett. You can read about why in the followup blog post.\n\n“Hey! You got your Haskell in my Racket!”\n\n“No, you got your Racket in my Haskell!”\n\nWelcome to the Rascal programming language.\n\nWhy Rascal?\nWhy yet another programming language? Anyone who knows me knows that I already have two programming languages that I really like: Haskell and Racket. Really, I think they’re both great! Each brings some things to the table that aren’t really available in any other programming language I’ve ever used.\n\nHaskell, in many ways, is a programming language that fits my mental model of how to structure programs better than any other programming language I’ve used. Some people would vehemently disagree, and it seems that there is almost certainly some heavy subjectivity in how people think about programming. I think Haskell’s model is awesome once you get used to it, though, but this blog post is not really going to try and convince you why you should care about Haskell (though that is something I want to write at some point). What you should understand, though, is that to me, Haskell is pretty close to what I want in a programming language.\n\nAt the same time, though, Haskell has problems, and a lot of that revolves around its story for metaprogramming. “Metaprogramming” is another M word that people seem to be very afraid of, and for good reason: most metaprogramming systems are ad-hoc, unsafe, unpredictable footguns that require delicate care to use properly, and even then the resulting code is brittle and difficult to understand. Haskell doesn’t suffer from this problem as much as some languages, but it isn’t perfect by any means: Haskell has at least two different metaprogramming systems (generics and Template Haskell) that are designed for different tasks, but they’re both limited in scope and both tend to be pretty complicated to use.\n\nDiscussing the merits and drawbacks of Haskell’s various metaprogramming capabilities is also outside the scope of this blog post, but there’s one fact that I want to bring up, which is that Haskell does not provide any mechanism for adding syntactic abstractions to the language. What do I mean by this? Well, in order to understand what a “syntactic abstraction” is and why you should care about it, I want to shift gears a little and take a look at why Racket is so amazing.\n\nA programmable programming language: theory and practice\nI feel confident in saying that Racket has the most advanced macro system in the world, and it is pretty much unparalleled in that space. There are many languages with powerful type systems, but Racket is more or less alone in many of the niches it occupies. Racket has a large number of innovations that I don’t know of in any other programming language, and a significant portion of them focus on making Racket a programmable programming language, a language for building languages.\n\nThis lofty goal is backed up by decades of research, providing Racket with an unparalleled toolkit for creating languages that can communicate, be extended, and even cooperate with tooling to provide introspection and error diagnostics. Working in Haskell feels like carefully designing a mould that cleanly and precisely fits your domain, carefully carving, cutting, and whittling. In contrast, working with Racket feels like moulding your domain until it looks the way you want it to look, poking and prodding at a pliable substrate. The sheer ease of it all is impossible for me to convey in words, so you will have to see it for yourself.\n\nAll this stuff is super abstract, though. What does it mean for practical programming, and why should you care? Well, I’m not going to try and sell you if you’re extremely skeptical, but if you’re interested, I gave a talk on some of Racket’s linguistic capabilities last year called Languages in an Afternoon. If you’re curious, give it a watch, and you might find yourself (hopefully) a little impressed. If you prefer reading, well, I have some blog posts on this very blog that demonstrate what Racket can do.\n\nThe basic idea, though, is that by having a simple syntax and a powerful macro system with a formalization of lexical scope, users can effectively invent entirely new language constructs as ordinary libraries, constructs that would have to be core forms in other programming languages. For example, Racket supports pattern-matching, but it isn’t built into the compiler: it’s simply implemented in the racket/match module distributed with Racket. Not only is it defined in ordinary Racket code, it’s actually extensible, so users can add their own pattern-matching forms that cooperate with match.\n\nThis is the power of a macro system to produce “syntactic abstractions”, things that can transform the way a user thinks of the code they’re writing. Racket has the unique capability of making these abstractions both easy to write and watertight, so instead of being a scary tool you have to handle with extreme care, you can easily whip up a powerful, user-friendly embedded domain specific language in a matter of minutes, and it’ll be safe, provide error reporting for misuse, and cooperate with existing tooling pretty much out of the box.\n\nFusing Haskell and Racket\nSo, let’s assume that we do want Haskell’s strong type system and that we also want a powerful metaprogramming model that permits syntactic extensions. What would that look like? Well, one way we could do it is to put one in front of the other: macro expansion is, by nature, a compile-time pass, so we could stick a macroexpander in front of the typechecker. This leads to a simple technique: first, macroexpand the program to erase the macros, then typecheck it and erase the types, then send the resulting code off to be compiled. This technique has the following properties:\n\n\nFirst of all, it’s easy to implement. Racket’s macroexpander, while complex, is well-documented in academic literature and works extremely well in practice. In fact, this strategy has already been implemented! Typed Racket, the gradually-typed sister language of Racket, expands every program before typechecking. It would be possible to effectively create a “Lisp-flavored Haskell” by using this technique, and it might not even be that hard.\n\n\nUnfortunately, there’s a huge problem with this approach: type information is not available at macroexpansion time. This is the real dealbreaker with the “expand, then typecheck” model, since static type information is some of the most useful information possibly available to a macro writer. In an ideal world, macros should not only have access to type information, they should be able to manipulate it and metaprogram the typechecker as necessary, but if macroexpansion is a separate phase from typechecking, then that information simply doesn’t exist yet.\n\n\nFor me, the second option is unacceptable. I am not satisfied by a “Lisp-flavored Haskell”; I want my types and macros to be able to cooperate and communicate with each other. The trouble, though, is that solving that problem is really, really hard! For a couple years now, I’ve been wishing this ideal language existed, but I’ve had no idea how to make it actually work. Template Haskell implements a highly restricted system of interweaving typechecking and splice evaluation, but it effectively does it by running the typechecker and the splice expander alternately, splitting the source into chunks and typechecking them one at a time. This works okay for Template Haskell, but for the more powerful macro system I am looking for, it wouldn’t scale.\n\nThere’s something a little bit curious, though, about the problem as I just described it. The processes of “macroexpanding the program to erase the macros” and “typechecking the program to erase the types” sound awfully similar. It seems like maybe these are two sides of the same coin, and it would be wonderful if we could encode one in terms of the other, effectively turning the two passes into a single, unified pass. Unfortunately, while this sounds great, I had no idea how to do this (and it didn’t help that I really had no idea how existing type systems were actually implemented).\n\nFortunately, last year, Stephen Chang, Alex Knauth, and Ben Greenman put together a rather exciting paper called Type Systems as Macros, which does precisely what I just described, and it delivers it all in a remarkably simple and elegant presentation. The idea is to “distribute” the task of typechecking over the individual forms of the language, leveraging existing macro communication facilities avaiable in the Racket macroexpander to propagate type information as macros are expanded. To me, it was exactly what I was looking for, and I almost immediately started playing with it and seeing what I could do with it.\n\nThe result is Rascal, a programming language built in the Racket ecosystem that attempts to implement a Haskell-like type system.\n\nA first peek at Rascal\nRascal is a very new programming language I’ve only been working on over the past few months. It is extremely experimental, riddled with bugs, half-baked, and may turn your computer into scrambled eggs. Still, while I might not recommend that you actually use it just yet, I want to try and share what it is I’m working on, since I’d bet at least a few other people will find it interesting, too.\n\nFirst, let me say this up front: Rascal is probably a lot closer to Haskell than Racket. That might come as a surprise, given that Rascal has very Lisp-y syntax, it’s written in Racket, and it runs on the Racket platform, but semantically, Rascal is mostly just Haskell 98. This is important, because it may come as a surprise, given that there are so few statically typed Lisps, but there’s obviously no inherent reason that Lisps need to be dynamically typed. They just seem to have mostly evolved that way.\n\nTaking a look at a snippet of Rascal code, it’s easy to see that the language doesn’t work quite like a traditional Lisp, though:1\n\n(def+ map-every-other : (forall [a] {{a -> a} -> (List a) -> (List a)})\n  [_ nil            -> nil]\n  [_ {x :: nil}     -> {x :: nil}]\n  [f {x :: y :: ys} -> {x :: (f y) :: (map-every-other f ys)}])\n\nThis is a Lisp with all the goodies you would expect out of Haskell: static types, parametric polymorphism, automatically curried functions, algebraic datatypes, pattern-matching, infix operators, and of course, typeclasses. Yes, with Rascal you can have your monads in all their statically dispatched glory:\n\n(data (Maybe a)\n  (just a)\n  nothing)\n\n(instance (Monad Maybe)\n  [join (case-lambda\n          [(just (just x)) (just x)]\n          [_               nothing])])\n\nSo far, though, this really is just “Haskell with parentheses”. As alluded to above, however, Rascal is a bit more than that.\n\nCore forms can be implemented as derived concepts\nRascal’s type system is currently very simple, being nothing more than Hindley-Milner plus ad-hoc polymorphism in the form of typeclasses. Something interesting to note about it is that it does not implement ADTs or pattern-matching anywhere in the core! In fact, ADTs are defined as two macros data and case, in an entirely separate module, which can be imported just like any other library.\n\nThe main rascal language provides ADTs by default, of course, but it would be perfectly possible to produce a rascal/kernel language which does not include them at all. In this particular case, it seems unlikely that Rascal programmers would want their own implementation of ADTs, but it’s an interesting proof of concept, and it hints at other “core” features that could be implemented using macros.\n\nSimple syntactic transformations are, of course, trivially defined as macros. Haskell do notation is defined as an eleven-line macro in rascal/monad, and GHC’s useful LambdaCase extension is also possible to implement without modifying Rascal at all. This is useful, because there are many syntactic shorthands that are extremely useful to implement, but don’t make any sense to be in GHC because they are specific to certain libraries or applications. Racket’s macro system makes those not only possible, but actually pretty easy.\n\nWhile the extent of what is possible to implement as derived forms remains to be seen, many useful GHC features seem quite possible to implement without touching the core language, including things like GeneralizedNewtypeDeriving and other generic deriving mechanisms like GHC.Generics, DeriveGeneric, and DeriveAnyClass.\n\nThe language is not enough\nNo language is perfect. Most people would agree with this, but I would take it a step further: no language is even sufficient! This makes a lot of sense, given that general-purpose programming languages are designed to do everything, and it’s impossible to do everything well.\n\nHaskell programmers know this, and they happily endorse the creation of embedded domain specific languages. These are fantastic, and we need more of them. Things like servant let me write a third of the code I might otherwise need to, and the most readable code is the code you didn’t have to write in the first place. DSLs are good.\n\nUnfortunately, building DSLs is traditionally difficult, largely in part because building embedded DSLs means figuring out a way to encode your domain into your host language of choice. Sometimes, your domain simply does not elegantly map to your host language’s syntax or semantics, and you have to come up with a compromise. This is easy to see with servant, which, while it does a remarkably good job, still has to resort to some very clever type magic to create some semblance of an API description in Haskell types:\n\ntype UserAPI = \"users\" :> Get '[JSON] [User]\n          :<|> \"users\" :> ReqBody '[JSON] User :> Post '[JSON] User\n          :<|> \"users\" :> Capture \"userid\" Integer\n                       :> Get '[JSON] User\n          :<|> \"users\" :> Capture \"userid\" Integer\n                       :> ReqBody '[JSON] User\n                       :> Put '[JSON] User\n\nThe above code is remarkably readable for what it is, but what if we didn’t have to worry about working within the constraints of Haskell’s syntax? What if we could design a syntax that was truly the best for the job? Perhaps we would come up with something like this:\n\n(define-api User-API\n  #:content-types [JSON]\n  [GET  \"users\"                    => (List User)]\n  [POST \"users\"                    => User -> User]\n  [GET  \"users\" [userid : Integer] => User]\n  [PUT  \"users\" [userid : Integer] => User -> User])\n\nThis would be extremely easy to write with Racket’s macro-writing utilities, and it could even be made extensible. This could also avoid having to do the complicated typeclass trickery servant has to perform to then generate code from the above specification, since it would be much easier to just generate the necessary code directly (which still maintaining type safety).\n\nIn addition to the type-level hacks that Haskell programmers often have to pull in order to make these kinds of fancy DSLs work, free monads tend to be used to create domain-specific languages. This works okay for some DSLs, but remember that when you use a free monad, you are effectively writing a runtime interpreter for your language! Macros, on the other hand, are compiled, and you get ability to compile your DSL to code that can be optimized by all the existing facilities of the compiler toolchain.\n\nRascal is embryonic\nI’m pretty excited about Rascal. I think that it could have the potential to do some pretty interesting things, and I have some ideas in my head for how having macros in a Haskell-like language could change things. I also think that, based on what I’ve seen so far, having both macros and a Haskell-like type system could give rise to completely different programming paradigms than exist in either Haskell or Racket today. My gut tells me that this is a case where the whole might actually be greater than the sum of its parts.\n\nThat said, Rascal doesn’t really exist yet. Yes, there is a GitHub repository, and it has some code in it that does… something. Unfortunately, the code is also currently extremely buggy, to the point of being borderline broken, and it’s also in such early stages that you can’t really do anything interesting with it, aside from some tiny toy programs.\n\nAs I have worked on Rascal, I’ve come to a somewhat unfortunate conclusion, which is that I really have almost zero interest in implementing type systems. I felt that way before I started the project, but I was hoping that maybe once I got into them, I would find them more interesting. Unfortunately, as much as I love working with powerful type systems (and really, I adore working with Haskell and using all the fancy features GHC provides), I find implementing the software that makes them tick completely dull.\n\nStill, I’m willing to invest the time to get something that I can use. Even so, resources for practical type system implementation are scarce. I want to thank Mark P Jones for his wonderful resource Typing Haskell in Haskell, without which getting to where I am now would likely have been impossible. I also want to thank Stephen Diehl for his wonderful Write You a Haskell series, which was also wonderfully useful to study, even if it is unfinished and doesn’t cover anything beyond ML just yet.\n\nEven with these wonderful resources, I’ve come to the realization that I probably can’t do all of this on my own. I consider myself pretty familiar with macros and macro expanders at this point, but I don’t know much about type systems (at least not their implementation), and I could absolutely use some help. So if you’re interested in Rascal and think you might be able to pitch in, please: I would appreciate even the littlest bits of help or guidance!\n\nIn the meantime, I will try to keep picking away at Rascal in the small amount of free time I currently have. Thanks, as always, to all the amazing people who have contributed to the tools I’ve been using for this project: special thanks to the authors of Type Systems as Macros for their help as well as the people I mentioned just above, and also to all of the people who have built Racket and Haskell and made them what they are today. Without them, Rascal would most definitely not exist.\n\n\nNote that most of the Rascal code in this blog post probably doesn’t actually work on the current Rascal implementation. Pretty much all of it can be implemented in the current implementation, the syntax just isn’t quite as nice yet.\n ↩","isoDate":"2017-01-02T00:00:00.000Z","timestamp":"1/1/2017"},{"title":"Using types to unit-test in Haskell","pubDate":"2016-10-03T00:00:00.000Z","author":"Alexis King","content":"<article><p>Object-oriented programming languages make unit testing easy by providing obvious boundaries between units of code in the form of classes and interfaces. These boundaries make it easy to stub out parts of a system to test functionality in isolation, which makes it possible to write fast, deterministic test suites that are robust in the face of change. When writing Haskell, it can be unclear how to accomplish the same goals: even inside pure code, it can become difficult to test a particular code path without also testing all its collaborators.\n</p><p>Fortunately, by taking advantage of Haskell’s expressive type system, it’s possible to not only achieve parity with object-oriented testing techniques, but also to provide stronger static guarantees as well. Furthermore, it’s all possible without resorting to extra-linguistic hacks that static object-oriented languages sometimes use for mocking, such as dynamic bytecode generation.\n</p><h2><a name=\"first-an-aside-on-testing-philosophy\"></a>First, an aside on testing philosophy</h2><p>Testing methodology is a controversial topic within the larger programming community, and there are a multitude of different approaches. This blog post is about <em>unit testing</em>, an already nebulous term with a number of different definitions. For the purposes of this post, I will define a unit test as a test that stubs out collaborators of the code under test in some way. Accomplishing that in Haskell is what this is primarily about.\n</p><p>I want to be clear that I do not think that unit tests are the only way to write tests, nor the best way, nor even always an applicable way. Depending on your domain, rigorous unit testing might not even make sense, and other forms of tests (end-to-end, integration, benchmarks, etc.) might fulfill your needs.\n</p><p>In practice, though, implementing those other kinds of tests seems to be well-documented in Haskell compared to pure, object-oriented style unit testing. As my Haskell applications have grown, I have found myself wanting a more fine-grained testing tool that allows me to both test a piece of my codebase in isolation and also use my domain-specific types. This blog post is about that.\n</p><p>With that disclaimer out of the way, let’s talk about testing in Haskell.\n</p><h2><a name=\"drawing-seams-using-types\"></a>Drawing seams using types</h2><p>One of the primary attributes of unit tests in object-oriented languages, especially statically-typed ones, is the concept of “seams” within a codebase. These are internal boundaries between components of a system. Some boundaries are obvious—interactions with a database, manipulation of the file system, and performing I/O over the network, to name a few examples—but others are more subtle. Especially in larger codebases, it can be helpful to isolate two related but distinct pieces of functionality as much as possible, which makes them easier to reason about, even if they’re actually part of the same codebase.\n</p><p>In OO languages, these seams are often marked using interfaces, whether explicitly (in the case of static languages) or implicitly (in the case of dynamic ones). By programming to an interface, it’s possible to create “fake” implementations of that interface for use in unit tests, effectively making it possible to stub out code that isn’t directly relevant to the code being tested.\n</p><p>In Haskell, representing these seams is a lot less obvious. Consider a fairly trivial function that reverses a file’s contents on the file system:\n</p><pre><code class=\"pygments\"><span class=\"nf\">reverseFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>\n<span class=\"nf\">reverseFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">contents</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">readFile</span> <span class=\"n\">path</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"p\">(</span><span class=\"n\">reverse</span> <span class=\"n\">contents</span><span class=\"p\">)</span></code></pre><p>This function is impossible to test without testing against a real file system. It simply performs I/O directly, and there’s no way to “mock out” the file system for testing purposes. Now, admittedly, this function is so trivial that a unit test might not seem worth the cost, but consider a slightly more complicated function that interacts with a database:\n</p><pre><code class=\"pygments\"><span class=\"nf\">renderUserProfile</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">IO</span> <span class=\"kt\">HTML</span>\n<span class=\"nf\">renderUserProfile</span> <span class=\"n\">userId</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">user</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">fetchUser</span> <span class=\"n\">userId</span>\n  <span class=\"n\">posts</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">fetchRecentPosts</span> <span class=\"n\">userId</span>\n\n  <span class=\"n\">return</span> <span class=\"o\">$</span> <span class=\"n\">div</span>\n    <span class=\"p\">[</span> <span class=\"n\">h1</span> <span class=\"p\">(</span><span class=\"n\">userName</span> <span class=\"n\">user</span> <span class=\"o\">&lt;&gt;</span> <span class=\"s\">\"’s Profile\"</span><span class=\"p\">)</span>\n    <span class=\"p\">,</span> <span class=\"n\">h2</span> <span class=\"s\">\"Recent Posts\"</span>\n    <span class=\"p\">,</span> <span class=\"n\">ul</span> <span class=\"p\">(</span><span class=\"n\">map</span> <span class=\"p\">(</span><span class=\"n\">li</span> <span class=\"o\">.</span> <span class=\"n\">postTitle</span><span class=\"p\">)</span> <span class=\"n\">posts</span><span class=\"p\">)</span>\n    <span class=\"p\">]</span></code></pre><p>It might now be a bit more clear that it could be useful to test the above function without running a real database and doing all the necessary context setup before each test case. Indeed, it would be nice if a test could just provide stubbed implementations for <code>fetchUser</code> and <code>fetchRecentPosts</code>, then make assertions about the output.\n</p><p>One way to solve this problem is to pass the results of those two functions to <code>renderUserProfile</code> as arguments, turning it into a pure function that could be easily tested. This becomes obnoxious for functions of even just slightly more complexity, though (it is not unreasonable to imagine needing a handful of different queries to render a user’s profile page), and it requires significantly restructuring code simply because the tests need it.\n</p><p>The above code is not only difficult to test, however—it has another problem, too. Specifically, both functions return <code>IO</code> values, which means they can effectively do <em>anything</em>. Haskell has a very strong type system for typing terms, but it doesn’t provide any guarantees about effects beyond a simple yes/no answer about function purity. Even though the <code>renderUserProfile</code> function should really only need to interact with the database, it could theoretically delete files, send emails, make HTTP requests, or do any number of other things.\n</p><p>Fortunately, it’s possible to solve <em>both</em> problems—a lack of testability and a lack of type safety—using the same general technique. This approach is reminiscent of the interface-based seams of object-oriented languages, but unlike most object-oriented approaches, it provides additional type safety guarantees without the need to explicitly modify the code to support some kind of dependency injection.\n</p><h3><a name=\"making-implicit-interfaces-explicit\"></a>Making implicit interfaces explicit</h3><p>Statically typed, object-oriented languages provide interfaces as a language construct to encode certain kinds of contracts into the type system, and Haskell has something similar. Typeclasses are, in many ways, an analog to OO interfaces, and they can be used in a similar way. In the above case, let’s write down interfaces that the <code>reverseFile</code> and <code>renderUserProfile</code> functions can use:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFS</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n\n<span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadDB</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fetchUser</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">User</span>\n  <span class=\"n\">fetchRecentPosts</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">[</span><span class=\"kt\">Post</span><span class=\"p\">]</span></code></pre><p>The really nice thing about these interfaces is that our function implementations don’t have to change <em>at all</em> to take advantage of them. In fact, all we have to change is their types:\n</p><pre><code class=\"pygments\"><span class=\"nf\">reverseFile</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFS</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n<span class=\"nf\">reverseFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">contents</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">readFile</span> <span class=\"n\">path</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"p\">(</span><span class=\"n\">reverse</span> <span class=\"n\">contents</span><span class=\"p\">)</span>\n\n<span class=\"nf\">renderUserProfile</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadDB</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">HTML</span>\n<span class=\"nf\">renderUserProfile</span> <span class=\"n\">userId</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">user</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">fetchUser</span> <span class=\"n\">userId</span>\n  <span class=\"n\">posts</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">fetchRecentPosts</span> <span class=\"n\">userId</span>\n\n  <span class=\"n\">return</span> <span class=\"o\">$</span> <span class=\"n\">div</span>\n    <span class=\"p\">[</span> <span class=\"n\">h1</span> <span class=\"p\">(</span><span class=\"n\">userName</span> <span class=\"n\">user</span> <span class=\"o\">&lt;&gt;</span> <span class=\"s\">\"’s Profile\"</span><span class=\"p\">)</span>\n    <span class=\"p\">,</span> <span class=\"n\">h2</span> <span class=\"s\">\"Recent Posts\"</span>\n    <span class=\"p\">,</span> <span class=\"n\">ul</span> <span class=\"p\">(</span><span class=\"n\">map</span> <span class=\"p\">(</span><span class=\"n\">li</span> <span class=\"o\">.</span> <span class=\"n\">postTitle</span><span class=\"p\">)</span> <span class=\"n\">posts</span><span class=\"p\">)</span>\n    <span class=\"p\">]</span></code></pre><p>This is pretty neat, since we haven’t had to alter our code at all, but we’ve managed to completely decouple ourselves from <code>IO</code>. This has the direct effect of both making our code more abstract (we no longer rely on the “real” file system or a “real” database, which makes our code easier to test) and restricting what our functions can do (just from looking at the type signatures, we know what side-effects they can perform).\n</p><p>Of course, since we’re now coding against an interface, our code doesn’t actually do much of anything. If we want to actually use the functions we’ve written, we’ll have to define instances of <code>MonadFS</code> and <code>MonadDB</code>. When actually running our code, we’ll probably still use <code>IO</code> (or some monad transformer stack with <code>IO</code> at the bottom), so we can define trivial instances for that existing use case:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadFS</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">readFile</span>\n  <span class=\"n\">writeFile</span> <span class=\"ow\">=</span> <span class=\"kt\">Prelude</span><span class=\"o\">.</span><span class=\"n\">writeFile</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadDB</span> <span class=\"kt\">IO</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fetchUser</span> <span class=\"ow\">=</span> <span class=\"kt\">SQL</span><span class=\"o\">.</span><span class=\"n\">fetchUser</span>\n  <span class=\"n\">fetchRecentPosts</span> <span class=\"ow\">=</span> <span class=\"kt\">SQL</span><span class=\"o\">.</span><span class=\"n\">fetchRecentPosts</span></code></pre><p>Even if we go no further, <strong>this is already incredibly useful</strong>. By restricting the sorts of effects our functions can perform at the type level, it becomes a lot easier to see which code is interacting with what. This can be invaluable when working in a part of a moderately large codebase that you are unfamiliar with. Even if the only instance of these typeclasses is <code>IO</code>, the benefits are immediately apparent.\n</p><p>Of course, this blog post is about testing, so we’re going to go further and take advantage of these seams we’ve now drawn. The question is: how?\n</p><h2><a name=\"testing-with-typeclasses-an-initial-attempt\"></a>Testing with typeclasses: an initial attempt</h2><p>Given that we now have functions depending on an interface instead of <code>IO</code>, we can create separate instances of our typeclasses for use in tests. Let’s start with the <code>renderUserProfile</code> function. We’ll create a simple wrapper around the <code>Identity</code> type, since we don’t actually care much about the “effects” of our <code>MonadDB</code> methods:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">Data.Functor.Identity</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">TestM</span> <span class=\"p\">(</span><span class=\"kt\">Identity</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">)</span>\n\n<span class=\"nf\">unTestM</span> <span class=\"ow\">::</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">unTestM</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"p\">(</span><span class=\"kt\">Identity</span> <span class=\"n\">x</span><span class=\"p\">))</span> <span class=\"ow\">=</span> <span class=\"n\">x</span></code></pre><p>Now, we’ll create a trivial instance of <code>MonadDB</code> for <code>TestM</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadDB</span> <span class=\"kt\">TestM</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fetchUser</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"n\">return</span> <span class=\"kt\">User</span> <span class=\"p\">{</span> <span class=\"n\">userName</span> <span class=\"ow\">=</span> <span class=\"s\">\"Alyssa\"</span> <span class=\"p\">}</span>\n  <span class=\"n\">fetchRecentPosts</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"n\">return</span>\n    <span class=\"p\">[</span> <span class=\"kt\">Post</span> <span class=\"p\">{</span> <span class=\"n\">postTitle</span> <span class=\"ow\">=</span> <span class=\"s\">\"Metacircular Evaluator\"</span> <span class=\"p\">}</span> <span class=\"p\">]</span></code></pre><p>With this instance, it’s now possible to write a simple unit test of the <code>renderUserProfile</code> function that doesn’t need a real database running at all:\n</p><pre><code class=\"pygments\"><span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"renderUserProfile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"shows the user’s name\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">result</span> <span class=\"ow\">=</span> <span class=\"n\">unTestM</span> <span class=\"p\">(</span><span class=\"n\">renderUserProfile</span> <span class=\"p\">(</span><span class=\"n\">intToId</span> <span class=\"mi\">1234</span><span class=\"p\">))</span>\n    <span class=\"n\">result</span> <span class=\"p\">`</span><span class=\"n\">shouldContainElement</span><span class=\"p\">`</span> <span class=\"n\">h1</span> <span class=\"s\">\"Alyssa’s Profile\"</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"shows a list of the user’s posts\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">result</span> <span class=\"ow\">=</span> <span class=\"n\">unTestM</span> <span class=\"p\">(</span><span class=\"n\">renderUserProfile</span> <span class=\"p\">(</span><span class=\"n\">intToId</span> <span class=\"mi\">1234</span><span class=\"p\">))</span>\n    <span class=\"n\">result</span> <span class=\"p\">`</span><span class=\"n\">shouldContainElement</span><span class=\"p\">`</span> <span class=\"n\">ul</span> <span class=\"p\">[</span> <span class=\"n\">li</span> <span class=\"s\">\"Metacircular Evaluator\"</span> <span class=\"p\">]</span></code></pre><p>This is pretty nice, and running the above tests reveals a nice property of these kinds of isolated test cases: the test suite runs <em>really, really fast</em>. Communicating with a database, even in extremely simple ways, takes a measurable amount of time, especially with dozens of tests. In contrast, even with hundreds of tests, our unit test suite runs in less than a tenth of a second.\n</p><p>This all seems to be successful, so let’s try and apply the same testing technique to <code>reverseFile</code>.\n</p><h3><a name=\"testing-side-effectful-code\"></a>Testing side-effectful code</h3><p>Looking at the type signature for <code>reverseFile</code>, we have a small problem:\n</p><pre><code class=\"pygments\"><span class=\"nf\">reverseFile</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFS</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span></code></pre><p>Specifically, the return type is <code>()</code>. Making any assertions against the result of this function would be completely worthless, given that it’s guaranteed to be the same exact thing each time. Instead, <code>reverseFile</code> is inherently side-effectful, so we want to be able to test that it properly interacts with the file system in the correct way.\n</p><p>In order to do this, a simple wrapper around <code>Identity</code> won’t be enough, but we can replace it with something more powerful: <code>Writer</code>. Specifically, we can use a writer monad to “log” what gets called in order to test side-effects. We’ll start by creating a new <code>TestM</code> type, just like last time:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">TestM</span> <span class=\"p\">(</span><span class=\"kt\">Writer</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">]</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">])</span>\n\n<span class=\"nf\">logTestM</span> <span class=\"ow\">::</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">]</span>\n<span class=\"nf\">logTestM</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">execWriter</span> <span class=\"n\">w</span></code></pre><p>Using this slightly more powerful type, we can write a useful instance of <code>MonadFS</code> that will track the argument given to <code>writeFile</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">MonadFS</span> <span class=\"kt\">TestM</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"n\">return</span> <span class=\"s\">\"hello\"</span>\n  <span class=\"n\">writeFile</span> <span class=\"kr\">_</span> <span class=\"n\">contents</span> <span class=\"ow\">=</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">contents</span><span class=\"p\">]</span></code></pre><p>Again, the instance is quite simple, but it now enables us to write a straightforward unit test for <code>reverseFile</code>:\n</p><pre><code class=\"pygments\"><span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"reverseFile\"</span> <span class=\"o\">$</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reverses a file’s contents on the filesystem\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">calls</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">calls</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"olleh\"</span><span class=\"p\">]</span></code></pre><p>Again, quite simple to both implement and use, and the test itself is blindingly fast. There’s another problem, though, which is that we have technically left part of <code>reverseFile</code> untested: we’ve completely ignored the <code>path</code> argument.\n</p><p>In this contrived example, it may seem silly to test something so trivial, but in real code, it’s quite possible that one would care very much about testing multiple different aspects about a single function. When testing <code>renderUserProfile</code>, this was not hard, since we could reuse the same <code>TestM</code> type and <code>MonadDB</code> instance for both test cases, but in the <code>reverseFile</code> example, we’ve ignored the path entirely.\n</p><p>We <em>could</em> adjust our <code>MonadFS</code> instance to also track the path provided to each method, but this has a few problems. First, it means every test case would depend on all the various properties we are testing, which would mean updating every test case when we add a new one. It would also be simply impossible if we needed to track multiple types—in this particular case, it turns out that <code>String</code> and <code>FilePath</code> are actually the same type, but in practice, there may be a handful of disparate, incompatible types.\n</p><p>Both of the above issues could be fixed by creating a sum type and manually filtering out the relevant elements in each test case, but a much more intuitive approach would be to simply have a separate instance for each case. Unfortunately, in Haskell, creating a new instance means creating an entirely new type. To illustrate how much duplication that would entail, we could create the following type and instance for testing proper propagation of the <code>path</code> argument:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">TestM&#39;</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">TestM&#39;</span> <span class=\"p\">(</span><span class=\"kt\">Writer</span> <span class=\"p\">[</span><span class=\"kt\">FilePath</span><span class=\"p\">]</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"p\">[</span><span class=\"kt\">FilePath</span><span class=\"p\">])</span>\n\n<span class=\"nf\">logTestM&#39;</span> <span class=\"ow\">::</span> <span class=\"kt\">TestM&#39;</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"p\">[</span><span class=\"kt\">FilePath</span><span class=\"p\">]</span>\n<span class=\"nf\">logTestM&#39;</span> <span class=\"p\">(</span><span class=\"kt\">TestM&#39;</span> <span class=\"n\">w</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">execWriter</span> <span class=\"n\">w</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">MonadFS</span> <span class=\"kt\">TestM&#39;</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"\"</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"kr\">_</span> <span class=\"ow\">=</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span></code></pre><p>Now it’s possible to add an extra test case that asserts that the proper path is provided to the two filesystem functions:\n</p><pre><code class=\"pygments\"><span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"reverseFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reverses a file’s contents on the filesystem\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">calls</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">calls</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"olleh\"</span><span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"operates on the file at the provided path\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">paths</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM&#39;</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">paths</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">]</span></code></pre><p>This works, but it’s ultimately unacceptably complicated. Our test harness code is now significantly larger than the actual tests themselves, and the amount of boilerplate is frustrating. Verbose test suites are especially bad, since forcing programmers to jump through hoops just to implement a single test reduces the likelihood that people will actually write good tests, if they write tests at all. In contrast, if writing tests is easy, then people will naturally write more of them.\n</p><p>The above strategy to writing tests is not good enough, but it does reveal a particular problem: in Haskell, typeclass instances are not first-class values that can be manipulated and abstracted over, they are static constructs that can only be managed by the compiler, and users do not have a direct way to modify them. With some cleverness, however, we can actually create an approximation of first-class typeclass dictionaries, which will allow us to dramatically simplify the above testing mechanism.\n</p><h2><a name=\"creating-first-class-typeclass-instances\"></a>Creating first-class typeclass instances</h2><p>In order to provide an easy way to construct instances, we need a way to represent instances as ordinary Haskell values. This is not terribly difficult, given that instances are conceptually just records containing a collection of functions. For example, we could create a datatype that represents an instance of the <code>MonadFS</code> typeclass:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">MonadFSInst</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n  <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n  <span class=\"p\">}</span></code></pre><p>To avoid namespace clashes with the actual method identifiers, the record fields are prefixed with an underscore, but otherwise, the translation is remarkably straightforward. Using this record type, we can easily create values that represent the two instances we defined above:\n</p><pre><code class=\"pygments\"><span class=\"nf\">contentInst</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadWriter</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">]</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFSInst</span> <span class=\"n\">m</span>\n<span class=\"nf\">contentInst</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n  <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"hello\"</span>\n  <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">contents</span><span class=\"p\">]</span>\n  <span class=\"p\">}</span>\n\n<span class=\"nf\">pathInst</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadWriter</span> <span class=\"p\">[</span><span class=\"kt\">FilePath</span><span class=\"p\">]</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFSInst</span> <span class=\"n\">m</span>\n<span class=\"nf\">pathInst</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n  <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"\"</span>\n  <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span>\n  <span class=\"p\">}</span></code></pre><p>These two values represent two different implementations of <code>MonadFS</code>, but since they’re ordinary Haskell values, they can be manipulated and even <em>extended</em> like any other records. This can be extremely useful, since it makes it possible to create a sort of “base” instance, then have individual test cases override individual pieces of functionality piecemeal.\n</p><p>Of course, although we’ve written these two instances, we have no way to actually use them. After all, Haskell does not provide a way to explicitly provide typeclass dictionaries. Fortunately, we can create a sort of “proxy” type that will use a reader to thread the dictionary around explicitly, and the instance can defer to the dictionary’s implementation.\n</p><h3><a name=\"creating-an-instance-proxy\"></a>Creating an instance proxy</h3><p>To represent our proxy type, we’ll use a combination of a <code>Writer</code> and a <code>ReaderT</code>; the former to implement the logging used by instances, and the latter to actually thread around the dictionary. Our type will look like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">TestM</span> <span class=\"n\">log</span> <span class=\"n\">a</span> <span class=\"ow\">=</span>\n    <span class=\"kt\">TestM</span> <span class=\"p\">(</span><span class=\"kt\">ReaderT</span> <span class=\"p\">(</span><span class=\"kt\">MonadFSInst</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">log</span><span class=\"p\">))</span> <span class=\"p\">(</span><span class=\"kt\">Writer</span> <span class=\"n\">log</span><span class=\"p\">)</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span> <span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadReader</span> <span class=\"p\">(</span><span class=\"kt\">MonadFSInst</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">log</span><span class=\"p\">))</span>\n           <span class=\"p\">,</span> <span class=\"kt\">MonadWriter</span> <span class=\"n\">log</span>\n           <span class=\"p\">)</span>\n\n<span class=\"nf\">logTestM</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFSInst</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">log</span><span class=\"p\">)</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">TestM</span> <span class=\"n\">log</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">log</span>\n<span class=\"nf\">logTestM</span> <span class=\"n\">inst</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">execWriter</span> <span class=\"p\">(</span><span class=\"n\">runReaderT</span> <span class=\"n\">m</span> <span class=\"n\">inst</span><span class=\"p\">)</span></code></pre><p>This might look rather complicated, and it is, but let’s break down exactly what it’s doing.\n</p><ol><li><p>The <code>TestM</code> type includes two type parameters. The first is the type of value that will be logged (hence the name <code>log</code>), which corresponds to the argument to <code>Writer</code> from previous incarnations of <code>TestM</code>. Unlike those types, though, we want this version to work with any <code>Monoid</code>, so we’ll make it a type parameter. The second parameter is simply the type of the current monadic value, as before.\n</p></li><li><p>The type itself is defined as a wrapper around a small monad transformer stack, the first of which is <code>ReaderT</code>. The state threaded around by the reader is, in this case, the instance dictionary, which is <code>MonadFSInst</code>.\n</p><p>However, recall that <code>MonadFSInst</code> accepts a type variable—the type of a monad itself—so we must provide <code>TestM log</code> as an argument to <code>MonadFSInst</code>. This slight bit of indirection allows us to tie the knot between the mutually dependent instances and proxy type.\n</p></li><li><p>The base monad in the transformer stack is <code>Writer</code>, which is used to actually implement the logging functionality, just like in prior cases. The only difference now is that the <code>log</code> type parameter now determines what the writer actually produces.\n</p></li><li><p>Finally, as before, we use <code>GeneralizedNewtypeDeriving</code> to derive all the relevant <code>mtl</code> classes, adding the somewhat wordy <code>MonadReader</code> constraint to the list.\n</p></li></ol><p>Using this single type, we can now implement a <code>MonadFS</code> instance that defers to the dictionary carried around within <code>TestM</code>’s reader state:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">Monoid</span> <span class=\"n\">log</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">MonadFS</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">log</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">readFile</span> <span class=\"n\">path</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">f</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">asks</span> <span class=\"n\">_readFile</span>\n    <span class=\"n\">f</span> <span class=\"n\">path</span>\n  <span class=\"n\">writeFile</span> <span class=\"n\">path</span> <span class=\"n\">contents</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n    <span class=\"n\">f</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">asks</span> <span class=\"n\">_writeFile</span>\n    <span class=\"n\">f</span> <span class=\"n\">path</span> <span class=\"n\">contents</span></code></pre><p>This may seem somewhat boilerplate-y, and it is to some extent, but the important consideration is that this boilerplate only needs to be written <em>once</em>. With this in place, it’s now possible to write an arbitrary number of first-class instances that use the above mechanism without extending the mechanism at all.\n</p><p>To see what actually using this code would look like, let’s update the <code>reverseFile</code> tests to use the new <code>TestM</code> implementation, as well as the <code>contentInst</code> and <code>pathInst</code> dictionaries from earlier:\n</p><pre><code class=\"pygments\"><span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"reverseFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reverses a file’s contents on the filesystem\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">calls</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"n\">contentInst</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">calls</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"olleh\"</span><span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"operates on the file at the provided path\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">paths</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"n\">pathInst</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">paths</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">]</span></code></pre><p>We can do a little bit better, though. Really, the definitions of <code>contentInst</code> and <code>pathInst</code> are specific to each test case. With ordinary typeclass instances, we cannot scope them to any particular block, but since <code>MonadFSInst</code> is just an ordinary Haskell datatype, we can manipulate them just like any other Haskell values. Therefore, we can just inline those instances’ definitions into the test cases themselves to keep them closer to the actual tests.\n</p><pre><code class=\"pygments\"><span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"reverseFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reverses a file’s contents on the filesystem\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">contentInst</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n          <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"hello\"</span>\n          <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">contents</span><span class=\"p\">]</span>\n          <span class=\"p\">}</span>\n    <span class=\"kr\">let</span> <span class=\"n\">calls</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"n\">contentInst</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">calls</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"olleh\"</span><span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"operates on the file at the provided path\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">pathInst</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n          <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"\"</span>\n          <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">tell</span> <span class=\"p\">[</span><span class=\"n\">path</span><span class=\"p\">]</span>\n          <span class=\"p\">}</span>\n    <span class=\"kr\">let</span> <span class=\"n\">paths</span> <span class=\"ow\">=</span> <span class=\"n\">logTestM</span> <span class=\"n\">pathInst</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span>\n    <span class=\"n\">paths</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">]</span></code></pre><p>This is pretty good. We’re now able to create inline instances of our <code>MonadFS</code> typeclass, which allows us to write extremely concise unit tests using ordinary Haskell typeclasses as system seams. We’ve managed to cut down on the boilerplate considerably, though we still have a couple problems. For one, this example only uses a single typeclass containing only two methods. A real <code>MonadFS</code> typeclass would likely have at least a dozen methods for performing various filesystem operations, and writing out the instance dictionaries for every single method, even the ones that aren’t used within the code under test, would be pretty frustratingly verbose.\n</p><p>This problem is solvable, though. Since instances are just ordinary Haskell records, we can create a “base” instance that just throws an exception whenever the method is called:\n</p><pre><code class=\"pygments\"><span class=\"nf\">baseInst</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadFSInst</span> <span class=\"n\">m</span>\n<span class=\"nf\">baseInst</span> <span class=\"ow\">=</span> <span class=\"kt\">MonadFSInst</span>\n  <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"ne\">error</span> <span class=\"s\">\"unimplemented instance method ‘_readFile’\"</span>\n  <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"ne\">error</span> <span class=\"s\">\"unimplemented instance method ‘_writeFile’\"</span>\n  <span class=\"p\">}</span></code></pre><p>Then code that only uses <code>readFile</code> could only override that particular method, for example:\n</p><pre><code class=\"pygments\"><span class=\"kr\">let</span> <span class=\"n\">myInst</span> <span class=\"ow\">=</span> <span class=\"n\">baseInst</span> <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"o\">...</span> <span class=\"p\">}</span></code></pre><p>Normally, of course, this would be a terrible idea. However, since this is all just test code, it can be extremely useful in quickly figuring out what methods need to be stubbed out for a particular test case. Since all the code actually gets run at test time, attempts to use unimplemented instance methods will immediately raise an error, informing the programmer which methods need to be implemented to make the test pass. This can also help to significantly cut down on the amount of effort it takes to implement each test.\n</p><p>Another problem is that our approach is specialized exclusively to <code>MonadFS</code>. What about functions that use both <code>MonadFS</code> <em>and</em> <code>MonadDB</code>, for example? Fortunately, that is not hard to solve, either. We can adapt the <code>MonadFSInst</code> type to include fields for all of the typeclasses relevant to our system, turning it into a generic test fixture of sorts:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">FixtureInst</span> <span class=\"n\">m</span> <span class=\"ow\">=</span> <span class=\"kt\">FixtureInst</span>\n  <span class=\"p\">{</span> <span class=\"c1\">-- MonadFS</span>\n    <span class=\"n\">_readFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">String</span>\n  <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">::</span> <span class=\"kt\">FilePath</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">String</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"nb\">()</span>\n\n    <span class=\"c1\">-- MonadDB</span>\n  <span class=\"p\">,</span> <span class=\"n\">_fetchUser</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">User</span>\n  <span class=\"p\">,</span> <span class=\"n\">_fetchRecentPosts</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">[</span><span class=\"kt\">Post</span><span class=\"p\">]</span>\n  <span class=\"p\">}</span></code></pre><p>Updating <code>TestM</code> to use <code>FixtureInst</code> instead of <code>MonadFSInst</code> is trivial, and all the rest of the infrastructure still works. However, this means that every time a new typeclass is added, three things need to be updated:\n</p><ol><li><p>Its methods need to be added to the <code>FixtureInst</code> record.\n</p></li><li><p>Those methods need to be given error-raising defaults in the <code>baseInst</code> value.\n</p></li><li><p>An actual instance of the typeclass needs to be written for <code>TestM</code> that defers to the <code>FixtureInst</code> value.\n</p></li></ol><p>Furthermore, most of this manual manipulation of methods is required every time a particular typeclass changes, whether that means adding a method, removing a method, renaming a method, or changing a method’s type. This is especially frustrating given that all this code is really just mechanical boilerplate that could all be derived by the set of typeclasses being tested.\n</p><p>That last point is especially important: aside from the instances themselves, every piece of boilerplate above is obviously possible to generate from existing types alone. With that piece of information in mind, we can do even better: we can use Template Haskell.\n</p><h2><a name=\"removing-the-boilerplate-using-test-fixture\"></a>Removing the boilerplate using <code>test-fixture</code></h2><p>The above code was not only rather boilerplate-heavy, it was pretty complicated. Fortunately, you don’t actually have to write it. Enter the library <a href=\"http://hackage.haskell.org/package/test-fixture\"><code>test-fixture</code></a>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.TestFixture</span>\n<span class=\"kr\">import</span> <span class=\"nn\">Control.Monad.TestFixture.TH</span>\n\n<span class=\"nf\">mkFixture</span> <span class=\"s\">\"FixtureInst\"</span> <span class=\"p\">[</span><span class=\"kt\">&#39;&#39;MonadFS</span><span class=\"p\">,</span> <span class=\"kt\">&#39;&#39;MonadDB</span><span class=\"p\">]</span>\n\n<span class=\"nf\">spec</span> <span class=\"ow\">=</span> <span class=\"n\">describe</span> <span class=\"s\">\"reverseFile\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n  <span class=\"n\">it</span> <span class=\"s\">\"reverses a file’s contents on the filesystem\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">contentInst</span> <span class=\"ow\">=</span> <span class=\"n\">def</span>\n          <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"hello\"</span>\n          <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"kr\">_</span> <span class=\"n\">contents</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">log</span> <span class=\"n\">contents</span>\n          <span class=\"p\">}</span>\n    <span class=\"kr\">let</span> <span class=\"n\">calls</span> <span class=\"ow\">=</span> <span class=\"n\">logTestFixture</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span> <span class=\"n\">contentInst</span>\n    <span class=\"n\">calls</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"olleh\"</span><span class=\"p\">]</span>\n\n  <span class=\"n\">it</span> <span class=\"s\">\"operates on the file at the provided path\"</span> <span class=\"o\">$</span> <span class=\"kr\">do</span>\n    <span class=\"kr\">let</span> <span class=\"n\">pathInst</span> <span class=\"ow\">=</span> <span class=\"n\">def</span>\n          <span class=\"p\">{</span> <span class=\"n\">_readFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">log</span> <span class=\"n\">path</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">return</span> <span class=\"s\">\"\"</span>\n          <span class=\"p\">,</span> <span class=\"n\">_writeFile</span> <span class=\"ow\">=</span> <span class=\"nf\">\\</span><span class=\"n\">path</span> <span class=\"kr\">_</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">log</span> <span class=\"n\">path</span>\n          <span class=\"p\">}</span>\n    <span class=\"kr\">let</span> <span class=\"n\">paths</span> <span class=\"ow\">=</span> <span class=\"n\">logTestFixture</span> <span class=\"p\">(</span><span class=\"n\">reverseFile</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">)</span> <span class=\"n\">pathInst</span>\n    <span class=\"n\">paths</span> <span class=\"p\">`</span><span class=\"n\">shouldBe</span><span class=\"p\">`</span> <span class=\"p\">[</span><span class=\"s\">\"foo.txt\"</span><span class=\"p\">,</span> <span class=\"s\">\"foo.txt\"</span><span class=\"p\">]</span></code></pre><p><strong>That’s it.</strong> The above code automatically generates everything you need to write fast, simple, deterministic unit tests in Haskell. The <code>mkFixture</code> function is a Template Haskell macro that expands into a definition quite similar to the <code>FixtureInst</code> type we wrote by hand, but since it’s automatically generated from the typeclass definitions, it never needs to be updated.\n</p><p>The <code>logTestFixture</code> function replaces the <code>logTestM</code> function we wrote by hand, but it works exactly the same. The <code>Control.Monad.TestFixture</code> library also exports a <code>log</code> function that is a synonym for <code>tell . singleton</code>, but using <code>tell</code> directly still works if you prefer.\n</p><p>The <code>mkFixture</code> function also generates a <code>Default</code> instance, which replaces the <code>baseInst</code> value defined earlier. It functions the same way, though, producing useful error messages that refer to the names of unimplemented typeclass methods that have not been stubbed out.\n</p><p>This blog post is not a <code>test-fixture</code> tutorial—indeed, it is much more complicated than a <code>test-fixture</code> tutorial would be, since it covers what the library is really doing under the hood—but if you’re interested, I would highly recommend you take a look at the <a href=\"http://hackage.haskell.org/package/test-fixture\"><code>test-fixture</code> documentation on Hackage</a>.\n</p><h2><a name=\"conclusion-credits-and-similar-techniques\"></a>Conclusion, credits, and similar techniques</h2><p>This blog post came about as the result of a need my coworkers and I found when writing Haskell code; we wanted a way to write unit tests quickly and easily, but we didn’t find much advice from the rest of the Haskell ecosystem. The <code>test-fixture</code> library is the result of that exploratory work, and we currently use it to test a significant portion of our Haskell code.\n</p><p>It would be extremely unfair to suggest that I was the inventor of this technique or the inventor of the library. Two of my coworkers, <a href=\"https://github.com/jxv\">Joe Vargas</a> and <a href=\"https://github.com/aztecrex\">Greg Wiley</a>, came up with the general approach and wrote <code>Control.Monad.TestFixture</code>, and I simply wrote the Template Haskell macro to eliminate the boilerplate. With that in mind, I think I can say with some fairness that I think this technique is a joy to use when unit testing is a desirable goal, and I would definitely recommend it if you are interested in doing isolated testing in Haskell.\n</p><p>The general technique of using typeclasses to emulate effects was in part inspired by the well-known <code>mtl</code> library. An alternate approach to writing unit-testable Haskell code is using free monads, but overall, I prefer this approach over free monads because the typeclass constraints add type safety in ways that free monads do not (at least not without additional boilerplate), and this approach also lends itself well to static analysis-based boilerplate reduction techniques. It has its own tradeoffs, though, so if you’ve had success with free monads, then I certainly make no claim this is a superior approach, just one that I’ve personally found pleasant.\n</p><p>As a final note, if you <em>do</em> check out <code>test-fixture</code>, feel free to leave feedback by opening issues on <a href=\"https://github.com/cjdev/test-fixture/issues\">the GitHub issue tracker</a>—even things like confusing documentation are worth a bug report.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Object-oriented programming languages make unit testing easy by providing obvious boundaries between units of code in the form of classes and interfaces. These boundaries make it easy to stub out parts of a system to test functionality in isolation, which makes it possible to write fast, deterministic test suites that are robust in the face of change. When writing Haskell, it can be unclear how to accomplish the same goals: even inside pure code, it can become difficult to test a particular code path without also testing all its collaborators.\n\nFortunately, by taking advantage of Haskell’s expressive type system, it’s possible to not only achieve parity with object-oriented testing techniques, but also to provide stronger static guarantees as well. Furthermore, it’s all possible without resorting to extra-linguistic hacks that static object-oriented languages sometimes use for mocking, such as dynamic bytecode generation.\n\nFirst, an aside on testing philosophy\nTesting methodology is a controversial topic within the larger programming community, and there are a multitude of different approaches. This blog post is about unit testing, an already nebulous term with a number of different definitions. For the purposes of this post, I will define a unit test as a test that stubs out collaborators of the code under test in some way. Accomplishing that in Haskell is what this is primarily about.\n\nI want to be clear that I do not think that unit tests are the only way to write tests, nor the best way, nor even always an applicable way. Depending on your domain, rigorous unit testing might not even make sense, and other forms of tests (end-to-end, integration, benchmarks, etc.) might fulfill your needs.\n\nIn practice, though, implementing those other kinds of tests seems to be well-documented in Haskell compared to pure, object-oriented style unit testing. As my Haskell applications have grown, I have found myself wanting a more fine-grained testing tool that allows me to both test a piece of my codebase in isolation and also use my domain-specific types. This blog post is about that.\n\nWith that disclaimer out of the way, let’s talk about testing in Haskell.\n\nDrawing seams using types\nOne of the primary attributes of unit tests in object-oriented languages, especially statically-typed ones, is the concept of “seams” within a codebase. These are internal boundaries between components of a system. Some boundaries are obvious—interactions with a database, manipulation of the file system, and performing I/O over the network, to name a few examples—but others are more subtle. Especially in larger codebases, it can be helpful to isolate two related but distinct pieces of functionality as much as possible, which makes them easier to reason about, even if they’re actually part of the same codebase.\n\nIn OO languages, these seams are often marked using interfaces, whether explicitly (in the case of static languages) or implicitly (in the case of dynamic ones). By programming to an interface, it’s possible to create “fake” implementations of that interface for use in unit tests, effectively making it possible to stub out code that isn’t directly relevant to the code being tested.\n\nIn Haskell, representing these seams is a lot less obvious. Consider a fairly trivial function that reverses a file’s contents on the file system:\n\nreverseFile :: FilePath -> IO ()\nreverseFile path = do\n  contents <- readFile path\n  writeFile path (reverse contents)\nThis function is impossible to test without testing against a real file system. It simply performs I/O directly, and there’s no way to “mock out” the file system for testing purposes. Now, admittedly, this function is so trivial that a unit test might not seem worth the cost, but consider a slightly more complicated function that interacts with a database:\n\nrenderUserProfile :: Id User -> IO HTML\nrenderUserProfile userId = do\n  user <- fetchUser userId\n  posts <- fetchRecentPosts userId\n\n  return $ div\n    [ h1 (userName user <> \"’s Profile\")\n    , h2 \"Recent Posts\"\n    , ul (map (li . postTitle) posts)\n    ]\nIt might now be a bit more clear that it could be useful to test the above function without running a real database and doing all the necessary context setup before each test case. Indeed, it would be nice if a test could just provide stubbed implementations for fetchUser and fetchRecentPosts, then make assertions about the output.\n\nOne way to solve this problem is to pass the results of those two functions to renderUserProfile as arguments, turning it into a pure function that could be easily tested. This becomes obnoxious for functions of even just slightly more complexity, though (it is not unreasonable to imagine needing a handful of different queries to render a user’s profile page), and it requires significantly restructuring code simply because the tests need it.\n\nThe above code is not only difficult to test, however—it has another problem, too. Specifically, both functions return IO values, which means they can effectively do anything. Haskell has a very strong type system for typing terms, but it doesn’t provide any guarantees about effects beyond a simple yes/no answer about function purity. Even though the renderUserProfile function should really only need to interact with the database, it could theoretically delete files, send emails, make HTTP requests, or do any number of other things.\n\nFortunately, it’s possible to solve both problems—a lack of testability and a lack of type safety—using the same general technique. This approach is reminiscent of the interface-based seams of object-oriented languages, but unlike most object-oriented approaches, it provides additional type safety guarantees without the need to explicitly modify the code to support some kind of dependency injection.\n\nMaking implicit interfaces explicit\nStatically typed, object-oriented languages provide interfaces as a language construct to encode certain kinds of contracts into the type system, and Haskell has something similar. Typeclasses are, in many ways, an analog to OO interfaces, and they can be used in a similar way. In the above case, let’s write down interfaces that the reverseFile and renderUserProfile functions can use:\n\nclass Monad m => MonadFS m where\n  readFile :: FilePath -> m String\n  writeFile :: FilePath -> String -> m ()\n\nclass Monad m => MonadDB m where\n  fetchUser :: Id User -> m User\n  fetchRecentPosts :: Id User -> m [Post]\nThe really nice thing about these interfaces is that our function implementations don’t have to change at all to take advantage of them. In fact, all we have to change is their types:\n\nreverseFile :: MonadFS m => FilePath -> m ()\nreverseFile path = do\n  contents <- readFile path\n  writeFile path (reverse contents)\n\nrenderUserProfile :: MonadDB m => Id User -> m HTML\nrenderUserProfile userId = do\n  user <- fetchUser userId\n  posts <- fetchRecentPosts userId\n\n  return $ div\n    [ h1 (userName user <> \"’s Profile\")\n    , h2 \"Recent Posts\"\n    , ul (map (li . postTitle) posts)\n    ]\nThis is pretty neat, since we haven’t had to alter our code at all, but we’ve managed to completely decouple ourselves from IO. This has the direct effect of both making our code more abstract (we no longer rely on the “real” file system or a “real” database, which makes our code easier to test) and restricting what our functions can do (just from looking at the type signatures, we know what side-effects they can perform).\n\nOf course, since we’re now coding against an interface, our code doesn’t actually do much of anything. If we want to actually use the functions we’ve written, we’ll have to define instances of MonadFS and MonadDB. When actually running our code, we’ll probably still use IO (or some monad transformer stack with IO at the bottom), so we can define trivial instances for that existing use case:\n\ninstance MonadFS IO where\n  readFile = Prelude.readFile\n  writeFile = Prelude.writeFile\n\ninstance MonadDB IO where\n  fetchUser = SQL.fetchUser\n  fetchRecentPosts = SQL.fetchRecentPosts\nEven if we go no further, this is already incredibly useful. By restricting the sorts of effects our functions can perform at the type level, it becomes a lot easier to see which code is interacting with what. This can be invaluable when working in a part of a moderately large codebase that you are unfamiliar with. Even if the only instance of these typeclasses is IO, the benefits are immediately apparent.\n\nOf course, this blog post is about testing, so we’re going to go further and take advantage of these seams we’ve now drawn. The question is: how?\n\nTesting with typeclasses: an initial attempt\nGiven that we now have functions depending on an interface instead of IO, we can create separate instances of our typeclasses for use in tests. Let’s start with the renderUserProfile function. We’ll create a simple wrapper around the Identity type, since we don’t actually care much about the “effects” of our MonadDB methods:\n\nimport Data.Functor.Identity\n\nnewtype TestM a = TestM (Identity a)\n  deriving (Functor, Applicative, Monad)\n\nunTestM :: TestM a -> a\nunTestM (TestM (Identity x)) = x\nNow, we’ll create a trivial instance of MonadDB for TestM:\n\ninstance MonadDB TestM where\n  fetchUser _ = return User { userName = \"Alyssa\" }\n  fetchRecentPosts _ = return\n    [ Post { postTitle = \"Metacircular Evaluator\" } ]\nWith this instance, it’s now possible to write a simple unit test of the renderUserProfile function that doesn’t need a real database running at all:\n\nspec = describe \"renderUserProfile\" $ do\n  it \"shows the user’s name\" $ do\n    let result = unTestM (renderUserProfile (intToId 1234))\n    result `shouldContainElement` h1 \"Alyssa’s Profile\"\n\n  it \"shows a list of the user’s posts\" $ do\n    let result = unTestM (renderUserProfile (intToId 1234))\n    result `shouldContainElement` ul [ li \"Metacircular Evaluator\" ]\nThis is pretty nice, and running the above tests reveals a nice property of these kinds of isolated test cases: the test suite runs really, really fast. Communicating with a database, even in extremely simple ways, takes a measurable amount of time, especially with dozens of tests. In contrast, even with hundreds of tests, our unit test suite runs in less than a tenth of a second.\n\nThis all seems to be successful, so let’s try and apply the same testing technique to reverseFile.\n\nTesting side-effectful code\nLooking at the type signature for reverseFile, we have a small problem:\n\nreverseFile :: MonadFS m => FilePath -> m ()\nSpecifically, the return type is (). Making any assertions against the result of this function would be completely worthless, given that it’s guaranteed to be the same exact thing each time. Instead, reverseFile is inherently side-effectful, so we want to be able to test that it properly interacts with the file system in the correct way.\n\nIn order to do this, a simple wrapper around Identity won’t be enough, but we can replace it with something more powerful: Writer. Specifically, we can use a writer monad to “log” what gets called in order to test side-effects. We’ll start by creating a new TestM type, just like last time:\n\nnewtype TestM a = TestM (Writer [String] a)\n  deriving (Functor, Applicative, Monad, MonadWriter [String])\n\nlogTestM :: TestM a -> [String]\nlogTestM (TestM w) = execWriter w\nUsing this slightly more powerful type, we can write a useful instance of MonadFS that will track the argument given to writeFile:\n\ninstance MonadFS TestM where\n  readFile _ = return \"hello\"\n  writeFile _ contents = tell [contents]\nAgain, the instance is quite simple, but it now enables us to write a straightforward unit test for reverseFile:\n\nspec = describe \"reverseFile\" $\n  it \"reverses a file’s contents on the filesystem\" $ do\n    let calls = logTestM (reverseFile \"foo.txt\")\n    calls `shouldBe` [\"olleh\"]\nAgain, quite simple to both implement and use, and the test itself is blindingly fast. There’s another problem, though, which is that we have technically left part of reverseFile untested: we’ve completely ignored the path argument.\n\nIn this contrived example, it may seem silly to test something so trivial, but in real code, it’s quite possible that one would care very much about testing multiple different aspects about a single function. When testing renderUserProfile, this was not hard, since we could reuse the same TestM type and MonadDB instance for both test cases, but in the reverseFile example, we’ve ignored the path entirely.\n\nWe could adjust our MonadFS instance to also track the path provided to each method, but this has a few problems. First, it means every test case would depend on all the various properties we are testing, which would mean updating every test case when we add a new one. It would also be simply impossible if we needed to track multiple types—in this particular case, it turns out that String and FilePath are actually the same type, but in practice, there may be a handful of disparate, incompatible types.\n\nBoth of the above issues could be fixed by creating a sum type and manually filtering out the relevant elements in each test case, but a much more intuitive approach would be to simply have a separate instance for each case. Unfortunately, in Haskell, creating a new instance means creating an entirely new type. To illustrate how much duplication that would entail, we could create the following type and instance for testing proper propagation of the path argument:\n\nnewtype TestM' a = TestM' (Writer [FilePath] a)\n  deriving (Functor, Applicative, Monad, MonadWriter [FilePath])\n\nlogTestM' :: TestM' a -> [FilePath]\nlogTestM' (TestM' w) = execWriter w\n\ninstance MonadFS TestM' where\n  readFile path = tell [path] >> return \"\"\n  writeFile path _ = tell [path]\nNow it’s possible to add an extra test case that asserts that the proper path is provided to the two filesystem functions:\n\nspec = describe \"reverseFile\" $ do\n  it \"reverses a file’s contents on the filesystem\" $ do\n    let calls = logTestM (reverseFile \"foo.txt\")\n    calls `shouldBe` [\"olleh\"]\n\n  it \"operates on the file at the provided path\" $ do\n    let paths = logTestM' (reverseFile \"foo.txt\")\n    paths `shouldBe` [\"foo.txt\", \"foo.txt\"]\nThis works, but it’s ultimately unacceptably complicated. Our test harness code is now significantly larger than the actual tests themselves, and the amount of boilerplate is frustrating. Verbose test suites are especially bad, since forcing programmers to jump through hoops just to implement a single test reduces the likelihood that people will actually write good tests, if they write tests at all. In contrast, if writing tests is easy, then people will naturally write more of them.\n\nThe above strategy to writing tests is not good enough, but it does reveal a particular problem: in Haskell, typeclass instances are not first-class values that can be manipulated and abstracted over, they are static constructs that can only be managed by the compiler, and users do not have a direct way to modify them. With some cleverness, however, we can actually create an approximation of first-class typeclass dictionaries, which will allow us to dramatically simplify the above testing mechanism.\n\nCreating first-class typeclass instances\nIn order to provide an easy way to construct instances, we need a way to represent instances as ordinary Haskell values. This is not terribly difficult, given that instances are conceptually just records containing a collection of functions. For example, we could create a datatype that represents an instance of the MonadFS typeclass:\n\ndata MonadFSInst m = MonadFSInst\n  { _readFile :: FilePath -> m String\n  , _writeFile :: FilePath -> String -> m ()\n  }\nTo avoid namespace clashes with the actual method identifiers, the record fields are prefixed with an underscore, but otherwise, the translation is remarkably straightforward. Using this record type, we can easily create values that represent the two instances we defined above:\n\ncontentInst :: MonadWriter [String] m => MonadFSInst m\ncontentInst = MonadFSInst\n  { _readFile = \\_ -> return \"hello\"\n  , _writeFile = \\_ contents -> tell [contents]\n  }\n\npathInst :: MonadWriter [FilePath] m => MonadFSInst m\npathInst = MonadFSInst\n  { _readFile = \\path -> tell [path] >> return \"\"\n  , _writeFile = \\path _ -> tell [path]\n  }\nThese two values represent two different implementations of MonadFS, but since they’re ordinary Haskell values, they can be manipulated and even extended like any other records. This can be extremely useful, since it makes it possible to create a sort of “base” instance, then have individual test cases override individual pieces of functionality piecemeal.\n\nOf course, although we’ve written these two instances, we have no way to actually use them. After all, Haskell does not provide a way to explicitly provide typeclass dictionaries. Fortunately, we can create a sort of “proxy” type that will use a reader to thread the dictionary around explicitly, and the instance can defer to the dictionary’s implementation.\n\nCreating an instance proxy\nTo represent our proxy type, we’ll use a combination of a Writer and a ReaderT; the former to implement the logging used by instances, and the latter to actually thread around the dictionary. Our type will look like this:\n\nnewtype TestM log a =\n    TestM (ReaderT (MonadFSInst (TestM log)) (Writer log) a)\n  deriving ( Functor, Applicative, Monad\n           , MonadReader (MonadFSInst (TestM log))\n           , MonadWriter log\n           )\n\nlogTestM :: MonadFSInst (TestM log) -> TestM log a -> log\nlogTestM inst (TestM m) = execWriter (runReaderT m inst)\nThis might look rather complicated, and it is, but let’s break down exactly what it’s doing.\n\n\nThe TestM type includes two type parameters. The first is the type of value that will be logged (hence the name log), which corresponds to the argument to Writer from previous incarnations of TestM. Unlike those types, though, we want this version to work with any Monoid, so we’ll make it a type parameter. The second parameter is simply the type of the current monadic value, as before.\n\n\nThe type itself is defined as a wrapper around a small monad transformer stack, the first of which is ReaderT. The state threaded around by the reader is, in this case, the instance dictionary, which is MonadFSInst.\n\nHowever, recall that MonadFSInst accepts a type variable—the type of a monad itself—so we must provide TestM log as an argument to MonadFSInst. This slight bit of indirection allows us to tie the knot between the mutually dependent instances and proxy type.\n\n\nThe base monad in the transformer stack is Writer, which is used to actually implement the logging functionality, just like in prior cases. The only difference now is that the log type parameter now determines what the writer actually produces.\n\n\nFinally, as before, we use GeneralizedNewtypeDeriving to derive all the relevant mtl classes, adding the somewhat wordy MonadReader constraint to the list.\n\n\nUsing this single type, we can now implement a MonadFS instance that defers to the dictionary carried around within TestM’s reader state:\n\ninstance Monoid log => MonadFS (TestM log) where\n  readFile path = do\n    f <- asks _readFile\n    f path\n  writeFile path contents = do\n    f <- asks _writeFile\n    f path contents\nThis may seem somewhat boilerplate-y, and it is to some extent, but the important consideration is that this boilerplate only needs to be written once. With this in place, it’s now possible to write an arbitrary number of first-class instances that use the above mechanism without extending the mechanism at all.\n\nTo see what actually using this code would look like, let’s update the reverseFile tests to use the new TestM implementation, as well as the contentInst and pathInst dictionaries from earlier:\n\nspec = describe \"reverseFile\" $ do\n  it \"reverses a file’s contents on the filesystem\" $ do\n    let calls = logTestM contentInst (reverseFile \"foo.txt\")\n    calls `shouldBe` [\"olleh\"]\n\n  it \"operates on the file at the provided path\" $ do\n    let paths = logTestM pathInst (reverseFile \"foo.txt\")\n    paths `shouldBe` [\"foo.txt\", \"foo.txt\"]\nWe can do a little bit better, though. Really, the definitions of contentInst and pathInst are specific to each test case. With ordinary typeclass instances, we cannot scope them to any particular block, but since MonadFSInst is just an ordinary Haskell datatype, we can manipulate them just like any other Haskell values. Therefore, we can just inline those instances’ definitions into the test cases themselves to keep them closer to the actual tests.\n\nspec = describe \"reverseFile\" $ do\n  it \"reverses a file’s contents on the filesystem\" $ do\n    let contentInst = MonadFSInst\n          { _readFile = \\_ -> return \"hello\"\n          , _writeFile = \\_ contents -> tell [contents]\n          }\n    let calls = logTestM contentInst (reverseFile \"foo.txt\")\n    calls `shouldBe` [\"olleh\"]\n\n  it \"operates on the file at the provided path\" $ do\n    let pathInst = MonadFSInst\n          { _readFile = \\path -> tell [path] >> return \"\"\n          , _writeFile = \\path _ -> tell [path]\n          }\n    let paths = logTestM pathInst (reverseFile \"foo.txt\")\n    paths `shouldBe` [\"foo.txt\", \"foo.txt\"]\nThis is pretty good. We’re now able to create inline instances of our MonadFS typeclass, which allows us to write extremely concise unit tests using ordinary Haskell typeclasses as system seams. We’ve managed to cut down on the boilerplate considerably, though we still have a couple problems. For one, this example only uses a single typeclass containing only two methods. A real MonadFS typeclass would likely have at least a dozen methods for performing various filesystem operations, and writing out the instance dictionaries for every single method, even the ones that aren’t used within the code under test, would be pretty frustratingly verbose.\n\nThis problem is solvable, though. Since instances are just ordinary Haskell records, we can create a “base” instance that just throws an exception whenever the method is called:\n\nbaseInst :: MonadFSInst m\nbaseInst = MonadFSInst\n  { _readFile = error \"unimplemented instance method ‘_readFile’\"\n  , _writeFile = error \"unimplemented instance method ‘_writeFile’\"\n  }\nThen code that only uses readFile could only override that particular method, for example:\n\nlet myInst = baseInst { _readFile = ... }\nNormally, of course, this would be a terrible idea. However, since this is all just test code, it can be extremely useful in quickly figuring out what methods need to be stubbed out for a particular test case. Since all the code actually gets run at test time, attempts to use unimplemented instance methods will immediately raise an error, informing the programmer which methods need to be implemented to make the test pass. This can also help to significantly cut down on the amount of effort it takes to implement each test.\n\nAnother problem is that our approach is specialized exclusively to MonadFS. What about functions that use both MonadFS and MonadDB, for example? Fortunately, that is not hard to solve, either. We can adapt the MonadFSInst type to include fields for all of the typeclasses relevant to our system, turning it into a generic test fixture of sorts:\n\ndata FixtureInst m = FixtureInst\n  { -- MonadFS\n    _readFile :: FilePath -> m String\n  , _writeFile :: FilePath -> String -> m ()\n\n    -- MonadDB\n  , _fetchUser :: Id User -> m User\n  , _fetchRecentPosts :: Id User -> m [Post]\n  }\nUpdating TestM to use FixtureInst instead of MonadFSInst is trivial, and all the rest of the infrastructure still works. However, this means that every time a new typeclass is added, three things need to be updated:\n\n\nIts methods need to be added to the FixtureInst record.\n\n\nThose methods need to be given error-raising defaults in the baseInst value.\n\n\nAn actual instance of the typeclass needs to be written for TestM that defers to the FixtureInst value.\n\n\nFurthermore, most of this manual manipulation of methods is required every time a particular typeclass changes, whether that means adding a method, removing a method, renaming a method, or changing a method’s type. This is especially frustrating given that all this code is really just mechanical boilerplate that could all be derived by the set of typeclasses being tested.\n\nThat last point is especially important: aside from the instances themselves, every piece of boilerplate above is obviously possible to generate from existing types alone. With that piece of information in mind, we can do even better: we can use Template Haskell.\n\nRemoving the boilerplate using test-fixture\nThe above code was not only rather boilerplate-heavy, it was pretty complicated. Fortunately, you don’t actually have to write it. Enter the library test-fixture:\n\nimport Control.Monad.TestFixture\nimport Control.Monad.TestFixture.TH\n\nmkFixture \"FixtureInst\" [''MonadFS, ''MonadDB]\n\nspec = describe \"reverseFile\" $ do\n  it \"reverses a file’s contents on the filesystem\" $ do\n    let contentInst = def\n          { _readFile = \\_ -> return \"hello\"\n          , _writeFile = \\_ contents -> log contents\n          }\n    let calls = logTestFixture (reverseFile \"foo.txt\") contentInst\n    calls `shouldBe` [\"olleh\"]\n\n  it \"operates on the file at the provided path\" $ do\n    let pathInst = def\n          { _readFile = \\path -> log path >> return \"\"\n          , _writeFile = \\path _ -> log path\n          }\n    let paths = logTestFixture (reverseFile \"foo.txt\") pathInst\n    paths `shouldBe` [\"foo.txt\", \"foo.txt\"]\nThat’s it. The above code automatically generates everything you need to write fast, simple, deterministic unit tests in Haskell. The mkFixture function is a Template Haskell macro that expands into a definition quite similar to the FixtureInst type we wrote by hand, but since it’s automatically generated from the typeclass definitions, it never needs to be updated.\n\nThe logTestFixture function replaces the logTestM function we wrote by hand, but it works exactly the same. The Control.Monad.TestFixture library also exports a log function that is a synonym for tell . singleton, but using tell directly still works if you prefer.\n\nThe mkFixture function also generates a Default instance, which replaces the baseInst value defined earlier. It functions the same way, though, producing useful error messages that refer to the names of unimplemented typeclass methods that have not been stubbed out.\n\nThis blog post is not a test-fixture tutorial—indeed, it is much more complicated than a test-fixture tutorial would be, since it covers what the library is really doing under the hood—but if you’re interested, I would highly recommend you take a look at the test-fixture documentation on Hackage.\n\nConclusion, credits, and similar techniques\nThis blog post came about as the result of a need my coworkers and I found when writing Haskell code; we wanted a way to write unit tests quickly and easily, but we didn’t find much advice from the rest of the Haskell ecosystem. The test-fixture library is the result of that exploratory work, and we currently use it to test a significant portion of our Haskell code.\n\nIt would be extremely unfair to suggest that I was the inventor of this technique or the inventor of the library. Two of my coworkers, Joe Vargas and Greg Wiley, came up with the general approach and wrote Control.Monad.TestFixture, and I simply wrote the Template Haskell macro to eliminate the boilerplate. With that in mind, I think I can say with some fairness that I think this technique is a joy to use when unit testing is a desirable goal, and I would definitely recommend it if you are interested in doing isolated testing in Haskell.\n\nThe general technique of using typeclasses to emulate effects was in part inspired by the well-known mtl library. An alternate approach to writing unit-testable Haskell code is using free monads, but overall, I prefer this approach over free monads because the typeclass constraints add type safety in ways that free monads do not (at least not without additional boilerplate), and this approach also lends itself well to static analysis-based boilerplate reduction techniques. It has its own tradeoffs, though, so if you’ve had success with free monads, then I certainly make no claim this is a superior approach, just one that I’ve personally found pleasant.\n\nAs a final note, if you do check out test-fixture, feel free to leave feedback by opening issues on the GitHub issue tracker—even things like confusing documentation are worth a bug report.","isoDate":"2016-10-03T00:00:00.000Z","timestamp":"10/2/2016"},{"title":"Understanding the npm dependency model","pubDate":"2016-08-24T00:00:00.000Z","author":"Alexis King","content":"<article><p>Currently, <a href=\"https://www.npmjs.com\">npm</a> is <em>the</em> package manager for the frontend world. Sure, there are alternatives, but for the time being, npm seems to have won. Even tools like <a href=\"https://bower.io\">Bower</a> are being pushed to the wayside in favor of the One True Package Manager, but what’s most interesting to me is npm’s relatively novel approach to dependency management. Unfortunately, in my experience, it is actually not particularly well understood, so consider this an attempt to clarify how exactly it works and how it affects <strong>you</strong> as a user or package developer.\n</p><h2><a name=\"first-the-basics\"></a>First, the basics</h2><p>At a high level, npm is not too dissimilar from other package managers for programming languages: packages depend on other packages, and they express those dependencies with <em>version ranges</em>. npm happens to use the <a href=\"http://semver.org\">semver</a> versioning scheme to express those ranges, but the way it performs version resolution is mostly immaterial; what matters is that packages can depend on ranges rather than specific versions of packages.\n</p><p>This is rather important in any ecosystem, since locking a library to a specific set of dependencies could cause significant problems, but it’s actually much less of a problem in npm’s case compared to other, similar package systems. Indeed, it is often safe for a library author to pin a dependency to a specific version without affecting dependent packages or applications. The tricky bit is determining <em>when</em> this is safe and when it’s not, and this is what I so frequently find that people get wrong.\n</p><h2><a name=\"dependency-duplication-and-the-dependency-tree\"></a>Dependency duplication and the dependency tree</h2><p>Most users of npm (or at least most package authors) eventually learn that, unlike other package managers, npm installs a <em>tree</em> of dependencies. That is, every package installed gets its own set of dependencies rather than forcing every package to share the same canonical set of packages. Obviously, virtually every single package manager in existence has to model a dependency tree at some point, since that’s how dependencies are expressed by programmers.\n</p><p>For example, consider two packages, <code>foo</code> and <code>bar</code>. Each of them have their own set of dependencies, which can be represented as a tree:\n</p><pre><code>foo\n├── hello ^0.1.2\n└── world ^1.0.7\n\nbar\n├── hello ^0.2.8\n└── goodbye ^3.4.0\n</code></pre><p>Imagine an application that depends on <em>both</em> <code>foo</code> and <code>bar</code>. Obviously, the <code>world</code> and <code>goodbye</code> dependencies are totally unrelated, so how npm handles them is relatively uninteresting. However, consider the case of <code>hello</code>: both packages require conflicting versions.\n</p><p>Most package managers (including RubyGems/Bundler, pip, and Cabal) would simply barf here, reporting a version conflict. This is because, in most package management models, <strong>only one version of any particular package can be installed at a time</strong>. In that sense, one of the package manager’s primary responsibilities is to figure out a set of package versions that will satisfy every version constraint simultaneously.\n</p><p>In contrast, npm has a somewhat easier job: it’s totally okay with installing different versions of the same package because each package gets its own set of dependencies. In the aforementioned example, the resulting directory structure would look something like this:\n</p><pre><code>node_modules/\n├── foo/\n│   └── node_modules/\n│       ├── hello/\n│       └── world/\n└── bar/\n    └── node_modules/\n        ├── hello/\n        └── goodbye/\n</code></pre><p>Notably, the directory structure very closely mirrors the actual dependency tree. The above diagram is something of a simplification: in practice, each transitive dependency would have its own <code>node_modules</code> directory and so on, but the directory structure can get pretty messy pretty quickly. (Furthermore, npm 3 performs some optimizations to attempt to share dependencies when it can, but those are ultimately unnecessary to actually understanding the model.)\n</p><p>This model is, of course, extremely simple. The obvious effect is that every package gets its own little sandbox, which works absolutely marvelously for utility libraries like <code>ramda</code>, <code>lodash</code>, or <code>underscore</code>. If <code>foo</code> depends on <code>ramda@^0.19.0</code> but <code>bar</code> depends on <code>ramda@^0.22.0</code>, they can both coexist completely peacefully without any problems.\n</p><p>At first blush, this system is <em>obviously</em> better than the alternative, flat model, so long as the underlying runtime supports the required module loading scheme. However, it is not without drawbacks.\n</p><p>The most apparent downside is a significant increase in code size, given the potential for many, many copies of the same package, all with different versions. An increase in code size can often mean more than just a larger program—it can have a significant impact on performance. Larger programs just don’t fit into CPU caches as easily, and merely having to page a program in and out can significantly slow things down. That’s mostly just a tradeoff, though, since you’re sacrificing performance, not program correctness.\n</p><p>The more insidious problem (and the one that I see crop up quite a lot in the npm ecosystem without much thought) is how dependency isolation can affect cross-package communication.\n</p><h2><a name=\"dependency-isolation-and-values-that-pass-package-boundaries\"></a>Dependency isolation and values that pass package boundaries</h2><p>The earlier example of using <code>ramda</code> is a place where npm’s default dependency management scheme really shines, given that Ramda just provides a bunch of plain ol’ functions. Passing these around is totally harmless. In fact, mixing functions from two different versions of Ramda would be totally okay! Unfortunately, not all cases are nearly that simple.\n</p><p>Consider, for a moment, <code>react</code>. React components are very much <em>not</em> plain old data; they are complex values that can be extended, instantiated, and rendered in a variety of ways. React represents component structure and state using an internal, private format, using a mixture of carefully arranged keys and values and some of the more powerful features of JavaScript’s object system. This internal structure might very well change between React versions, so a React component defined with <code>react@0.3.0</code> likely won’t work quite right with <code>react@15.3.1</code>.\n</p><p>With that in mind, consider two packages that define their own React components and export them for consumers to use. Looking at their dependency tree, we might see something like this:\n</p><pre><code>awesome-button\n└── react ^0.3.0\n\namazing-modal\n└── react ^15.3.1\n</code></pre><p>Given that these two packages use wildly different versions of React, npm would give each of them their own copy of React, as requested, and packages would happily install. However, if you tried to use these components together, they wouldn’t work at all! A newer version of React simply cannot understand an old version’s component, so you would get a (likely confusing) runtime error.\n</p><p>What went wrong? Well, dependency isolation works great when a package’s dependencies are purely implementation details, never observable from outside of a package. However, as soon as a package’s dependency becomes exposed as part of its <em>interface</em>, dependency isolation is not only subtly wrong, it can cause complete failure at runtime. These are cases when traditional dependency management are much better—they will tell you as soon as you attempt to install two packages that they just don’t work together, rather than waiting for you to figure that out for yourself.\n</p><p>This might not sound <em>too</em> bad—after all, JavaScript is a very dynamic language, so static guarantees are mostly few and far between, and your tests should catch these problems should they arise—but it can cause unnecessary issues when two packages <em>can</em> theoretically work together fine, but because npm assigned each one its own copy of a particular package (that is, it wasn’t quite smart enough to figure out it could give them both the same copy), things break down.\n</p><p>Looking outside of npm specifically and considering this model when applied to other languages, it becomes increasingly clear that this won’t do. This blog post was inspired by <a href=\"https://www.reddit.com/r/haskell/comments/4zc6y3/why_doesnt_cabal_use_a_model_like_that_of_npm/?ref=share&amp;ref_source=link\">a Reddit thread discussing the npm model applied to Haskell</a>, and this flaw was touted as a reason why it couldn’t possibly work for such a static language.\n</p><p>Due to the way the JavaScript ecosystem has evolved, it’s true that most people can often get away with this subtle potential for incorrect behavior without any problems. Specifically, JavaScript tends to rely on duck typing rather than more restrictive checks like <code>instanceof</code>, so objects that satisfy the same protocol will still be compatible, even if their implementations aren’t <em>quite</em> the same. However, npm actually provides a robust solution to this problem that allows package authors to explicitly express these “cross-interface” dependencies.\n</p><h3><a name=\"peer-dependencies\"></a>Peer dependencies</h3><p>Normally, npm package dependencies are listed under a <code>\"dependencies\"</code> key in the package’s <code>package.json</code> file. There is, however, another, less-used key called <code>\"peerDependencies\"</code>, which has the same format as the ordinary dependencies list. The difference shows up in how npm performs dependency resolution: rather than getting its own copy of a peer dependency, a package expects that dependency to be provided by its dependent.\n</p><p>This effectively means that peer dependencies are effectively resolved using the “traditional” dependency resolution mechanism that tools like Bundler and Cabal use: there must be one canonical version that satisfies everyone’s constraint. Since npm 3, things are a little bit less straightforward (specifically, peer dependencies are not automatically installed unless a dependent package explicitly depends on the peer package itself), but the basic idea is the same. This means that package authors must make a choice for each dependency they install: should it be a normal dependency or a peer dependency?\n</p><p>This is where I think people tend to get a little lost, even those familiar with the peer dependency mechanism. Fortunately, the answer is relatively simple: is the dependency in question visible in <em>any place</em> in the package’s interface?\n</p><p>This is sometimes hard to see in JavaScript because the “types” are invisible; that is, they are dynamic and rarely explicitly written out. However, just because the types are dynamic does not mean they are not there at runtime (and in the heads of various programmers), so the rule still holds: if the type of a function in a package’s public interface somehow depends on a dependency, it should be a peer dependency.\n</p><p>To make this a little more concrete, let’s look at a couple of examples. First off, let’s take a look at some simple cases, starting with some uses of <code>ramda</code>:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"p\">{</span> <span class=\"nx\">merge</span><span class=\"p\">,</span> <span class=\"nx\">add</span> <span class=\"p\">}</span> <span class=\"nx\">from</span> <span class=\"s1\">&#39;ramda&#39;</span>\n\n<span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">withDefaultConfig</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nx\">config</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span>\n  <span class=\"nx\">merge</span><span class=\"p\">({</span> <span class=\"nx\">path</span><span class=\"o\">:</span> <span class=\"s1\">&#39;.&#39;</span> <span class=\"p\">},</span> <span class=\"nx\">config</span><span class=\"p\">)</span>\n\n<span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">add5</span> <span class=\"o\">=</span> <span class=\"nx\">add</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span></code></pre><p>The first example here is pretty obvious: in <code>withDefaultConfig</code>, <code>merge</code> is used purely as an implementation detail, so it’s safe, and it’s not part of the module’s interface. In <code>add5</code>, the example is a little trickier: the result of <code>add(5)</code> is a partially-applied function created by Ramda, so technically, a Ramda-created value is a part of this module’s interface. However, the contract <code>add5</code> has with the outside world is simply that it is a JavaScript function that adds five to its argument, and it doesn’t depend on any Ramda-specific functionality, so <code>ramda</code> can safely be a non-peer dependency.\n</p><p>Now let’s look at another example using the <code>jpeg</code> image library:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"p\">{</span> <span class=\"nx\">Jpeg</span> <span class=\"p\">}</span> <span class=\"nx\">from</span> <span class=\"s1\">&#39;jpeg&#39;</span>\n\n<span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">createSquareBuffer</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nx\">size</span><span class=\"p\">,</span> <span class=\"nx\">cb</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span>\n  <span class=\"nx\">createSquareJpeg</span><span class=\"p\">(</span><span class=\"nx\">size</span><span class=\"p\">).</span><span class=\"nx\">encode</span><span class=\"p\">(</span><span class=\"nx\">cb</span><span class=\"p\">)</span>\n\n<span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">createSquareJpeg</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nx\">size</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span>\n  <span class=\"k\">new</span> <span class=\"nx\">Jpeg</span><span class=\"p\">(</span><span class=\"nx\">Buffer</span><span class=\"p\">.</span><span class=\"nx\">alloc</span><span class=\"p\">(</span><span class=\"nx\">size</span> <span class=\"o\">*</span> <span class=\"nx\">size</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"nx\">size</span><span class=\"p\">,</span> <span class=\"nx\">size</span><span class=\"p\">)</span></code></pre><p>In this case, the <code>createSquareBuffer</code> function invokes a callback with an ordinary Node.js <code>Buffer</code> object, so the <code>jpeg</code> library is an implementation detail. If that were the only function exposed by this module, <code>jpeg</code> could safely be a non-peer dependency. However, the <code>createSquareJpeg</code> function violates that rule: it returns a <code>Jpeg</code> object, which is an opaque value with a structure defined exclusively by the <code>jpeg</code> library. Therefore, a package with the above module <em>must</em> list <code>jpeg</code> as a peer dependency.\n</p><p>This sort of restriction works in reverse, too. For example, consider the following module:\n</p><pre><code class=\"pygments\"><span class=\"kr\">import</span> <span class=\"p\">{</span> <span class=\"nx\">writeFile</span> <span class=\"p\">}</span> <span class=\"nx\">from</span> <span class=\"s1\">&#39;fs&#39;</span>\n\n<span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">writeJpeg</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"nx\">filename</span><span class=\"p\">,</span> <span class=\"nx\">jpeg</span><span class=\"p\">,</span> <span class=\"nx\">cb</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span>\n  <span class=\"nx\">jpeg</span><span class=\"p\">.</span><span class=\"nx\">encode</span><span class=\"p\">((</span><span class=\"nx\">image</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span> <span class=\"nx\">fs</span><span class=\"p\">.</span><span class=\"nx\">writeFile</span><span class=\"p\">(</span><span class=\"nx\">filename</span><span class=\"p\">,</span> <span class=\"nx\">image</span><span class=\"p\">,</span> <span class=\"nx\">cb</span><span class=\"p\">))</span></code></pre><p>The above module does not even <em>import</em> the <code>jpeg</code> package, yet it implicitly depends on the <code>encode</code> method of the <code>Jpeg</code> interface. Therefore, despite not even explicitly using it anywhere in the code, a package containing the above module should include <code>jpeg</code> as a peer dependency.\n</p><p>They key is to carefully consider what contract your modules have with their dependents. If those contracts involve other packages in any way, they should be peer dependencies. If they don’t, they should be ordinary dependencies.\n</p><h2><a name=\"applying-the-npm-model-to-other-programming-languages\"></a>Applying the npm model to other programming languages</h2><p>The npm model of package management is more complicated than that of other languages, but it provides a real advantage: implementation details are kept as implementation details. In other systems, it’s quite possible to find yourself in “dependency hell”, when you personally know that the version conflict reported by your package manager is not a real problem, but because the package system must pick a single canonical version, there’s no way to make progress without adjusting code in your dependencies. This is extremely frustrating.\n</p><p>This sort of dependency isolation is not the most advanced form of package management in existence—indeed, far from it—but it’s definitely more powerful than most other mainstream systems out there. Of course, most other languages could not adopt the npm model simply by changing the package manager: having a global package namespace can prevent multiple versions of the same package being installed at a <em>runtime</em> level. The reason npm is able to do what it does is because Node itself supports it.\n</p><p>That said, the dichotomy between peer and non-peer dependencies is a little confusing, especially to people who aren’t package authors. Figuring out which packages need to go in which group is not always obvious or trivial. Fortunately, other languages might be able to help.\n</p><p>Returning to Haskell, its strong static type system would potentially allow this distinction to be detected entirely automatically, and Cabal could actually report an error when a package used in an exposed interface was not listed as a peer dependency (much like how it currently prevents importing a transitive dependency without explicitly depending on it). This would allow helper function packages to keep on being implementation details while still maintaining strong interface safety. This would likely take a lot of work to get just right—managing the global nature of typeclass instances would likely make this much more complicated than a naïve approach would accommodate—but it would add a nice layer of flexibility that does not currently exist.\n</p><p>From the perspective of JavaScript, npm has demonstrated that it can be a capable package manager, despite the monumental burden placed upon it by the ever-growing, ever-changing JS ecosystem. As a package author myself, I would implore other users to carefully consider the peer dependencies feature and work hard to encode their interfaces’ contracts using it—it’s a commonly misunderstood gem of the npm model, and I hope this blog post helped to shed at least a little more light upon it.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Currently, npm is the package manager for the frontend world. Sure, there are alternatives, but for the time being, npm seems to have won. Even tools like Bower are being pushed to the wayside in favor of the One True Package Manager, but what’s most interesting to me is npm’s relatively novel approach to dependency management. Unfortunately, in my experience, it is actually not particularly well understood, so consider this an attempt to clarify how exactly it works and how it affects you as a user or package developer.\n\nFirst, the basics\nAt a high level, npm is not too dissimilar from other package managers for programming languages: packages depend on other packages, and they express those dependencies with version ranges. npm happens to use the semver versioning scheme to express those ranges, but the way it performs version resolution is mostly immaterial; what matters is that packages can depend on ranges rather than specific versions of packages.\n\nThis is rather important in any ecosystem, since locking a library to a specific set of dependencies could cause significant problems, but it’s actually much less of a problem in npm’s case compared to other, similar package systems. Indeed, it is often safe for a library author to pin a dependency to a specific version without affecting dependent packages or applications. The tricky bit is determining when this is safe and when it’s not, and this is what I so frequently find that people get wrong.\n\nDependency duplication and the dependency tree\nMost users of npm (or at least most package authors) eventually learn that, unlike other package managers, npm installs a tree of dependencies. That is, every package installed gets its own set of dependencies rather than forcing every package to share the same canonical set of packages. Obviously, virtually every single package manager in existence has to model a dependency tree at some point, since that’s how dependencies are expressed by programmers.\n\nFor example, consider two packages, foo and bar. Each of them have their own set of dependencies, which can be represented as a tree:\n\nfoo\n├── hello ^0.1.2\n└── world ^1.0.7\n\nbar\n├── hello ^0.2.8\n└── goodbye ^3.4.0\n\nImagine an application that depends on both foo and bar. Obviously, the world and goodbye dependencies are totally unrelated, so how npm handles them is relatively uninteresting. However, consider the case of hello: both packages require conflicting versions.\n\nMost package managers (including RubyGems/Bundler, pip, and Cabal) would simply barf here, reporting a version conflict. This is because, in most package management models, only one version of any particular package can be installed at a time. In that sense, one of the package manager’s primary responsibilities is to figure out a set of package versions that will satisfy every version constraint simultaneously.\n\nIn contrast, npm has a somewhat easier job: it’s totally okay with installing different versions of the same package because each package gets its own set of dependencies. In the aforementioned example, the resulting directory structure would look something like this:\n\nnode_modules/\n├── foo/\n│   └── node_modules/\n│       ├── hello/\n│       └── world/\n└── bar/\n    └── node_modules/\n        ├── hello/\n        └── goodbye/\n\nNotably, the directory structure very closely mirrors the actual dependency tree. The above diagram is something of a simplification: in practice, each transitive dependency would have its own node_modules directory and so on, but the directory structure can get pretty messy pretty quickly. (Furthermore, npm 3 performs some optimizations to attempt to share dependencies when it can, but those are ultimately unnecessary to actually understanding the model.)\n\nThis model is, of course, extremely simple. The obvious effect is that every package gets its own little sandbox, which works absolutely marvelously for utility libraries like ramda, lodash, or underscore. If foo depends on ramda@^0.19.0 but bar depends on ramda@^0.22.0, they can both coexist completely peacefully without any problems.\n\nAt first blush, this system is obviously better than the alternative, flat model, so long as the underlying runtime supports the required module loading scheme. However, it is not without drawbacks.\n\nThe most apparent downside is a significant increase in code size, given the potential for many, many copies of the same package, all with different versions. An increase in code size can often mean more than just a larger program—it can have a significant impact on performance. Larger programs just don’t fit into CPU caches as easily, and merely having to page a program in and out can significantly slow things down. That’s mostly just a tradeoff, though, since you’re sacrificing performance, not program correctness.\n\nThe more insidious problem (and the one that I see crop up quite a lot in the npm ecosystem without much thought) is how dependency isolation can affect cross-package communication.\n\nDependency isolation and values that pass package boundaries\nThe earlier example of using ramda is a place where npm’s default dependency management scheme really shines, given that Ramda just provides a bunch of plain ol’ functions. Passing these around is totally harmless. In fact, mixing functions from two different versions of Ramda would be totally okay! Unfortunately, not all cases are nearly that simple.\n\nConsider, for a moment, react. React components are very much not plain old data; they are complex values that can be extended, instantiated, and rendered in a variety of ways. React represents component structure and state using an internal, private format, using a mixture of carefully arranged keys and values and some of the more powerful features of JavaScript’s object system. This internal structure might very well change between React versions, so a React component defined with react@0.3.0 likely won’t work quite right with react@15.3.1.\n\nWith that in mind, consider two packages that define their own React components and export them for consumers to use. Looking at their dependency tree, we might see something like this:\n\nawesome-button\n└── react ^0.3.0\n\namazing-modal\n└── react ^15.3.1\n\nGiven that these two packages use wildly different versions of React, npm would give each of them their own copy of React, as requested, and packages would happily install. However, if you tried to use these components together, they wouldn’t work at all! A newer version of React simply cannot understand an old version’s component, so you would get a (likely confusing) runtime error.\n\nWhat went wrong? Well, dependency isolation works great when a package’s dependencies are purely implementation details, never observable from outside of a package. However, as soon as a package’s dependency becomes exposed as part of its interface, dependency isolation is not only subtly wrong, it can cause complete failure at runtime. These are cases when traditional dependency management are much better—they will tell you as soon as you attempt to install two packages that they just don’t work together, rather than waiting for you to figure that out for yourself.\n\nThis might not sound too bad—after all, JavaScript is a very dynamic language, so static guarantees are mostly few and far between, and your tests should catch these problems should they arise—but it can cause unnecessary issues when two packages can theoretically work together fine, but because npm assigned each one its own copy of a particular package (that is, it wasn’t quite smart enough to figure out it could give them both the same copy), things break down.\n\nLooking outside of npm specifically and considering this model when applied to other languages, it becomes increasingly clear that this won’t do. This blog post was inspired by a Reddit thread discussing the npm model applied to Haskell, and this flaw was touted as a reason why it couldn’t possibly work for such a static language.\n\nDue to the way the JavaScript ecosystem has evolved, it’s true that most people can often get away with this subtle potential for incorrect behavior without any problems. Specifically, JavaScript tends to rely on duck typing rather than more restrictive checks like instanceof, so objects that satisfy the same protocol will still be compatible, even if their implementations aren’t quite the same. However, npm actually provides a robust solution to this problem that allows package authors to explicitly express these “cross-interface” dependencies.\n\nPeer dependencies\nNormally, npm package dependencies are listed under a \"dependencies\" key in the package’s package.json file. There is, however, another, less-used key called \"peerDependencies\", which has the same format as the ordinary dependencies list. The difference shows up in how npm performs dependency resolution: rather than getting its own copy of a peer dependency, a package expects that dependency to be provided by its dependent.\n\nThis effectively means that peer dependencies are effectively resolved using the “traditional” dependency resolution mechanism that tools like Bundler and Cabal use: there must be one canonical version that satisfies everyone’s constraint. Since npm 3, things are a little bit less straightforward (specifically, peer dependencies are not automatically installed unless a dependent package explicitly depends on the peer package itself), but the basic idea is the same. This means that package authors must make a choice for each dependency they install: should it be a normal dependency or a peer dependency?\n\nThis is where I think people tend to get a little lost, even those familiar with the peer dependency mechanism. Fortunately, the answer is relatively simple: is the dependency in question visible in any place in the package’s interface?\n\nThis is sometimes hard to see in JavaScript because the “types” are invisible; that is, they are dynamic and rarely explicitly written out. However, just because the types are dynamic does not mean they are not there at runtime (and in the heads of various programmers), so the rule still holds: if the type of a function in a package’s public interface somehow depends on a dependency, it should be a peer dependency.\n\nTo make this a little more concrete, let’s look at a couple of examples. First off, let’s take a look at some simple cases, starting with some uses of ramda:\n\nimport { merge, add } from 'ramda'\n\nexport const withDefaultConfig = (config) =>\n  merge({ path: '.' }, config)\n\nexport const add5 = add(5)\nThe first example here is pretty obvious: in withDefaultConfig, merge is used purely as an implementation detail, so it’s safe, and it’s not part of the module’s interface. In add5, the example is a little trickier: the result of add(5) is a partially-applied function created by Ramda, so technically, a Ramda-created value is a part of this module’s interface. However, the contract add5 has with the outside world is simply that it is a JavaScript function that adds five to its argument, and it doesn’t depend on any Ramda-specific functionality, so ramda can safely be a non-peer dependency.\n\nNow let’s look at another example using the jpeg image library:\n\nimport { Jpeg } from 'jpeg'\n\nexport const createSquareBuffer = (size, cb) =>\n  createSquareJpeg(size).encode(cb)\n\nexport const createSquareJpeg = (size) =>\n  new Jpeg(Buffer.alloc(size * size, 0), size, size)\nIn this case, the createSquareBuffer function invokes a callback with an ordinary Node.js Buffer object, so the jpeg library is an implementation detail. If that were the only function exposed by this module, jpeg could safely be a non-peer dependency. However, the createSquareJpeg function violates that rule: it returns a Jpeg object, which is an opaque value with a structure defined exclusively by the jpeg library. Therefore, a package with the above module must list jpeg as a peer dependency.\n\nThis sort of restriction works in reverse, too. For example, consider the following module:\n\nimport { writeFile } from 'fs'\n\nexport const writeJpeg = (filename, jpeg, cb) =>\n  jpeg.encode((image) => fs.writeFile(filename, image, cb))\nThe above module does not even import the jpeg package, yet it implicitly depends on the encode method of the Jpeg interface. Therefore, despite not even explicitly using it anywhere in the code, a package containing the above module should include jpeg as a peer dependency.\n\nThey key is to carefully consider what contract your modules have with their dependents. If those contracts involve other packages in any way, they should be peer dependencies. If they don’t, they should be ordinary dependencies.\n\nApplying the npm model to other programming languages\nThe npm model of package management is more complicated than that of other languages, but it provides a real advantage: implementation details are kept as implementation details. In other systems, it’s quite possible to find yourself in “dependency hell”, when you personally know that the version conflict reported by your package manager is not a real problem, but because the package system must pick a single canonical version, there’s no way to make progress without adjusting code in your dependencies. This is extremely frustrating.\n\nThis sort of dependency isolation is not the most advanced form of package management in existence—indeed, far from it—but it’s definitely more powerful than most other mainstream systems out there. Of course, most other languages could not adopt the npm model simply by changing the package manager: having a global package namespace can prevent multiple versions of the same package being installed at a runtime level. The reason npm is able to do what it does is because Node itself supports it.\n\nThat said, the dichotomy between peer and non-peer dependencies is a little confusing, especially to people who aren’t package authors. Figuring out which packages need to go in which group is not always obvious or trivial. Fortunately, other languages might be able to help.\n\nReturning to Haskell, its strong static type system would potentially allow this distinction to be detected entirely automatically, and Cabal could actually report an error when a package used in an exposed interface was not listed as a peer dependency (much like how it currently prevents importing a transitive dependency without explicitly depending on it). This would allow helper function packages to keep on being implementation details while still maintaining strong interface safety. This would likely take a lot of work to get just right—managing the global nature of typeclass instances would likely make this much more complicated than a naïve approach would accommodate—but it would add a nice layer of flexibility that does not currently exist.\n\nFrom the perspective of JavaScript, npm has demonstrated that it can be a capable package manager, despite the monumental burden placed upon it by the ever-growing, ever-changing JS ecosystem. As a package author myself, I would implore other users to carefully consider the peer dependencies feature and work hard to encode their interfaces’ contracts using it—it’s a commonly misunderstood gem of the npm model, and I hope this blog post helped to shed at least a little more light upon it.","isoDate":"2016-08-24T00:00:00.000Z","timestamp":"8/23/2016"},{"title":"Climbing the infinite ladder of abstraction","pubDate":"2016-08-11T00:00:00.000Z","author":"Alexis King","content":"<article><p>I started programming in elementary school.\n</p><p>When I was young, I was fascinated by the idea of automation. I loathed doing the same repetitive task over and over again, and I always yearned for a way to <a href=\"https://xkcd.com/974/\">solve the general problem</a>. When I learned about programming, I was immediately hooked: it was <em>so easy</em> to turn repetitive tasks into automated pipelines that would free me from ever having to do the same dull, frustrating exercise ever again.\n</p><p>Of course, one of the first things I found out once I’d started was that nothing is ever quite so simple. Before long, my solutions to eliminate repetition grew repetitive, and it became clear I spent a lot of time typing out the same things, over and over again, creating the very problem I had initially set out to destroy. It was through this that I grew interested in functions, classes, and other repetition-reducing aids, and soon enough, I discovered the wonderful world of <strong>abstraction</strong>.\n</p><h2><a name=\"the-brick-wall-of-inexpressiveness\"></a>The brick wall of inexpressiveness</h2><p>When I started programming, I was mostly playing with ActionScript and Java, just tinkering with things and seeing what I could come up with. I had quite a lot of fun, and the joy of solving problems hooked me almost immediately, but I also ran into frustrations pretty quickly. Specifically, I started writing a lot of code that looked like this:\n</p><pre><code class=\"pygments\"><span class=\"kd\">public</span> <span class=\"n\">String</span> <span class=\"nf\">getName</span><span class=\"o\">()</span> <span class=\"o\">{</span>\n  <span class=\"k\">return</span> <span class=\"k\">this</span><span class=\"o\">.</span><span class=\"na\">name</span><span class=\"o\">;</span>\n<span class=\"o\">}</span>\n\n<span class=\"kd\">public</span> <span class=\"kt\">void</span> <span class=\"nf\">setName</span><span class=\"o\">(</span><span class=\"n\">String</span> <span class=\"n\">name</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n  <span class=\"k\">this</span><span class=\"o\">.</span><span class=\"na\">name</span> <span class=\"o\">=</span> <span class=\"n\">name</span><span class=\"o\">;</span>\n<span class=\"o\">}</span></code></pre><p>This is a bit of a cheap example, given that Java getters and setters are something of a programming language punching bag at this point, but I really did write them, and I really did get frustrated by them! I learned object-oriented design patterns, and I pored over books, forum threads, blog posts, and Stack Overflow questions about how to structure code to prevent spaghetti, but no matter how hard I tried, I kept having to type things that looked suspiciously similar to each other.\n</p><p>It was really quite frustrating, because no matter how I approached the problem, I ended up with a boilerplate-heavy mess. The <em>whole reason</em> I got started programming was to avoid this sort of thing, so what could I do? Well, it became increasingly obvious to me that Java had to go, and I needed to try something else. I started learning two very different programming languages, JavaScript and Objective-C, and I liked them both, for different reasons.\n</p><p>When I learned JavaScript, I discovered the closure, the first-class function, and I was entranced by it. Through jQuery, I learned of its power to design APIs that could be fun to use, dropping the boring, “heavy” feeling that Java carried around everywhere. With Objective-C, on the other hand, I learned about the power of a more dynamic object system, something with interesting syntax and the ability to handle “message passing” at a far higher level than Java ever could.\n</p><p>Both of these languages were flawed, as all languages are, but they opened my mind to the idea that <em>programming languages</em> could drastically influence the way I thought about problem solving, and they set me on a quest to find the programming language that would eliminate boilerplate once and for all.\n</p><h2><a name=\"discovering-lisp\"></a>Discovering Lisp</h2><p>Over the next few years, I grew to appreciate JavaScript’s small, simple core, despite rather disliking its object system and poor faculties for user-friendly data modeling. I pored over its history, and I found out that its design was heavily influenced by an obscure little language called Scheme, as well as an even more obscure language called Self, and a part of me started to wonder what it would be like to incorporate those languages’ ideas without some of the compromises JavaScript had made.\n</p><p>This idea lingered in the back of my head for a couple years, and while I tried to play with Scheme a couple times, it was simply too inaccessible for me. I was used to languages with powerful, easy to use IDEs, and when I found myself with nothing more than a command-line executable and rather scarce documentation, I was at a loss for how to begin. Even if I could do math in the REPL, where could I go from there? I’d started programming by building games, then websites. What could I possibly do with Scheme?\n</p><p>The language (or rather, its lack of an ecosystem) proved too intimidating for me at that young age, but the idea of Lisp’s homoiconicity stuck with me. Eventually, I started to design my very own programming language, a <a href=\"https://github.com/lexi-lambda/libsol\">highly dynamic Lisp with a prototypal object system called Sol</a>. I worked on it for about a year, and when I was done with it, it had a not-too-shabby complement of features: it had lambdas, macros, a fully-featured object model, and a CommonJS-esque module system, complete with the ability to dynamically import arbitrary C extensions. It was by far the largest project I’d ever worked on, and when I was done, I was pretty pleased.\n</p><p>Unfortunately, it was also abysmally slow.\n</p><p>I turned to a local college to find some people who could give me feedback and maybe point me in the right direction, and someone told me about another obscure programming language called <a href=\"http://racket-lang.org\">Racket</a>. At about the same time, someone pointed me to a totally different language called <a href=\"https://www.haskell.org\">Haskell</a>. This was uncharted territory for me, and for a while, I didn’t really explore either of those languages further. Eventually, though, I dove into them in earnest, and what I found has dramatically altered my perspective on programming since then.\n</p><h2><a name=\"a-journey-into-complexity\"></a>A journey into complexity</h2><p>Fast forward about three years, and today, I am employed writing Haskell, and I spend most of my free time writing Racket. These languages left a mark on me, and while I’ve learned <em>so much more</em> since then, I find myself continually bucking the mainstream and coming back to functional programming, hygienic macros, and possibly the most powerful type system in existence in a production-ready programming language.\n</p><p>I’ve also started realizing something else, though: <strong>the languages I’ve settled into are <em>really complicated</em>.</strong>\n</p><p>When I started programming, I thought about things like numbers, text, and shapes on a screen. Before long, I learned about functions, then classes, then message-passing and lambdas. I dove into macros and typeclasses, and now I speak in functors and monads, sets of scopes and internal definition contexts, and parser combinators and domain specific languages.\n</p><p>Why?\n</p><p>Sometimes I talk to fellow programmers, and they are horrified by the types of terms I fling around. “Why would you ever need something called a ‘monad’?” they ask, completely perplexed. “Macros are confusing,” they argue. “Being explicit is better.”\n</p><p>Obviously, I disagree, but why? What have I given up? If my fellow programmers cannot understand what I’m writing, is it actually worth it?\n</p><p>I’ve searched for years to find a programming language that will eliminate boilerplate, that will allow me to express my ideas succinctly and cleanly, that will let me turn hard problems into trivial ones, and I’ve discovered two completely different approaches to tackling those issues. Racket has macros, and Haskell has its fancy type system. Both of these things are lightyears ahead of where I was nearly a decade ago, writing dozens of lines of repetitive Java that ultimately did very little, but I’m still dealing with the same problems.\n</p><p>Racket knows too little about my program—it can’t figure out what I mean based on the type of thing I’m operating on because it is (mostly) dynamically typed. I <em>still</em> have to clarify myself and write things that feel redundant because the computer isn’t smart enough to figure out the “obvious”. Similarly, Haskell is too limiting—the compiler cannot deduce constraints I can solve in my head in seconds, and its syntax is not extensible like Racket’s is. Every day, I peer into piles upon piles of monadic computation, and really, what have I gained?\n</p><h3><a name=\"improvement-but-never-mastery\"></a>Improvement, but never mastery</h3><p>Like almost anything in life, programming is not really a perfectable art. There’s always some unlearned skill or undiscovered technique, and part of this potential for perpetual self-improvement is one of the things that I find so attractive about the field. That said, I this it is reasonable to say that certain languages have higher ceilings than others.\n</p><p>For example I am pretty confident that I <em>get</em> JavaScript. The language has lots of nooks and crannies that I don’t completely understand, but I feel pretty confident that I understand its semantics well enough to be able to grasp any piece of JavaScript code without too much incredulity. Now, that’s not to say that JavaScript is a simplistic language—far from it—but most of the ways I improve my JavaScripting abilities are learning new techniques <em>within</em> the language, not entirely new linguistic constructs.\n</p><p>On the other hand, languages like Haskell and Racket tend to blur the line. I feel like I have a good grasp of Haskell’s core, but do I have a good intuition for laziness? Do I completely grok type families? What about <code>TypeInType</code>? Ultimately, I have to come to the conclusion that I do not fully understand Haskell, much less a lot of the advanced category theory that composes some of its most powerful libraries. Racket manages to blur the line between language and library even further, and while I consider myself a decent Racketeer, I absolutely do <em>not</em> have a good grasp on all the intricacies of Racket’s macro system.\n</p><p>This is especially obvious to me at work, given that I write Haskell in a team setting. Just like back when I was writing Java, I end up with solutions that don’t satisfy me, and I reach for increasingly powerful constructs to help alleviate my qualms. Sometimes, I find myself cracking out <code>DataKinds</code>, and it might even help my problem, but there’s a cost: my coworkers are sometimes confused.\n</p><p>Every time I climb to the next rung on the ladder of abstraction, those only a couple rungs below me (even if we’re all hundreds of rungs up!) find themselves perplexed. In the worst case, people may even blame their confusion on their own inadequacy or lack of skill. This is <em>terrible</em>, especially when I know that, by the time they’ve caught up, I’ll be off playing with some new toy: comonads or type families or classy lenses. The cycle continues, and nobody is ever truly satisfied—I always want to find a new abstraction that will make things simpler, and those just a couple steps behind me struggle to keep up.\n</p><p>Of course, I experience it from the opposite perspective just as often: I delve into Edward Kmett’s fancier libraries or Phil Freeman’s blog posts about category theory, and I recognize that I am rather lost. Sometimes, I find myself understanding things, but just as often, I cannot wrap my head around the concepts being discussed. I may figure them out eventually, sure, but by then everyone else has moved on to even <em>more</em> advanced things, and still, none of them truly solve my problems.\n</p><h2><a name=\"ultimately-it-all-has-at-least-a-little-value\"></a>Ultimately, it all has (at least a little) value</h2><p>It would be nice to think about all that and say, well, “Let’s finally break the cycle. Let’s stop deluding ourselves into thinking our solutions to our self-made problems are actually solving anything.” It would be great if I could tell myself that, but I unfortunately really can’t.\n</p><p>The scariest part of all is that I think it’s completely worthwhile.\n</p><p>So much of these more and more complicated abstractions are trying to do the same basic thing: come up with a better way of modeling the problem. In some sense, that’s all programming really is, modeling a domain in a way that can be leveraged by a digital computer. Our increasingly complicated DSLs <em>seem</em> unnecessarily complicated, they <em>seem</em> increasingly removed from reality, but that’s only because we’re getting better at creating languages that are closer to our domains without the baggage of preconceptions that came before us.\n</p><p>The downside is that, without an understanding of those preconceptions, a lot of what we come up with seems like patent gibberish to those unaware of our languages’ history.\n</p><p>Most programmers, even those who have never seen BASIC before, can figure out what this snippet does:\n</p><pre><code class=\"pygments\"><span class=\"nl\">10</span><span class=\"w\"> </span><span class=\"kr\">INPUT</span><span class=\"w\"> </span><span class=\"s2\">\"What is your name: \"</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"vg\">U$</span>\n<span class=\"nl\">20</span><span class=\"w\"> </span><span class=\"kr\">PRINT</span><span class=\"w\"> </span><span class=\"s2\">\"Hello \"</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"vg\">U$</span></code></pre><p>On the other hand, very few would probably understand this one:\n</p><pre><code class=\"pygments\"><span class=\"c1\">-- | A class for categories.</span>\n<span class=\"c1\">--   id and (.) must form a monoid.</span>\n<span class=\"kr\">class</span> <span class=\"kt\">Category</span> <span class=\"n\">cat</span> <span class=\"kr\">where</span>\n    <span class=\"c1\">-- | the identity morphism</span>\n    <span class=\"n\">id</span> <span class=\"ow\">::</span> <span class=\"n\">cat</span> <span class=\"n\">a</span> <span class=\"n\">a</span>\n\n    <span class=\"c1\">-- | morphism composition</span>\n    <span class=\"p\">(</span><span class=\"o\">.</span><span class=\"p\">)</span> <span class=\"ow\">::</span> <span class=\"n\">cat</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">cat</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">cat</span> <span class=\"n\">a</span> <span class=\"n\">c</span></code></pre><p>Yet very few new programs are being written in BASIC, and lots are being written in Haskell.\n</p><p>Even one of the most popular, fastest-growing programming languages in the world, JavaScript, a language considered relatively accessible compared to things like Haskell, would likely be incomprehensible to a programmer not familiar with its syntax:\n</p><pre><code class=\"pygments\"><span class=\"kr\">export</span> <span class=\"kr\">const</span> <span class=\"nx\">composeWithProps</span> <span class=\"o\">=</span> <span class=\"nx\">curry</span><span class=\"p\">((</span><span class=\"nx\">a</span><span class=\"p\">,</span> <span class=\"nx\">parentProps</span><span class=\"p\">,</span> <span class=\"nx\">b</span><span class=\"p\">)</span> <span class=\"p\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"kr\">const</span> <span class=\"nx\">composed</span> <span class=\"o\">=</span> <span class=\"nx\">childProps</span> <span class=\"p\">=&gt;</span>\n    <span class=\"nx\">createElement</span><span class=\"p\">(</span><span class=\"nx\">a</span><span class=\"p\">,</span> <span class=\"nx\">parentProps</span><span class=\"p\">,</span> <span class=\"nx\">createElement</span><span class=\"p\">(</span><span class=\"nx\">b</span><span class=\"p\">,</span> <span class=\"nx\">omit</span><span class=\"p\">([</span><span class=\"s1\">&#39;children&#39;</span><span class=\"p\">],</span> <span class=\"nx\">childProps</span><span class=\"p\">),</span> <span class=\"nx\">childProps</span><span class=\"p\">.</span><span class=\"nx\">children</span><span class=\"p\">));</span>\n  <span class=\"c1\">// give the composed component a pretty display name for debugging</span>\n  <span class=\"nx\">composed</span><span class=\"p\">.</span><span class=\"nx\">displayName</span> <span class=\"o\">=</span> <span class=\"sb\">`Composed(</span><span class=\"si\">${</span><span class=\"nx\">getDisplayName</span><span class=\"p\">(</span><span class=\"nx\">a</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"sb\">, </span><span class=\"si\">${</span><span class=\"nx\">getDisplayName</span><span class=\"p\">(</span><span class=\"nx\">b</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"sb\">)`</span><span class=\"p\">;</span>\n  <span class=\"k\">return</span> <span class=\"nx\">composed</span><span class=\"p\">;</span>\n<span class=\"p\">});</span></code></pre><p>Moving towards increasingly specialized syntaxes is not inherently bad—it can often be indicative of a more streamlined, domain-specific way of thinking—but while it may dramatically increase the productivity of a seasoned programmer, it can be nothing short of baffling to a newcomer.\n</p><p>That, specifically, is the crux of my fear: are we always aware of who we are optimizing for? I do not have a moral problem with writing code to optimize concision for seasoned programmers; after all, brevity is one of the primary ways code is made more readable (verbosity is the enemy of understanding). However, when that concision comes at the cost of beginners’ understanding, the picture becomes a bit more grey. It is not wrong to write things that are highly optimized for one’s own knowledge and understanding, and establishing a group of such people can make for an <em>extremely</em> productive team. It’s just also important to understand that others will likely be confused, and without being willing to invest the time and money into education, smart, diligent people will still fail to grasp the concepts, and they will likely be wholly uninterested in them.\n</p><h3><a name=\"reactionary-anti-intellectualism-and-the-search-for-moderation\"></a>Reactionary anti-intellectualism and the search for moderation</h3><p>I have noticed lately that people close to my circles have started regularly slinging insults at people who work in highly specialized notation. Math, including things like category and type theory, has become an especially acceptable punching bag. <a href=\"https://twitter.com/lexi_lambda/status/763111451691134976\">I recently tweeted a picture of some rather dense mathematics from a paper I’d read</a>, and I was frankly disturbed at some of the vitriolic responses. Academia is sometimes described as “masturbatory”, and honestly, that is both offensive and hypocritical.\n</p><p>Mathematical notation is not perfect, no more than dense Haskell, heavily metaprogrammed Ruby, or IIFE-packed JavaScript. Still, it serves a purpose, and sometimes spelling things out is neither practically feasible nor a theoretical improvement. Programmers would not take kindly to being asked to write all their code out as prose, nor would they like being told that using higher-order functions like <code>map</code> should be banned because they are too confusing and not immediately self-explanatory.\n</p><p>I am glad that people are focusing on usability and accessibility more than ever, and I think that’s one of the areas I’m the most interested in. I want to get the best of both worlds: I aim to write code in a highly concise, precise style, but I try and produce intuitive interfaces with human-readable errors upon failure. To me, a user-hostile yet technically functional library is a buggy one, and I would happily file a bug report about a confusing API or error message.\n</p><p>Abstraction is what seems to make programming possible, and indeed, it’s what makes most modern <em>technology</em> possible. It’s what allows people to drive a car without knowing how an internal combustion engine works, and it’s what allows people to browse the web without having a deep understanding of internet protocol. In programming, abstraction serves a similar purpose. Of course, just like all tools, abstractions can have rather different goals: the average user will not pick up Photoshop in a day, but a power user is not going to be satisfied with Paint.\n</p><p>Programmers are professionals, and we work in a technical domain. I am absolutely of the belief that programming, like any other field, is not always about what comes easiest: sometimes it’s important to sit down and study for a while to grok a particularly complicated concept, and other times, it’s simply important to learn by trying, failing, and asking questions. I strive to find that blend of accessible, concise, and robust, and just like everything else, that target shifts depending on the situation and people I’m working with.\n</p><p>I honestly don’t know if Racket and Haskell are worth their costs in complexity. At the end of the day, maybe what really matters is writing simple, consistent things that other people can understand. I really hope that there is a place for more powerful languages within a team, but there’s something to be said about which languages tend to get the most popular.\n</p><p>Ultimately, though, I am just trying to be aware of the tradeoffs I’m making, the benefits I’m getting, and the impact on those I’m working with. I will continue to search for abstractions that can better fit my needs, and I am sure I will keep on climbing the ladder of abstraction for years to come—I just really hope I’m not wasting my time.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"I started programming in elementary school.\n\nWhen I was young, I was fascinated by the idea of automation. I loathed doing the same repetitive task over and over again, and I always yearned for a way to solve the general problem. When I learned about programming, I was immediately hooked: it was so easy to turn repetitive tasks into automated pipelines that would free me from ever having to do the same dull, frustrating exercise ever again.\n\nOf course, one of the first things I found out once I’d started was that nothing is ever quite so simple. Before long, my solutions to eliminate repetition grew repetitive, and it became clear I spent a lot of time typing out the same things, over and over again, creating the very problem I had initially set out to destroy. It was through this that I grew interested in functions, classes, and other repetition-reducing aids, and soon enough, I discovered the wonderful world of abstraction.\n\nThe brick wall of inexpressiveness\nWhen I started programming, I was mostly playing with ActionScript and Java, just tinkering with things and seeing what I could come up with. I had quite a lot of fun, and the joy of solving problems hooked me almost immediately, but I also ran into frustrations pretty quickly. Specifically, I started writing a lot of code that looked like this:\n\npublic String getName() {\n  return this.name;\n}\n\npublic void setName(String name) {\n  this.name = name;\n}\nThis is a bit of a cheap example, given that Java getters and setters are something of a programming language punching bag at this point, but I really did write them, and I really did get frustrated by them! I learned object-oriented design patterns, and I pored over books, forum threads, blog posts, and Stack Overflow questions about how to structure code to prevent spaghetti, but no matter how hard I tried, I kept having to type things that looked suspiciously similar to each other.\n\nIt was really quite frustrating, because no matter how I approached the problem, I ended up with a boilerplate-heavy mess. The whole reason I got started programming was to avoid this sort of thing, so what could I do? Well, it became increasingly obvious to me that Java had to go, and I needed to try something else. I started learning two very different programming languages, JavaScript and Objective-C, and I liked them both, for different reasons.\n\nWhen I learned JavaScript, I discovered the closure, the first-class function, and I was entranced by it. Through jQuery, I learned of its power to design APIs that could be fun to use, dropping the boring, “heavy” feeling that Java carried around everywhere. With Objective-C, on the other hand, I learned about the power of a more dynamic object system, something with interesting syntax and the ability to handle “message passing” at a far higher level than Java ever could.\n\nBoth of these languages were flawed, as all languages are, but they opened my mind to the idea that programming languages could drastically influence the way I thought about problem solving, and they set me on a quest to find the programming language that would eliminate boilerplate once and for all.\n\nDiscovering Lisp\nOver the next few years, I grew to appreciate JavaScript’s small, simple core, despite rather disliking its object system and poor faculties for user-friendly data modeling. I pored over its history, and I found out that its design was heavily influenced by an obscure little language called Scheme, as well as an even more obscure language called Self, and a part of me started to wonder what it would be like to incorporate those languages’ ideas without some of the compromises JavaScript had made.\n\nThis idea lingered in the back of my head for a couple years, and while I tried to play with Scheme a couple times, it was simply too inaccessible for me. I was used to languages with powerful, easy to use IDEs, and when I found myself with nothing more than a command-line executable and rather scarce documentation, I was at a loss for how to begin. Even if I could do math in the REPL, where could I go from there? I’d started programming by building games, then websites. What could I possibly do with Scheme?\n\nThe language (or rather, its lack of an ecosystem) proved too intimidating for me at that young age, but the idea of Lisp’s homoiconicity stuck with me. Eventually, I started to design my very own programming language, a highly dynamic Lisp with a prototypal object system called Sol. I worked on it for about a year, and when I was done with it, it had a not-too-shabby complement of features: it had lambdas, macros, a fully-featured object model, and a CommonJS-esque module system, complete with the ability to dynamically import arbitrary C extensions. It was by far the largest project I’d ever worked on, and when I was done, I was pretty pleased.\n\nUnfortunately, it was also abysmally slow.\n\nI turned to a local college to find some people who could give me feedback and maybe point me in the right direction, and someone told me about another obscure programming language called Racket. At about the same time, someone pointed me to a totally different language called Haskell. This was uncharted territory for me, and for a while, I didn’t really explore either of those languages further. Eventually, though, I dove into them in earnest, and what I found has dramatically altered my perspective on programming since then.\n\nA journey into complexity\nFast forward about three years, and today, I am employed writing Haskell, and I spend most of my free time writing Racket. These languages left a mark on me, and while I’ve learned so much more since then, I find myself continually bucking the mainstream and coming back to functional programming, hygienic macros, and possibly the most powerful type system in existence in a production-ready programming language.\n\nI’ve also started realizing something else, though: the languages I’ve settled into are really complicated.\n\nWhen I started programming, I thought about things like numbers, text, and shapes on a screen. Before long, I learned about functions, then classes, then message-passing and lambdas. I dove into macros and typeclasses, and now I speak in functors and monads, sets of scopes and internal definition contexts, and parser combinators and domain specific languages.\n\nWhy?\n\nSometimes I talk to fellow programmers, and they are horrified by the types of terms I fling around. “Why would you ever need something called a ‘monad’?” they ask, completely perplexed. “Macros are confusing,” they argue. “Being explicit is better.”\n\nObviously, I disagree, but why? What have I given up? If my fellow programmers cannot understand what I’m writing, is it actually worth it?\n\nI’ve searched for years to find a programming language that will eliminate boilerplate, that will allow me to express my ideas succinctly and cleanly, that will let me turn hard problems into trivial ones, and I’ve discovered two completely different approaches to tackling those issues. Racket has macros, and Haskell has its fancy type system. Both of these things are lightyears ahead of where I was nearly a decade ago, writing dozens of lines of repetitive Java that ultimately did very little, but I’m still dealing with the same problems.\n\nRacket knows too little about my program—it can’t figure out what I mean based on the type of thing I’m operating on because it is (mostly) dynamically typed. I still have to clarify myself and write things that feel redundant because the computer isn’t smart enough to figure out the “obvious”. Similarly, Haskell is too limiting—the compiler cannot deduce constraints I can solve in my head in seconds, and its syntax is not extensible like Racket’s is. Every day, I peer into piles upon piles of monadic computation, and really, what have I gained?\n\nImprovement, but never mastery\nLike almost anything in life, programming is not really a perfectable art. There’s always some unlearned skill or undiscovered technique, and part of this potential for perpetual self-improvement is one of the things that I find so attractive about the field. That said, I this it is reasonable to say that certain languages have higher ceilings than others.\n\nFor example I am pretty confident that I get JavaScript. The language has lots of nooks and crannies that I don’t completely understand, but I feel pretty confident that I understand its semantics well enough to be able to grasp any piece of JavaScript code without too much incredulity. Now, that’s not to say that JavaScript is a simplistic language—far from it—but most of the ways I improve my JavaScripting abilities are learning new techniques within the language, not entirely new linguistic constructs.\n\nOn the other hand, languages like Haskell and Racket tend to blur the line. I feel like I have a good grasp of Haskell’s core, but do I have a good intuition for laziness? Do I completely grok type families? What about TypeInType? Ultimately, I have to come to the conclusion that I do not fully understand Haskell, much less a lot of the advanced category theory that composes some of its most powerful libraries. Racket manages to blur the line between language and library even further, and while I consider myself a decent Racketeer, I absolutely do not have a good grasp on all the intricacies of Racket’s macro system.\n\nThis is especially obvious to me at work, given that I write Haskell in a team setting. Just like back when I was writing Java, I end up with solutions that don’t satisfy me, and I reach for increasingly powerful constructs to help alleviate my qualms. Sometimes, I find myself cracking out DataKinds, and it might even help my problem, but there’s a cost: my coworkers are sometimes confused.\n\nEvery time I climb to the next rung on the ladder of abstraction, those only a couple rungs below me (even if we’re all hundreds of rungs up!) find themselves perplexed. In the worst case, people may even blame their confusion on their own inadequacy or lack of skill. This is terrible, especially when I know that, by the time they’ve caught up, I’ll be off playing with some new toy: comonads or type families or classy lenses. The cycle continues, and nobody is ever truly satisfied—I always want to find a new abstraction that will make things simpler, and those just a couple steps behind me struggle to keep up.\n\nOf course, I experience it from the opposite perspective just as often: I delve into Edward Kmett’s fancier libraries or Phil Freeman’s blog posts about category theory, and I recognize that I am rather lost. Sometimes, I find myself understanding things, but just as often, I cannot wrap my head around the concepts being discussed. I may figure them out eventually, sure, but by then everyone else has moved on to even more advanced things, and still, none of them truly solve my problems.\n\nUltimately, it all has (at least a little) value\nIt would be nice to think about all that and say, well, “Let’s finally break the cycle. Let’s stop deluding ourselves into thinking our solutions to our self-made problems are actually solving anything.” It would be great if I could tell myself that, but I unfortunately really can’t.\n\nThe scariest part of all is that I think it’s completely worthwhile.\n\nSo much of these more and more complicated abstractions are trying to do the same basic thing: come up with a better way of modeling the problem. In some sense, that’s all programming really is, modeling a domain in a way that can be leveraged by a digital computer. Our increasingly complicated DSLs seem unnecessarily complicated, they seem increasingly removed from reality, but that’s only because we’re getting better at creating languages that are closer to our domains without the baggage of preconceptions that came before us.\n\nThe downside is that, without an understanding of those preconceptions, a lot of what we come up with seems like patent gibberish to those unaware of our languages’ history.\n\nMost programmers, even those who have never seen BASIC before, can figure out what this snippet does:\n\n10 INPUT \"What is your name: \"; U$\n20 PRINT \"Hello \"; U$\nOn the other hand, very few would probably understand this one:\n\n-- | A class for categories.\n--   id and (.) must form a monoid.\nclass Category cat where\n    -- | the identity morphism\n    id :: cat a a\n\n    -- | morphism composition\n    (.) :: cat b c -> cat a b -> cat a c\nYet very few new programs are being written in BASIC, and lots are being written in Haskell.\n\nEven one of the most popular, fastest-growing programming languages in the world, JavaScript, a language considered relatively accessible compared to things like Haskell, would likely be incomprehensible to a programmer not familiar with its syntax:\n\nexport const composeWithProps = curry((a, parentProps, b) => {\n  const composed = childProps =>\n    createElement(a, parentProps, createElement(b, omit(['children'], childProps), childProps.children));\n  // give the composed component a pretty display name for debugging\n  composed.displayName = `Composed(${getDisplayName(a)}, ${getDisplayName(b)})`;\n  return composed;\n});\nMoving towards increasingly specialized syntaxes is not inherently bad—it can often be indicative of a more streamlined, domain-specific way of thinking—but while it may dramatically increase the productivity of a seasoned programmer, it can be nothing short of baffling to a newcomer.\n\nThat, specifically, is the crux of my fear: are we always aware of who we are optimizing for? I do not have a moral problem with writing code to optimize concision for seasoned programmers; after all, brevity is one of the primary ways code is made more readable (verbosity is the enemy of understanding). However, when that concision comes at the cost of beginners’ understanding, the picture becomes a bit more grey. It is not wrong to write things that are highly optimized for one’s own knowledge and understanding, and establishing a group of such people can make for an extremely productive team. It’s just also important to understand that others will likely be confused, and without being willing to invest the time and money into education, smart, diligent people will still fail to grasp the concepts, and they will likely be wholly uninterested in them.\n\nReactionary anti-intellectualism and the search for moderation\nI have noticed lately that people close to my circles have started regularly slinging insults at people who work in highly specialized notation. Math, including things like category and type theory, has become an especially acceptable punching bag. I recently tweeted a picture of some rather dense mathematics from a paper I’d read, and I was frankly disturbed at some of the vitriolic responses. Academia is sometimes described as “masturbatory”, and honestly, that is both offensive and hypocritical.\n\nMathematical notation is not perfect, no more than dense Haskell, heavily metaprogrammed Ruby, or IIFE-packed JavaScript. Still, it serves a purpose, and sometimes spelling things out is neither practically feasible nor a theoretical improvement. Programmers would not take kindly to being asked to write all their code out as prose, nor would they like being told that using higher-order functions like map should be banned because they are too confusing and not immediately self-explanatory.\n\nI am glad that people are focusing on usability and accessibility more than ever, and I think that’s one of the areas I’m the most interested in. I want to get the best of both worlds: I aim to write code in a highly concise, precise style, but I try and produce intuitive interfaces with human-readable errors upon failure. To me, a user-hostile yet technically functional library is a buggy one, and I would happily file a bug report about a confusing API or error message.\n\nAbstraction is what seems to make programming possible, and indeed, it’s what makes most modern technology possible. It’s what allows people to drive a car without knowing how an internal combustion engine works, and it’s what allows people to browse the web without having a deep understanding of internet protocol. In programming, abstraction serves a similar purpose. Of course, just like all tools, abstractions can have rather different goals: the average user will not pick up Photoshop in a day, but a power user is not going to be satisfied with Paint.\n\nProgrammers are professionals, and we work in a technical domain. I am absolutely of the belief that programming, like any other field, is not always about what comes easiest: sometimes it’s important to sit down and study for a while to grok a particularly complicated concept, and other times, it’s simply important to learn by trying, failing, and asking questions. I strive to find that blend of accessible, concise, and robust, and just like everything else, that target shifts depending on the situation and people I’m working with.\n\nI honestly don’t know if Racket and Haskell are worth their costs in complexity. At the end of the day, maybe what really matters is writing simple, consistent things that other people can understand. I really hope that there is a place for more powerful languages within a team, but there’s something to be said about which languages tend to get the most popular.\n\nUltimately, though, I am just trying to be aware of the tradeoffs I’m making, the benefits I’m getting, and the impact on those I’m working with. I will continue to search for abstractions that can better fit my needs, and I am sure I will keep on climbing the ladder of abstraction for years to come—I just really hope I’m not wasting my time.","isoDate":"2016-08-11T00:00:00.000Z","timestamp":"8/10/2016"},{"title":"Four months with Haskell","pubDate":"2016-06-12T00:00:00.000Z","author":"Alexis King","content":"<article><p>At the end of January of this year, I switched to a new job, almost exclusively because I was enticed by the idea of being able to write Haskell. The concept of using such an interesting programming language every day instead of what I’d been doing before (mostly Rails and JavaScript) was very exciting, and I’m pleased to say that the switch seems to have been well worth it.\n</p><p>Haskell was a language I had played with in the past but never really used for anything terribly practical, but lately I think I can confidently say that it really is an <em>incredible</em> programming language. At the same time, it has some significant drawbacks, too, though probably not the ones people expect. I certainly wasn’t prepared for some of the areas where Haskell would blow me away, nor was I capable of realizing which parts would leave me hopelessly frustrated until I actually sat down and started writing lots and lots of code.\n</p><h2><a name=\"dispelling-some-myths\"></a>Dispelling some myths</h2><p>Before moving on and discussing my experiences in depth, I want to take a quick detour to dispel some frequent rumors I hear about why Haskell is at least potentially problematic. These are things I hear a <em>lot</em>, and nothing in my experience so far would lead me to believe these are actually true. Ultimately, I don’t want to spend too much time on these—I think that, for the most part, they are nitpicks that people complain about to avoid understanding the deeper and more insidious problems with the language—but I think it’s important to at least mention them.\n</p><h3><a name=\"hiring-haskell-developers-is-not-hard\"></a>Hiring Haskell developers is not hard</h3><p>I am on the first Haskell team in my company, and I am among the first Haskell developers we ever hired. Not only were we hiring without much experience with Haskell at all, we explicitly <em>did not</em> want to hire remote. Debate all you like about whether or not permitting remote work is a good idea, but I don’t think anyone would dispute that this constraint makes hiring much harder. We didn’t have any trouble finding a very large stream of qualified applicants, and it definitely seems to have dispelled any fears that we would have trouble finding new candidates in the future.\n</p><h3><a name=\"performing-i-o-in-haskell-is-easy\"></a>Performing I/O in Haskell is easy</h3><p>Haskell’s purity is a point of real contention, and it’s one of the most frustrating complaints I often hear about Haskell. It is surprisingly common to hear concerns along the lines of “I don’t want to use Haskell because its academic devotion to purity sounds like it would make it very hard to get anything done”. There are very valid reasons to avoid Haskell, but in practice, I/O is not one of them. In fact, I found that isolating I/O in Haskell was much the same as isolating I/O in every other language, which I need to do anyway to permit unit testing.\n</p><p>...you <em>do</em> write deterministic unit tests for your impure logic, right?\n</p><h3><a name=\"working-with-lots-of-monads-is-not-very-difficult\"></a>Working with lots of monads is not very difficult</h3><p>The “M word” has ended up being a running joke <em>about</em> Haskell that actually ends up coming up fairly rarely <em>within</em> the Haskell community. To be clear, there is <em>no doubt</em> in my mind that monads make Haskell intimidating and provide a steep learning curve for new users. The proliferation of the joke that monads are impossible to explain, to the point of becoming mythologized, is absolutely indicative of a deeper problem about Haskell’s accessibility. However, once people learn the basics about monads, I’ve found that applying them is just as natural as applying any other programming pattern.\n</p><p>Monads are used to assist the programmer, not impede them, and they really do pay off in practice. When something has a monadic interface, there’s a decent chance I already know what that interface is going to do, and that makes working with lots of different monads surprisingly easy. Admittedly, I do rely very, very heavily on tooling to help me out here, but with things like mouseover type tooltips, I’ve actually found that working with a variety of different monads and monad transformers is actually quite pleasant, and it makes things very readable!\n</p><h2><a name=\"haskell-the-good-parts\"></a>Haskell: the good parts</h2><p>With the disclaimers out of the way, I really just want to gush for a little bit. This is not going to be an objective, reasoned survey of why Haskell is good. I am not even really going to touch upon why types are so great and why purity is so wonderful—I’d love to discuss those in depth, but that’s for a different blog post. For now, I just want to touch upon the real surprises, the real things that made me <em>excited</em> about Haskell in ways I didn’t expect. These are the things that my subjective little experience has found fun.\n</p><h3><a name=\"language-extensions-are-haskell\"></a>Language extensions <em>are</em> Haskell</h3><p>There was a time in my life when I spent a lot of time writing C. There are a lot of compilers for C, and they all implement the language in subtly different but often incompatible ways, especially on different platforms. The only way to maintain a modicum of predictability was to adhere to the standards <em>religiously</em>, even when certain GCC or MSVC extensions seem tantalizingly useful. I was actually bitten a few times by real instances where I figured I’d just use a harmless extension that was implemented everywhere, then found out it worked slightly differently across different compilers in a particular edge case. It was a learning experience.\n</p><p>It seems that this fear provides a very real distrust for using GHC’s numerous <em>language extensions</em>, and indeed, for a long time, I felt that it was probably an admirable goal to stick to Haskell 98 or Haskell 2010 as closely as possible. Sometimes I chose a slightly more verbose solution that was standard Haskell to avoid turning on a trivial extension that would make the code look a little bit cleaner.\n</p><p>About a year later, I’m finding that attitude was not only a mistake, but it forced me to often completely miss out on a lot of Haskell’s core value. GHC <em>won</em>, and now GHC and Haskell are basically synonymous. With that in mind, the portability concerns of language extensions are a bit of a non-issue, and turning them on is a very good idea! Some extensions are more than a little dangerous, so they cannot all be turned on without thinking, but the question is absolutely not “Is using language extensions a good idea?” and more “Is using <em>this</em> language extension a good idea?”\n</p><p>This is important, and I bring it up for a reason: so much of the awesomeness of Haskell is locked behind language extensions. Turning a lot of these on is one of the main things that made me really start to see how incredibly powerful Haskell actually is.\n</p><h3><a name=\"phantom-types\"></a>Phantom types</h3><p>I’m going to start out by talking about <em>phantom types</em>, which are a pretty simple concept but a powerful one, and they serve as the foundation for a lot of other cool type-level tricks that can make Haskell extremely interesting. The basic idea of a phantom type is simple; it’s a type parameter that isn’t actually used to represent any particular runtime value:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Id</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Id</span> <span class=\"kt\">Text</span></code></pre><p>This type represents an id for some kind of value, but although the kind of value is specified in the type as the <code>a</code> type parameter, it isn’t actually used anywhere on the data definition—no matter what <code>a</code> is, an <code>Id</code> is just a piece of text. This makes it possible to write functions that operate on specific kinds of ids, and those invariants will be statically checked by the compiler, even though the runtime representation is entirely identical:\n</p><pre><code class=\"pygments\"><span class=\"nf\">fetchUser</span> <span class=\"ow\">::</span> <span class=\"kt\">MonadDB</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">User</span></code></pre><p>Using <code>FlexibleInstances</code>, it’s also possible to create different instances for different kinds of ids. For example, it would be possible to have different <code>Show</code> instances depending on the type of id in question.\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">Show</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"kt\">User</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">show</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"n\">txt</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"s\">\"user #\"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">unpack</span> <span class=\"n\">txt</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">Show</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"kt\">Post</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">show</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"n\">txt</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"s\">\"post #\"</span> <span class=\"o\">&lt;&gt;</span> <span class=\"n\">unpack</span> <span class=\"n\">txt</span></code></pre><p>This provides a simple framework for encoding entirely arbitrary information into the type system, then asking the compiler to actually check assertions about that information. This is made even more powerful with some other extensions, which I’ll talk about shortly.\n</p><h3><a name=\"letting-the-compiler-write-code\"></a>Letting the compiler write code</h3><p>One of the things I really dislike, more than most things, is boilerplate. A little bit of boilerplate is fine—even necessary at times—but as soon as I start wondering if a code generator would improve things, I think the programming language has pretty much failed me.\n</p><p>I write a lot of Racket because, in a sense, Racket is the ultimate boilerplate killer: the macro system is a first-class code generator integrated with the rest of the language, and it means that boilerplate is almost never an issue. Of course, that’s not always true: sometimes a bit of boilerplate <em>is</em> still necessary because macros cannot deduce enough information about the program to generate the code entirely on their own, and in Haskell, some of that information is actually present in the type system.\n</p><p>This leads to two absolutely incredible extensions, both of which are simple and related, but which actually <em>completely change</em> how I approach problems when programming. These two extensions are <code>GeneralizedNewtypeDeriving</code> and <code>StandaloneDeriving</code>.\n</p><h4><a name=\"newtypes-and-type-safety\"></a>Newtypes and type safety</h4><p>The basic idea is that “newtypes” are just simple wrapper types in Haskell. This turns out to be extremely important when trying to find the value of Haskell because they allow you to harden type safety by specializing types to <em>your</em> domain. For example, consider a type representing a user’s name:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Name</span> <span class=\"ow\">=</span> <span class=\"kt\">Name</span> <span class=\"kt\">Text</span></code></pre><p>This type is extremely simple, and in fact isn’t even at all different from a simple <code>Text</code> value with respect to its representation, since all combinations of unicode characters are allowed in a name. Therefore, what’s the point of a separate type? Well, this allows Haskell to introduce actual compilation failures when two different kinds of textual data are mixed. This is not a new idea, and even in languages that don’t support this sort of thing, Joel Spolsky’s old blog post <a href=\"http://www.joelonsoftware.com/articles/Wrong.html\">Making Wrong Code Look Wrong</a> describes how it can be done by convention. Still, almost every modern language makes this possible: in C, it would be a single-member <code>struct</code>, in class-based OO languages, it would be a single-member class... this is not a complicated idea.\n</p><p>The difference lies in its usage. In other languages, this strategy is actually not very frequently employed for the simple reason that it is almost always extremely annoying. You are forced to do tons of wrapping/unwrapping, and at that point it isn’t really clear if you’re even getting all that much value out of the distinction when your first solution to a type mismatch is wrapping or unwrapping the value without a second thought. In Haskell, however, this can be heavily mitigated by asking the compiler to <em>automatically derive typeclass implementations</em>, which allow the unwrapping/wrapping to effectively happen implicitly for a constrained set of operations.\n</p><h4><a name=\"using-generalizednewtypederiving\"></a>Using <code>GeneralizedNewtypeDeriving</code></h4><p>Consider the <code>Name</code> type once again, but this time, let’s derive a class:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Name</span> <span class=\"ow\">=</span> <span class=\"kt\">Name</span> <span class=\"kt\">Text</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">IsString</span><span class=\"p\">)</span></code></pre><p>The <code>IsString</code> typeclass in Haskell allows custom types to automatically be created from string literals. It is <em>not</em> handled specially by Haskell’s <code>deriving</code> mechanism. Since <code>Text</code> implements <code>IsString</code>, an instance will be generated that simply defers to the underlying type, automatically generating the code to wrap the result up in a <code>Name</code> box at the end. This means that code like this will now just magically work:\n</p><pre><code class=\"pygments\"><span class=\"nf\">name</span> <span class=\"ow\">::</span> <span class=\"kt\">Name</span>\n<span class=\"nf\">name</span> <span class=\"ow\">=</span> <span class=\"s\">\"Alyssa P. Hacker\"</span></code></pre><p>No boilerplate needs to be written! This is a neat trick, but it actually turns out to be far more useful than that simple example in practice. What really makes this functionality shine is when you want to derive <em>some</em> kinds of functionality but disallow some others. For example, using the <a href=\"https://hackage.haskell.org/package/text-conversions\"><code>text-conversions</code></a> package, it’s possible to do something like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">Id</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Id</span> <span class=\"kt\">Text</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Eq</span><span class=\"p\">,</span> <span class=\"kt\">Show</span><span class=\"p\">,</span> <span class=\"kt\">ToText</span><span class=\"p\">,</span> <span class=\"kt\">ToJSON</span><span class=\"p\">)</span></code></pre><p>This creates an opaque <code>Id</code> type, but it automatically generates conversions <em>to</em> textual formats. However, it does <em>not</em> automatically create <code>FromText</code> or <code>FromJSON</code> instances, which would be dangerous because decoding <code>Id</code>s can potentially fail. It’s then possible to write out those instances manually to preserve a type safety:\n</p><pre><code class=\"pygments\"><span class=\"kr\">instance</span> <span class=\"kt\">FromText</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"n\">a</span><span class=\"p\">))</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fromText</span> <span class=\"n\">str</span> <span class=\"ow\">=</span> <span class=\"kr\">if</span> <span class=\"n\">isValidId</span> <span class=\"n\">str</span> <span class=\"kr\">then</span> <span class=\"kt\">Just</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"n\">str</span><span class=\"p\">)</span> <span class=\"kr\">else</span> <span class=\"kt\">Nothing</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">FromJSON</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">parseJSON</span> <span class=\"p\">(</span><span class=\"kt\">String</span> <span class=\"n\">val</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">maybe</span> <span class=\"p\">(</span><span class=\"n\">fail</span> <span class=\"s\">\"invalid id\"</span><span class=\"p\">)</span> <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">fromText</span> <span class=\"n\">val</span><span class=\"p\">)</span>\n  <span class=\"n\">parseJSON</span> <span class=\"kr\">_</span>            <span class=\"ow\">=</span> <span class=\"n\">fail</span> <span class=\"s\">\"invalid id\"</span></code></pre><h4><a name=\"using-standalonederiving\"></a>Using <code>StandaloneDeriving</code></h4><p>The ordinary <code>deriving</code> mechanism is extremely useful, especially when paired with the above, but sometimes it is desirable to have a little bit more flexibility. In these cases, <code>StandaloneDeriving</code> can help.\n</p><p>Take the <code>Id</code> example again: it has a phantom type, and simply adding something like <code>deriving (ToText)</code> with derive <code>ToText</code> instances for <em>all</em> kinds of ids. It is potentially useful, however, to derive instances for more specific id types. Using standalone <code>deriving</code> constructs permits this sort of flexibility.\n</p><pre><code class=\"pygments\"><span class=\"kr\">deriving</span> <span class=\"kr\">instance</span> <span class=\"kt\">ToText</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"kt\">User</span><span class=\"p\">)</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">ToText</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"kt\">Post</span><span class=\"p\">)</span> <span class=\"kr\">where</span>\n  <span class=\"n\">toText</span> <span class=\"ow\">=</span> <span class=\"n\">postIdToText</span></code></pre><p>This is an example where GHC language extensions end up becoming significantly more than the sum of their parts, which seems to be a fairly frequent realization. The <code>StandaloneDeriving</code> mechanism is a little bit useful without <code>GeneralizedNewtypeDeriving</code>, but when combined, they are incredibly powerful tools for getting a very fine-grained kind of type safety <em>without</em> writing any boilerplate.\n</p><h3><a name=\"datakinds-are-super-cool-with-caveats\"></a>DataKinds are super cool, with caveats</h3><p>Phantom types are quite wonderful, but they can only encode <em>types</em>, not arbitrary data. That’s where <code>DataKinds</code> and <code>KindSignatures</code> come in: they allow lifting arbitrary datatypes to the type level so that things that would normally be purely runtime values can be used at compile-time as well.\n</p><p>The way this works is pretty simple—when you define a datatype, you also define a “datakind”:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">RegistrationStatus</span> <span class=\"ow\">=</span> <span class=\"kt\">Registered</span> <span class=\"o\">|</span> <span class=\"kt\">Anonymous</span></code></pre><p>Normally, the above declaration declares a <em>type</em>, <code>RegistrationStatus</code>, and two <em>data constructors</em>, <code>Registered</code> and <code>Anonymous</code>. With <code>DataKinds</code>, it also defines a <em>kind</em>, <code>RegistrationStatus</code>, and two <em>type constructors</em>, <code>Registered</code> and <code>Anonymous.</code>\n</p><p>If that’s confusing, the way to understand that is to realize there is a sort of natural ordering here: types describe values, and kinds describe types. Therefore, turning on <code>DataKinds</code> “lifts” each definition by a single level, so types become kinds and values become types. This permits using these things at the type level:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">UserId</span> <span class=\"p\">(</span><span class=\"n\">s</span> <span class=\"ow\">::</span> <span class=\"kt\">RegistrationStatus</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"kt\">UserId</span> <span class=\"kt\">Text</span></code></pre><p>In this example, <code>UserId</code> still has a single phantom type variable, <code>s</code>, but this time it is constrained to the <code>RegistrationStatus</code> kind. Therefore, it can <em>only</em> be <code>Registered</code> or <code>Anonymous</code>. This cooperates well with the aforementioned <code>StandaloneDeriving</code> mechanism, and it mostly provides a convenient way to constrain type variables to custom kinds.\n</p><p>In general, <code>DataKinds</code> is a much more powerful extension, allowing things like type-level natural numbers or strings, which can be used to perform actual type-level computation (especially in combination with <code>TypeFamilies</code>) or a sort of metaprogramming. In some cases, they can even be used to implement things emulating things you can do with dependent types.\n</p><p>I think <code>DataKinds</code> are a very cool Haskell extension, but there are a couple caveats. One of the main ones is how new kinds are defined: <code>DataKinds</code> “hijacks” the existing datatype declaration syntax by making every single datatype declaration define a type <em>and</em> a kind. This is a little confusing, and it would be nice if a different syntax was used so that each could be defined independently.\n</p><p>Similarly, it seems that a lot of work is being done to allow using runtime values at the type level, but I wonder if people will ever need to use, say, runtime values at the <em>kind</em> level. This immediately evokes thoughts of Racket’s phase-based macro system, and I wonder if some of this duplication would be unnecessary with something similar.\n</p><p>Food for thought, but overall, <code>DataKinds</code> are a very nice addition to help with precisely and specifically typing particular problems.\n</p><h3><a name=\"typeclasses-can-emulate-effects\"></a>Typeclasses can emulate effects</h3><p>This is something that I’ve found interesting in my time writing Haskell because I have <em>no idea</em> if it’s idiomatic or not, but it seems pretty powerful. The initial motivator for this idea was figuring out how to test our code without constantly dropping into <code>IO</code>.\n</p><p>More generally, we wanted to be able to unit test by “mocking” out collaborators, as it would be described in object oriented programming. I was always semi-distrustful of mocking, and indeed, it seems likely that it is heavily abused in certain circles, but I’ve come to appreciate the need that sometimes it is important to stub things out, <em>even in pure code</em>.\n</p><p>As an example, consider some code that needs access to the current time. This is something that would normally require <code>IO</code>, but we likely want to be able to use the value in a pure context without “infecting” the entire program with <code>IO</code> types. In Haskell, I have generally seen three ways of handling this sort of thing:\n</p><ol><li><p>Just inject the required values into the function and produce them “higher up” where I/O is okay. If threading the value around becomes too burdensome, use a Reader monad.\n</p></li><li><p>Use a free monad or similar to create a pure DSL of sorts, then write interpreters for various implementations, one of which uses <code>IO</code>.\n</p></li><li><p>Create custom monadic typeclasses that provide interfaces to the functionality you want to perform, then create instances, one of which is an instance over <code>IO</code>.\n</p></li></ol><p>This last approach seems to be less common in Haskell, but it’s the approach we took, and it seems to work out remarkably well. Returning to the need to get the current time, we could pretty easily write such a typeclass to encode that need:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">CurrentTime</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">getCurrentTime</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"kt\">UTCTime</span></code></pre><p>Now we can write functions that use the current time:\n</p><pre><code class=\"pygments\"><span class=\"nf\">validateToken</span> <span class=\"ow\">::</span> <span class=\"kt\">CurrentTime</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Token</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">Bool</span>\n<span class=\"nf\">validateToken</span> <span class=\"n\">tok</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">currentTime</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getCurrentTime</span>\n  <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">tokenExpirationDate</span> <span class=\"n\">tok</span> <span class=\"o\">&gt;</span> <span class=\"n\">currentTime</span><span class=\"p\">)</span></code></pre><p>Now, we can write instances for <code>CurrentTime</code> that will allow us to run the same code in different contexts:\n</p><pre><code class=\"pygments\"><span class=\"kr\">newtype</span> <span class=\"kt\">AppM</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">AppM</span> <span class=\"p\">{</span> <span class=\"n\">runAppM</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"n\">a</span> <span class=\"p\">}</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">,</span> <span class=\"kt\">MonadIO</span><span class=\"p\">)</span>\n\n<span class=\"kr\">newtype</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">TestM</span> <span class=\"p\">(</span><span class=\"kt\">Identity</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"kr\">deriving</span> <span class=\"p\">(</span><span class=\"kt\">Functor</span><span class=\"p\">,</span> <span class=\"kt\">Applicative</span><span class=\"p\">,</span> <span class=\"kt\">Monad</span><span class=\"p\">)</span>\n\n<span class=\"nf\">runTestM</span> <span class=\"ow\">::</span> <span class=\"kt\">TestM</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">a</span>\n<span class=\"nf\">runTestM</span> <span class=\"p\">(</span><span class=\"kt\">TestM</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"ow\">=</span> <span class=\"n\">runIdentity</span> <span class=\"n\">x</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">CurrentTime</span> <span class=\"kt\">AppM</span> <span class=\"kr\">where</span>\n  <span class=\"n\">getCurrentTime</span> <span class=\"ow\">=</span> <span class=\"n\">liftIO</span> <span class=\"kt\">Data</span><span class=\"o\">.</span><span class=\"kt\">Time</span><span class=\"o\">.</span><span class=\"kt\">Clock</span><span class=\"o\">.</span><span class=\"n\">getCurrentTime</span>\n\n<span class=\"kr\">instance</span> <span class=\"kt\">CurrentTime</span> <span class=\"kt\">TestM</span> <span class=\"kr\">where</span>\n  <span class=\"n\">getCurrentTime</span> <span class=\"ow\">=</span> <span class=\"n\">return</span> <span class=\"o\">$</span> <span class=\"n\">posixSecondsToUTCTime</span> <span class=\"mi\">0</span></code></pre><p>Where this really starts to shine is when adding additional effects. For example, the above token validation function might also need information about some kind of secret used for signing. Under this model, it’s just another typeclass:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">TokenSecret</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">getTokenSecret</span> <span class=\"ow\">::</span> <span class=\"n\">m</span> <span class=\"kt\">Secret</span>\n\n<span class=\"nf\">validateToken</span> <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">CurrentTime</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">TokenSecret</span> <span class=\"n\">m</span><span class=\"p\">)</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Token</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">Bool</span>\n<span class=\"nf\">validateToken</span> <span class=\"n\">tok</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>\n  <span class=\"n\">currentTime</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getCurrentTime</span>\n  <span class=\"n\">secret</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">getTokenSecret</span>\n  <span class=\"n\">return</span> <span class=\"p\">(</span><span class=\"n\">tokenExpirationDate</span> <span class=\"n\">tok</span> <span class=\"o\">&gt;</span> <span class=\"n\">currentTime</span>\n       <span class=\"o\">&amp;&amp;</span> <span class=\"n\">verifySignature</span> <span class=\"n\">tok</span> <span class=\"n\">secret</span><span class=\"p\">)</span></code></pre><p>Of course, so far all of these functions have been extremely simple, and we’ve basically been using them as a glorified reader monad. In practice, though, we use this pattern for lots more than just retrieving values. For example, we might have a typeclass for database interactions:\n</p><pre><code class=\"pygments\"><span class=\"kr\">class</span> <span class=\"kt\">Monad</span> <span class=\"n\">m</span> <span class=\"ow\">=&gt;</span> <span class=\"kt\">Persistence</span> <span class=\"n\">m</span> <span class=\"kr\">where</span>\n  <span class=\"n\">fetchUser</span> <span class=\"ow\">::</span> <span class=\"kt\">Id</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"kt\">User</span><span class=\"p\">)</span>\n  <span class=\"n\">insertUser</span> <span class=\"ow\">::</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"p\">(</span><span class=\"kt\">Either</span> <span class=\"kt\">PersistenceError</span> <span class=\"p\">(</span><span class=\"kt\">Id</span> <span class=\"kt\">User</span><span class=\"p\">))</span></code></pre><p>With all of this done, it becomes incredibly easy to see which functions are using which effects:\n</p><pre><code class=\"pygments\"><span class=\"nf\">postUsers</span>\n  <span class=\"ow\">::</span> <span class=\"p\">(</span><span class=\"kt\">CurrentTime</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">Persistence</span> <span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"kt\">TokenSecret</span> <span class=\"n\">m</span><span class=\"p\">)</span>\n  <span class=\"ow\">=&gt;</span> <span class=\"kt\">User</span> <span class=\"ow\">-&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">Response</span>\n<span class=\"nf\">postUsers</span> <span class=\"ow\">=</span> <span class=\"o\">...</span>\n\n<span class=\"nf\">getHealthcheck</span>\n  <span class=\"ow\">::</span> <span class=\"kt\">CurrentTime</span> <span class=\"n\">m</span>\n  <span class=\"ow\">=&gt;</span> <span class=\"n\">m</span> <span class=\"kt\">Response</span>\n<span class=\"nf\">getHealthcheck</span> <span class=\"ow\">=</span> <span class=\"o\">...</span></code></pre><p>There’s no need to perform any lifting, and this all seems to scale quite nicely. We’ve written some additional utilities to help write tests against functions using these kinds of monadic interfaces, and even though there’s a little bit of annoying boilerplate in a few spots, overall it seems to work quite elegantly.\n</p><p>I’m not entirely sure how common this is in the Haskell community, but it’s certainly pretty neat how easy it is to get nearly all of the benefits of effect types in other languages simply by composing some of Haskell’s simplest features.\n</p><h3><a name=\"atom-s-ide-haskell-tooling-is-invaluable\"></a>Atom’s ide-haskell tooling is invaluable</h3><p>Alright, so, confession time: I don’t use Emacs.\n</p><p>I know, I know, how is that possible? I write Lisp, after all. Well, honestly, I tried picking it up a number of times, but none of those times did I get far enough to ditch my other tools. For Racket work, I use DrRacket, but for almost everything else, I use Atom.\n</p><p>Atom has a lot of flaws, but it’s also pretty amazing in places, and I absolutely <em>love</em> the Haskell tooling written by the wonderful <a href=\"https://github.com/atom-haskell\">atom-haskell</a> folks. I use it constantly, and even though it doesn’t always work perfectly, it works pretty well. When it has problems, I’ve at least figured out how to get it working correctly.\n</p><p>This is probably hard to really explain without seeing it for yourself, but I’ve found that I basically <em>depend</em> on this sort of tooling to be fully productive in Haskell, and I have no problem admitting that. The ability to get instant feedback about type errors tied to visual source locations, to be able to directly manipulate the source by selecting expressions and getting type information, and even the option to get inline linter suggestions means I spend a lot less time glancing at the terminal, and even less time in the REPL.\n</p><p>The tooling is far from perfect, and it leaves a lot to be desired in places (the idea of using that static information for automated, project-wide refactoring <em>a la</em> Java is tantalizing), but most of those things are ideas of what amazing things could be, not broken or missing essentials. I am pretty satisfied with ide-haskell right now, and I can only hope it continues to get better and better.\n</p><h2><a name=\"frustrations-drawbacks-and-pain-points\"></a>Frustrations, drawbacks, and pain points</h2><p>Haskell is not perfect. In fact, far from it. There is a vast array of little annoyances that I have with the language, as is the case with any language. Still, there are a few overarching problems that I would really like to at least mention. These are the biggest sources of frustration for me so far.\n</p><h3><a name=\"purity-failure-and-exception-handling\"></a>Purity, failure, and exception-handling</h3><p>One of Haskell’s defining features is its purity—I don’t think many would disagree with that. Some people consider it a drawback, others consider it one of its greatest boons. Personally, I like it a lot, and I think one of the best parts about it is how it requires the programmer to be incredibly deliberate about failure.\n</p><p>In many languages, when looking up a value from a container where the key doesn’t exist, there are really two ways to go about expressing this failure:\n</p><ol><li><p>Throw an exception.\n</p></li><li><p>Return <code>null</code>.\n</p></li></ol><p>The former is scary because it means <em>any</em> call to any function can make the entire program blow up, and it’s often impossible to know which functions even have the potential to throw. This creates a certain kind of non-local control flow that can sometimes cause a lot of unpredictability. The second option is much the same, especially when any value in a program might be <code>null</code>; it just defers the failure.\n</p><p>In languages with option types, this is somewhat mitigated. Java now has option types, too, but they are still frequently cumbersome to use because there is nothing like monads to use to simply chain operations together. Haskell, in comparison, has an incredible complement of tools to simply handle errors without a whole lot of burden on the programmer, and I have found that, in practice, this is <em>actually helpful</em> and I really do write better error-handling code.\n</p><h4><a name=\"first-the-good-parts\"></a>First, the good parts</h4><p>I have seen a comparison drawn between throwing checked exceptions and returning <code>Maybe</code> or <code>Either</code> types, but in practice the difference is massive. Handling checked exceptions is a monotonous chore because they are not first-class values, they are actually entirely separate linguistic constructs. Consider a library that throws a <code>LibraryException</code>, and you want to wrap that library and convert those exceptions to <code>ApplicationException</code>s. Well, have fun writing this code dozens of times:\n</p><pre><code class=\"pygments\"><span class=\"k\">try</span> <span class=\"o\">{</span>\n  <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">doSomething</span><span class=\"o\">();</span>\n<span class=\"o\">}</span> <span class=\"k\">catch</span> <span class=\"o\">(</span><span class=\"n\">LibraryException</span> <span class=\"n\">ex</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n  <span class=\"k\">throw</span> <span class=\"n\">ApplicationException</span><span class=\"o\">.</span><span class=\"na\">fromLibraryException</span><span class=\"o\">(</span><span class=\"n\">ex</span><span class=\"o\">);</span>\n<span class=\"o\">}</span>\n\n<span class=\"c1\">// ...</span>\n\n<span class=\"k\">try</span> <span class=\"o\">{</span>\n  <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">doSomethingElse</span><span class=\"o\">();</span>\n<span class=\"o\">}</span> <span class=\"k\">catch</span> <span class=\"o\">(</span><span class=\"n\">LibraryException</span> <span class=\"n\">ex</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n  <span class=\"k\">throw</span> <span class=\"n\">ApplicationException</span><span class=\"o\">.</span><span class=\"na\">fromLibraryException</span><span class=\"o\">(</span><span class=\"n\">ex</span><span class=\"o\">);</span>\n<span class=\"o\">}</span></code></pre><p>In Haskell, failure is just represented by first-class values, and it’s totally possible to write helper functions to abstract over that kind of boilerplate:\n</p><pre><code class=\"pygments\"><span class=\"nf\">libraryToApplication</span> <span class=\"ow\">::</span> <span class=\"kt\">LibraryError</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">ApplicationError</span>\n<span class=\"nf\">libraryToApplication</span> <span class=\"ow\">=</span> <span class=\"o\">...</span>\n\n<span class=\"nf\">liftLibrary</span> <span class=\"ow\">::</span> <span class=\"kt\">Either</span> <span class=\"kt\">LibraryError</span> <span class=\"n\">a</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Either</span> <span class=\"kt\">ApplicationError</span> <span class=\"n\">a</span>\n<span class=\"nf\">liftLibrary</span> <span class=\"ow\">=</span> <span class=\"n\">mapLeft</span> <span class=\"n\">libraryToApplication</span></code></pre><p>Now, that same boilerplate-y code becomes nearly invisible:\n</p><pre><code class=\"pygments\"><span class=\"nf\">x</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftLibrary</span> <span class=\"n\">doSomething</span>\n\n<span class=\"c1\">-- ...</span>\n\n<span class=\"nf\">y</span> <span class=\"ow\">&lt;-</span> <span class=\"n\">liftLibrary</span> <span class=\"n\">doSomethingElse</span></code></pre><p>This might not <em>seem</em> like much, but it really cuts down on the amount of visual noise, which ends up making all the difference. Boilerplate incurs a cost much bigger than simply taking the time to type it all out (though that’s important, too): the cognitive overhead of parsing which parts of a program are boilerplate has a significant impact on readability.\n</p><h4><a name=\"so-what-s-the-problem\"></a>So what’s the problem?</h4><p>If error handling is so great in Haskell, then why am I putting it under the complaints section? Well, it turns out that not everyone seems to think it’s as great as I make it out to be because people seem to keep writing Haskell APIs that throw exceptions!\n</p><p>Despite what some purists would have you believe, Haskell has exceptions, and they are not uncommon. Lots of things can throw exceptions, some of which are probably reasonable. Failing to connect to a database is a pretty catastrophic error, so it seems fair that it would throw. On the other hand, inserting a duplicate record is pretty normal operation, so it seems like that should <em>not</em> throw.\n</p><p>I mostly treat exceptions in Haskell as unrecoverable catastrophes. If I throw an error in <em>my</em> code, I do not intend to catch it. That means something horrible happened, and I just want that horribleness to show up in a log somewhere so I can fix the problem. If I care about failure, there are better ways to handle that failure gracefully.\n</p><p>It’s also probably worth noting that exceptions in Haskell can be thrown from anywhere, even pure code, but can only be <em>caught</em> within the <code>IO</code> monad. This is especially scary, but I’ve seen it happen in actual libraries out in the wild, even ones that the entire Haskell ecosystem is built on. One of the crowning examples of this is the <code>text</code> package, which provides a function called <code>decodeUtf8</code> to convert bytestrings into text. Its type is very simple:\n</p><pre><code class=\"pygments\"><span class=\"nf\">decodeUtf8</span> <span class=\"ow\">::</span> <span class=\"kt\">ByteString</span> <span class=\"ow\">-&gt;</span> <span class=\"kt\">Text</span></code></pre><p>But wait, what if the bytestring is not actually a valid UTF-8 string?\n</p><p>Boom. There goes the application.\n</p><p>Okay, okay, well, at least the <code>text</code> package provides another function, this one called <code>decodeUtf8'</code>, which returns an <code>Either</code>. This is good, and I’ve trained myself to only ever use <code>decodeUtf8'</code>, but it still has some pretty significant problems:\n</p><ul><li><p>The <em>safe</em> version of this function is the “prime” version, rather than the other way around, which encourages people to use the unsafe one. Ideally, the unsafe one should be explicitly labeled as such... maybe call it <code>unsafeDecodeUtf8</code>?\n</p></li><li><p>This is not a hypothetical problem. When using a Haskell JWT library, we found a function that converts a string into a JWT. Since not all strings are JWTs, the library intelligently returns a <code>Maybe</code>. Therefore, we figured we were safe.\n</p><p>A couple weeks later, we found that providing this function with invalid data was returning HTTP 500 errors. Why? Our error handling was meticulous! Well, the answer was a <code>decodeUtf8</code> call, hidden inside of the JWT library. This is especially egregious, given that the API it exposed returned a <code>Maybe</code> anyway! It would have been trivial to use the safe version there, instead, but the poor, misleading name led the library developer to overlook the bug lurking in the otherwise innocuous function.\n</p><p>Even worse, this function was totally pure, and we used it in pure code, so we could not simply wrap the function and catch the exception. We had two options: use <code>unsafePerformIO</code> (yuck!) or perform a check before handing the data to the buggy function. We chose the latter, but in some cases, I imagine that could be too difficult to do in order to make it feasible.\n</p></li></ul><p>The point I’m trying to make is that this is a real problem, and it seems to me that throwing exceptions invalidates one of the primary advantages of Haskell. It disappointed me to realize that a significant amount of code written by FP Complete, one of the primary authors of some of the most important “modern Haskell” code in existence (including Stack), seem to very frequently expose APIs that will throw.\n</p><p>I’m not sure how much of this stems from a fundamental divide in the Haskell ecosystem and how much it is simply due to Michael Snoyman’s coding style, given that he is the primary author of a number of these tools and libraries that seem very eager to throw exceptions. As just one example of a real situation in which we were surprised by this behavior, we used Snoyman’s http-client library and found that it mysteriously throws upon nearly <em>any</em> failure state:\n</p><blockquote><p>A note on exceptions: for the most part, all actions that perform I/O should be assumed to throw an <code>HttpException</code> in the event of some problem, and all pure functions will be total. For example, <code>withResponse</code>, <code>httpLbs</code>, and <code>BodyReader</code> can all throw exceptions.\n</p></blockquote><p>This doesn’t seem entirely unreasonable—after all, isn’t a failure to negotiate TLS fairly catastrophic?—until you consider our use case. We needed to make a subrequest during the extent of another HTTP request to our server, and if that subrequest fails, we absolutely need to handle that failure gracefully. Of course, this is not <em>terrible</em> given that we are in <code>IO</code> so we can actually catch these exceptions, but since this behavior was only noted in a single aside at the top of the documentation, we didn’t realize we were forgetting error handling until far too late and requests were silently failing.\n</p><p>Exceptions seem to devalue one of the most powerful concepts in Haskell: if I don’t consider all the possibilities, my code <em>does not compile</em>. In practice, when working with APIs that properly encode these possibilities into the type system, this value proposition seems to be real. I really do find myself writing code that works correctly as soon as it compiles. It’s almost magical.\n</p><p>Using exceptions throws that all out the window, and I wish the Haskell ecosystem was generally more cautious about when to use them.\n</p><h3><a name=\"the-string-problem\"></a>The String problem</h3><p>I sort of alluded to this a tiny bit in the last section, and that is probably indicative of how bad this issue is. I’m just going to be blunt: <strong>In Haskell, strings suck.</strong>\n</p><p>This is always a bit of an amusing point whenever it is discussed because of how silly it seems. Haskell is a research language with a cutting-edge type system and some of the fanciest features of any language in existence. When everyday programming might use things like “profunctors”, “injective type families”, and “generalized algebraic datatypes”, you would think that dealing with <em>strings</em> would be a well-solved problem.\n</p><p>But it isn’t. Haskell libraries frequently use not one, not two, but <strong><em>five</em></strong> kinds of strings. Let’s list them off, shall we?\n</p><ul><li><p>First off, there’s the built-in <code>String</code> type, which is actually an alias for the <code>[Char]</code> type. For those not intimately familiar with Haskell, that’s a <em>linked list of characters</em>. As <a href=\"http://www.stephendiehl.com/\">Stephen Diehl</a> recently put it in <a href=\"http://www.stephendiehl.com/posts/strings.html\">a blog post describing the disaster that is Haskell string types</a>:\n</p><blockquote><p>This is not only a bad representation, it’s quite possibly the least efficient (non-contrived) representation of text data possible and has horrible performance in both time and space. <em>And it’s used everywhere in Haskell.</em>\n</p></blockquote><p>The point is, it’s really bad. This type is not a useful representation for textual data in practical applications.\n</p></li><li><p>Moving on, we have a fairly decent type, <code>Text</code>, which comes from <code>Data.Text</code> in the <code>text</code> package. This is a decent representation of text, and it’s probably the one that everything should use. Well, maybe. Because <code>Text</code> comes in two varieties: lazy and strict. Nobody seems to agree on which of those two should be used, though, and they are totally incompatible types: functions that work with one kind of text won’t work with the other. You have to manually convert between them.\n</p></li><li><p>Finally, we have <code>ByteString</code>, which is horribly misnamed because it really isn’t a string at all, at least not in the textual sense. A better name for this type would have simply been <code>Bytes</code>, which sounds a lot scarier. And that would be good, because data typed as a <code>ByteString</code> is as close as you can get in Haskell to not assigning a type at all: a bytestring holds arbitrary bytes without assigning them any meaning whatsoever!\n</p><p>Or at least, that’s the intention. The trouble is that people <em>don’t</em> treat bytestrings like that—they just use them to toss pieces of text around, even when those pieces of text have a well-defined encoding and represent textual data. This leads to the <code>decodeUtf8</code> problem mentioned above, but it’s bigger than that because it often ends up with some poor APIs that assign some interpretation to <code>ByteString</code> data without assigning it a different type.\n</p><p>Again, this is throwing away so much of Haskell’s safety. It would be like using <code>Int</code> to keep track of boolean data (“just use 0 and 1!”) or using empty and singleton lists instead of using <code>Maybe</code>. When you use the precise type, you encode invariants and contracts into statically-checked assertions, but when you use general types like <code>ByteString</code>, you give that up.\n</p><p>Oh, and did I mention that <code>ByteString</code>s also come in incompatible lazy and strict versions, too?\n</p></li></ul><p>So, obviously, the answer is to just stop using the bad types and to just use (one kind of) <code>Text</code> everywhere. Great! Except that the other types are totally inescapable. The entire standard library uses <code>String</code> exclusively—after all, <code>text</code> is a separate package—and small libraries often use <code>String</code> instead of <code>text</code> because they have no need to bring in the dependency. Of course, this just means every real application pays the performance hit of converting between all these different kinds of strings.\n</p><p>Similarly, those that <em>do</em> use <code>Text</code> often use different kinds of text, so code ends up littered with <code>fromStrict</code> or <code>toStrict</code> coercions, which (again) have a cost. I’ve already ranted enough about <code>ByteString</code>, but basically, if you’re using <code>ByteString</code> in your API to pass around data that is semantically text, you are causing me pain. Please stop.\n</p><p>It seems that the way <code>Data.Text</code> probably <em>should</em> have been designed was by making <code>Text</code> a typeclass, then making the lazy and strict implementations instances of that typeclass. Still, the fact that both of them exist would always cause problems. I’m actually unsure which one is the “correct” choice—I don’t know enough about how the two perform in practice—but it seems likely that picking <em>either</em> one would be a performance improvement over the current system, which is constantly spending time converting between the two.\n</p><p>This issue has been ranted about plenty, so I won’t ramble on, but if you’re designing new libraries, please, <em>please</em> use <code>Text</code>. Your users will thank you.\n</p><h3><a name=\"documentation-is-nearly-worthless\"></a>Documentation is nearly worthless</h3><p>Finally, let’s talk about documentation.\n</p><p>One of my favorite programming languages is Racket. Racket has a documentation tool called Scribble. Scribble is special because it is a totally separate domain-specific language for writing documentation, and it makes it fun and easy to write good explanations. There are even forms for typesetting automatically-rendered examples that look like a REPL. If the examples ever break or become incorrect, the docs don’t even compile.\n</p><p>All of the Racket core library documentation makes sure to set a good example about what good documentation should look like. The vast majority of the documentation is paragraphs of prose and simple but practical examples. There are also type signatures (in the form of contracts), and those are super important, but they are so effective because of how the prose explains what each function does, when to use it, <em>why</em> you’d use it, and <em>why you wouldn’t use it</em>.\n</p><p>Everything is cross-referenced automatically. The documentation is completely searchable locally out of the box. As soon as you install a package, its docs are automatically indexed. User-written libraries tend to have pretty good docs, too, because the standard libraries set such a good example <em>and</em> because the tools are so fantastic. Racket docs are really nice, and they’re so good they actually make things like Stack Overflow or even Google mostly irrelevant. It’s all there in the manual.\n</p><p>Haskell documentation is the opposite of everything I just said.\n</p><ul><li><p>The core libraries are poorly documented. Most functions include a sentence of description, and almost none include examples. At their worst, the descriptions simply restate the type signature.\n</p></li><li><p>Third-party libraries’ documentation is even worse, going frequently completely undocumented and actually only including type signatures and nothing else.\n</p></li><li><p>Haddock is an incredibly user-hostile tool for writing anything other than tiny snippets of documentation and is not very good at supporting prose. Notably, Haddock’s documentation is not generated using Haddock (and it still manages to be almost unusable). Forcing all documentation into inline comments makes users unlikely to write much explanation, and there is no ability for abstraction.\n</p></li><li><p>Reading documentation locally is very difficult because there is no easy way to open documentation for a particular package in a web browser, and it’s <em>certainly</em> not searchable. This is especially ridiculous given that Hoogle exists, which is one of best ways to search API docs in existence. There should be a <code>stack hoogle</code> command that just opens a Hoogle page for all locally-installed packages and Just Works, but there isn’t.\n</p></li><li><p>Most valuable information exists outside of documentation, so Google becomes a go-to immediately after a quick glance at the docs, and information is spread across blog posts, mailing lists, and obscure reddit posts.\n</p></li></ul><p>This is a problem that cannot be fixed by just making Haddock better, nor can it be fixed simply by improving the existing standard library documentation. There is a fundamental problem with Haskell documentation (which, to be completely fair, is not unique to Haskell), which is that its tools do not support anything more than API docs.\n</p><p>Good documentation is so much more than “here’s what this function does”; it’s about guides and tutorials and case studies and common pitfalls. <a href=\"http://docs.racket-lang.org/lens/lens-guide.html\">This is documentation for someone new to lenses.</a> <a href=\"https://hackage.haskell.org/package/lens#readme\">This is not.</a> Take note of the difference.\n</p><h2><a name=\"conclusion-and-other-thoughts\"></a>Conclusion and other thoughts</h2><p>Haskell is an incredible programming platform, and indeed, it is sometimes mind-boggling how complete it is. It also has a lot of rough edges, sometimes in places that feel like they need a lot more care, or perhaps they’re even simply unfinished.\n</p><p>I could spend weeks writing about all the things I really like or dislike about the language, discussing in fine detail all the things that have made me excited or all the little bits that have made me want to tear my hair out. Heck, I could probably spend a month writing about strings alone. That’s not the point, though... I took a risk with Haskell, and it’s paid off. I’m not yet sure exactly how I feel about it, or when I would chose it relative to other tools, but it is currently very high on my list of favorite technologies.\n</p><p>I did not come to Haskell with a distaste for static typing, despite the fact that I write so much Racket, a dynamically typed language (by default, at least). I don’t really use Typed Racket, and despite my love for Haskell and its type system, I am not sure I will use much more of it than I did before. Haskell and Racket are very different languages, which is justified in some places and probably sort of circumstantial in others.\n</p><p>The future of Haskell seems bright, and a lot of the changes in the just-released GHC 8 are extremely exciting. I did not list records as a pain point because the changes in GHC 8 appear to make them a <em>lot</em> more palatable, although whether or not they solve that problem completely remains to be seen. I will absolutely continue to write Haskell and push it to its limits where I can, and hopefully try and take as much as I can from it along the way.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"At the end of January of this year, I switched to a new job, almost exclusively because I was enticed by the idea of being able to write Haskell. The concept of using such an interesting programming language every day instead of what I’d been doing before (mostly Rails and JavaScript) was very exciting, and I’m pleased to say that the switch seems to have been well worth it.\n\nHaskell was a language I had played with in the past but never really used for anything terribly practical, but lately I think I can confidently say that it really is an incredible programming language. At the same time, it has some significant drawbacks, too, though probably not the ones people expect. I certainly wasn’t prepared for some of the areas where Haskell would blow me away, nor was I capable of realizing which parts would leave me hopelessly frustrated until I actually sat down and started writing lots and lots of code.\n\nDispelling some myths\nBefore moving on and discussing my experiences in depth, I want to take a quick detour to dispel some frequent rumors I hear about why Haskell is at least potentially problematic. These are things I hear a lot, and nothing in my experience so far would lead me to believe these are actually true. Ultimately, I don’t want to spend too much time on these—I think that, for the most part, they are nitpicks that people complain about to avoid understanding the deeper and more insidious problems with the language—but I think it’s important to at least mention them.\n\nHiring Haskell developers is not hard\nI am on the first Haskell team in my company, and I am among the first Haskell developers we ever hired. Not only were we hiring without much experience with Haskell at all, we explicitly did not want to hire remote. Debate all you like about whether or not permitting remote work is a good idea, but I don’t think anyone would dispute that this constraint makes hiring much harder. We didn’t have any trouble finding a very large stream of qualified applicants, and it definitely seems to have dispelled any fears that we would have trouble finding new candidates in the future.\n\nPerforming I/O in Haskell is easy\nHaskell’s purity is a point of real contention, and it’s one of the most frustrating complaints I often hear about Haskell. It is surprisingly common to hear concerns along the lines of “I don’t want to use Haskell because its academic devotion to purity sounds like it would make it very hard to get anything done”. There are very valid reasons to avoid Haskell, but in practice, I/O is not one of them. In fact, I found that isolating I/O in Haskell was much the same as isolating I/O in every other language, which I need to do anyway to permit unit testing.\n\n...you do write deterministic unit tests for your impure logic, right?\n\nWorking with lots of monads is not very difficult\nThe “M word” has ended up being a running joke about Haskell that actually ends up coming up fairly rarely within the Haskell community. To be clear, there is no doubt in my mind that monads make Haskell intimidating and provide a steep learning curve for new users. The proliferation of the joke that monads are impossible to explain, to the point of becoming mythologized, is absolutely indicative of a deeper problem about Haskell’s accessibility. However, once people learn the basics about monads, I’ve found that applying them is just as natural as applying any other programming pattern.\n\nMonads are used to assist the programmer, not impede them, and they really do pay off in practice. When something has a monadic interface, there’s a decent chance I already know what that interface is going to do, and that makes working with lots of different monads surprisingly easy. Admittedly, I do rely very, very heavily on tooling to help me out here, but with things like mouseover type tooltips, I’ve actually found that working with a variety of different monads and monad transformers is actually quite pleasant, and it makes things very readable!\n\nHaskell: the good parts\nWith the disclaimers out of the way, I really just want to gush for a little bit. This is not going to be an objective, reasoned survey of why Haskell is good. I am not even really going to touch upon why types are so great and why purity is so wonderful—I’d love to discuss those in depth, but that’s for a different blog post. For now, I just want to touch upon the real surprises, the real things that made me excited about Haskell in ways I didn’t expect. These are the things that my subjective little experience has found fun.\n\nLanguage extensions are Haskell\nThere was a time in my life when I spent a lot of time writing C. There are a lot of compilers for C, and they all implement the language in subtly different but often incompatible ways, especially on different platforms. The only way to maintain a modicum of predictability was to adhere to the standards religiously, even when certain GCC or MSVC extensions seem tantalizingly useful. I was actually bitten a few times by real instances where I figured I’d just use a harmless extension that was implemented everywhere, then found out it worked slightly differently across different compilers in a particular edge case. It was a learning experience.\n\nIt seems that this fear provides a very real distrust for using GHC’s numerous language extensions, and indeed, for a long time, I felt that it was probably an admirable goal to stick to Haskell 98 or Haskell 2010 as closely as possible. Sometimes I chose a slightly more verbose solution that was standard Haskell to avoid turning on a trivial extension that would make the code look a little bit cleaner.\n\nAbout a year later, I’m finding that attitude was not only a mistake, but it forced me to often completely miss out on a lot of Haskell’s core value. GHC won, and now GHC and Haskell are basically synonymous. With that in mind, the portability concerns of language extensions are a bit of a non-issue, and turning them on is a very good idea! Some extensions are more than a little dangerous, so they cannot all be turned on without thinking, but the question is absolutely not “Is using language extensions a good idea?” and more “Is using this language extension a good idea?”\n\nThis is important, and I bring it up for a reason: so much of the awesomeness of Haskell is locked behind language extensions. Turning a lot of these on is one of the main things that made me really start to see how incredibly powerful Haskell actually is.\n\nPhantom types\nI’m going to start out by talking about phantom types, which are a pretty simple concept but a powerful one, and they serve as the foundation for a lot of other cool type-level tricks that can make Haskell extremely interesting. The basic idea of a phantom type is simple; it’s a type parameter that isn’t actually used to represent any particular runtime value:\n\nnewtype Id a = Id Text\nThis type represents an id for some kind of value, but although the kind of value is specified in the type as the a type parameter, it isn’t actually used anywhere on the data definition—no matter what a is, an Id is just a piece of text. This makes it possible to write functions that operate on specific kinds of ids, and those invariants will be statically checked by the compiler, even though the runtime representation is entirely identical:\n\nfetchUser :: MonadDB m => Id User -> m User\nUsing FlexibleInstances, it’s also possible to create different instances for different kinds of ids. For example, it would be possible to have different Show instances depending on the type of id in question.\n\ninstance Show (Id User) where\n  show (Id txt) = \"user #\" <> unpack txt\n\ninstance Show (Id Post) where\n  show (Id txt) = \"post #\" <> unpack txt\nThis provides a simple framework for encoding entirely arbitrary information into the type system, then asking the compiler to actually check assertions about that information. This is made even more powerful with some other extensions, which I’ll talk about shortly.\n\nLetting the compiler write code\nOne of the things I really dislike, more than most things, is boilerplate. A little bit of boilerplate is fine—even necessary at times—but as soon as I start wondering if a code generator would improve things, I think the programming language has pretty much failed me.\n\nI write a lot of Racket because, in a sense, Racket is the ultimate boilerplate killer: the macro system is a first-class code generator integrated with the rest of the language, and it means that boilerplate is almost never an issue. Of course, that’s not always true: sometimes a bit of boilerplate is still necessary because macros cannot deduce enough information about the program to generate the code entirely on their own, and in Haskell, some of that information is actually present in the type system.\n\nThis leads to two absolutely incredible extensions, both of which are simple and related, but which actually completely change how I approach problems when programming. These two extensions are GeneralizedNewtypeDeriving and StandaloneDeriving.\n\nNewtypes and type safety\nThe basic idea is that “newtypes” are just simple wrapper types in Haskell. This turns out to be extremely important when trying to find the value of Haskell because they allow you to harden type safety by specializing types to your domain. For example, consider a type representing a user’s name:\n\nnewtype Name = Name Text\nThis type is extremely simple, and in fact isn’t even at all different from a simple Text value with respect to its representation, since all combinations of unicode characters are allowed in a name. Therefore, what’s the point of a separate type? Well, this allows Haskell to introduce actual compilation failures when two different kinds of textual data are mixed. This is not a new idea, and even in languages that don’t support this sort of thing, Joel Spolsky’s old blog post Making Wrong Code Look Wrong describes how it can be done by convention. Still, almost every modern language makes this possible: in C, it would be a single-member struct, in class-based OO languages, it would be a single-member class... this is not a complicated idea.\n\nThe difference lies in its usage. In other languages, this strategy is actually not very frequently employed for the simple reason that it is almost always extremely annoying. You are forced to do tons of wrapping/unwrapping, and at that point it isn’t really clear if you’re even getting all that much value out of the distinction when your first solution to a type mismatch is wrapping or unwrapping the value without a second thought. In Haskell, however, this can be heavily mitigated by asking the compiler to automatically derive typeclass implementations, which allow the unwrapping/wrapping to effectively happen implicitly for a constrained set of operations.\n\nUsing GeneralizedNewtypeDeriving\nConsider the Name type once again, but this time, let’s derive a class:\n\nnewtype Name = Name Text\n  deriving (IsString)\nThe IsString typeclass in Haskell allows custom types to automatically be created from string literals. It is not handled specially by Haskell’s deriving mechanism. Since Text implements IsString, an instance will be generated that simply defers to the underlying type, automatically generating the code to wrap the result up in a Name box at the end. This means that code like this will now just magically work:\n\nname :: Name\nname = \"Alyssa P. Hacker\"\nNo boilerplate needs to be written! This is a neat trick, but it actually turns out to be far more useful than that simple example in practice. What really makes this functionality shine is when you want to derive some kinds of functionality but disallow some others. For example, using the text-conversions package, it’s possible to do something like this:\n\nnewtype Id a = Id Text\n  deriving (Eq, Show, ToText, ToJSON)\nThis creates an opaque Id type, but it automatically generates conversions to textual formats. However, it does not automatically create FromText or FromJSON instances, which would be dangerous because decoding Ids can potentially fail. It’s then possible to write out those instances manually to preserve a type safety:\n\ninstance FromText (Maybe (Id a)) where\n  fromText str = if isValidId str then Just (Id str) else Nothing\n\ninstance FromJSON (Id a) where\n  parseJSON (String val) = maybe (fail \"invalid id\") return (fromText val)\n  parseJSON _            = fail \"invalid id\"\nUsing StandaloneDeriving\nThe ordinary deriving mechanism is extremely useful, especially when paired with the above, but sometimes it is desirable to have a little bit more flexibility. In these cases, StandaloneDeriving can help.\n\nTake the Id example again: it has a phantom type, and simply adding something like deriving (ToText) with derive ToText instances for all kinds of ids. It is potentially useful, however, to derive instances for more specific id types. Using standalone deriving constructs permits this sort of flexibility.\n\nderiving instance ToText (Id User)\n\ninstance ToText (Id Post) where\n  toText = postIdToText\nThis is an example where GHC language extensions end up becoming significantly more than the sum of their parts, which seems to be a fairly frequent realization. The StandaloneDeriving mechanism is a little bit useful without GeneralizedNewtypeDeriving, but when combined, they are incredibly powerful tools for getting a very fine-grained kind of type safety without writing any boilerplate.\n\nDataKinds are super cool, with caveats\nPhantom types are quite wonderful, but they can only encode types, not arbitrary data. That’s where DataKinds and KindSignatures come in: they allow lifting arbitrary datatypes to the type level so that things that would normally be purely runtime values can be used at compile-time as well.\n\nThe way this works is pretty simple—when you define a datatype, you also define a “datakind”:\n\ndata RegistrationStatus = Registered | Anonymous\nNormally, the above declaration declares a type, RegistrationStatus, and two data constructors, Registered and Anonymous. With DataKinds, it also defines a kind, RegistrationStatus, and two type constructors, Registered and Anonymous.\n\nIf that’s confusing, the way to understand that is to realize there is a sort of natural ordering here: types describe values, and kinds describe types. Therefore, turning on DataKinds “lifts” each definition by a single level, so types become kinds and values become types. This permits using these things at the type level:\n\nnewtype UserId (s :: RegistrationStatus) = UserId Text\nIn this example, UserId still has a single phantom type variable, s, but this time it is constrained to the RegistrationStatus kind. Therefore, it can only be Registered or Anonymous. This cooperates well with the aforementioned StandaloneDeriving mechanism, and it mostly provides a convenient way to constrain type variables to custom kinds.\n\nIn general, DataKinds is a much more powerful extension, allowing things like type-level natural numbers or strings, which can be used to perform actual type-level computation (especially in combination with TypeFamilies) or a sort of metaprogramming. In some cases, they can even be used to implement things emulating things you can do with dependent types.\n\nI think DataKinds are a very cool Haskell extension, but there are a couple caveats. One of the main ones is how new kinds are defined: DataKinds “hijacks” the existing datatype declaration syntax by making every single datatype declaration define a type and a kind. This is a little confusing, and it would be nice if a different syntax was used so that each could be defined independently.\n\nSimilarly, it seems that a lot of work is being done to allow using runtime values at the type level, but I wonder if people will ever need to use, say, runtime values at the kind level. This immediately evokes thoughts of Racket’s phase-based macro system, and I wonder if some of this duplication would be unnecessary with something similar.\n\nFood for thought, but overall, DataKinds are a very nice addition to help with precisely and specifically typing particular problems.\n\nTypeclasses can emulate effects\nThis is something that I’ve found interesting in my time writing Haskell because I have no idea if it’s idiomatic or not, but it seems pretty powerful. The initial motivator for this idea was figuring out how to test our code without constantly dropping into IO.\n\nMore generally, we wanted to be able to unit test by “mocking” out collaborators, as it would be described in object oriented programming. I was always semi-distrustful of mocking, and indeed, it seems likely that it is heavily abused in certain circles, but I’ve come to appreciate the need that sometimes it is important to stub things out, even in pure code.\n\nAs an example, consider some code that needs access to the current time. This is something that would normally require IO, but we likely want to be able to use the value in a pure context without “infecting” the entire program with IO types. In Haskell, I have generally seen three ways of handling this sort of thing:\n\n\nJust inject the required values into the function and produce them “higher up” where I/O is okay. If threading the value around becomes too burdensome, use a Reader monad.\n\n\nUse a free monad or similar to create a pure DSL of sorts, then write interpreters for various implementations, one of which uses IO.\n\n\nCreate custom monadic typeclasses that provide interfaces to the functionality you want to perform, then create instances, one of which is an instance over IO.\n\n\nThis last approach seems to be less common in Haskell, but it’s the approach we took, and it seems to work out remarkably well. Returning to the need to get the current time, we could pretty easily write such a typeclass to encode that need:\n\nclass Monad m => CurrentTime m where\n  getCurrentTime :: m UTCTime\nNow we can write functions that use the current time:\n\nvalidateToken :: CurrentTime m => Token -> m Bool\nvalidateToken tok = do\n  currentTime <- getCurrentTime\n  return (tokenExpirationDate tok > currentTime)\nNow, we can write instances for CurrentTime that will allow us to run the same code in different contexts:\n\nnewtype AppM a = AppM { runAppM :: IO a }\n  deriving (Functor, Applicative, Monad, MonadIO)\n\nnewtype TestM a = TestM (Identity a)\n  deriving (Functor, Applicative, Monad)\n\nrunTestM :: TestM a -> a\nrunTestM (TestM x) = runIdentity x\n\ninstance CurrentTime AppM where\n  getCurrentTime = liftIO Data.Time.Clock.getCurrentTime\n\ninstance CurrentTime TestM where\n  getCurrentTime = return $ posixSecondsToUTCTime 0\nWhere this really starts to shine is when adding additional effects. For example, the above token validation function might also need information about some kind of secret used for signing. Under this model, it’s just another typeclass:\n\nclass Monad m => TokenSecret m where\n  getTokenSecret :: m Secret\n\nvalidateToken :: (CurrentTime m, TokenSecret m) => Token -> m Bool\nvalidateToken tok = do\n  currentTime <- getCurrentTime\n  secret <- getTokenSecret\n  return (tokenExpirationDate tok > currentTime\n       && verifySignature tok secret)\nOf course, so far all of these functions have been extremely simple, and we’ve basically been using them as a glorified reader monad. In practice, though, we use this pattern for lots more than just retrieving values. For example, we might have a typeclass for database interactions:\n\nclass Monad m => Persistence m where\n  fetchUser :: Id User -> m (Maybe User)\n  insertUser :: User -> m (Either PersistenceError (Id User))\nWith all of this done, it becomes incredibly easy to see which functions are using which effects:\n\npostUsers\n  :: (CurrentTime m, Persistence m, TokenSecret m)\n  => User -> m Response\npostUsers = ...\n\ngetHealthcheck\n  :: CurrentTime m\n  => m Response\ngetHealthcheck = ...\nThere’s no need to perform any lifting, and this all seems to scale quite nicely. We’ve written some additional utilities to help write tests against functions using these kinds of monadic interfaces, and even though there’s a little bit of annoying boilerplate in a few spots, overall it seems to work quite elegantly.\n\nI’m not entirely sure how common this is in the Haskell community, but it’s certainly pretty neat how easy it is to get nearly all of the benefits of effect types in other languages simply by composing some of Haskell’s simplest features.\n\nAtom’s ide-haskell tooling is invaluable\nAlright, so, confession time: I don’t use Emacs.\n\nI know, I know, how is that possible? I write Lisp, after all. Well, honestly, I tried picking it up a number of times, but none of those times did I get far enough to ditch my other tools. For Racket work, I use DrRacket, but for almost everything else, I use Atom.\n\nAtom has a lot of flaws, but it’s also pretty amazing in places, and I absolutely love the Haskell tooling written by the wonderful atom-haskell folks. I use it constantly, and even though it doesn’t always work perfectly, it works pretty well. When it has problems, I’ve at least figured out how to get it working correctly.\n\nThis is probably hard to really explain without seeing it for yourself, but I’ve found that I basically depend on this sort of tooling to be fully productive in Haskell, and I have no problem admitting that. The ability to get instant feedback about type errors tied to visual source locations, to be able to directly manipulate the source by selecting expressions and getting type information, and even the option to get inline linter suggestions means I spend a lot less time glancing at the terminal, and even less time in the REPL.\n\nThe tooling is far from perfect, and it leaves a lot to be desired in places (the idea of using that static information for automated, project-wide refactoring a la Java is tantalizing), but most of those things are ideas of what amazing things could be, not broken or missing essentials. I am pretty satisfied with ide-haskell right now, and I can only hope it continues to get better and better.\n\nFrustrations, drawbacks, and pain points\nHaskell is not perfect. In fact, far from it. There is a vast array of little annoyances that I have with the language, as is the case with any language. Still, there are a few overarching problems that I would really like to at least mention. These are the biggest sources of frustration for me so far.\n\nPurity, failure, and exception-handling\nOne of Haskell’s defining features is its purity—I don’t think many would disagree with that. Some people consider it a drawback, others consider it one of its greatest boons. Personally, I like it a lot, and I think one of the best parts about it is how it requires the programmer to be incredibly deliberate about failure.\n\nIn many languages, when looking up a value from a container where the key doesn’t exist, there are really two ways to go about expressing this failure:\n\n\nThrow an exception.\n\n\nReturn null.\n\n\nThe former is scary because it means any call to any function can make the entire program blow up, and it’s often impossible to know which functions even have the potential to throw. This creates a certain kind of non-local control flow that can sometimes cause a lot of unpredictability. The second option is much the same, especially when any value in a program might be null; it just defers the failure.\n\nIn languages with option types, this is somewhat mitigated. Java now has option types, too, but they are still frequently cumbersome to use because there is nothing like monads to use to simply chain operations together. Haskell, in comparison, has an incredible complement of tools to simply handle errors without a whole lot of burden on the programmer, and I have found that, in practice, this is actually helpful and I really do write better error-handling code.\n\nFirst, the good parts\nI have seen a comparison drawn between throwing checked exceptions and returning Maybe or Either types, but in practice the difference is massive. Handling checked exceptions is a monotonous chore because they are not first-class values, they are actually entirely separate linguistic constructs. Consider a library that throws a LibraryException, and you want to wrap that library and convert those exceptions to ApplicationExceptions. Well, have fun writing this code dozens of times:\n\ntry {\n  x = doSomething();\n} catch (LibraryException ex) {\n  throw ApplicationException.fromLibraryException(ex);\n}\n\n// ...\n\ntry {\n  y = doSomethingElse();\n} catch (LibraryException ex) {\n  throw ApplicationException.fromLibraryException(ex);\n}\nIn Haskell, failure is just represented by first-class values, and it’s totally possible to write helper functions to abstract over that kind of boilerplate:\n\nlibraryToApplication :: LibraryError -> ApplicationError\nlibraryToApplication = ...\n\nliftLibrary :: Either LibraryError a -> Either ApplicationError a\nliftLibrary = mapLeft libraryToApplication\nNow, that same boilerplate-y code becomes nearly invisible:\n\nx <- liftLibrary doSomething\n\n-- ...\n\ny <- liftLibrary doSomethingElse\nThis might not seem like much, but it really cuts down on the amount of visual noise, which ends up making all the difference. Boilerplate incurs a cost much bigger than simply taking the time to type it all out (though that’s important, too): the cognitive overhead of parsing which parts of a program are boilerplate has a significant impact on readability.\n\nSo what’s the problem?\nIf error handling is so great in Haskell, then why am I putting it under the complaints section? Well, it turns out that not everyone seems to think it’s as great as I make it out to be because people seem to keep writing Haskell APIs that throw exceptions!\n\nDespite what some purists would have you believe, Haskell has exceptions, and they are not uncommon. Lots of things can throw exceptions, some of which are probably reasonable. Failing to connect to a database is a pretty catastrophic error, so it seems fair that it would throw. On the other hand, inserting a duplicate record is pretty normal operation, so it seems like that should not throw.\n\nI mostly treat exceptions in Haskell as unrecoverable catastrophes. If I throw an error in my code, I do not intend to catch it. That means something horrible happened, and I just want that horribleness to show up in a log somewhere so I can fix the problem. If I care about failure, there are better ways to handle that failure gracefully.\n\nIt’s also probably worth noting that exceptions in Haskell can be thrown from anywhere, even pure code, but can only be caught within the IO monad. This is especially scary, but I’ve seen it happen in actual libraries out in the wild, even ones that the entire Haskell ecosystem is built on. One of the crowning examples of this is the text package, which provides a function called decodeUtf8 to convert bytestrings into text. Its type is very simple:\n\ndecodeUtf8 :: ByteString -> Text\nBut wait, what if the bytestring is not actually a valid UTF-8 string?\n\nBoom. There goes the application.\n\nOkay, okay, well, at least the text package provides another function, this one called decodeUtf8', which returns an Either. This is good, and I’ve trained myself to only ever use decodeUtf8', but it still has some pretty significant problems:\n\n\nThe safe version of this function is the “prime” version, rather than the other way around, which encourages people to use the unsafe one. Ideally, the unsafe one should be explicitly labeled as such... maybe call it unsafeDecodeUtf8?\n\n\nThis is not a hypothetical problem. When using a Haskell JWT library, we found a function that converts a string into a JWT. Since not all strings are JWTs, the library intelligently returns a Maybe. Therefore, we figured we were safe.\n\nA couple weeks later, we found that providing this function with invalid data was returning HTTP 500 errors. Why? Our error handling was meticulous! Well, the answer was a decodeUtf8 call, hidden inside of the JWT library. This is especially egregious, given that the API it exposed returned a Maybe anyway! It would have been trivial to use the safe version there, instead, but the poor, misleading name led the library developer to overlook the bug lurking in the otherwise innocuous function.\n\nEven worse, this function was totally pure, and we used it in pure code, so we could not simply wrap the function and catch the exception. We had two options: use unsafePerformIO (yuck!) or perform a check before handing the data to the buggy function. We chose the latter, but in some cases, I imagine that could be too difficult to do in order to make it feasible.\n\n\nThe point I’m trying to make is that this is a real problem, and it seems to me that throwing exceptions invalidates one of the primary advantages of Haskell. It disappointed me to realize that a significant amount of code written by FP Complete, one of the primary authors of some of the most important “modern Haskell” code in existence (including Stack), seem to very frequently expose APIs that will throw.\n\nI’m not sure how much of this stems from a fundamental divide in the Haskell ecosystem and how much it is simply due to Michael Snoyman’s coding style, given that he is the primary author of a number of these tools and libraries that seem very eager to throw exceptions. As just one example of a real situation in which we were surprised by this behavior, we used Snoyman’s http-client library and found that it mysteriously throws upon nearly any failure state:\n\nA note on exceptions: for the most part, all actions that perform I/O should be assumed to throw an HttpException in the event of some problem, and all pure functions will be total. For example, withResponse, httpLbs, and BodyReader can all throw exceptions.\n\nThis doesn’t seem entirely unreasonable—after all, isn’t a failure to negotiate TLS fairly catastrophic?—until you consider our use case. We needed to make a subrequest during the extent of another HTTP request to our server, and if that subrequest fails, we absolutely need to handle that failure gracefully. Of course, this is not terrible given that we are in IO so we can actually catch these exceptions, but since this behavior was only noted in a single aside at the top of the documentation, we didn’t realize we were forgetting error handling until far too late and requests were silently failing.\n\nExceptions seem to devalue one of the most powerful concepts in Haskell: if I don’t consider all the possibilities, my code does not compile. In practice, when working with APIs that properly encode these possibilities into the type system, this value proposition seems to be real. I really do find myself writing code that works correctly as soon as it compiles. It’s almost magical.\n\nUsing exceptions throws that all out the window, and I wish the Haskell ecosystem was generally more cautious about when to use them.\n\nThe String problem\nI sort of alluded to this a tiny bit in the last section, and that is probably indicative of how bad this issue is. I’m just going to be blunt: In Haskell, strings suck.\n\nThis is always a bit of an amusing point whenever it is discussed because of how silly it seems. Haskell is a research language with a cutting-edge type system and some of the fanciest features of any language in existence. When everyday programming might use things like “profunctors”, “injective type families”, and “generalized algebraic datatypes”, you would think that dealing with strings would be a well-solved problem.\n\nBut it isn’t. Haskell libraries frequently use not one, not two, but five kinds of strings. Let’s list them off, shall we?\n\n\nFirst off, there’s the built-in String type, which is actually an alias for the [Char] type. For those not intimately familiar with Haskell, that’s a linked list of characters. As Stephen Diehl recently put it in a blog post describing the disaster that is Haskell string types:\n\nThis is not only a bad representation, it’s quite possibly the least efficient (non-contrived) representation of text data possible and has horrible performance in both time and space. And it’s used everywhere in Haskell.\n\nThe point is, it’s really bad. This type is not a useful representation for textual data in practical applications.\n\n\nMoving on, we have a fairly decent type, Text, which comes from Data.Text in the text package. This is a decent representation of text, and it’s probably the one that everything should use. Well, maybe. Because Text comes in two varieties: lazy and strict. Nobody seems to agree on which of those two should be used, though, and they are totally incompatible types: functions that work with one kind of text won’t work with the other. You have to manually convert between them.\n\n\nFinally, we have ByteString, which is horribly misnamed because it really isn’t a string at all, at least not in the textual sense. A better name for this type would have simply been Bytes, which sounds a lot scarier. And that would be good, because data typed as a ByteString is as close as you can get in Haskell to not assigning a type at all: a bytestring holds arbitrary bytes without assigning them any meaning whatsoever!\n\nOr at least, that’s the intention. The trouble is that people don’t treat bytestrings like that—they just use them to toss pieces of text around, even when those pieces of text have a well-defined encoding and represent textual data. This leads to the decodeUtf8 problem mentioned above, but it’s bigger than that because it often ends up with some poor APIs that assign some interpretation to ByteString data without assigning it a different type.\n\nAgain, this is throwing away so much of Haskell’s safety. It would be like using Int to keep track of boolean data (“just use 0 and 1!”) or using empty and singleton lists instead of using Maybe. When you use the precise type, you encode invariants and contracts into statically-checked assertions, but when you use general types like ByteString, you give that up.\n\nOh, and did I mention that ByteStrings also come in incompatible lazy and strict versions, too?\n\n\nSo, obviously, the answer is to just stop using the bad types and to just use (one kind of) Text everywhere. Great! Except that the other types are totally inescapable. The entire standard library uses String exclusively—after all, text is a separate package—and small libraries often use String instead of text because they have no need to bring in the dependency. Of course, this just means every real application pays the performance hit of converting between all these different kinds of strings.\n\nSimilarly, those that do use Text often use different kinds of text, so code ends up littered with fromStrict or toStrict coercions, which (again) have a cost. I’ve already ranted enough about ByteString, but basically, if you’re using ByteString in your API to pass around data that is semantically text, you are causing me pain. Please stop.\n\nIt seems that the way Data.Text probably should have been designed was by making Text a typeclass, then making the lazy and strict implementations instances of that typeclass. Still, the fact that both of them exist would always cause problems. I’m actually unsure which one is the “correct” choice—I don’t know enough about how the two perform in practice—but it seems likely that picking either one would be a performance improvement over the current system, which is constantly spending time converting between the two.\n\nThis issue has been ranted about plenty, so I won’t ramble on, but if you’re designing new libraries, please, please use Text. Your users will thank you.\n\nDocumentation is nearly worthless\nFinally, let’s talk about documentation.\n\nOne of my favorite programming languages is Racket. Racket has a documentation tool called Scribble. Scribble is special because it is a totally separate domain-specific language for writing documentation, and it makes it fun and easy to write good explanations. There are even forms for typesetting automatically-rendered examples that look like a REPL. If the examples ever break or become incorrect, the docs don’t even compile.\n\nAll of the Racket core library documentation makes sure to set a good example about what good documentation should look like. The vast majority of the documentation is paragraphs of prose and simple but practical examples. There are also type signatures (in the form of contracts), and those are super important, but they are so effective because of how the prose explains what each function does, when to use it, why you’d use it, and why you wouldn’t use it.\n\nEverything is cross-referenced automatically. The documentation is completely searchable locally out of the box. As soon as you install a package, its docs are automatically indexed. User-written libraries tend to have pretty good docs, too, because the standard libraries set such a good example and because the tools are so fantastic. Racket docs are really nice, and they’re so good they actually make things like Stack Overflow or even Google mostly irrelevant. It’s all there in the manual.\n\nHaskell documentation is the opposite of everything I just said.\n\n\nThe core libraries are poorly documented. Most functions include a sentence of description, and almost none include examples. At their worst, the descriptions simply restate the type signature.\n\n\nThird-party libraries’ documentation is even worse, going frequently completely undocumented and actually only including type signatures and nothing else.\n\n\nHaddock is an incredibly user-hostile tool for writing anything other than tiny snippets of documentation and is not very good at supporting prose. Notably, Haddock’s documentation is not generated using Haddock (and it still manages to be almost unusable). Forcing all documentation into inline comments makes users unlikely to write much explanation, and there is no ability for abstraction.\n\n\nReading documentation locally is very difficult because there is no easy way to open documentation for a particular package in a web browser, and it’s certainly not searchable. This is especially ridiculous given that Hoogle exists, which is one of best ways to search API docs in existence. There should be a stack hoogle command that just opens a Hoogle page for all locally-installed packages and Just Works, but there isn’t.\n\n\nMost valuable information exists outside of documentation, so Google becomes a go-to immediately after a quick glance at the docs, and information is spread across blog posts, mailing lists, and obscure reddit posts.\n\n\nThis is a problem that cannot be fixed by just making Haddock better, nor can it be fixed simply by improving the existing standard library documentation. There is a fundamental problem with Haskell documentation (which, to be completely fair, is not unique to Haskell), which is that its tools do not support anything more than API docs.\n\nGood documentation is so much more than “here’s what this function does”; it’s about guides and tutorials and case studies and common pitfalls. This is documentation for someone new to lenses. This is not. Take note of the difference.\n\nConclusion and other thoughts\nHaskell is an incredible programming platform, and indeed, it is sometimes mind-boggling how complete it is. It also has a lot of rough edges, sometimes in places that feel like they need a lot more care, or perhaps they’re even simply unfinished.\n\nI could spend weeks writing about all the things I really like or dislike about the language, discussing in fine detail all the things that have made me excited or all the little bits that have made me want to tear my hair out. Heck, I could probably spend a month writing about strings alone. That’s not the point, though... I took a risk with Haskell, and it’s paid off. I’m not yet sure exactly how I feel about it, or when I would chose it relative to other tools, but it is currently very high on my list of favorite technologies.\n\nI did not come to Haskell with a distaste for static typing, despite the fact that I write so much Racket, a dynamically typed language (by default, at least). I don’t really use Typed Racket, and despite my love for Haskell and its type system, I am not sure I will use much more of it than I did before. Haskell and Racket are very different languages, which is justified in some places and probably sort of circumstantial in others.\n\nThe future of Haskell seems bright, and a lot of the changes in the just-released GHC 8 are extremely exciting. I did not list records as a pain point because the changes in GHC 8 appear to make them a lot more palatable, although whether or not they solve that problem completely remains to be seen. I will absolutely continue to write Haskell and push it to its limits where I can, and hopefully try and take as much as I can from it along the way.","isoDate":"2016-06-12T00:00:00.000Z","timestamp":"6/11/2016"},{"title":"Simple, safe multimethods in Racket","pubDate":"2016-02-18T00:00:00.000Z","author":"Alexis King","content":"<article><p>Racket ships with <code>racket/generic</code>, a system for defining <em>generic methods</em>, functions that work differently depending on what sort of value they are supplied. I have made heavy use of this feature in my collections library, and it has worked well for my needs, but that system does have a bit of a limitation: it only supports <em>single dispatch</em>. Method implementations may only be chosen based on a single argument, so multiple dispatch is impossible.\n</p><h2><a name=\"motivating-multiple-dispatch\"></a>Motivating multiple dispatch</h2><p>What is multiple dispatch and why is it necessary? Well, in most cases, it <em>isn’t</em> necessary at all. <a href=\"http://dl.acm.org/citation.cfm?doid=1449764.1449808\">It has been shown that multiple dispatch is much rarer than single dispatch in practice.</a> However, when actually needed, having multiple dispatch in the toolbox is a valuable asset.\n</p><p>A classic example of multiple dispatch is multiplication over both scalars and vectors. Ideally, all of the following operations should work:\n</p><pre><code>2 × 3 = 6\n2 × ⟨3, 4⟩ = ⟨6, 8⟩\n⟨3, 4⟩ × 2 = ⟨6, 8⟩\n</code></pre><p>In practice, most languages do not support such flexible dispatch rules without fairly complicated branching constructs to handle each permutation of input types. Furthermore, since most languages only support single dispatch (such as most object-oriented languages), it is nearly impossible to add support for a new combination of types to an existing method.\n</p><p>To illustrate the above, even if a language supported operator overloading <em>and</em> it included a <code>Vector</code> class that overloaded multiplication to properly work with numbers and vectors, it might not implement matrix multiplication. If a user defines a <code>Matrix</code> class, they may overload <em>its</em> multiplication to support numbers, vectors, and matrices, but it is impossible to extend the multiplication implementation for the <code>Vector</code> class. That method is now completely set in stone, unless it is edited directly (and the programmer may not have access to <code>Vector</code>’s implementation).\n</p><p>Multiple dispatch solves all of these problems. Rather than specify implementations of functions for singular types, it is possible to specify implementations for sets of types. In the above example, a programmer would be able to define a new function that operates on <code>Vector</code> and <code>Matrix</code> arguments. Since each definition does not “belong” to any given type, extending this set of operations is trivial.\n</p><h2><a name=\"multiple-dispatch-in-racket\"></a>Multiple dispatch in Racket</h2><p>This blog post is somewhat long and technical, so before proceeding any further, I want to show some real code that actually works so you can get a feel for what I’m talking about. As a proof-of-concept, I have created <a href=\"https://github.com/lexi-lambda/racket-multimethod\">a very simple implementation of multiple dispatch in Racket</a>. The above example would look like this in Racket using my module:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">multimethod</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">mul</span>\n         <span class=\"p\">(</span><span class=\"k\">struct-out</span> <span class=\"n\">num</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">struct-out</span> <span class=\"n\">vec</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">num</span> <span class=\"p\">(</span><span class=\"n\">val</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">vec</span> <span class=\"p\">(</span><span class=\"n\">vals</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-generic</span> <span class=\"p\">(</span><span class=\"n\">mul</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">num</span> <span class=\"n\">num</span><span class=\"p\">)</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">num</span> <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">y</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">num</span> <span class=\"n\">vec</span><span class=\"p\">)</span> <span class=\"n\">n</span> <span class=\"n\">v</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">vec</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"nb\">curry</span> <span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">n</span><span class=\"p\">))</span> <span class=\"p\">(</span><span class=\"n\">vec-vals</span> <span class=\"n\">v</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">vec</span> <span class=\"n\">num</span><span class=\"p\">)</span> <span class=\"n\">v</span> <span class=\"n\">n</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">mul</span> <span class=\"n\">n</span> <span class=\"n\">v</span><span class=\"p\">))</span></code></pre><p>Pardon the somewhat clunky syntax, but the functionality is there. Using the above code works as expected:\n</p><pre><code>&gt; (mul (num 2) (num 3))\n(num 6)\n&gt; (mul (num 2) (vec '(3 4)))\n(vec '(6 8))\n&gt; (mul (vec '(3 4)) (num 2))\n(vec '(6 8))\n</code></pre><p>Making the above snippet work is not particularly hard. In fact, it’s likely that most competent Racketeers could do it without much thought. However, there’s a tiny bit more going on behind the scenes than it may seem.\n</p><h2><a name=\"the-problem-with-multiple-dispatch\"></a>The problem with multiple dispatch</h2><p>The single-dispatch design limitation of <code>racket/generic</code> comes directly from a desire to avoid what has been described as “spooky action at a distance”, a problem that is prevalent in many systems that support methods with multiple dispatch (aka <em>multimethods</em>). Specifically, the issue arises when new method implementations are defined for existing datatypes, which can have far-reaching effects throughout a program because the method table is global state. Both CLOS and Clojure suffer from this shortcoming.\n</p><p>Interestingly, Haskell with multi-parameter typeclasses (a nonstandard but highly useful extension) makes it quite trivial to create constructs similar to multiple dispatch (though the overload resolution is done at compile-time). The similarities are significant: Haskell <em>also</em> suffers from the possibility of a certain sort of “spooky action”. However, Haskell’s static typing and resolution allows the compiler to catch these potential issues, known as “orphan instances”, at compile time. Even though Racket does not support the same sort of static typing, the same idea can be used to keep multiple dispatch safe using the macro system.\n</p><h2><a name=\"safe-dynamically-typed-multiple-dispatch\"></a>Safe, dynamically-typed multiple dispatch</h2><p>In order to make multiple dispatch safe, we first need to determine exactly what is unsafe. Haskell has rules for determining what constitutes an “orphan instance”, and these rules are equally applicable for determining dangerous multimethod implementations. Specifically, a definition can be considered unsafe if <em>both</em> of the following conditions are true:\n</p><ol><li><p>The multimethod that is being implemented was declared in a different module from the implementation.\n</p></li><li><p><em>All</em> of the types used for dispatch in the multimethod instance were declared in a different module from the implementation.\n</p></li></ol><p>Conversely, a multimethod implementation is safe if <em>either</em> of the following conditions are true:\n</p><ol><li><p>The multimethod that is being implemented is declared in the same module as the implementation.\n</p></li><li><p><em>Any</em> of the types used for dispatch in the multimethod instance are declared in the same module as the implementation.\n</p></li></ol><p>Why do these two rules provide a strong enough guarantee to eliminate the dangers created by global state? Well, to understand that, we need to understand what can go wrong if these rules are ignored.\n</p><h3><a name=\"multimethods-and-dangerous-instances\"></a>Multimethods and dangerous instances</h3><p>What exactly is this dangerous-sounding “spooky action”, and what causes it? Well, the trouble stems from the side-effectful nature of multimethod instance definitions. Consider the Racket module from earlier, which defines multiplication instances for scalars and vectors:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">mul</span>\n         <span class=\"p\">(</span><span class=\"k\">struct-out</span> <span class=\"n\">num</span><span class=\"p\">)</span>\n         <span class=\"p\">(</span><span class=\"k\">struct-out</span> <span class=\"n\">vec</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">num</span> <span class=\"p\">(</span><span class=\"n\">val</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">vec</span> <span class=\"p\">(</span><span class=\"n\">vals</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-generic</span> <span class=\"p\">(</span><span class=\"n\">mul</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">num</span> <span class=\"n\">num</span><span class=\"p\">)</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">num</span> <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">y</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">num</span> <span class=\"n\">vec</span><span class=\"p\">)</span> <span class=\"n\">n</span> <span class=\"n\">v</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">vec</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"nb\">curry</span> <span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">num-val</span> <span class=\"n\">n</span><span class=\"p\">))</span> <span class=\"p\">(</span><span class=\"n\">vec-vals</span> <span class=\"n\">v</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">vec</span> <span class=\"n\">num</span><span class=\"p\">)</span> <span class=\"n\">v</span> <span class=\"n\">n</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">mul</span> <span class=\"n\">n</span> <span class=\"n\">v</span><span class=\"p\">))</span></code></pre><p>Note that there is not actually a <code>(mul vec vec)</code> implementation. This is intentional: there are <em>two</em> ways to take the product of two vectors, so no default implementation is provided. However, it is possible that another module might desire an instance for <code>mul</code> that takes the dot product, and the programmer might write the following definition:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">((</span><span class=\"n\">mul</span> <span class=\"n\">vec</span> <span class=\"n\">vec</span><span class=\"p\">)</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">num</span> <span class=\"p\">(</span><span class=\"nb\">foldl</span> <span class=\"nb\">+</span> <span class=\"mi\">0</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">vec-vals</span> <span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">vec-vals</span> <span class=\"n\">y</span><span class=\"p\">)))))</span></code></pre><p>However, there is something fishy about the above definition: it doesn’t need to be exported with <code>provide</code> to work! Since instances don’t create new bindings, they only add dispatch options, they don’t ever need to <code>provide</code> anything. This is problematic, though: it means that a program could continue to happily compile <em>even if</em> the module containing the dot product instance was never loaded with <code>require</code>, but an attempt to multiply two vectors would fail at runtime, claiming that there was no <code>(mul vec vec)</code> implementation. This drastic change of behavior violates Racket programmers’ assumptions about the guarantees made by modules (<code>require</code> should not cause any side-effects if the module’s bindings are not used).\n</p><p>Of course, while this seems potentially unexpected, it is workable: just be careful to <code>require</code> modules containing instances. Unfortunately, it gets much worse—what if a different library defines <em>its own</em> <code>(mul vec vec)</code> instance? What if that instance takes the cross product instead? That library may function entirely properly on its own, but when loaded alongside the program that defines a dot product instance, it is impossible to determine which instance should be used where. Because <code>define-instance</code> operates by modifying the aforementioned global state, the implementations clash, and the two systems <em>cannot</em> continue to operate together as written.\n</p><p>This is pretty bad. Defining extra instances is a reasonable use-case for multiple dispatch, but if these instances can break <em>third-party code</em>, how can they be trusted? This sort of problem can make multiple dispatch difficult to reason about and even more difficult to trust.\n</p><h3><a name=\"what-determines-safety\"></a>What determines safety?</h3><p>With those problems in mind, we can turn back to the two rules for <em>safe</em> multiple dispatch. How do they prevent the above issues? Well, let’s take them one at a time.\n</p><p>Remember that an instance can be unequivocally determined to be safe if either of the two conditions are true, so we can consider them entirely independently. The first one is simple—an instance is safe if the following condition holds:\n</p><blockquote><p>The multimethod that is being implemented is declared in the same module as the implementation.\n</p></blockquote><p>This one is pretty obvious. It is impossible to create a “bad” instance of a method declared in the same module because it is impossible to import the method without also bringing in the instance. Furthermore, a conflicting instance cannot be defined at the place where the types themselves are defined because that would require a circular module dependency, which Racket does not permit.\n</p><p>With the above explanation in mind, the second condition should make sense, too:\n</p><blockquote><p><em>Any</em> of the types used for dispatch in the multimethod instance are declared in the same module as the implementation.\n</p></blockquote><p>The same argument for the first point holds for the second, but with the parties swapped. Again, it is impossible to use the instance without somehow requiring the module that defines the datatype itself, so the instance would always be required, anyway. The most interesting aspect of this condition is that it demonstrates that instances can be defined for existing datatypes (that are defined in other modules) just so long as <em>at least one</em> of the datatypes is defined in the same module. This continues to permit the important use-case of extending the interfaces of existing types.\n</p><h3><a name=\"encoding-the-safety-rules-into-racket-s-macro-system\"></a>Encoding the safety rules into Racket’s macro system</h3><p>In order to keep track of which methods and instances are defined where, I leveraged a technique based on the one <a href=\"http://www.ccs.neu.edu/racket/pubs/scheme2007-ctf.pdf\">used by Typed Racket to keep track of whether or not a typed identifier is used in a typed or untyped context</a>. However, instead of using a simple mutable boolean flag, I used a mutable <a href=\"http://docs.racket-lang.org/syntax/syntax-helpers.html#%28tech._identifier._set%29\">free identifier set</a>, which keeps track of the identifiers within a given module that should be considered “privileged”.\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket/base</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">syntax/id-set</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">provide</span> <span class=\"n\">mark-id-as-privileged!</span>\n         <span class=\"n\">id-privileged?</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">privileged-ids</span> <span class=\"p\">(</span><span class=\"n\">mutable-free-id-set</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">mark-id-as-privileged!</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">free-id-set-add!</span> <span class=\"n\">privileged-ids</span> <span class=\"n\">id</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">id-privileged?</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">free-id-set-member?</span> <span class=\"n\">privileged-ids</span> <span class=\"n\">id</span><span class=\"p\">))</span></code></pre><p>Making this work with <code>define-generic</code> is obvious: just invoke <code>mark-id-as-privileged!</code> on the method name to note that the method is “privileged” in the scope of the current module. Keeping track of privileged structs is similarly straightforward, though it is a little more devious: the <code>multimethod</code> module provides a custom <code>struct</code> macro that just expands to <code>struct</code> from <code>racket/base</code>, but adds privilege information.\n</p><p>The <code>define-instance</code> macro does all the heavy lifting to ensure that only privileged identifiers can be used in instance definitions. A simple check for the identifier annotations is performed before proceeding with macro expansion:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"n\">privileged?</span> <span class=\"p\">(</span><span class=\"nb\">ormap</span> <span class=\"n\">id-privileged?</span> <span class=\"n\">types</span><span class=\"p\">))</span>\n  <span class=\"p\">(</span><span class=\"n\">assert-privileged-struct!</span> <span class=\"p\">(</span><span class=\"nb\">first</span> <span class=\"n\">types</span><span class=\"p\">)))</span></code></pre><p>When the privilege checks fail, an error is raised:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">assert-privileged-struct!</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"n\">id-privileged?</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"nb\">raise-syntax-error</span> <span class=\"o\">&#39;</span><span class=\"ss\">define-instance</span>\n                        <span class=\"s2\">\"expected name of struct defined in current module\"</span>\n                        <span class=\"n\">id</span><span class=\"p\">)))</span></code></pre><p>With the above safeguards in place, the dangerous dot product implementation from above <strong>would not be allowed</strong>. The checks manage to encode both of the safety rules into the macro system such that invalid instances will fail <em>at compile time</em>, preventing dangerous uses of multimethods from ever slipping by unnoticed.\n</p><h3><a name=\"actually-implementing-multiple-dispatch\"></a>Actually implementing multiple dispatch</h3><p>The rest of the multimethod implementation is relatively straightforward and is not even particularly robust. If anything, it is the bare minimum of what would be needed to allow the safety mechanisms above to work. Lots of features that would likely be needed in a real implementation are not included, and graceful error handling is largely ignored.\n</p><p>Multimethods themselves are implemented as Racket <a href=\"http://docs.racket-lang.org/guide/proc-macros.html#%28tech._transformer._binding%29\">transformer bindings</a> containing custom data, including a reference to the multimethod’s arity and dispatch table. The custom datatype includes a <code>prop:procedure</code> structure type property, which allows such bindings to also function as macros. The macro procedure expands to an operation that looks up the proper instance to use in the multimethod’s dispatch table and invokes it with the supplied arguments.\n</p><p>The relevant code for defining multimethods is reproduced below:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">multimethod</span> <span class=\"p\">(</span><span class=\"n\">arity</span> <span class=\"n\">dispatch-table</span><span class=\"p\">)</span>\n    <span class=\"kd\">#:property</span> <span class=\"nb\">prop:procedure</span>\n    <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"p\">(</span><span class=\"n\">method</span> <span class=\"n\">stx</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"n\">syntax-parse</span> <span class=\"n\">stx</span>\n        <span class=\"p\">[(</span><span class=\"n\">method</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n         <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">apply-multimethod</span> <span class=\"n\">method</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"n\">arg</span> <span class=\"k\">...</span><span class=\"p\">))]</span>\n        <span class=\"p\">[</span><span class=\"n\">method</span>\n         <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"n\">args</span> <span class=\"p\">(</span><span class=\"n\">apply-multimethod</span> <span class=\"n\">method</span> <span class=\"n\">args</span><span class=\"p\">))]))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">define-generic</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"n\">method:id</span> <span class=\"n\">arg:id</span> <span class=\"n\">...+</span><span class=\"p\">))</span>\n     <span class=\"p\">(</span><span class=\"k\">with-syntax</span> <span class=\"p\">([</span><span class=\"n\">arity</span> <span class=\"p\">(</span><span class=\"nb\">length</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">arg</span><span class=\"p\">))]</span>\n                   <span class=\"p\">[</span><span class=\"n\">dispatch-table</span> <span class=\"p\">(</span><span class=\"n\">generate-temporary</span> <span class=\"o\">#&#39;</span><span class=\"n\">method</span><span class=\"p\">)])</span>\n       <span class=\"p\">(</span><span class=\"n\">mark-id-as-privileged!</span> <span class=\"o\">#&#39;</span><span class=\"n\">method</span><span class=\"p\">)</span>\n       <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n           <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">dispatch-table</span> <span class=\"p\">(</span><span class=\"nb\">make-hash</span><span class=\"p\">))</span>\n           <span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">method</span> <span class=\"p\">(</span><span class=\"n\">multimethod</span> <span class=\"n\">arity</span> <span class=\"o\">#&#39;</span><span class=\"n\">dispatch-table</span><span class=\"p\">))))]))</span></code></pre><p>The dispatch tables are implemented entirely in terms of Racket’s structure types, so while they can be defined on arbitrary structure types (including ones defined in the Racket standard library), they <em>cannot</em> be defined on primitives such as pairs or vectors. Implementations are registered in the dispatch table using the compile-time information associated with structs’ transformer bindings, and the same information is retrieved from struct instances at runtime to look up the proper implementation to call. Notably, this only works if the struct is <code>#:transparent</code>, or more generally and accurately, if the calling code has access to the struct’s inspector. All structs defined by the <code>struct</code> form from the <code>multimethod</code> module are automatically marked as <code>#:transparent</code>.\n</p><p>The following code implements defining multimethod instances:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">assert-privileged-struct!</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"n\">id-privileged?</span> <span class=\"n\">id</span><span class=\"p\">)</span>\n      <span class=\"p\">(</span><span class=\"nb\">raise-syntax-error</span> <span class=\"o\">&#39;</span><span class=\"ss\">define-instance</span>\n                          <span class=\"s2\">\"expected name of struct defined in current module\"</span>\n                          <span class=\"n\">id</span><span class=\"p\">))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">define-instance</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"c1\">; standard (define (proc ...) ...) shorthand</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"p\">((</span><span class=\"n\">method</span> <span class=\"n\">type:id</span> <span class=\"n\">...+</span><span class=\"p\">)</span> <span class=\"o\">.</span> <span class=\"n\">args</span><span class=\"p\">)</span> <span class=\"n\">body:expr</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">define-instance</span> <span class=\"p\">(</span><span class=\"n\">method</span> <span class=\"n\">type</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"k\">λ</span> <span class=\"n\">args</span> <span class=\"n\">body</span> <span class=\"k\">...</span><span class=\"p\">))]</span>\n    <span class=\"c1\">; full (define proc lambda-expr) notation</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"p\">(</span><span class=\"n\">method</span> <span class=\"n\">type:id</span> <span class=\"n\">...+</span><span class=\"p\">)</span> <span class=\"n\">proc:expr</span><span class=\"p\">)</span>\n     <span class=\"p\">(</span><span class=\"k\">let*</span> <span class=\"p\">([</span><span class=\"n\">multimethod</span> <span class=\"p\">(</span><span class=\"nb\">syntax-local-value</span> <span class=\"o\">#&#39;</span><span class=\"n\">method</span><span class=\"p\">)]</span>\n            <span class=\"p\">[</span><span class=\"n\">privileged?</span> <span class=\"p\">(</span><span class=\"n\">id-privileged?</span> <span class=\"o\">#&#39;</span><span class=\"n\">method</span><span class=\"p\">)])</span>\n       <span class=\"p\">(</span><span class=\"k\">unless</span> <span class=\"p\">(</span><span class=\"k\">or</span> <span class=\"n\">privileged?</span> <span class=\"p\">(</span><span class=\"nb\">ormap</span> <span class=\"n\">id-privileged?</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">type</span><span class=\"p\">)))</span>\n         <span class=\"p\">(</span><span class=\"n\">assert-privileged-struct!</span> <span class=\"p\">(</span><span class=\"nb\">first</span> <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">type</span><span class=\"p\">))))</span>\n       <span class=\"p\">(</span><span class=\"k\">with-syntax</span> <span class=\"p\">([</span><span class=\"n\">dispatch-table</span> <span class=\"p\">(</span><span class=\"n\">multimethod-dispatch-table</span> <span class=\"n\">multimethod</span><span class=\"p\">)]</span>\n                     <span class=\"p\">[(</span><span class=\"n\">struct-type-id</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">map</span> <span class=\"p\">(</span><span class=\"nb\">compose1</span> <span class=\"nb\">first</span> <span class=\"n\">extract-struct-info</span> <span class=\"nb\">syntax-local-value</span><span class=\"p\">)</span>\n                                                <span class=\"p\">(</span><span class=\"n\">attribute</span> <span class=\"n\">type</span><span class=\"p\">))])</span>\n         <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">let</span> <span class=\"p\">([</span><span class=\"n\">struct-types</span> <span class=\"p\">(</span><span class=\"nb\">list</span> <span class=\"n\">struct-type-id</span> <span class=\"k\">...</span><span class=\"p\">)])</span>\n             <span class=\"p\">(</span><span class=\"nb\">hash-set!</span> <span class=\"n\">dispatch-table</span> <span class=\"n\">struct-types</span> <span class=\"n\">proc</span><span class=\"p\">))))]))</span></code></pre><p>The resulting implementation is a useful, if certainly incomplete implementation of multimethods in Racket that does not sacrifice the safety provided by <code>racket/generic</code>’s single-dispatch approach.\n</p><h2><a name=\"related-work-advantages-and-disadvantages-and-areas-for-future-improvement\"></a>Related work, advantages and disadvantages, and areas for future improvement</h2><p>As previously mentioned, this implementation of multiple dispatch was inspired by the types of APIs offered by CLOS and Clojure while also maintaining the safety of <code>racket/generic</code>. The inspiration for the safety rules came from GHC’s detection of orphan instances. Although most of the ideas presented above exist in other places, I am unsure if the concept of safety checking has been used before in any dynamically-typed programming languages.\n</p><p>The primary advantage offered over Racket’s existing generics system is obvious: multiple dispatch. Furthermore, this system can supersede many uses of <code>racket/generic</code> simply by dispatching on a single type. However, the current implementation does <em>not</em> support all of the features of <code>racket/generic</code>, such as supporting non-structure types and allowing fallback implementations. While those are well within the realm of possibility, other things like attaching structure type properties are probably not possible with this approach, so it is unlikely that the existing system could be subsumed by one like this one.\n</p><p>Additionally, this implementation would almost certainly need numerous improvements before being useful to most programmers:\n</p><ul><li><p><strong>Good error reporting for failure cases.</strong> Right now, even something obvious like calling a method on values that do not implement it simply fails with an error produced by <code>hash-ref</code>. In a more interesting sense, using the arity to generate compile-time error messages for <code>define-instance</code> would be a nice improvement.\n</p></li><li><p><strong>Support for Racket primitive data types.</strong> This might require some cooperation from Racket itself to permit an elegant implementation, but they could also just be special-cased. So long as lookup for primitives was done <em>after</em> consulting the main dispatch table, there wouldn’t be any performance hit for non-primitive types.\n</p></li><li><p><strong>Option to supply fallback implementations.</strong> This wouldn’t be too hard at all, though it’s questionable whether or not it would be useful without method groupings like <code>define/generic</code> provides. There would likely also need to be some sort of way to check if a set of values implements a particular method.\n</p></li><li><p><strong>Better cooperation with structure inspectors to alleviate the need for all structures to be transparent.</strong> It’s currently unclear to me how exactly this works and how it <em>should</em> work. There might be a better way to do this without mucking with inspectors.\n</p></li><li><p><strong>Much more flexible argument lists, including the ability to specify arguments that are not used for dispatch.</strong> This is really a pretty fundamental requirement, but the parsing required was significant enough for me to put it off for this initial prototype.\n</p></li><li><p><strong>Scribble forms to document generic methods and their instances.</strong> This is something <code>racket/generic</code> <em>doesn’t</em> have, and it has suffered for it. It would be very nice to have easy documentation forms for multimethods.\n</p></li><li><p><strong>Proper consideration of struct subtyping.</strong> Racket structs support subtyping, which I have not given much thought for this prototype. It is possible that subtyping violates constraints I had assumed would hold, so reviewing the existing code with that context would be useful.\n</p></li></ul><p>I’m not sure how much effort is involved in most of the above ideas, and in fact I’m not even completely sure how useful this system is to begin with. I have not found myself reaching much for multiple dispatch in my time as a Racket programmer, but that could simply be because it was previously unavailable. It will be interesting to see if that changes now that I have built this system, even if it is a bit rough around the edges.\n</p><h2><a name=\"conclusion\"></a>Conclusion</h2><p>Despite the lack of need for multiple dispatch to solve most problems, as indicated by its general lack of support in mainstream programming languages, it’s a nice tool to have in the toolbox, and it <em>is</em> asked for in the Racket community from time to time (perhaps due to its familiarity in other parts of the Lisp world). Time will tell if pointing people to something like this will create or stifle interest in multiple dispatch for Racket.\n</p><p>The source for the <a href=\"https://github.com/lexi-lambda/racket-multimethod\"><code>multimethod</code> package can be found here</a> if you are at all interested in playing with it yourself.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Racket ships with racket/generic, a system for defining generic methods, functions that work differently depending on what sort of value they are supplied. I have made heavy use of this feature in my collections library, and it has worked well for my needs, but that system does have a bit of a limitation: it only supports single dispatch. Method implementations may only be chosen based on a single argument, so multiple dispatch is impossible.\n\nMotivating multiple dispatch\nWhat is multiple dispatch and why is it necessary? Well, in most cases, it isn’t necessary at all. It has been shown that multiple dispatch is much rarer than single dispatch in practice. However, when actually needed, having multiple dispatch in the toolbox is a valuable asset.\n\nA classic example of multiple dispatch is multiplication over both scalars and vectors. Ideally, all of the following operations should work:\n\n2 × 3 = 6\n2 × ⟨3, 4⟩ = ⟨6, 8⟩\n⟨3, 4⟩ × 2 = ⟨6, 8⟩\n\nIn practice, most languages do not support such flexible dispatch rules without fairly complicated branching constructs to handle each permutation of input types. Furthermore, since most languages only support single dispatch (such as most object-oriented languages), it is nearly impossible to add support for a new combination of types to an existing method.\n\nTo illustrate the above, even if a language supported operator overloading and it included a Vector class that overloaded multiplication to properly work with numbers and vectors, it might not implement matrix multiplication. If a user defines a Matrix class, they may overload its multiplication to support numbers, vectors, and matrices, but it is impossible to extend the multiplication implementation for the Vector class. That method is now completely set in stone, unless it is edited directly (and the programmer may not have access to Vector’s implementation).\n\nMultiple dispatch solves all of these problems. Rather than specify implementations of functions for singular types, it is possible to specify implementations for sets of types. In the above example, a programmer would be able to define a new function that operates on Vector and Matrix arguments. Since each definition does not “belong” to any given type, extending this set of operations is trivial.\n\nMultiple dispatch in Racket\nThis blog post is somewhat long and technical, so before proceeding any further, I want to show some real code that actually works so you can get a feel for what I’m talking about. As a proof-of-concept, I have created a very simple implementation of multiple dispatch in Racket. The above example would look like this in Racket using my module:\n\n#lang racket\n\n(require multimethod)\n\n(provide mul\n         (struct-out num)\n         (struct-out vec))\n\n(struct num (val))\n(struct vec (vals))\n\n(define-generic (mul a b))\n\n(define-instance ((mul num num) x y)\n  (num (* (num-val x) (num-val y))))\n\n(define-instance ((mul num vec) n v)\n  (vec (map (curry * (num-val n)) (vec-vals v))))\n\n(define-instance ((mul vec num) v n)\n  (mul n v))\nPardon the somewhat clunky syntax, but the functionality is there. Using the above code works as expected:\n\n> (mul (num 2) (num 3))\n(num 6)\n> (mul (num 2) (vec '(3 4)))\n(vec '(6 8))\n> (mul (vec '(3 4)) (num 2))\n(vec '(6 8))\n\nMaking the above snippet work is not particularly hard. In fact, it’s likely that most competent Racketeers could do it without much thought. However, there’s a tiny bit more going on behind the scenes than it may seem.\n\nThe problem with multiple dispatch\nThe single-dispatch design limitation of racket/generic comes directly from a desire to avoid what has been described as “spooky action at a distance”, a problem that is prevalent in many systems that support methods with multiple dispatch (aka multimethods). Specifically, the issue arises when new method implementations are defined for existing datatypes, which can have far-reaching effects throughout a program because the method table is global state. Both CLOS and Clojure suffer from this shortcoming.\n\nInterestingly, Haskell with multi-parameter typeclasses (a nonstandard but highly useful extension) makes it quite trivial to create constructs similar to multiple dispatch (though the overload resolution is done at compile-time). The similarities are significant: Haskell also suffers from the possibility of a certain sort of “spooky action”. However, Haskell’s static typing and resolution allows the compiler to catch these potential issues, known as “orphan instances”, at compile time. Even though Racket does not support the same sort of static typing, the same idea can be used to keep multiple dispatch safe using the macro system.\n\nSafe, dynamically-typed multiple dispatch\nIn order to make multiple dispatch safe, we first need to determine exactly what is unsafe. Haskell has rules for determining what constitutes an “orphan instance”, and these rules are equally applicable for determining dangerous multimethod implementations. Specifically, a definition can be considered unsafe if both of the following conditions are true:\n\n\nThe multimethod that is being implemented was declared in a different module from the implementation.\n\n\nAll of the types used for dispatch in the multimethod instance were declared in a different module from the implementation.\n\n\nConversely, a multimethod implementation is safe if either of the following conditions are true:\n\n\nThe multimethod that is being implemented is declared in the same module as the implementation.\n\n\nAny of the types used for dispatch in the multimethod instance are declared in the same module as the implementation.\n\n\nWhy do these two rules provide a strong enough guarantee to eliminate the dangers created by global state? Well, to understand that, we need to understand what can go wrong if these rules are ignored.\n\nMultimethods and dangerous instances\nWhat exactly is this dangerous-sounding “spooky action”, and what causes it? Well, the trouble stems from the side-effectful nature of multimethod instance definitions. Consider the Racket module from earlier, which defines multiplication instances for scalars and vectors:\n\n(provide mul\n         (struct-out num)\n         (struct-out vec))\n\n(struct num (val))\n(struct vec (vals))\n\n(define-generic (mul a b))\n\n(define-instance ((mul num num) x y)\n  (num (* (num-val x) (num-val y))))\n\n(define-instance ((mul num vec) n v)\n  (vec (map (curry * (num-val n)) (vec-vals v))))\n\n(define-instance ((mul vec num) v n)\n  (mul n v))\nNote that there is not actually a (mul vec vec) implementation. This is intentional: there are two ways to take the product of two vectors, so no default implementation is provided. However, it is possible that another module might desire an instance for mul that takes the dot product, and the programmer might write the following definition:\n\n(define-instance ((mul vec vec) x y)\n  (num (foldl + 0 (map * (vec-vals x) (vec-vals y)))))\nHowever, there is something fishy about the above definition: it doesn’t need to be exported with provide to work! Since instances don’t create new bindings, they only add dispatch options, they don’t ever need to provide anything. This is problematic, though: it means that a program could continue to happily compile even if the module containing the dot product instance was never loaded with require, but an attempt to multiply two vectors would fail at runtime, claiming that there was no (mul vec vec) implementation. This drastic change of behavior violates Racket programmers’ assumptions about the guarantees made by modules (require should not cause any side-effects if the module’s bindings are not used).\n\nOf course, while this seems potentially unexpected, it is workable: just be careful to require modules containing instances. Unfortunately, it gets much worse—what if a different library defines its own (mul vec vec) instance? What if that instance takes the cross product instead? That library may function entirely properly on its own, but when loaded alongside the program that defines a dot product instance, it is impossible to determine which instance should be used where. Because define-instance operates by modifying the aforementioned global state, the implementations clash, and the two systems cannot continue to operate together as written.\n\nThis is pretty bad. Defining extra instances is a reasonable use-case for multiple dispatch, but if these instances can break third-party code, how can they be trusted? This sort of problem can make multiple dispatch difficult to reason about and even more difficult to trust.\n\nWhat determines safety?\nWith those problems in mind, we can turn back to the two rules for safe multiple dispatch. How do they prevent the above issues? Well, let’s take them one at a time.\n\nRemember that an instance can be unequivocally determined to be safe if either of the two conditions are true, so we can consider them entirely independently. The first one is simple—an instance is safe if the following condition holds:\n\nThe multimethod that is being implemented is declared in the same module as the implementation.\n\nThis one is pretty obvious. It is impossible to create a “bad” instance of a method declared in the same module because it is impossible to import the method without also bringing in the instance. Furthermore, a conflicting instance cannot be defined at the place where the types themselves are defined because that would require a circular module dependency, which Racket does not permit.\n\nWith the above explanation in mind, the second condition should make sense, too:\n\nAny of the types used for dispatch in the multimethod instance are declared in the same module as the implementation.\n\nThe same argument for the first point holds for the second, but with the parties swapped. Again, it is impossible to use the instance without somehow requiring the module that defines the datatype itself, so the instance would always be required, anyway. The most interesting aspect of this condition is that it demonstrates that instances can be defined for existing datatypes (that are defined in other modules) just so long as at least one of the datatypes is defined in the same module. This continues to permit the important use-case of extending the interfaces of existing types.\n\nEncoding the safety rules into Racket’s macro system\nIn order to keep track of which methods and instances are defined where, I leveraged a technique based on the one used by Typed Racket to keep track of whether or not a typed identifier is used in a typed or untyped context. However, instead of using a simple mutable boolean flag, I used a mutable free identifier set, which keeps track of the identifiers within a given module that should be considered “privileged”.\n\n#lang racket/base\n\n(require syntax/id-set)\n\n(provide mark-id-as-privileged!\n         id-privileged?)\n\n(define privileged-ids (mutable-free-id-set))\n\n(define (mark-id-as-privileged! id)\n  (free-id-set-add! privileged-ids id))\n\n(define (id-privileged? id)\n  (free-id-set-member? privileged-ids id))\nMaking this work with define-generic is obvious: just invoke mark-id-as-privileged! on the method name to note that the method is “privileged” in the scope of the current module. Keeping track of privileged structs is similarly straightforward, though it is a little more devious: the multimethod module provides a custom struct macro that just expands to struct from racket/base, but adds privilege information.\n\nThe define-instance macro does all the heavy lifting to ensure that only privileged identifiers can be used in instance definitions. A simple check for the identifier annotations is performed before proceeding with macro expansion:\n\n(unless (or privileged? (ormap id-privileged? types))\n  (assert-privileged-struct! (first types)))\nWhen the privilege checks fail, an error is raised:\n\n(define (assert-privileged-struct! id)\n  (unless (id-privileged? id)\n    (raise-syntax-error 'define-instance\n                        \"expected name of struct defined in current module\"\n                        id)))\nWith the above safeguards in place, the dangerous dot product implementation from above would not be allowed. The checks manage to encode both of the safety rules into the macro system such that invalid instances will fail at compile time, preventing dangerous uses of multimethods from ever slipping by unnoticed.\n\nActually implementing multiple dispatch\nThe rest of the multimethod implementation is relatively straightforward and is not even particularly robust. If anything, it is the bare minimum of what would be needed to allow the safety mechanisms above to work. Lots of features that would likely be needed in a real implementation are not included, and graceful error handling is largely ignored.\n\nMultimethods themselves are implemented as Racket transformer bindings containing custom data, including a reference to the multimethod’s arity and dispatch table. The custom datatype includes a prop:procedure structure type property, which allows such bindings to also function as macros. The macro procedure expands to an operation that looks up the proper instance to use in the multimethod’s dispatch table and invokes it with the supplied arguments.\n\nThe relevant code for defining multimethods is reproduced below:\n\n(begin-for-syntax\n  (struct multimethod (arity dispatch-table)\n    #:property prop:procedure\n    (λ (method stx)\n      (syntax-parse stx\n        [(method arg ...)\n         #'(apply-multimethod method (list arg ...))]\n        [method\n         #'(λ args (apply-multimethod method args))]))))\n\n(define-syntax define-generic\n  (syntax-parser\n    [(_ (method:id arg:id ...+))\n     (with-syntax ([arity (length (attribute arg))]\n                   [dispatch-table (generate-temporary #'method)])\n       (mark-id-as-privileged! #'method)\n       #'(begin\n           (define dispatch-table (make-hash))\n           (define-syntax method (multimethod arity #'dispatch-table))))]))\nThe dispatch tables are implemented entirely in terms of Racket’s structure types, so while they can be defined on arbitrary structure types (including ones defined in the Racket standard library), they cannot be defined on primitives such as pairs or vectors. Implementations are registered in the dispatch table using the compile-time information associated with structs’ transformer bindings, and the same information is retrieved from struct instances at runtime to look up the proper implementation to call. Notably, this only works if the struct is #:transparent, or more generally and accurately, if the calling code has access to the struct’s inspector. All structs defined by the struct form from the multimethod module are automatically marked as #:transparent.\n\nThe following code implements defining multimethod instances:\n\n(begin-for-syntax\n  (define (assert-privileged-struct! id)\n    (unless (id-privileged? id)\n      (raise-syntax-error 'define-instance\n                          \"expected name of struct defined in current module\"\n                          id))))\n\n(define-syntax define-instance\n  (syntax-parser\n    ; standard (define (proc ...) ...) shorthand\n    [(_ ((method type:id ...+) . args) body:expr ...+)\n     #'(define-instance (method type ...) (λ args body ...))]\n    ; full (define proc lambda-expr) notation\n    [(_ (method type:id ...+) proc:expr)\n     (let* ([multimethod (syntax-local-value #'method)]\n            [privileged? (id-privileged? #'method)])\n       (unless (or privileged? (ormap id-privileged? (attribute type)))\n         (assert-privileged-struct! (first (attribute type))))\n       (with-syntax ([dispatch-table (multimethod-dispatch-table multimethod)]\n                     [(struct-type-id ...) (map (compose1 first extract-struct-info syntax-local-value)\n                                                (attribute type))])\n         #'(let ([struct-types (list struct-type-id ...)])\n             (hash-set! dispatch-table struct-types proc))))]))\nThe resulting implementation is a useful, if certainly incomplete implementation of multimethods in Racket that does not sacrifice the safety provided by racket/generic’s single-dispatch approach.\n\nRelated work, advantages and disadvantages, and areas for future improvement\nAs previously mentioned, this implementation of multiple dispatch was inspired by the types of APIs offered by CLOS and Clojure while also maintaining the safety of racket/generic. The inspiration for the safety rules came from GHC’s detection of orphan instances. Although most of the ideas presented above exist in other places, I am unsure if the concept of safety checking has been used before in any dynamically-typed programming languages.\n\nThe primary advantage offered over Racket’s existing generics system is obvious: multiple dispatch. Furthermore, this system can supersede many uses of racket/generic simply by dispatching on a single type. However, the current implementation does not support all of the features of racket/generic, such as supporting non-structure types and allowing fallback implementations. While those are well within the realm of possibility, other things like attaching structure type properties are probably not possible with this approach, so it is unlikely that the existing system could be subsumed by one like this one.\n\nAdditionally, this implementation would almost certainly need numerous improvements before being useful to most programmers:\n\n\nGood error reporting for failure cases. Right now, even something obvious like calling a method on values that do not implement it simply fails with an error produced by hash-ref. In a more interesting sense, using the arity to generate compile-time error messages for define-instance would be a nice improvement.\n\n\nSupport for Racket primitive data types. This might require some cooperation from Racket itself to permit an elegant implementation, but they could also just be special-cased. So long as lookup for primitives was done after consulting the main dispatch table, there wouldn’t be any performance hit for non-primitive types.\n\n\nOption to supply fallback implementations. This wouldn’t be too hard at all, though it’s questionable whether or not it would be useful without method groupings like define/generic provides. There would likely also need to be some sort of way to check if a set of values implements a particular method.\n\n\nBetter cooperation with structure inspectors to alleviate the need for all structures to be transparent. It’s currently unclear to me how exactly this works and how it should work. There might be a better way to do this without mucking with inspectors.\n\n\nMuch more flexible argument lists, including the ability to specify arguments that are not used for dispatch. This is really a pretty fundamental requirement, but the parsing required was significant enough for me to put it off for this initial prototype.\n\n\nScribble forms to document generic methods and their instances. This is something racket/generic doesn’t have, and it has suffered for it. It would be very nice to have easy documentation forms for multimethods.\n\n\nProper consideration of struct subtyping. Racket structs support subtyping, which I have not given much thought for this prototype. It is possible that subtyping violates constraints I had assumed would hold, so reviewing the existing code with that context would be useful.\n\n\nI’m not sure how much effort is involved in most of the above ideas, and in fact I’m not even completely sure how useful this system is to begin with. I have not found myself reaching much for multiple dispatch in my time as a Racket programmer, but that could simply be because it was previously unavailable. It will be interesting to see if that changes now that I have built this system, even if it is a bit rough around the edges.\n\nConclusion\nDespite the lack of need for multiple dispatch to solve most problems, as indicated by its general lack of support in mainstream programming languages, it’s a nice tool to have in the toolbox, and it is asked for in the Racket community from time to time (perhaps due to its familiarity in other parts of the Lisp world). Time will tell if pointing people to something like this will create or stifle interest in multiple dispatch for Racket.\n\nThe source for the multimethod package can be found here if you are at all interested in playing with it yourself.","isoDate":"2016-02-18T00:00:00.000Z","timestamp":"2/17/2016"},{"title":"ADTs in Typed Racket with macros","pubDate":"2015-12-21T00:00:00.000Z","author":"Alexis King","content":"<article><p>Macros are one of Racket's flagship features, and its macro system really is state of the art. Of course, it can sometimes be difficult to demonstrate <em>why</em> macros are so highly esteemed, in part because it can be hard to find self-contained examples of using macros in practice. Of course, one thing that macros are perfect for is filling a \"hole\" in the language by introducing a feature a language lacks, and one of those features in Typed Racket is <strong>ADTs</strong>.\n</p><h2><a name=\"warning-this-is-not-a-macro-tutorial\"></a>Warning: this is not a macro tutorial</h2><p>First, a disclaimer: this post assumes at least some knowledge of Scheme/Racket macros. Ideally, you would be familiar with Racket itself. But if you aren't, fear not: if you get lost, don't worry. Hold on to the bigger picture, and you'll likely learn more than someone who knows enough to follow all the way through. If you <em>are</em> interested in learning about macros, I must recommend Greg Hendershott's <a href=\"http://www.greghendershott.com/fear-of-macros/\">Fear of Macros</a>. It is good. This is not that.\n</p><p>Now, with that out of the way, let's get started.\n</p><h2><a name=\"what-we-re-building\"></a>What we&rsquo;re building</h2><p><a href=\"https://en.wikipedia.org/wiki/Algebraic_data_type\">Algebraic data types</a>, or <em>ADTs</em>, are a staple of the ML family of functional programming languages. I won't go into detail here—I want to focus on the implementation—but they're a very descriptive way of modeling data that encourages designing functions in terms of pattern-matching, something that Racket is already good at.\n</p><p>Racket also already has a facility for creating custom data structures in the form of <em>structs</em>, which are extremely flexible, but also a little verbose. Racket structs are more powerful than we need, but that means we can implement our ADTs in terms of Racket's struct system.\n</p><p>With that in mind, what should our syntax look like? Well, let's consider a quintessential example of ADTs: modeling a simple tree. For now, let's just consider a tree of integers. For reference, the Haskell syntax for such a data structure would look like this:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Tree</span> <span class=\"ow\">=</span> <span class=\"kt\">Empty</span>\n          <span class=\"o\">|</span> <span class=\"kt\">Leaf</span> <span class=\"kt\">Int</span>\n          <span class=\"o\">|</span> <span class=\"kt\">Node</span> <span class=\"kt\">Tree</span> <span class=\"kt\">Tree</span></code></pre><p>This already demonstrates a few of the core things we'll need to build:\n</p><ol><li><p>Each ADT has a <em>data type</em>, in this case <code>Tree</code>. This name only exists in the world of types, it isn't a value.\n</p></li><li><p>Each ADT has various <em>data constructors</em>, in this case <code>Leaf</code> and <code>Node</code>.\n</p></li><li><p>Each data constructor may accept any number of arguments, each of which have a specific type.\n</p></li><li><p>The types that data constructors may accept include the ADT's datatype itself—that is, definitions can be recursive.\n</p></li></ol><p>Of course, there's one more important feature we're missing: polymorphism. Our definition of a tree is overly-specific, and really, it should be able to hold any kind of data, not just integers. In Haskell, we can do that by adding a type parameter:\n</p><pre><code class=\"pygments\"><span class=\"kr\">data</span> <span class=\"kt\">Tree</span> <span class=\"n\">a</span> <span class=\"ow\">=</span> <span class=\"kt\">Empty</span>\n            <span class=\"o\">|</span> <span class=\"kt\">Leaf</span> <span class=\"n\">a</span>\n            <span class=\"o\">|</span> <span class=\"kt\">Node</span> <span class=\"p\">(</span><span class=\"kt\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span></code></pre><p>With this in mind, we can add a fifth and final point to our list:\n</p><ol start=\"5\"><li><p>ADTs must be able to be parametrically polymorphic.\n</p></li></ol><p>That covers all of our requirements for basic ADTs. Now we're ready to port this idea to Racket.\n</p><h3><a name=\"describing-adts-in-racket\"></a>Describing ADTs in Racket</h3><p>How should we take the Haskell syntax for an ADT definition and adapt it to Racket's parenthetical s-expressions? By taking some cues from the Haskell implementation, Typed Racket's type syntax, and Racket's naming conventions, a fairly logical syntax emerges:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-datatype</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"n\">Empty</span>\n  <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)))</span></code></pre><p>This looks pretty good. Just like with the Haskell implementation, <code>Tree</code> should only exist at the type level, and <code>Empty</code>, <code>Leaf</code>, and <code>Node</code> should be constructor functions. Our syntax mirrors Racket function application, too—the proper way to create a leaf would be <code>(Leaf 7)</code>.\n</p><p>Now that we can create ADT values, how should we extract the values from them? Well, just like in ML-likes, we can use pattern-matching. We don't need to reinvent the wheel for this one; we should be able to just use Racket's <code>match</code>[racket] with our datatypes. For example, a function that sums all the values in a tree might look like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">:</span> <span class=\"n\">tree-sum</span> <span class=\"p\">((</span><span class=\"n\">Tree</span> <span class=\"n\">Integer</span><span class=\"p\">)</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Integer</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">tree-sum</span> <span class=\"n\">tree</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"n\">tree</span>\n    <span class=\"p\">[(</span><span class=\"n\">Empty</span><span class=\"p\">)</span>    <span class=\"mi\">0</span>               <span class=\"p\">]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Leaf</span> <span class=\"n\">n</span><span class=\"p\">)</span>   <span class=\"n\">n</span>               <span class=\"p\">]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Node</span> <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"p\">(</span><span class=\"n\">tree-sum</span> <span class=\"n\">l</span><span class=\"p\">)</span>\n                   <span class=\"p\">(</span><span class=\"n\">tree-sum</span> <span class=\"n\">r</span><span class=\"p\">))]))</span></code></pre><p>Given that Racket's <code>struct</code> form automatically produces identifiers that cooperate with <code>match</code>, this shouldn't be hard at all. And with our syntax settled, we're ready to begin implementation.\n</p><h2><a name=\"implementing-adts-as-syntax\"></a>Implementing ADTs as syntax</h2><p>Now for the fun part. To implement our ADT syntax, we'll employ Racket's industrial-strength macro DSL, <a href=\"http://docs.racket-lang.org/syntax/stxparse.html\"><code>syntax/parse</code></a>. The <code>syntax/parse</code> library works like the traditional Scheme <code>syntax-case</code> on steroids, and one of the most useful features is the ability to define \"syntax classes\" that encapsulate reusable parsing rules into declarative components.\n</p><p>Since this is not a macro tutorial, the following implementation assumes you already know how to use <code>syntax/parse</code>. However, all of the concepts here are well within the reaches of any intermediate macrologist, so don't be intimidated by some of the more complex topics at play.\n</p><h3><a name=\"parsing-types-with-a-syntax-class\"></a>Parsing types with a syntax class</h3><p>To implement ADTs, we're going to want to define exactly one syntax class, a class that describes the grammar for a type. As we've seen, types can be bare identifiers, like <code>Tree</code>, or they can be identifiers with parameters, like <code>(Tree a)</code>. We'll want to cover both cases.\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">type</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"n\">name:id</span> <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">param</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"p\">())</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">name:id</span> <span class=\"n\">param</span> <span class=\"n\">...+</span><span class=\"p\">))))</span></code></pre><p>This syntax class has two rules, one that's a bare identifier, and one that's a list. The ellipsis followed by a plus (<code>...+</code>) in the second example means \"one or more\", so parsing those parameters will automatically be handled for us. In the bare identifier example, we use <code>#:attr</code> to give the <code>param</code> attribute the default value of an empty list, so this syntax class will actually <em>normalize</em> the input we get in addition to actually parsing it.\n</p><h3><a name=\"a-first-attempt-at-define-datatype\"></a>A first attempt at <code>define-datatype</code></h3><p>Now we can move on to actually implementing <code>define-datatype</code>. The rules are simple: we need to generate a structure type for each one of the data constructors, and we need to generate a type definition for the parent type itself. This is pretty simple to implement using <code>syntax-parser</code>, which actually does the parsing for our macro.\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">define-datatype</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">type-name:type</span> <span class=\"n\">data-constructor:type</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n     <span class=\"p\">]))</span></code></pre><p>This definition will do all the parsing we need. It parses the entire macro \"invocation\", ignoring the first datum with <code>_</code> (which will just be the identifier <code>define-datatype</code>), then expecting a <code>type-name</code>, which uses the <code>type</code> syntax class we defined above. Next, we expect zero or more <code>data-constructor</code>s, which also use the <code>type</code> syntax class. That's all we have to do for parsing. We now have all the information we need to actually output the expansion for the macro.\n</p><p>Of course, it won't be that easy: this is the difficult part. The first step is to generate a Racket struct for each data constructor. We can do this pretty easily with some simple use of Racket's syntax templating facility. A naïve attempt would look like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">define-datatype</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">type-name:type</span> <span class=\"n\">data-constructor:type</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n         <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">data-constructor.name</span> <span class=\"p\">([</span><span class=\"n\">f</span> <span class=\"n\">:</span> <span class=\"n\">data-constructor.param</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n         <span class=\"k\">...</span><span class=\"p\">))]))</span></code></pre><p>This is actually really close to being correct. This will generate a struct definition for each <code>data-constructor</code>, where each struct has the name of the data constructor and the same number of fields as arguments provided. The trouble is that in Racket structs, all of the fields have <em>names</em>, but in our ADTs, all the fields are anonymous and by-position. Currently, we're just using the same name for <em>all</em> the fields, <code>f</code>, so if any data constructor has two or more fields, we'll get an error.\n</p><p>Since we don't care about the field names, what we want to do is just generate random names for every field. To do this, we can use a Racket function called <code>generate-temporary</code>, which generates random identifiers. Our next attempt might look like this:\n</p><pre><code class=\"pygments\"><span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n    <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">data-constructor.name</span>\n      <span class=\"p\">([</span><span class=\"o\">#,</span><span class=\"p\">(</span><span class=\"n\">generate-temporary</span><span class=\"p\">)</span> <span class=\"n\">:</span> <span class=\"n\">data-constructor.param</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n    <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><p>The <code>#,</code> lets us \"escape\" from the template to execute <code>(generate-temporary)</code> and interpolate its result into the syntax. Unfortunately, this doesn't work. We <em>do</em> generate a random field name, but the ellipsis will re-use the same generated value when it repeats the fields, rendering our whole effort pointless. We need to generate the field names once per type.\n</p><h3><a name=\"more-leveraging-syntax-classes\"></a>More leveraging syntax classes</h3><p>As it turns out, this is <em>also</em> easy to do with syntax classes. We can add an extra attribute to our <code>type</code> syntax class to generate a random identifier with each one. Again, we can use <code>#:attr</code> to do that automatically. Our new definition for <code>type</code> will look like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">type</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"n\">name:id</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">param</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"p\">()</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">field-id</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"p\">())</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">name:id</span> <span class=\"n\">param</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">field-id</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">generate-temporaries</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">param</span> <span class=\"k\">...</span><span class=\"p\">)))))</span></code></pre><p>Here we're using <code>generate-temporaries</code> instead of <code>generate-temporary</code>, which will conveniently generate a new identifier for each of the elements in the list we provide it. This way, we'll get a fresh identifier for each <code>param</code>.\n</p><p>We can now fix our macro to use this <code>field-id</code> attribute instead of the static field name:\n</p><pre><code class=\"pygments\"><span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n    <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">data-constructor.name</span>\n      <span class=\"p\">([</span><span class=\"n\">data-constructor.field-id</span> <span class=\"n\">:</span> <span class=\"n\">data-constructor.param</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n    <span class=\"k\">...</span><span class=\"p\">)</span></code></pre><h3><a name=\"creating-the-supertype\"></a>Creating the supertype</h3><p>We're almost done—now we just need to implement our overall type, the one defined by <code>type-name</code>. This is implemented as a trivial type alias, but we need to ensure that polymorphic types are properly handled. For example, a non-polymorphic type would need to be handled like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-type</span> <span class=\"n\">Tree</span> <span class=\"p\">(</span><span class=\"n\">U</span> <span class=\"n\">Empty</span> <span class=\"n\">Leaf</span> <span class=\"n\">Node</span><span class=\"p\">))</span></code></pre><p>However, a polymorphic type alias would need to include the type parameters in each subtype, like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-type</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">U</span> <span class=\"p\">(</span><span class=\"n\">Empty</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"n\">a</span><span class=\"p\">)))</span></code></pre><p>How can we do this? Well, so far, we've been very declarative by using syntax patterns, templates, and classes. However, this is a more pernicious problem to solve with our declarative tools. Fortunately, it's very easy to fall back to using <strong>procedural macros</strong>.\n</p><p>To build each properly-instantiated type, we'll use a combination of <code>define/with-syntax</code> and Racket's list comprehensions, <code>for/list</code>. The <code>define/with-syntax</code> form binds values to pattern identifiers, which can be used within syntax patterns just like the ones bound by <code>syntax-parser</code>. This will allow us to break up our result into multiple steps. Technically, <code>define/with-syntax</code> is not strictly necessary—we could just use <code>#`</code> and <code>#,</code>—but it's cleaner to work with.\n</p><p>We'll start by defining a set of instantiated data constructor types, one per <code>data-constructor</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define/with-syntax</span> <span class=\"p\">[</span><span class=\"n\">data-type</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n  <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">name</span> <span class=\"p\">(</span><span class=\"nb\">in-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">data-constructor.name</span> <span class=\"k\">...</span><span class=\"p\">))])</span>\n    <span class=\"p\">))</span></code></pre><p>Now we can fill in the body with any code we'd like, so long as each body returns a syntax object. We can use some trivial branching logic to determine which form we need:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define/with-syntax</span> <span class=\"p\">[</span><span class=\"n\">data-type</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n  <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">name</span> <span class=\"p\">(</span><span class=\"nb\">in-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">data-constructor.name</span> <span class=\"k\">...</span><span class=\"p\">))])</span>\n    <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">stx-null?</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n        <span class=\"n\">name</span>\n        <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"o\">#,</span><span class=\"n\">name</span> <span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">))))</span></code></pre><p>Now with our definition for <code>data-type</code>, we can implement our type alias for the supertype extremely easily:\n</p><pre><code class=\"pygments\"><span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">define-type</span> <span class=\"n\">type-name</span> <span class=\"p\">(</span><span class=\"n\">U</span> <span class=\"n\">data-type</span> <span class=\"k\">...</span><span class=\"p\">))</span></code></pre><h3><a name=\"putting-it-all-together\"></a>Putting it all together</h3><p>There's just one more thing to do before we can call this macro finished: we need to ensure that all the type parameters defined by <code>type-name</code> are in scope for each data constructor's structure definition. We can do this by making use of <code>type-name.param</code> within each produced struct definition, resulting in this:\n</p><pre><code class=\"pygments\"><span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n    <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"n\">data-constructor.name</span> <span class=\"p\">(</span><span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n      <span class=\"p\">([</span><span class=\"n\">data-constructor.field-id</span> <span class=\"n\">:</span> <span class=\"n\">data-constructor.param</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n    <span class=\"k\">...</span><span class=\"p\">)</span></code></pre><p>And we're done! The final macro, now completed, looks like this:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">begin-for-syntax</span>\n  <span class=\"p\">(</span><span class=\"n\">define-syntax-class</span> <span class=\"n\">type</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"n\">name:id</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">param</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"p\">()</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">field-id</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&#39;</span><span class=\"p\">())</span>\n    <span class=\"p\">(</span><span class=\"n\">pattern</span> <span class=\"p\">(</span><span class=\"n\">name:id</span> <span class=\"n\">param</span> <span class=\"n\">...+</span><span class=\"p\">)</span>\n             <span class=\"kd\">#:attr</span> <span class=\"p\">[</span><span class=\"n\">field-id</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"nb\">generate-temporaries</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">param</span> <span class=\"k\">...</span><span class=\"p\">)))))</span>\n\n<span class=\"p\">(</span><span class=\"k\">define-syntax</span> <span class=\"n\">define-datatype</span>\n  <span class=\"p\">(</span><span class=\"n\">syntax-parser</span>\n    <span class=\"p\">[(</span><span class=\"k\">_</span> <span class=\"n\">type-name:type</span> <span class=\"n\">data-constructor:type</span> <span class=\"k\">...</span><span class=\"p\">)</span>\n\n     <span class=\"p\">(</span><span class=\"n\">define/with-syntax</span> <span class=\"p\">[</span><span class=\"n\">data-type</span> <span class=\"k\">...</span><span class=\"p\">]</span>\n       <span class=\"p\">(</span><span class=\"k\">for/list</span> <span class=\"p\">([</span><span class=\"n\">name</span> <span class=\"p\">(</span><span class=\"nb\">in-syntax</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">data-constructor.name</span> <span class=\"k\">...</span><span class=\"p\">))])</span>\n         <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">stx-null?</span> <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">))</span>\n             <span class=\"n\">name</span>\n             <span class=\"o\">#`</span><span class=\"p\">(</span><span class=\"o\">#,</span><span class=\"n\">name</span> <span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">))))</span>\n\n     <span class=\"o\">#&#39;</span><span class=\"p\">(</span><span class=\"k\">begin</span>\n         <span class=\"p\">(</span><span class=\"k\">struct</span> <span class=\"p\">(</span><span class=\"n\">type-name.param</span> <span class=\"k\">...</span><span class=\"p\">)</span> <span class=\"n\">data-constructor.name</span>\n           <span class=\"p\">([</span><span class=\"n\">data-constructor.field-id</span> <span class=\"n\">:</span> <span class=\"n\">data-constructor.param</span><span class=\"p\">]</span> <span class=\"k\">...</span><span class=\"p\">))</span> <span class=\"k\">...</span>\n         <span class=\"p\">(</span><span class=\"n\">define-type</span> <span class=\"n\">type-name</span> <span class=\"p\">(</span><span class=\"n\">U</span> <span class=\"n\">data-type</span> <span class=\"k\">...</span><span class=\"p\">)))]))</span></code></pre><p>It's a little bit dense, certainly, but it is not as complicated or scary as it might seem. It's a simple, mostly declarative, powerful way to transform a DSL into ordinary Typed Racket syntax, and now all we have to do is put it to use.\n</p><h2><a name=\"using-our-adts\"></a>Using our ADTs</h2><p>With the macro built, we can now actually use our ADTs using the syntax we described! The following is now <em>valid code</em>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-datatype</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"n\">Empty</span>\n  <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Tree</span> <span class=\"n\">a</span><span class=\"p\">)))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Empty</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"mi\">7</span><span class=\"p\">)))</span>\n<span class=\"nb\">-</span> <span class=\"n\">:</span> <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"n\">Positive-Byte</span><span class=\"p\">)</span>\n<span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Node</span> <span class=\"p\">(</span><span class=\"n\">Empty</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Leaf</span> <span class=\"mi\">7</span><span class=\"p\">)))</span></code></pre><p>We can use this to define common data types, such as Haskell's <code>Maybe</code>:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-datatype</span> <span class=\"p\">(</span><span class=\"n\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Just</span> <span class=\"n\">a</span><span class=\"p\">)</span>\n  <span class=\"n\">Nothing</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">:</span> <span class=\"n\">maybe-default</span> <span class=\"p\">(</span><span class=\"n\">All</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"n\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"n\">a</span> <span class=\"k\">-&gt;</span> <span class=\"n\">a</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">maybe-default</span> <span class=\"n\">m</span> <span class=\"n\">v</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"n\">m</span>\n    <span class=\"p\">[(</span><span class=\"n\">Just</span> <span class=\"n\">a</span><span class=\"p\">)</span>  <span class=\"n\">a</span><span class=\"p\">]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Nothing</span><span class=\"p\">)</span> <span class=\"n\">v</span><span class=\"p\">]))</span>\n\n<span class=\"p\">(</span><span class=\"n\">:</span> <span class=\"n\">maybe-then</span> <span class=\"p\">(</span><span class=\"n\">All</span> <span class=\"p\">[</span><span class=\"n\">a</span><span class=\"p\">]</span> <span class=\"p\">(</span><span class=\"n\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">))</span> <span class=\"k\">-&gt;</span> <span class=\"p\">(</span><span class=\"n\">Maybe</span> <span class=\"n\">a</span><span class=\"p\">)))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">maybe-then</span> <span class=\"n\">m</span> <span class=\"n\">f</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"n\">m</span>\n    <span class=\"p\">[(</span><span class=\"n\">Just</span> <span class=\"n\">a</span><span class=\"p\">)</span>  <span class=\"p\">(</span><span class=\"n\">f</span> <span class=\"n\">a</span><span class=\"p\">)]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Nothing</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Nothing</span><span class=\"p\">)]))</span></code></pre><p>And of course, we can also use it to define ADTs that use concrete types rather that type parameters, if we so desire. This implements a small mathematical language, along with a trivial interpreter:\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">define-datatype</span> <span class=\"n\">Expr</span>\n  <span class=\"p\">(</span><span class=\"n\">Value</span> <span class=\"n\">Number</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Add</span> <span class=\"n\">Expr</span> <span class=\"n\">Expr</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Subtract</span> <span class=\"n\">Expr</span> <span class=\"n\">Expr</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Multiply</span> <span class=\"n\">Expr</span> <span class=\"n\">Expr</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">Divide</span> <span class=\"n\">Expr</span> <span class=\"n\">Expr</span><span class=\"p\">))</span>\n\n<span class=\"p\">(</span><span class=\"n\">:</span> <span class=\"n\">evaluate</span> <span class=\"p\">(</span><span class=\"n\">Expr</span> <span class=\"k\">-&gt;</span> <span class=\"n\">Number</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">e</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"k\">match</span> <span class=\"n\">e</span>\n    <span class=\"p\">[(</span><span class=\"n\">Value</span> <span class=\"n\">x</span><span class=\"p\">)</span>      <span class=\"n\">x</span>                            <span class=\"p\">]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Add</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span>      <span class=\"p\">(</span><span class=\"nb\">+</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">b</span><span class=\"p\">))]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Subtract</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">-</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">b</span><span class=\"p\">))]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Multiply</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"nb\">*</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">b</span><span class=\"p\">))]</span>\n    <span class=\"p\">[(</span><span class=\"n\">Divide</span> <span class=\"n\">a</span> <span class=\"n\">b</span><span class=\"p\">)</span>   <span class=\"p\">(</span><span class=\"nb\">/</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"n\">b</span><span class=\"p\">))]))</span>\n\n<span class=\"nb\">&gt;</span> <span class=\"p\">(</span><span class=\"n\">evaluate</span> <span class=\"p\">(</span><span class=\"n\">Add</span> <span class=\"p\">(</span><span class=\"n\">Value</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n                 <span class=\"p\">(</span><span class=\"n\">Multiply</span> <span class=\"p\">(</span><span class=\"n\">Divide</span> <span class=\"p\">(</span><span class=\"n\">Value</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"n\">Value</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n                           <span class=\"p\">(</span><span class=\"n\">Value</span> <span class=\"mi\">7</span><span class=\"p\">))))</span>\n<span class=\"mi\">4</span> <span class=\"m\">1/2</span></code></pre><p>There's all the power of ADTs, right in Racket, all implemented in 22 lines of code. If you'd like to see all the code together in a runnable form, <a href=\"https://gist.github.com/lexi-lambda/18cf7a9156f743a1317e\">I&rsquo;ve put together a gist here</a>.\n</p><h2><a name=\"conclusions-and-credit\"></a>Conclusions and credit</h2><p>This isn't the simplest macro to create, nor is it the most complex. The code examples might not even make much sense until you try it out yourself. Macros, like any difficult concept, are not always easy to pick up, but they certainly <em>are</em> powerful. The ability to extend the language in such a way, in the matter of minutes, is unparalleled in languages other than Lisp.\n</p><p>This is, of course, a blessing and a curse. Lisps reject some of the syntactic landmarks that often aid in readability for the power to abstract programs into their bare components. In the end, is this uniform conciseness more or less readable? That's an incredibly subjective question, one that has prompted powerfully impassioned discussions, and I will not attempt to argue one way or the other here.\n</p><p>That said, I think it's pretty cool.\n</p><p>Finally, I must give credit where credit is due. Thanks to <a href=\"http://andmkent.com\">Andrew M. Kent</a> for the creation of the <a href=\"https://github.com/andmkent/datatype\">datatype</a> package, which served as the inspiration for this blog post. Many thanks to <a href=\"http://www.ccs.neu.edu/home/samth/\">Sam Tobin-Hochstadt</a> for his work creating Typed Racket, as well as helping me dramatically simplify the implementation used in this blog post. Also thanks to <a href=\"http://www.ccs.neu.edu/home/ryanc/\">Ryan Culpepper</a> and <a href=\"http://www.ccs.neu.edu/home/matthias/\">Matthias Felleisen</a> for their work on creating <code>syntax/parse</code>, which is truly a marvelous tool for exploring the world of macros, and, of course, a big thanks to <a href=\"http://www.cs.utah.edu/~mflatt/\">Matthew Flatt</a> for his implementation of hygiene in Racket, as well as much of the rest of Racket itself. Not to mention the entire legacy of those who formulated the foundations of the Scheme macro system and created the framework for all of this to be possible so many decades later.\n</p><p>Truly, working in Racket feels like standing on the shoulders of giants. If you're intrigued, give it a shot. It's a fun feeling.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Macros are one of Racket's flagship features, and its macro system really is state of the art. Of course, it can sometimes be difficult to demonstrate why macros are so highly esteemed, in part because it can be hard to find self-contained examples of using macros in practice. Of course, one thing that macros are perfect for is filling a \"hole\" in the language by introducing a feature a language lacks, and one of those features in Typed Racket is ADTs.\n\nWarning: this is not a macro tutorial\nFirst, a disclaimer: this post assumes at least some knowledge of Scheme/Racket macros. Ideally, you would be familiar with Racket itself. But if you aren't, fear not: if you get lost, don't worry. Hold on to the bigger picture, and you'll likely learn more than someone who knows enough to follow all the way through. If you are interested in learning about macros, I must recommend Greg Hendershott's Fear of Macros. It is good. This is not that.\n\nNow, with that out of the way, let's get started.\n\nWhat we’re building\nAlgebraic data types, or ADTs, are a staple of the ML family of functional programming languages. I won't go into detail here—I want to focus on the implementation—but they're a very descriptive way of modeling data that encourages designing functions in terms of pattern-matching, something that Racket is already good at.\n\nRacket also already has a facility for creating custom data structures in the form of structs, which are extremely flexible, but also a little verbose. Racket structs are more powerful than we need, but that means we can implement our ADTs in terms of Racket's struct system.\n\nWith that in mind, what should our syntax look like? Well, let's consider a quintessential example of ADTs: modeling a simple tree. For now, let's just consider a tree of integers. For reference, the Haskell syntax for such a data structure would look like this:\n\ndata Tree = Empty\n          | Leaf Int\n          | Node Tree Tree\nThis already demonstrates a few of the core things we'll need to build:\n\n\nEach ADT has a data type, in this case Tree. This name only exists in the world of types, it isn't a value.\n\n\nEach ADT has various data constructors, in this case Leaf and Node.\n\n\nEach data constructor may accept any number of arguments, each of which have a specific type.\n\n\nThe types that data constructors may accept include the ADT's datatype itself—that is, definitions can be recursive.\n\n\nOf course, there's one more important feature we're missing: polymorphism. Our definition of a tree is overly-specific, and really, it should be able to hold any kind of data, not just integers. In Haskell, we can do that by adding a type parameter:\n\ndata Tree a = Empty\n            | Leaf a\n            | Node (Tree a) (Tree a)\nWith this in mind, we can add a fifth and final point to our list:\n\n\nADTs must be able to be parametrically polymorphic.\n\n\nThat covers all of our requirements for basic ADTs. Now we're ready to port this idea to Racket.\n\nDescribing ADTs in Racket\nHow should we take the Haskell syntax for an ADT definition and adapt it to Racket's parenthetical s-expressions? By taking some cues from the Haskell implementation, Typed Racket's type syntax, and Racket's naming conventions, a fairly logical syntax emerges:\n\n(define-datatype (Tree a)\n  Empty\n  (Leaf a)\n  (Node (Tree a) (Tree a)))\nThis looks pretty good. Just like with the Haskell implementation, Tree should only exist at the type level, and Empty, Leaf, and Node should be constructor functions. Our syntax mirrors Racket function application, too—the proper way to create a leaf would be (Leaf 7).\n\nNow that we can create ADT values, how should we extract the values from them? Well, just like in ML-likes, we can use pattern-matching. We don't need to reinvent the wheel for this one; we should be able to just use Racket's match[racket] with our datatypes. For example, a function that sums all the values in a tree might look like this:\n\n(: tree-sum ((Tree Integer) -> Integer))\n(define (tree-sum tree)\n  (match tree\n    [(Empty)    0               ]\n    [(Leaf n)   n               ]\n    [(Node l r) (+ (tree-sum l)\n                   (tree-sum r))]))\nGiven that Racket's struct form automatically produces identifiers that cooperate with match, this shouldn't be hard at all. And with our syntax settled, we're ready to begin implementation.\n\nImplementing ADTs as syntax\nNow for the fun part. To implement our ADT syntax, we'll employ Racket's industrial-strength macro DSL, syntax/parse. The syntax/parse library works like the traditional Scheme syntax-case on steroids, and one of the most useful features is the ability to define \"syntax classes\" that encapsulate reusable parsing rules into declarative components.\n\nSince this is not a macro tutorial, the following implementation assumes you already know how to use syntax/parse. However, all of the concepts here are well within the reaches of any intermediate macrologist, so don't be intimidated by some of the more complex topics at play.\n\nParsing types with a syntax class\nTo implement ADTs, we're going to want to define exactly one syntax class, a class that describes the grammar for a type. As we've seen, types can be bare identifiers, like Tree, or they can be identifiers with parameters, like (Tree a). We'll want to cover both cases.\n\n(begin-for-syntax\n  (define-syntax-class type\n    (pattern name:id #:attr [param 1] '())\n    (pattern (name:id param ...+))))\nThis syntax class has two rules, one that's a bare identifier, and one that's a list. The ellipsis followed by a plus (...+) in the second example means \"one or more\", so parsing those parameters will automatically be handled for us. In the bare identifier example, we use #:attr to give the param attribute the default value of an empty list, so this syntax class will actually normalize the input we get in addition to actually parsing it.\n\nA first attempt at define-datatype\nNow we can move on to actually implementing define-datatype. The rules are simple: we need to generate a structure type for each one of the data constructors, and we need to generate a type definition for the parent type itself. This is pretty simple to implement using syntax-parser, which actually does the parsing for our macro.\n\n(define-syntax define-datatype\n  (syntax-parser\n    [(_ type-name:type data-constructor:type ...)\n     ]))\nThis definition will do all the parsing we need. It parses the entire macro \"invocation\", ignoring the first datum with _ (which will just be the identifier define-datatype), then expecting a type-name, which uses the type syntax class we defined above. Next, we expect zero or more data-constructors, which also use the type syntax class. That's all we have to do for parsing. We now have all the information we need to actually output the expansion for the macro.\n\nOf course, it won't be that easy: this is the difficult part. The first step is to generate a Racket struct for each data constructor. We can do this pretty easily with some simple use of Racket's syntax templating facility. A naïve attempt would look like this:\n\n(define-syntax define-datatype\n  (syntax-parser\n    [(_ type-name:type data-constructor:type ...)\n     #'(begin\n         (struct data-constructor.name ([f : data-constructor.param] ...)\n         ...))]))\nThis is actually really close to being correct. This will generate a struct definition for each data-constructor, where each struct has the name of the data constructor and the same number of fields as arguments provided. The trouble is that in Racket structs, all of the fields have names, but in our ADTs, all the fields are anonymous and by-position. Currently, we're just using the same name for all the fields, f, so if any data constructor has two or more fields, we'll get an error.\n\nSince we don't care about the field names, what we want to do is just generate random names for every field. To do this, we can use a Racket function called generate-temporary, which generates random identifiers. Our next attempt might look like this:\n\n#`(begin\n    (struct data-constructor.name\n      ([#,(generate-temporary) : data-constructor.param] ...)\n    ...))\nThe #, lets us \"escape\" from the template to execute (generate-temporary) and interpolate its result into the syntax. Unfortunately, this doesn't work. We do generate a random field name, but the ellipsis will re-use the same generated value when it repeats the fields, rendering our whole effort pointless. We need to generate the field names once per type.\n\nMore leveraging syntax classes\nAs it turns out, this is also easy to do with syntax classes. We can add an extra attribute to our type syntax class to generate a random identifier with each one. Again, we can use #:attr to do that automatically. Our new definition for type will look like this:\n\n(begin-for-syntax\n  (define-syntax-class type\n    (pattern name:id\n             #:attr [param 1] '()\n             #:attr [field-id 1] '())\n    (pattern (name:id param ...+)\n             #:attr [field-id 1] (generate-temporaries #'(param ...)))))\nHere we're using generate-temporaries instead of generate-temporary, which will conveniently generate a new identifier for each of the elements in the list we provide it. This way, we'll get a fresh identifier for each param.\n\nWe can now fix our macro to use this field-id attribute instead of the static field name:\n\n#'(begin\n    (struct data-constructor.name\n      ([data-constructor.field-id : data-constructor.param] ...))\n    ...)\nCreating the supertype\nWe're almost done—now we just need to implement our overall type, the one defined by type-name. This is implemented as a trivial type alias, but we need to ensure that polymorphic types are properly handled. For example, a non-polymorphic type would need to be handled like this:\n\n(define-type Tree (U Empty Leaf Node))\nHowever, a polymorphic type alias would need to include the type parameters in each subtype, like this:\n\n(define-type (Tree a) (U (Empty a) (Leaf a) (Node a)))\nHow can we do this? Well, so far, we've been very declarative by using syntax patterns, templates, and classes. However, this is a more pernicious problem to solve with our declarative tools. Fortunately, it's very easy to fall back to using procedural macros.\n\nTo build each properly-instantiated type, we'll use a combination of define/with-syntax and Racket's list comprehensions, for/list. The define/with-syntax form binds values to pattern identifiers, which can be used within syntax patterns just like the ones bound by syntax-parser. This will allow us to break up our result into multiple steps. Technically, define/with-syntax is not strictly necessary—we could just use #` and #,—but it's cleaner to work with.\n\nWe'll start by defining a set of instantiated data constructor types, one per data-constructor:\n\n(define/with-syntax [data-type ...]\n  (for/list ([name (in-syntax #'(data-constructor.name ...))])\n    ))\nNow we can fill in the body with any code we'd like, so long as each body returns a syntax object. We can use some trivial branching logic to determine which form we need:\n\n(define/with-syntax [data-type ...]\n  (for/list ([name (in-syntax #'(data-constructor.name ...))])\n    (if (stx-null? #'(type-name.param ...))\n        name\n        #`(#,name type-name.param ...))))\nNow with our definition for data-type, we can implement our type alias for the supertype extremely easily:\n\n#'(define-type type-name (U data-type ...))\nPutting it all together\nThere's just one more thing to do before we can call this macro finished: we need to ensure that all the type parameters defined by type-name are in scope for each data constructor's structure definition. We can do this by making use of type-name.param within each produced struct definition, resulting in this:\n\n#'(begin\n    (struct data-constructor.name (type-name.param ...)\n      ([data-constructor.field-id : data-constructor.param] ...))\n    ...)\nAnd we're done! The final macro, now completed, looks like this:\n\n(begin-for-syntax\n  (define-syntax-class type\n    (pattern name:id\n             #:attr [param 1] '()\n             #:attr [field-id 1] '())\n    (pattern (name:id param ...+)\n             #:attr [field-id 1] (generate-temporaries #'(param ...)))))\n\n(define-syntax define-datatype\n  (syntax-parser\n    [(_ type-name:type data-constructor:type ...)\n\n     (define/with-syntax [data-type ...]\n       (for/list ([name (in-syntax #'(data-constructor.name ...))])\n         (if (stx-null? #'(type-name.param ...))\n             name\n             #`(#,name type-name.param ...))))\n\n     #'(begin\n         (struct (type-name.param ...) data-constructor.name\n           ([data-constructor.field-id : data-constructor.param] ...)) ...\n         (define-type type-name (U data-type ...)))]))\nIt's a little bit dense, certainly, but it is not as complicated or scary as it might seem. It's a simple, mostly declarative, powerful way to transform a DSL into ordinary Typed Racket syntax, and now all we have to do is put it to use.\n\nUsing our ADTs\nWith the macro built, we can now actually use our ADTs using the syntax we described! The following is now valid code:\n\n(define-datatype (Tree a)\n  Empty\n  (Leaf a)\n  (Node (Tree a) (Tree a)))\n\n> (Node (Leaf 3) (Node (Empty) (Leaf 7)))\n- : (Node Positive-Byte)\n(Node (Leaf 3) (Node (Empty) (Leaf 7)))\nWe can use this to define common data types, such as Haskell's Maybe:\n\n(define-datatype (Maybe a)\n  (Just a)\n  Nothing)\n\n(: maybe-default (All [a] (Maybe a) a -> a))\n(define (maybe-default m v)\n  (match m\n    [(Just a)  a]\n    [(Nothing) v]))\n\n(: maybe-then (All [a] (Maybe a) (a -> (Maybe a)) -> (Maybe a)))\n(define (maybe-then m f)\n  (match m\n    [(Just a)  (f a)]\n    [(Nothing) (Nothing)]))\nAnd of course, we can also use it to define ADTs that use concrete types rather that type parameters, if we so desire. This implements a small mathematical language, along with a trivial interpreter:\n\n(define-datatype Expr\n  (Value Number)\n  (Add Expr Expr)\n  (Subtract Expr Expr)\n  (Multiply Expr Expr)\n  (Divide Expr Expr))\n\n(: evaluate (Expr -> Number))\n(define (evaluate e)\n  (match e\n    [(Value x)      x                            ]\n    [(Add a b)      (+ (evaluate a) (evaluate b))]\n    [(Subtract a b) (- (evaluate a) (evaluate b))]\n    [(Multiply a b) (* (evaluate a) (evaluate b))]\n    [(Divide a b)   (/ (evaluate a) (evaluate b))]))\n\n> (evaluate (Add (Value 1)\n                 (Multiply (Divide (Value 1) (Value 2))\n                           (Value 7))))\n4 1/2\nThere's all the power of ADTs, right in Racket, all implemented in 22 lines of code. If you'd like to see all the code together in a runnable form, I’ve put together a gist here.\n\nConclusions and credit\nThis isn't the simplest macro to create, nor is it the most complex. The code examples might not even make much sense until you try it out yourself. Macros, like any difficult concept, are not always easy to pick up, but they certainly are powerful. The ability to extend the language in such a way, in the matter of minutes, is unparalleled in languages other than Lisp.\n\nThis is, of course, a blessing and a curse. Lisps reject some of the syntactic landmarks that often aid in readability for the power to abstract programs into their bare components. In the end, is this uniform conciseness more or less readable? That's an incredibly subjective question, one that has prompted powerfully impassioned discussions, and I will not attempt to argue one way or the other here.\n\nThat said, I think it's pretty cool.\n\nFinally, I must give credit where credit is due. Thanks to Andrew M. Kent for the creation of the datatype package, which served as the inspiration for this blog post. Many thanks to Sam Tobin-Hochstadt for his work creating Typed Racket, as well as helping me dramatically simplify the implementation used in this blog post. Also thanks to Ryan Culpepper and Matthias Felleisen for their work on creating syntax/parse, which is truly a marvelous tool for exploring the world of macros, and, of course, a big thanks to Matthew Flatt for his implementation of hygiene in Racket, as well as much of the rest of Racket itself. Not to mention the entire legacy of those who formulated the foundations of the Scheme macro system and created the framework for all of this to be possible so many decades later.\n\nTruly, working in Racket feels like standing on the shoulders of giants. If you're intrigued, give it a shot. It's a fun feeling.","isoDate":"2015-12-21T00:00:00.000Z","timestamp":"12/20/2015"},{"title":"Functionally updating record types in Elm","pubDate":"2015-11-06T00:00:00.000Z","author":"Alexis King","content":"<article><p><a href=\"http://elm-lang.org\">Elm</a> is a wonderful language for building web apps, and I love so much of its approach to language design. Elm does so many things <em>right</em> straight out of the box, and that's a real breath of fresh air in the intersection of functional programming and web development. Still, it gets one thing wrong, and unfortunately, that one thing is incredibly important. Elm took the \"functions\" out of \"functional record types\".\n</p><p>Almost any software program, at its core, is all about data. Maybe it's about computing data, maybe it's about manipulating data, or maybe it's about displaying data, but at the end of the day, some sort of data model is going to be needed. The functional model is a breathtakingly elegant system for handling data and shuttling it around throughout a program, and <a href=\"https://en.wikipedia.org/wiki/Functional_reactive_programming\">functional reactive programming</a>, which Elm uses to model event-like interactions, makes this model work even better. The really important thing, though, is what tools Elm actually gives you to model your data.\n</p><h2><a name=\"a-brief-primer-on-elm-records\"></a>A brief primer on Elm records</h2><p>Elm supports all the core datatypes one would expect—numbers, strings, booleans, optionals, etc.—and it allows users to define their own types with ADTs. However, Elm also provides another datatype, which it calls \"records\". Records are similar to objects in JavaScript: they're effectively key-value mappings. They're cool data structures, and they work well. Here's an example of creating a <code>Point</code> datatype in Elm:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">alias</span> <span class=\"kt\">Point</span> <span class=\"nf\">=</span>\n  <span class=\"p\">{</span> <span class=\"nv\">x</span> <span class=\"nf\">:</span> <span class=\"kt\">Float</span><span class=\"p\">,</span> <span class=\"nv\">y</span> <span class=\"nf\">:</span> <span class=\"kt\">Float</span> <span class=\"p\">}</span></code></pre><p>Notice that <code>Point</code> is declared as a type <em>alias</em>, not as a separate type like an ADT. This is because record types are truly encoded in the type system as values with named fields, not as disparate types. This allows for some fun tricks, but that's outside the scope of this blog post.\n</p><h2><a name=\"the-good\"></a>The good</h2><p>What I'd like to discuss is what it looks like to <em>manipulate</em> these data structures. Constructing them is completely painless, and reading from them is super simple. This is where the record system gets everything very <em>right</em>.\n</p><pre><code class=\"pygments\"><span class=\"nv\">origin</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">origin</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">x</span> <span class=\"nf\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nv\">y</span> <span class=\"nf\">=</span> <span class=\"mi\">0</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">distanceBetween</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span>\n<span class=\"nv\">distanceBetween</span> <span class=\"nv\">a</span> <span class=\"nv\">b</span> <span class=\"nf\">=</span>\n  <span class=\"kr\">let</span> <span class=\"nv\">dx</span> <span class=\"nf\">=</span> <span class=\"nv\">a</span><span class=\"nf\">.</span><span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"nv\">b</span><span class=\"nf\">.</span><span class=\"nv\">x</span>\n      <span class=\"nv\">dy</span> <span class=\"nf\">=</span> <span class=\"nv\">a</span><span class=\"nf\">.</span><span class=\"nv\">y</span> <span class=\"nf\">-</span> <span class=\"nv\">b</span><span class=\"nf\">.</span><span class=\"nv\">y</span>\n  <span class=\"kr\">in</span> <span class=\"nv\">sqrt</span> <span class=\"p\">(</span><span class=\"nv\">dx</span><span class=\"nf\">*</span><span class=\"nv\">dx</span> <span class=\"nf\">+</span> <span class=\"nv\">dy</span><span class=\"nf\">*</span><span class=\"nv\">dy</span><span class=\"p\">)</span></code></pre><p>The syntax is clean and simple. Most importantly, however, the record system is functional (in the \"functional programming\" sense). In a functional system, it's useful to express concepts in terms of function composition, and this is very easy to do in Elm. Creating a function to access a field would normally be clunky if you always needed to do <code>record.field</code> to access the value. Fortunately, Elm provides some sugar:\n</p><pre><code class=\"pygments\"><span class=\"c1\">-- These two expressions are equivalent:</span>\n<span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">record</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">record</span><span class=\"nf\">.</span><span class=\"nv\">field</span><span class=\"p\">)</span>\n<span class=\"nf\">.</span><span class=\"nv\">field</span></code></pre><p>Using the <code>.field</code> shorthand allows writing some other functions in terms of composition, as most functional programmers would desire:\n</p><pre><code class=\"pygments\"><span class=\"nv\">doubledX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span>\n<span class=\"nv\">doubledX</span> <span class=\"nf\">=</span> <span class=\"p\">(</span><span class=\"nf\">(*)</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"nf\">&lt;&lt;</span> <span class=\"nf\">.</span><span class=\"nv\">x</span></code></pre><p>This satisfies me.\n</p><h2><a name=\"the-bad\"></a>The bad</h2><p>So if everything in Elm is so great, what am I complaining about? Well, while the syntax to access fields is convenient, the syntax to <em>functionally set</em> fields is questionably clunky. Consider a function that accepts a point and returns a new point with its <code>x</code> field set to <code>0</code>:\n</p><pre><code class=\"pygments\"><span class=\"nv\">zeroedX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">zeroedX</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">x</span> <span class=\"nf\">&lt;-</span> <span class=\"mi\">0</span> <span class=\"p\">}</span></code></pre><p>This doesn't look too bad, does it? It's clear and concise. To me, though, there's something deeply wrong here... this function has a lot of redundancy! It seems to me like we should be able to write this function more clearly in a point-free style. The <code>.field</code> shorthand \"functionalizes\" the record getter syntax, so there must be a function version of the update syntax, right? Maybe it would look something like this:\n</p><pre><code class=\"pygments\"><span class=\"nv\">zeroedX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">zeroedX</span> <span class=\"nf\">=</span> <span class=\"err\">!</span><span class=\"nv\">x</span> <span class=\"mi\">0</span></code></pre><p>But alas, there is no such syntax.\n</p><p>Now you may ask... why does it matter? This seems trivial, and in fact, the explicit updater syntax may actually be more readable by virtue of how explicit it is. You'd be right, because so far, these examples have been horribly contrived. But let's consider a slightly more useful example: <em>functionally updating</em> a record.\n</p><p>What's the difference? Well, say I wanted to take a point and increment its <code>x</code> field by one. Well, I can easily write a function for that:\n</p><pre><code class=\"pygments\"><span class=\"nv\">incrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">incrementX</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">x</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">point</span><span class=\"nf\">.</span><span class=\"nv\">x</span> <span class=\"nf\">+</span> <span class=\"mi\">1</span> <span class=\"p\">}</span></code></pre><p>Not terrible, though a <em>little</em> verbose. Still, what if we want to also add a function that <em>decrements</em> <code>x</code>?\n</p><pre><code class=\"pygments\"><span class=\"nv\">decrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">decrementX</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">x</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">point</span><span class=\"nf\">.</span><span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"mi\">1</span> <span class=\"p\">}</span></code></pre><p>Oh, gosh. That's basically the exact same definition but with the operation flipped. Plus we probably want these operations for <code>y</code>, too. Fortunately, there's an easy solution: just pass a function in to <em>transform</em> the value! We can define an <code>updateX</code> function that allows us to do that easily, then we can define our derived operations in terms of that:\n</p><pre><code class=\"pygments\"><span class=\"nv\">updateX</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Float</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">updateX</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">x</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span><span class=\"nf\">.</span><span class=\"nv\">x</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">incrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">incrementX</span> <span class=\"nf\">=</span> <span class=\"nv\">updateX</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"nv\">decrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">decrementX</span> <span class=\"nf\">=</span> <span class=\"nv\">updateX</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>Not only is that much cleaner, but we can now use it to implement all sorts of other operations that allow us to add, subtract, multiply, or divide the <code>x</code> field. Now we just need to generalize our solution to work with the <code>x</code> <em>and</em> <code>y</code> fields!\n</p><p>Oh, wait. <strong>We can't.</strong>\n</p><h2><a name=\"the-ugly\"></a>The ugly</h2><p>This is where everything breaks down completely. Elm does not offer enough abstraction to reduce this level of crazy duplication:\n</p><pre><code class=\"pygments\"><span class=\"nv\">updateX</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Float</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">updateX</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">x</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span><span class=\"nf\">.</span><span class=\"nv\">x</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">incrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">incrementX</span> <span class=\"nf\">=</span> <span class=\"nv\">updateX</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"nv\">decrementX</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">decrementX</span> <span class=\"nf\">=</span> <span class=\"nv\">updateX</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"nv\">updateY</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Float</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">updateY</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">point</span> <span class=\"nf\">|</span> <span class=\"nv\">y</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">point</span><span class=\"nf\">.</span><span class=\"nv\">y</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">incrementY</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">incrementY</span> <span class=\"nf\">=</span> <span class=\"nv\">updateY</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"nv\">decrementY</span> <span class=\"nf\">:</span> <span class=\"kt\">Point</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Point</span>\n<span class=\"nv\">decrementY</span> <span class=\"nf\">=</span> <span class=\"nv\">updateY</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>We sure can give it a shot, though. At the very least, we <em>can</em> implement the increment and decrement functions in a more general way by passing in an updater function:\n</p><pre><code class=\"pygments\"><span class=\"nv\">increment</span> <span class=\"nf\">:</span> <span class=\"p\">((</span><span class=\"kt\">Float</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Float</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span>\n<span class=\"nv\">increment</span> <span class=\"nv\">update</span> <span class=\"nf\">=</span> <span class=\"nv\">update</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>Now, with <code>updateX</code> and <code>updateY</code>, we can increment either field very clearly and expressively. If we shorten the names to <code>uX</code> and <code>uY</code>, then the resulting code is actually very readable:\n</p><pre><code class=\"pygments\"><span class=\"nv\">pointAbove</span> <span class=\"nf\">=</span> <span class=\"nv\">uY</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">+</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nv\">pointBelow</span> <span class=\"nf\">=</span> <span class=\"nv\">uY</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span></code></pre><p>It's almost like English now: \"update Y using this transformation\". This is actually pretty satisfactory. The trouble arises when you have a struct with many fields:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kr\">alias</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">=</span>\n  <span class=\"p\">{</span> <span class=\"nv\">health</span> <span class=\"nf\">:</span> <span class=\"kt\">Integer</span>\n  <span class=\"p\">,</span> <span class=\"nv\">strength</span> <span class=\"nf\">:</span> <span class=\"kt\">Integer</span>\n  <span class=\"p\">,</span> <span class=\"nv\">charisma</span> <span class=\"nf\">:</span> <span class=\"kt\">Integer</span>\n  <span class=\"p\">,</span> <span class=\"nv\">intellect</span> <span class=\"nf\">:</span> <span class=\"kt\">Integer</span>\n  <span class=\"c1\">-- etc.</span>\n  <span class=\"p\">}</span></code></pre><p>It might be very convenient to have generic functional updaters in this case. One could imagine a game that has <code>Potion</code> items:\n</p><pre><code class=\"pygments\"><span class=\"kr\">type</span> <span class=\"kt\">Potion</span> <span class=\"nf\">=</span> <span class=\"kt\">Potion</span> <span class=\"kt\">String</span> <span class=\"p\">(</span><span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span><span class=\"p\">)</span></code></pre><p>And then some different kinds of potions:\n</p><pre><code class=\"pygments\"><span class=\"nv\">potions</span> <span class=\"nf\">=</span>\n  <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"kt\">Potion</span> <span class=\"s\">\"Health Potion\"</span> <span class=\"p\">(</span><span class=\"nv\">uHealth</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">1</span><span class=\"p\">))),</span>\n  <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">Potion</span> <span class=\"s\">\"Greater Intellect Potion\"</span> <span class=\"p\">(</span><span class=\"nv\">uIntellect</span> <span class=\"p\">(</span><span class=\"nf\">(+)</span> <span class=\"mi\">3</span><span class=\"p\">)))</span>\n  <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"kt\">Potion</span> <span class=\"s\">\"Potion of Weakness\"</span> <span class=\"p\">(</span><span class=\"nv\">uStrength</span> <span class=\"p\">(</span><span class=\"nf\">\\</span><span class=\"nv\">x</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">x</span> <span class=\"nf\">//</span> <span class=\"mi\">5</span><span class=\"p\">)))</span>\n  <span class=\"p\">]</span></code></pre><p>This is a really elegant way to think about items that can affect a player's stats! Unfortunately, it also means you have to define updater functions for <em>every single field in the record</em>. This can get tedious rather quickly:\n</p><pre><code class=\"pygments\"><span class=\"nv\">uHealth</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Integer</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">uHealth</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">stats</span> <span class=\"nf\">|</span> <span class=\"nv\">health</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span><span class=\"nf\">.</span><span class=\"nv\">health</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">uStrength</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Integer</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">uStrength</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">stats</span> <span class=\"nf\">|</span> <span class=\"nv\">strength</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span><span class=\"nf\">.</span><span class=\"nv\">strength</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">uCharisma</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Integer</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">uCharisma</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">stats</span> <span class=\"nf\">|</span> <span class=\"nv\">charisma</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">f</span> <span class=\"nv\">stats</span><span class=\"nf\">.</span><span class=\"nv\">charisma</span> <span class=\"p\">}</span>\n\n<span class=\"c1\">-- etc.</span></code></pre><p>This is pretty icky. Could there be a better way?\n</p><h2><a name=\"trying-to-create-a-more-general-abstraction\"></a>Trying to create a more general abstraction</h2><p>Interestingly, this pattern doesn't <em>need</em> to be this bad. There are better ways to do this. Let's revisit our updater functions.\n</p><p>Really, <code>update</code> can be defined in terms of two other primitive operations: a read and a (functional) write. What would it look like if we implemented it that way instead of requiring special updater functions to be defined? Well, it would look like this:\n</p><pre><code class=\"pygments\"><span class=\"nv\">update</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"nv\">a</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">b</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"p\">(</span><span class=\"nv\">b</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"p\">(</span><span class=\"nv\">b</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">b</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span> <span class=\"nf\">-&gt;</span> <span class=\"nv\">a</span>\n<span class=\"nv\">update</span> <span class=\"nv\">get</span> <span class=\"nv\">set</span> <span class=\"nv\">f</span> <span class=\"nv\">x</span> <span class=\"nf\">=</span> <span class=\"nv\">set</span> <span class=\"p\">(</span><span class=\"nv\">f</span> <span class=\"p\">(</span><span class=\"nv\">get</span> <span class=\"nv\">x</span><span class=\"p\">))</span> <span class=\"nv\">x</span></code></pre><p>The type definition is a little long, but it's really pretty simple. We just supply a getter and a setter, then a function to do the transformation, and finally a record to actually transform. Of course, as you can see from the type, this function isn't actually specific to records: it can be used with any value for which a getter and setter can be provided.\n</p><p>The trouble here is that writing field setters isn't any easier in Elm than writing field updaters. They still look pretty verbose:\n</p><pre><code class=\"pygments\"><span class=\"nv\">sHealth</span> <span class=\"nf\">:</span> <span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">sHealth</span> <span class=\"nv\">x</span> <span class=\"nv\">stats</span> <span class=\"nf\">=</span> <span class=\"p\">{</span> <span class=\"nv\">stats</span> <span class=\"nf\">|</span> <span class=\"nv\">health</span> <span class=\"nf\">&lt;-</span> <span class=\"nv\">x</span> <span class=\"p\">}</span>\n\n<span class=\"nv\">uHealth</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Integer</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">uHealth</span> <span class=\"nf\">=</span> <span class=\"nv\">update</span> <span class=\"nf\">.</span><span class=\"nv\">health</span> <span class=\"nv\">sHealth</span></code></pre><p>So, at the end of it all, this isn't really a better abstraction. Still remember my fantasy <code>!field</code> setter shorthand half a blog post ago? Now perhaps it makes a little more sense. <em>If</em> such a syntax existed, then defining the updater would be incredibly simple:\n</p><pre><code class=\"pygments\"><span class=\"nv\">uHealth</span> <span class=\"nf\">:</span> <span class=\"p\">(</span><span class=\"kt\">Integer</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">Integer</span><span class=\"p\">)</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span> <span class=\"nf\">-&gt;</span> <span class=\"kt\">PlayerStats</span>\n<span class=\"nv\">uHealth</span> <span class=\"nf\">=</span> <span class=\"nv\">update</span> <span class=\"nf\">.</span><span class=\"nv\">health</span> <span class=\"err\">!</span><span class=\"nv\">health</span></code></pre><p>Still, no syntax, no easy updaters, and by extension, no easy, declarative description of behavior without quite a bit of boilerplate.\n</p><h2><a name=\"conclusions-and-related-work\"></a>Conclusions and related work</h2><p>Elm is a very promising language, and it seems to be in fairly rapid development. So far, its author, <a href=\"https://twitter.com/czaplic\">Evan Czaplicki</a>, has taken a very cautious approach to implementing language features, especially potentially redundant ones. This caution is why things like operator slicing, \"where\" clauses, and special updater syntax have not yet made it into the language. Maybe at some point these will be deemed important enough to include, but for the time being, they've been excluded.\n</p><p>I obviously think that having this sort of thing is incredibly important to being able to write expressive code without a huge amount of overhead. However, I also do <em>not</em> want to give the impression that I think adding special setter syntax is the only way to do it.\n</p><p>Seasoned functional programmers will surely have noticed that many of these concepts sound a lot like lenses, and Elm actually already has a lens-like library authored by Evan himself, called <a href=\"https://github.com/evancz/focus\">Focus</a>. This, however, does not actually solve the problem: it requires manual description of setters just like the purely function based approach does. Really, lenses are just the logical next step in the line of abstraction I've already laid out above.\n</p><p>Interestingly, PureScript and Elm, the two Haskell-likes-on-the-frontend that I've paid attention to (though PureScript is much closer to Haskell than Elm), both have this very same problem. Haskell itself solves it with macros via Template Haskell. My favorite language, Racket, solves it with its own macro system. Is there another way to do these things that doesn't involve introducing a heavyweight macro system? Definitely. But I think this is a <em>necessary feature</em>, not a \"nice to have\", so if a macro system is out of the picture, then a simpler, less flexible solution is the obvious logical alternative.\n</p><p>I really like Elm, and most of my experiences with it have been more than enough to convince me that it is a fantastic language for the job. Unfortunately, the issue of functional record updaters has been quite the frustrating obstacle in my otherwise frictionless ride. I will continue to happily use Elm over other, far less accommodating tools, but I hope that issues like these will be smoothed out as the language and its ecosystem matures.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Elm is a wonderful language for building web apps, and I love so much of its approach to language design. Elm does so many things right straight out of the box, and that's a real breath of fresh air in the intersection of functional programming and web development. Still, it gets one thing wrong, and unfortunately, that one thing is incredibly important. Elm took the \"functions\" out of \"functional record types\".\n\nAlmost any software program, at its core, is all about data. Maybe it's about computing data, maybe it's about manipulating data, or maybe it's about displaying data, but at the end of the day, some sort of data model is going to be needed. The functional model is a breathtakingly elegant system for handling data and shuttling it around throughout a program, and functional reactive programming, which Elm uses to model event-like interactions, makes this model work even better. The really important thing, though, is what tools Elm actually gives you to model your data.\n\nA brief primer on Elm records\nElm supports all the core datatypes one would expect—numbers, strings, booleans, optionals, etc.—and it allows users to define their own types with ADTs. However, Elm also provides another datatype, which it calls \"records\". Records are similar to objects in JavaScript: they're effectively key-value mappings. They're cool data structures, and they work well. Here's an example of creating a Point datatype in Elm:\n\ntype alias Point =\n  { x : Float, y : Float }\nNotice that Point is declared as a type alias, not as a separate type like an ADT. This is because record types are truly encoded in the type system as values with named fields, not as disparate types. This allows for some fun tricks, but that's outside the scope of this blog post.\n\nThe good\nWhat I'd like to discuss is what it looks like to manipulate these data structures. Constructing them is completely painless, and reading from them is super simple. This is where the record system gets everything very right.\n\norigin : Point\norigin = { x = 0, y = 0 }\n\ndistanceBetween : Point -> Point -> Float\ndistanceBetween a b =\n  let dx = a.x - b.x\n      dy = a.y - b.y\n  in sqrt (dx*dx + dy*dy)\nThe syntax is clean and simple. Most importantly, however, the record system is functional (in the \"functional programming\" sense). In a functional system, it's useful to express concepts in terms of function composition, and this is very easy to do in Elm. Creating a function to access a field would normally be clunky if you always needed to do record.field to access the value. Fortunately, Elm provides some sugar:\n\n-- These two expressions are equivalent:\n(\\record -> record.field)\n.field\nUsing the .field shorthand allows writing some other functions in terms of composition, as most functional programmers would desire:\n\ndoubledX : Point -> Float\ndoubledX = ((*) 2) << .x\nThis satisfies me.\n\nThe bad\nSo if everything in Elm is so great, what am I complaining about? Well, while the syntax to access fields is convenient, the syntax to functionally set fields is questionably clunky. Consider a function that accepts a point and returns a new point with its x field set to 0:\n\nzeroedX : Point -> Point\nzeroedX point = { point | x <- 0 }\nThis doesn't look too bad, does it? It's clear and concise. To me, though, there's something deeply wrong here... this function has a lot of redundancy! It seems to me like we should be able to write this function more clearly in a point-free style. The .field shorthand \"functionalizes\" the record getter syntax, so there must be a function version of the update syntax, right? Maybe it would look something like this:\n\nzeroedX : Point -> Point\nzeroedX = !x 0\nBut alas, there is no such syntax.\n\nNow you may ask... why does it matter? This seems trivial, and in fact, the explicit updater syntax may actually be more readable by virtue of how explicit it is. You'd be right, because so far, these examples have been horribly contrived. But let's consider a slightly more useful example: functionally updating a record.\n\nWhat's the difference? Well, say I wanted to take a point and increment its x field by one. Well, I can easily write a function for that:\n\nincrementX : Point -> Point\nincrementX point = { point | x <- point.x + 1 }\nNot terrible, though a little verbose. Still, what if we want to also add a function that decrements x?\n\ndecrementX : Point -> Point\ndecrementX point = { point | x <- point.x - 1 }\nOh, gosh. That's basically the exact same definition but with the operation flipped. Plus we probably want these operations for y, too. Fortunately, there's an easy solution: just pass a function in to transform the value! We can define an updateX function that allows us to do that easily, then we can define our derived operations in terms of that:\n\nupdateX : (Float -> Float) -> Point -> Point\nupdateX f point = { point | x <- f point.x }\n\nincrementX : Point -> Point\nincrementX = updateX ((+) 1)\n\ndecrementX : Point -> Point\ndecrementX = updateX (\\x -> x - 1)\nNot only is that much cleaner, but we can now use it to implement all sorts of other operations that allow us to add, subtract, multiply, or divide the x field. Now we just need to generalize our solution to work with the x and y fields!\n\nOh, wait. We can't.\n\nThe ugly\nThis is where everything breaks down completely. Elm does not offer enough abstraction to reduce this level of crazy duplication:\n\nupdateX : (Float -> Float) -> Point -> Point\nupdateX f point = { point | x <- f point.x }\n\nincrementX : Point -> Point\nincrementX = updateX ((+) 1)\n\ndecrementX : Point -> Point\ndecrementX = updateX (\\x -> x - 1)\n\nupdateY : (Float -> Float) -> Point -> Point\nupdateY f point = { point | y <- f point.y }\n\nincrementY : Point -> Point\nincrementY = updateY ((+) 1)\n\ndecrementY : Point -> Point\ndecrementY = updateY (\\x -> x - 1)\nWe sure can give it a shot, though. At the very least, we can implement the increment and decrement functions in a more general way by passing in an updater function:\n\nincrement : ((Float -> Float) -> a -> a) -> a -> a\nincrement update = update ((+) 1)\nNow, with updateX and updateY, we can increment either field very clearly and expressively. If we shorten the names to uX and uY, then the resulting code is actually very readable:\n\npointAbove = uY (\\x -> x + 1)\npointBelow = uY (\\x -> x - 1)\nIt's almost like English now: \"update Y using this transformation\". This is actually pretty satisfactory. The trouble arises when you have a struct with many fields:\n\ntype alias PlayerStats =\n  { health : Integer\n  , strength : Integer\n  , charisma : Integer\n  , intellect : Integer\n  -- etc.\n  }\nIt might be very convenient to have generic functional updaters in this case. One could imagine a game that has Potion items:\n\ntype Potion = Potion String (PlayerStats -> PlayerStats)\nAnd then some different kinds of potions:\n\npotions =\n  [ (Potion \"Health Potion\" (uHealth ((+) 1))),\n  , (Potion \"Greater Intellect Potion\" (uIntellect ((+) 3)))\n  , (Potion \"Potion of Weakness\" (uStrength (\\x -> x // 5)))\n  ]\nThis is a really elegant way to think about items that can affect a player's stats! Unfortunately, it also means you have to define updater functions for every single field in the record. This can get tedious rather quickly:\n\nuHealth : (Integer -> Integer) -> PlayerStats -> PlayerStats\nuHealth f stats = { stats | health <- f stats.health }\n\nuStrength : (Integer -> Integer) -> PlayerStats -> PlayerStats\nuStrength f stats = { stats | strength <- f stats.strength }\n\nuCharisma : (Integer -> Integer) -> PlayerStats -> PlayerStats\nuCharisma f stats = { stats | charisma <- f stats.charisma }\n\n-- etc.\nThis is pretty icky. Could there be a better way?\n\nTrying to create a more general abstraction\nInterestingly, this pattern doesn't need to be this bad. There are better ways to do this. Let's revisit our updater functions.\n\nReally, update can be defined in terms of two other primitive operations: a read and a (functional) write. What would it look like if we implemented it that way instead of requiring special updater functions to be defined? Well, it would look like this:\n\nupdate : (a -> b) -> (b -> a -> a) -> (b -> b) -> a -> a\nupdate get set f x = set (f (get x)) x\nThe type definition is a little long, but it's really pretty simple. We just supply a getter and a setter, then a function to do the transformation, and finally a record to actually transform. Of course, as you can see from the type, this function isn't actually specific to records: it can be used with any value for which a getter and setter can be provided.\n\nThe trouble here is that writing field setters isn't any easier in Elm than writing field updaters. They still look pretty verbose:\n\nsHealth : Integer -> PlayerStats -> PlayerStats\nsHealth x stats = { stats | health <- x }\n\nuHealth : (Integer -> Integer) -> PlayerStats -> PlayerStats\nuHealth = update .health sHealth\nSo, at the end of it all, this isn't really a better abstraction. Still remember my fantasy !field setter shorthand half a blog post ago? Now perhaps it makes a little more sense. If such a syntax existed, then defining the updater would be incredibly simple:\n\nuHealth : (Integer -> Integer) -> PlayerStats -> PlayerStats\nuHealth = update .health !health\nStill, no syntax, no easy updaters, and by extension, no easy, declarative description of behavior without quite a bit of boilerplate.\n\nConclusions and related work\nElm is a very promising language, and it seems to be in fairly rapid development. So far, its author, Evan Czaplicki, has taken a very cautious approach to implementing language features, especially potentially redundant ones. This caution is why things like operator slicing, \"where\" clauses, and special updater syntax have not yet made it into the language. Maybe at some point these will be deemed important enough to include, but for the time being, they've been excluded.\n\nI obviously think that having this sort of thing is incredibly important to being able to write expressive code without a huge amount of overhead. However, I also do not want to give the impression that I think adding special setter syntax is the only way to do it.\n\nSeasoned functional programmers will surely have noticed that many of these concepts sound a lot like lenses, and Elm actually already has a lens-like library authored by Evan himself, called Focus. This, however, does not actually solve the problem: it requires manual description of setters just like the purely function based approach does. Really, lenses are just the logical next step in the line of abstraction I've already laid out above.\n\nInterestingly, PureScript and Elm, the two Haskell-likes-on-the-frontend that I've paid attention to (though PureScript is much closer to Haskell than Elm), both have this very same problem. Haskell itself solves it with macros via Template Haskell. My favorite language, Racket, solves it with its own macro system. Is there another way to do these things that doesn't involve introducing a heavyweight macro system? Definitely. But I think this is a necessary feature, not a \"nice to have\", so if a macro system is out of the picture, then a simpler, less flexible solution is the obvious logical alternative.\n\nI really like Elm, and most of my experiences with it have been more than enough to convince me that it is a fantastic language for the job. Unfortunately, the issue of functional record updaters has been quite the frustrating obstacle in my otherwise frictionless ride. I will continue to happily use Elm over other, far less accommodating tools, but I hope that issues like these will be smoothed out as the language and its ecosystem matures.","isoDate":"2015-11-06T00:00:00.000Z","timestamp":"11/5/2015"},{"title":"Canonical factories for testing with factory_girl_api","pubDate":"2015-09-23T00:00:00.000Z","author":"Alexis King","content":"<article><p>Modern web applications are often built as <em>single-page apps</em>, which are great for keeping concerns separated, but problematic when tested. Logic needs to be duplicated in front- and back-end test suites, and if the two apps diverge, the tests won't catch the failure. I haven't found a very good solution to this problem aside from brittle, end-to-end integration tests.\n</p><p>To attempt to address a fraction of this problem, I built <a href=\"https://github.com/lexi-lambda/factory_girl_api\">factory_girl_api</a>, a way to share context setup between both sides of the application.\n</p><h2><a name=\"a-brief-overview-of-factory-girl\"></a>A brief overview of factory_girl</h2><p>In the land of Ruby and Rails, <a href=\"https://github.com/thoughtbot/factory_girl\">factory_girl</a> is a convenient gem for managing factories for models. Out of the box, it integrates with Rails' default ORM, ActiveRecord, and provides declarative syntax for describing what attributes factories should initialize. For example, a factory declaration used to create a widget might look like this:\n</p><pre><code class=\"pygments\"><span class=\"no\">FactoryGirl</span><span class=\"o\">.</span><span class=\"n\">define</span> <span class=\"k\">do</span>\n  <span class=\"n\">factory</span> <span class=\"ss\">:widget</span> <span class=\"k\">do</span>\n    <span class=\"n\">sequence</span><span class=\"p\">(</span><span class=\"ss\">:name</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"o\">|</span><span class=\"nb\">id</span><span class=\"o\">|</span> <span class=\"s1\">&#39;Widget #&#39;</span> <span class=\"o\">+</span> <span class=\"nb\">id</span> <span class=\"p\">}</span>\n    <span class=\"n\">price</span> <span class=\"mi\">10</span>\n\n    <span class=\"n\">trait</span> <span class=\"ss\">:expensive</span> <span class=\"k\">do</span>\n      <span class=\"n\">price</span> <span class=\"mi\">1000</span>\n    <span class=\"k\">end</span>\n  <span class=\"k\">end</span>\n<span class=\"k\">end</span></code></pre><p>This makes it easy to create new instances of <code>Widget</code> and use them for unit tests. For example, this would create and persist a widget with a unique name and a price of 10 units:\n</p><pre><code class=\"pygments\"><span class=\"n\">widget</span> <span class=\"o\">=</span> <span class=\"no\">FactoryGirl</span><span class=\"o\">.</span><span class=\"n\">create</span> <span class=\"ss\">:widget</span></code></pre><p>We can also create more expensive widgets by using the <code>:expensive</code> trait.\n</p><pre><code class=\"pygments\"><span class=\"n\">expensive_widget</span> <span class=\"o\">=</span> <span class=\"no\">FactoryGirl</span><span class=\"o\">.</span><span class=\"n\">create</span> <span class=\"ss\">:widget</span><span class=\"p\">,</span> <span class=\"ss\">:expensive</span></code></pre><p>Any number of traits can be specified at once. Additionally, it is possible to override individual attributes manually.\n</p><pre><code class=\"pygments\"><span class=\"n\">fancy_widget</span> <span class=\"o\">=</span> <span class=\"no\">FactoryGirl</span><span class=\"o\">.</span><span class=\"n\">create</span> <span class=\"ss\">:widget</span><span class=\"p\">,</span> <span class=\"ss\">:expensive</span><span class=\"p\">,</span> <span class=\"nb\">name</span><span class=\"p\">:</span> <span class=\"s1\">&#39;Fancy Widget&#39;</span></code></pre><p>It works well, and it keeps initialization boilerplate out of individual tests.\n</p><h2><a name=\"testing-on-the-front-end\"></a>Testing on the front-end</h2><p>Trouble arises when we need to write tests for the JavaScript application that use the same models. Suddenly, we need to duplicate the same kind of logic in our front-end tests. We might start out by setting up object state manually:\n</p><pre><code class=\"pygments\"><span class=\"kd\">var</span> <span class=\"nx\">fancyWidget</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">Widget</span><span class=\"p\">({</span>\n  <span class=\"nx\">name</span><span class=\"o\">:</span> <span class=\"s1\">&#39;Fancy Widget&#39;</span><span class=\"p\">,</span>\n  <span class=\"nx\">price</span><span class=\"o\">:</span> <span class=\"mi\">1000</span>\n<span class=\"p\">});</span></code></pre><p>Things can quickly get out of hand when models grow complex. Even if we use a factory library in JavaScript, it's possible for our front-end factories to diverge from their back-end counterparts. This means our integration tests will fail, but our unit tests will still blindly pass. Having to duplicate all that logic in two places is dangerous. It would be nice to have a <em>single, canonical source</em> for all of our factories.\n</p><h3><a name=\"reusing-server-side-factories-with-factory-girl-api\"></a>Reusing server-side factories with factory_girl_api</h3><p>To help alleviate this problem, I created the <a href=\"https://github.com/lexi-lambda/factory_girl_api\">factory_girl_api</a> gem for Rails and the <a href=\"https://github.com/lexi-lambda/angular-factory-girl-api\">angular-factory-girl-api</a> Bower package for Angular. These packages cooperate with each other to allow server-side factories to be used in JavaScript tests.\n</p><p>The Angular module provides a service with syntax comparable to factory_girl itself. Both traits and custom attributes are supported:\n</p><pre><code class=\"pygments\"><span class=\"nx\">FactoryGirl</span><span class=\"p\">.</span><span class=\"nx\">create</span><span class=\"p\">(</span><span class=\"s1\">&#39;widget&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;expensive&#39;</span><span class=\"p\">,</span> <span class=\"p\">{</span> <span class=\"nx\">name</span><span class=\"o\">:</span> <span class=\"s1\">&#39;Fancy Widget&#39;</span> <span class=\"p\">});</span></code></pre><p>In this case, however, a round-trip API call must be made to the server in order to call the factory and return the result. Because of this, the Angular version of FactoryGirl returns a promise that is resolved with the serialized version of the model, which can then be used as sample data in unit tests.\n</p><h3><a name=\"the-problems-with-relying-on-the-server-for-data\"></a>The problems with relying on the server for data</h3><p>In my preliminary use of this tool, it works. In many ways, it's much nicer than duplicating logic in both places. However, I'm not <em>completely</em> convinced it's the right solution yet.\n</p><p>First of all, it couples the front-end to the back-end, even during unit testing, which is disappointing. It means that a server needs to be running (in test mode) in order for the tests to run at all. For the kinds of projects I work on, this isn't really a bad thing, and the benefits of the reduced duplication far outweigh the downsides.\n</p><p>My real concern is that this solves a very small facet of the general problem with fragile front-end test suites. Single-page applications usually depend wholly on their integration with back-end APIs. If those APIs change, the tests will continue to happily pass as long as the API is simply mocked, which seems to be the usual solution in the front-end universe. This is, frankly, unacceptable in real application development.\n</p><h3><a name=\"potential-improvements-and-other-paths-to-success\"></a>Potential improvements and other paths to success</h3><p>I am ultimately unsatisfied with this approach, but writing brittle end-to-end integration tests is not the solution. This <em>kind</em> of thing may be a step in the right direction: writing tests that aren't really pure unit tests, but also aren't fragile full-stack integration tests. This is a middle-ground that seems infrequently traveled, perhaps due to a lack of tooling (or perhaps because it just doesn't work). I don't know.\n</p><p>Either way, I'm interested in where this is headed, and I'll be curious to see if I run into any roadblocks using the workflow I've created. If anyone else is interested in playing with these two libraries, the READMEs are much more comprehensive than what I've covered here. Take a look, and give them a spin!\n</p><ul><li><p><a href=\"https://github.com/lexi-lambda/factory_girl_api\">factory_girl_api</a>\n</p></li><li><p><a href=\"https://github.com/lexi-lambda/angular-factory-girl-api\">angular-factory-girl-api</a>\n</p></li></ul><ol class=\"footnotes\"></ol></article>","contentSnippet":"Modern web applications are often built as single-page apps, which are great for keeping concerns separated, but problematic when tested. Logic needs to be duplicated in front- and back-end test suites, and if the two apps diverge, the tests won't catch the failure. I haven't found a very good solution to this problem aside from brittle, end-to-end integration tests.\n\nTo attempt to address a fraction of this problem, I built factory_girl_api, a way to share context setup between both sides of the application.\n\nA brief overview of factory_girl\nIn the land of Ruby and Rails, factory_girl is a convenient gem for managing factories for models. Out of the box, it integrates with Rails' default ORM, ActiveRecord, and provides declarative syntax for describing what attributes factories should initialize. For example, a factory declaration used to create a widget might look like this:\n\nFactoryGirl.define do\n  factory :widget do\n    sequence(:name) { |id| 'Widget #' + id }\n    price 10\n\n    trait :expensive do\n      price 1000\n    end\n  end\nend\nThis makes it easy to create new instances of Widget and use them for unit tests. For example, this would create and persist a widget with a unique name and a price of 10 units:\n\nwidget = FactoryGirl.create :widget\nWe can also create more expensive widgets by using the :expensive trait.\n\nexpensive_widget = FactoryGirl.create :widget, :expensive\nAny number of traits can be specified at once. Additionally, it is possible to override individual attributes manually.\n\nfancy_widget = FactoryGirl.create :widget, :expensive, name: 'Fancy Widget'\nIt works well, and it keeps initialization boilerplate out of individual tests.\n\nTesting on the front-end\nTrouble arises when we need to write tests for the JavaScript application that use the same models. Suddenly, we need to duplicate the same kind of logic in our front-end tests. We might start out by setting up object state manually:\n\nvar fancyWidget = new Widget({\n  name: 'Fancy Widget',\n  price: 1000\n});\nThings can quickly get out of hand when models grow complex. Even if we use a factory library in JavaScript, it's possible for our front-end factories to diverge from their back-end counterparts. This means our integration tests will fail, but our unit tests will still blindly pass. Having to duplicate all that logic in two places is dangerous. It would be nice to have a single, canonical source for all of our factories.\n\nReusing server-side factories with factory_girl_api\nTo help alleviate this problem, I created the factory_girl_api gem for Rails and the angular-factory-girl-api Bower package for Angular. These packages cooperate with each other to allow server-side factories to be used in JavaScript tests.\n\nThe Angular module provides a service with syntax comparable to factory_girl itself. Both traits and custom attributes are supported:\n\nFactoryGirl.create('widget', 'expensive', { name: 'Fancy Widget' });\nIn this case, however, a round-trip API call must be made to the server in order to call the factory and return the result. Because of this, the Angular version of FactoryGirl returns a promise that is resolved with the serialized version of the model, which can then be used as sample data in unit tests.\n\nThe problems with relying on the server for data\nIn my preliminary use of this tool, it works. In many ways, it's much nicer than duplicating logic in both places. However, I'm not completely convinced it's the right solution yet.\n\nFirst of all, it couples the front-end to the back-end, even during unit testing, which is disappointing. It means that a server needs to be running (in test mode) in order for the tests to run at all. For the kinds of projects I work on, this isn't really a bad thing, and the benefits of the reduced duplication far outweigh the downsides.\n\nMy real concern is that this solves a very small facet of the general problem with fragile front-end test suites. Single-page applications usually depend wholly on their integration with back-end APIs. If those APIs change, the tests will continue to happily pass as long as the API is simply mocked, which seems to be the usual solution in the front-end universe. This is, frankly, unacceptable in real application development.\n\nPotential improvements and other paths to success\nI am ultimately unsatisfied with this approach, but writing brittle end-to-end integration tests is not the solution. This kind of thing may be a step in the right direction: writing tests that aren't really pure unit tests, but also aren't fragile full-stack integration tests. This is a middle-ground that seems infrequently traveled, perhaps due to a lack of tooling (or perhaps because it just doesn't work). I don't know.\n\nEither way, I'm interested in where this is headed, and I'll be curious to see if I run into any roadblocks using the workflow I've created. If anyone else is interested in playing with these two libraries, the READMEs are much more comprehensive than what I've covered here. Take a look, and give them a spin!\n\n\nfactory_girl_api\n\n\nangular-factory-girl-api","isoDate":"2015-09-23T00:00:00.000Z","timestamp":"9/22/2015"},{"title":"Managing application configuration with Envy","pubDate":"2015-08-30T00:00:00.000Z","author":"Alexis King","content":"<article><p>Application configuration can be a pain. Modern web apps don't live on dedicated boxes, they run on VPSes somewhere in the amorphous \"cloud\", and keeping configuration out of your application's repository can seem like more trouble than it's worth. Fortunately, <a href=\"http://12factor.net\">The Twelve-Factor App</a> provides a set of standards for keeping web apps sane, and <a href=\"http://12factor.net/config\">one of those guidelines advises keeping configuration in the environment</a>.\n</p><p><a href=\"https://github.com/lexi-lambda/envy\">Envy</a> is the declarative bridge between Racket code and the outside world of the environment.\n</p><h2><a name=\"introducing-envy\"></a>Introducing Envy</h2><p>I built Envy to distill the common tasks needed when working with environment variables into a single, declarative interface that eliminates boilerplate and makes it easy to see which environment variables an application depends on (instead of having them littered throughout the codebase). Using it is simple. Just require <code>envy</code> and you're good to go.\n</p><p>The best way to use Envy is to create a \"manifest\" module that declares all the environment variables your application might use. For example, the following module is a manifest that describes an application that uses three environment variables:\n</p><pre><code class=\"pygments\"><span class=\"c1\">; environment.rkt</span>\n<span class=\"kn\">#lang </span><span class=\"nn\">typed/racket/base</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">envy</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"n\">define/provide-environment</span>\n  <span class=\"n\">api-token</span>\n  <span class=\"p\">[</span><span class=\"n\">log-level</span> <span class=\"n\">:</span> <span class=\"n\">Symbol</span> <span class=\"kd\">#:default</span> <span class=\"o\">&#39;</span><span class=\"ss\">info</span><span class=\"p\">]</span>\n  <span class=\"p\">[</span><span class=\"n\">parallel?</span> <span class=\"n\">:</span> <span class=\"n\">Boolean</span><span class=\"p\">])</span></code></pre><p>When this module is required, Envy will automatically do the following:\n</p><ol><li><p>Envy will check the values of three environment variables: <code>API_TOKEN</code>, <code>LOG_LEVEL</code>, and <code>PARALLEL</code>.\n</p></li><li><p>If either <code>API_TOKEN</code> or <code>PARALLEL</code> is not set, an error will be raised:\n</p><pre><code>envy: The required environment variable \"API_TOKEN\" is not defined.\n</code></pre></li><li><p>The values for <code>LOG_LEVEL</code> and <code>PARALLEL</code> will be parsed to match their type annotations.\n</p></li><li><p>If <code>LOG_LEVEL</code> is not set, it will use the default value, <code>'info</code>.\n</p></li><li><p>The values will be stored in <code>api-token</code>, <code>log-level</code>, and <code>parallel?</code>, all of which will be provided by the enclosing module.\n</p></li></ol><p>Now just <code>(require (prefix-in env: \"environment.rkt\"))</code>, and the environment variables are guaranteed to be available in your application's code.\n</p><h2><a name=\"working-with-typed-racket\"></a>Working with Typed Racket</h2><p>As you may have noticed by the example above, Envy is built with Typed Racket in mind. In fact, <code>define/provide-environment</code> will <em>only</em> work within a Typed Racket module, but that doesn't mean Envy can't be used with plain Racket—the manifest module can always be required by any kind of Racket module.\n</p><p>However, when using Typed Racket, Envy provides additional bonuses. Environment variables are inherently untyped—they're all just strings—but Envy assigns the proper type to each environment variable automatically, so no casting is necessary.\n</p><pre><code>&gt; parallel?\n- : Boolean\n#t\n</code></pre><p>Envy really shines when using optional environment variables with the <code>#:default</code> option. The type of the value given to <code>#:default</code> doesn't need to be the same type of the environment variable itself, and if it isn't, Envy will assign the value a union type.\n</p><pre><code>&gt; (define-environment\n    [num-threads : Positive-Integer #:default #f])\n&gt; num-threads\n- : (U Positive-Integer #f)\n#f\n</code></pre><p>This added level of type-safety means it's easy to manage optional variables that don't have reasonable defaults: the type system will enforce that all code considers the possibility that such variables do not exist.\n</p><h2><a name=\"and-more\"></a>And more...</h2><p>To see the full set of features that Envy already provides, <a href=\"https://lexi-lambda.github.io/envy/envy.html\">take a look at the documentation</a>. That said, this is just the first release based on my initial use-cases, but I'm sure there are more features Envy could have to accommodate common application configuration patterns. If you have an idea that could make Envy better, <a href=\"https://github.com/lexi-lambda/envy/issues\">open an issue and make a suggestion</a>! I already have plans for a <code>#lang envy</code> DSL, which will hopefully cut the boilerplate out in its entirety.\n</p><p>And finally, to give credit where credit is due, Envy is heavily inspired by <a href=\"https://github.com/eval/envied\">Envied</a> (both in name and function), an environment variable manager for Ruby, which I've used to great effect.\n</p><p>Try it out!\n</p><ul><li><p><code>raco pkg install envy</code>\n</p></li><li><p><a href=\"https://github.com/lexi-lambda/envy\">Envy on GitHub</a>\n</p></li><li><p><a href=\"https://lexi-lambda.github.io/envy/envy.html\">Envy documentation</a>\n</p></li></ul><ol class=\"footnotes\"></ol></article>","contentSnippet":"Application configuration can be a pain. Modern web apps don't live on dedicated boxes, they run on VPSes somewhere in the amorphous \"cloud\", and keeping configuration out of your application's repository can seem like more trouble than it's worth. Fortunately, The Twelve-Factor App provides a set of standards for keeping web apps sane, and one of those guidelines advises keeping configuration in the environment.\n\nEnvy is the declarative bridge between Racket code and the outside world of the environment.\n\nIntroducing Envy\nI built Envy to distill the common tasks needed when working with environment variables into a single, declarative interface that eliminates boilerplate and makes it easy to see which environment variables an application depends on (instead of having them littered throughout the codebase). Using it is simple. Just require envy and you're good to go.\n\nThe best way to use Envy is to create a \"manifest\" module that declares all the environment variables your application might use. For example, the following module is a manifest that describes an application that uses three environment variables:\n\n; environment.rkt\n#lang typed/racket/base\n\n(require envy)\n\n(define/provide-environment\n  api-token\n  [log-level : Symbol #:default 'info]\n  [parallel? : Boolean])\nWhen this module is required, Envy will automatically do the following:\n\n\nEnvy will check the values of three environment variables: API_TOKEN, LOG_LEVEL, and PARALLEL.\n\n\nIf either API_TOKEN or PARALLEL is not set, an error will be raised:\n\nenvy: The required environment variable \"API_TOKEN\" is not defined.\n\n\nThe values for LOG_LEVEL and PARALLEL will be parsed to match their type annotations.\n\n\nIf LOG_LEVEL is not set, it will use the default value, 'info.\n\n\nThe values will be stored in api-token, log-level, and parallel?, all of which will be provided by the enclosing module.\n\n\nNow just (require (prefix-in env: \"environment.rkt\")), and the environment variables are guaranteed to be available in your application's code.\n\nWorking with Typed Racket\nAs you may have noticed by the example above, Envy is built with Typed Racket in mind. In fact, define/provide-environment will only work within a Typed Racket module, but that doesn't mean Envy can't be used with plain Racket—the manifest module can always be required by any kind of Racket module.\n\nHowever, when using Typed Racket, Envy provides additional bonuses. Environment variables are inherently untyped—they're all just strings—but Envy assigns the proper type to each environment variable automatically, so no casting is necessary.\n\n> parallel?\n- : Boolean\n#t\n\nEnvy really shines when using optional environment variables with the #:default option. The type of the value given to #:default doesn't need to be the same type of the environment variable itself, and if it isn't, Envy will assign the value a union type.\n\n> (define-environment\n    [num-threads : Positive-Integer #:default #f])\n> num-threads\n- : (U Positive-Integer #f)\n#f\n\nThis added level of type-safety means it's easy to manage optional variables that don't have reasonable defaults: the type system will enforce that all code considers the possibility that such variables do not exist.\n\nAnd more...\nTo see the full set of features that Envy already provides, take a look at the documentation. That said, this is just the first release based on my initial use-cases, but I'm sure there are more features Envy could have to accommodate common application configuration patterns. If you have an idea that could make Envy better, open an issue and make a suggestion! I already have plans for a #lang envy DSL, which will hopefully cut the boilerplate out in its entirety.\n\nAnd finally, to give credit where credit is due, Envy is heavily inspired by Envied (both in name and function), an environment variable manager for Ruby, which I've used to great effect.\n\nTry it out!\n\n\nraco pkg install envy\n\n\nEnvy on GitHub\n\n\nEnvy documentation","isoDate":"2015-08-30T00:00:00.000Z","timestamp":"8/29/2015"},{"title":"Deploying Racket applications on Heroku","pubDate":"2015-08-22T00:00:00.000Z","author":"Alexis King","content":"<article><p><a href=\"https://www.heroku.com\">Heroku</a> is a \"platform as a service\" that provides an incredibly simple way to deploy simple internet applications, and I take liberal advantage of its free tier for testing out simple applications. It has support for a variety of languages built-in, but Racket is not currently among them. Fortunately, Heroku provides an interface for adding custom build processes for arbitrary types of applications, called “buildpacks”. I've built one for Racket apps, and with just a little bit of configuration, it’s possible to get a Racket webserver running on Heroku.\n</p><h2><a name=\"building-the-server\"></a>Building the server</h2><p>Racket's <a href=\"http://docs.racket-lang.org/web-server/index.html\">web-server</a> package makes building and running a simple server incredibly easy. Here's all the code we'll need to get going:\n</p><pre><code class=\"pygments\"><span class=\"kn\">#lang </span><span class=\"nn\">racket</span>\n\n<span class=\"p\">(</span><span class=\"k\">require</span> <span class=\"n\">web-server/servlet</span>\n         <span class=\"n\">web-server/servlet-env</span><span class=\"p\">)</span>\n\n<span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"p\">(</span><span class=\"n\">start</span> <span class=\"n\">req</span><span class=\"p\">)</span>\n  <span class=\"p\">(</span><span class=\"n\">response/xexpr</span>\n   <span class=\"o\">&#39;</span><span class=\"p\">(</span><span class=\"ss\">html</span> <span class=\"p\">(</span><span class=\"ss\">head</span> <span class=\"p\">(</span><span class=\"ss\">title</span> <span class=\"s2\">\"Racket Heroku App\"</span><span class=\"p\">))</span>\n          <span class=\"p\">(</span><span class=\"ss\">body</span> <span class=\"p\">(</span><span class=\"ss\">h1</span> <span class=\"s2\">\"It works!\"</span><span class=\"p\">)))))</span>\n\n<span class=\"p\">(</span><span class=\"n\">serve/servlet</span> <span class=\"n\">start</span> <span class=\"kd\">#:servlet-path</span> <span class=\"s2\">\"/\"</span><span class=\"p\">)</span></code></pre><p>Running the above file will start up the server on the default port, 8080. When running on Heroku, however, we're required to bind to the port that Heroku provides via the <code>PORT</code> environment variable. We can access this using the Racket <code>getenv</code>[racket] function.\n</p><p>Additionally, the Racket web server specifically binds to localhost, but Heroku doesn't allow that restriction, so we need to pass <code>#f</code> for the <code>#:listen-ip</code> argument.\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"k\">define</span> <span class=\"n\">port</span> <span class=\"p\">(</span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nb\">getenv</span> <span class=\"s2\">\"PORT\"</span><span class=\"p\">)</span>\n                 <span class=\"p\">(</span><span class=\"nb\">string-&gt;number</span> <span class=\"p\">(</span><span class=\"nb\">getenv</span> <span class=\"s2\">\"PORT\"</span><span class=\"p\">))</span>\n                 <span class=\"mi\">8080</span><span class=\"p\">))</span>\n<span class=\"p\">(</span><span class=\"n\">serve/servlet</span> <span class=\"n\">start</span>\n               <span class=\"kd\">#:servlet-path</span> <span class=\"s2\">\"/\"</span>\n               <span class=\"kd\">#:listen-ip</span> <span class=\"no\">#f</span>\n               <span class=\"kd\">#:port</span> <span class=\"n\">port</span><span class=\"p\">)</span></code></pre><p>Also, by default, <code>serve/servlet</code>[racket] will open a web browser automatically when the program is run, which is very useful for rapid prototyping within something like DrRacket, but we'll want to turn that off.\n</p><pre><code class=\"pygments\"><span class=\"p\">(</span><span class=\"n\">serve/servlet</span> <span class=\"n\">start</span>\n               <span class=\"kd\">#:servlet-path</span> <span class=\"s2\">\"/\"</span>\n               <span class=\"kd\">#:listen-ip</span> <span class=\"no\">#f</span>\n               <span class=\"kd\">#:port</span> <span class=\"n\">port</span>\n               <span class=\"kd\">#:command-line?</span> <span class=\"no\">#t</span><span class=\"p\">)</span></code></pre><p>That's it! Now we have a Racket web server that can run on Heroku. Obviously it's not a very interesting application right now, but that's fine for our purposes.\n</p><h2><a name=\"setting-up-our-app-for-heroku\"></a>Setting up our app for Heroku</h2><p>The next step is to actually create an app on Heroku. Don't worry—it's free! That said, explaining precisely how Heroku works is outside the scope of this article. Just make an account, then create an app. I called mine \"racket-heroku-sample\". Once you've created an app and set up Heroku's command-line tool, you can specify the proper buildpack:\n</p><pre><code class=\"pygments\">$ git init\n$ heroku git:remote -a racket-heroku-sample\n$ heroku buildpacks:set https://github.com/lexi-lambda/heroku-buildpack-racket</code></pre><p>We'll also need to pick a particular Racket version before we deploy our app. At the time of this writing, Racket 6.2.1 is the latest version, so I just set the <code>RACKET_VERSION</code> environment variable as follows:\n</p><pre><code class=\"pygments\">$ heroku config:set <span class=\"nv\">RACKET_VERSION</span><span class=\"o\">=</span><span class=\"m\">6</span>.2.1</code></pre><p>Now there's just one thing left to do before we can push to Heroku: we need to tell Heroku what command to use to run our application. To do this, we use something called a \"Procfile\" that contains information about the process types for our app. Heroku supports multiple processes of different types, but we're just going to have a single web process.\n</p><p>Specifically, we just want to run our <code>serve.rkt</code> module. The Racket buildpack installs the repository as a package, so we can run <code>racket</code> with the <code>-l</code> flag to specify a module path, which will be more robust than specifying a filesystem path directly. Therefore, our Procfile will look like this:\n</p><pre><code>web: racket -l sample-heroku-app/server\n</code></pre><p>Now all that's left to do is push our repository to Heroku's git remote. Once the build completes, we can <a href=\"https://racket-heroku-sample.herokuapp.com\">navigate to our app&rsquo;s URL and actually see it running live</a>!\n</p><h2><a name=\"conclusion\"></a>Conclusion</h2><p>That's all that's needed to get a Racket app up and running on Heroku, but it probably isn't the best way to manage a real application. Usually it's best to use a continuous integration service to automatically deploy certain GitHub branches to Heroku, after running the tests, of course. Also, a real application would obviously be a little more complicated.\n</p><p>That said, this provides the foundation and shell. If you'd like to see the sample app used in this post, you can <a href=\"https://github.com/lexi-lambda/racket-sample-heroku-app\">find it on GitHub here</a>. For more details on the buildpack itself, <a href=\"https://github.com/lexi-lambda/heroku-buildpack-racket\">it&rsquo;s also available on GitHub here</a>.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"Heroku is a \"platform as a service\" that provides an incredibly simple way to deploy simple internet applications, and I take liberal advantage of its free tier for testing out simple applications. It has support for a variety of languages built-in, but Racket is not currently among them. Fortunately, Heroku provides an interface for adding custom build processes for arbitrary types of applications, called “buildpacks”. I've built one for Racket apps, and with just a little bit of configuration, it’s possible to get a Racket webserver running on Heroku.\n\nBuilding the server\nRacket's web-server package makes building and running a simple server incredibly easy. Here's all the code we'll need to get going:\n\n#lang racket\n\n(require web-server/servlet\n         web-server/servlet-env)\n\n(define (start req)\n  (response/xexpr\n   '(html (head (title \"Racket Heroku App\"))\n          (body (h1 \"It works!\")))))\n\n(serve/servlet start #:servlet-path \"/\")\nRunning the above file will start up the server on the default port, 8080. When running on Heroku, however, we're required to bind to the port that Heroku provides via the PORT environment variable. We can access this using the Racket getenv[racket] function.\n\nAdditionally, the Racket web server specifically binds to localhost, but Heroku doesn't allow that restriction, so we need to pass #f for the #:listen-ip argument.\n\n(define port (if (getenv \"PORT\")\n                 (string->number (getenv \"PORT\"))\n                 8080))\n(serve/servlet start\n               #:servlet-path \"/\"\n               #:listen-ip #f\n               #:port port)\nAlso, by default, serve/servlet[racket] will open a web browser automatically when the program is run, which is very useful for rapid prototyping within something like DrRacket, but we'll want to turn that off.\n\n(serve/servlet start\n               #:servlet-path \"/\"\n               #:listen-ip #f\n               #:port port\n               #:command-line? #t)\nThat's it! Now we have a Racket web server that can run on Heroku. Obviously it's not a very interesting application right now, but that's fine for our purposes.\n\nSetting up our app for Heroku\nThe next step is to actually create an app on Heroku. Don't worry—it's free! That said, explaining precisely how Heroku works is outside the scope of this article. Just make an account, then create an app. I called mine \"racket-heroku-sample\". Once you've created an app and set up Heroku's command-line tool, you can specify the proper buildpack:\n\n$ git init\n$ heroku git:remote -a racket-heroku-sample\n$ heroku buildpacks:set https://github.com/lexi-lambda/heroku-buildpack-racket\nWe'll also need to pick a particular Racket version before we deploy our app. At the time of this writing, Racket 6.2.1 is the latest version, so I just set the RACKET_VERSION environment variable as follows:\n\n$ heroku config:set RACKET_VERSION=6.2.1\nNow there's just one thing left to do before we can push to Heroku: we need to tell Heroku what command to use to run our application. To do this, we use something called a \"Procfile\" that contains information about the process types for our app. Heroku supports multiple processes of different types, but we're just going to have a single web process.\n\nSpecifically, we just want to run our serve.rkt module. The Racket buildpack installs the repository as a package, so we can run racket with the -l flag to specify a module path, which will be more robust than specifying a filesystem path directly. Therefore, our Procfile will look like this:\n\nweb: racket -l sample-heroku-app/server\n\nNow all that's left to do is push our repository to Heroku's git remote. Once the build completes, we can navigate to our app’s URL and actually see it running live!\n\nConclusion\nThat's all that's needed to get a Racket app up and running on Heroku, but it probably isn't the best way to manage a real application. Usually it's best to use a continuous integration service to automatically deploy certain GitHub branches to Heroku, after running the tests, of course. Also, a real application would obviously be a little more complicated.\n\nThat said, this provides the foundation and shell. If you'd like to see the sample app used in this post, you can find it on GitHub here. For more details on the buildpack itself, it’s also available on GitHub here.","isoDate":"2015-08-22T00:00:00.000Z","timestamp":"8/21/2015"},{"title":"Automatically deploying a Frog-powered blog to GitHub pages","pubDate":"2015-07-18T00:00:00.000Z","author":"Alexis King","content":"<article><p>So, I have a blog now. It's a simple static blog, but what's unique about it is that it's powered by Racket; specifically, it uses <a href=\"http://www.greghendershott.com\">Greg Hendershott</a>'s fantastic <a href=\"https://github.com/greghendershott/frog\">Frog</a> tool. I've taken this and moulded it to my tastes to build my blog, including configuring automatic deployment via <a href=\"https://travis-ci.org\">Travis CI</a>, so my blog is always up-to-date.\n</p><h2><a name=\"setting-up-frog\"></a>Setting up Frog</h2><p>I should note that Frog itself was wonderfully easy to drop in and get running. Just following the readme, a simple <code>raco pkg install frog</code> followed by <code>raco frog --init</code> and <code>raco frog -bp</code> created a running blog and opened it in my web browser. There was nothing more to it. Once that's done, all it takes to write a blog post is <code>raco frog -n \"Post Title\"</code>, and you're good to go.\n</p><p>By default, Frog uses Bootstrap, which provides a lot of the necessary scaffolding for you, but I opted to roll my own layout using flexbox. I also decided to use <a href=\"http://sass-lang.com\">Sass</a> for my stylesheets, potentially with support for <a href=\"http://coffeescript.org\">CoffeeScript</a> later, so I wanted to have a good flow for compiling all the resources for deployment. To do that, I used <a href=\"http://gulpjs.com\">Gulp</a> in conjunction with <a href=\"https://www.npmjs.com\">NPM</a> for build and dependency management.\n</p><p>Going this route has a few advantages, primarily the fact that updating dependencies becomes much easier, and I can build and deploy my blog with just a couple of commands without needing to commit compiled or minified versions of my sources to version control.\n</p><h2><a name=\"configuring-automatic-deployment-with-travis\"></a>Configuring automatic deployment with Travis</h2><p>Once Frog itself was configured and my styling was finished, I started looking into how to deploy my blog to a GitHub page without needing to check in any of the generated files to source control. I found a couple of resources, the most useful one being <a href=\"https://gist.github.com/domenic/ec8b0fc8ab45f39403dd\">this Gist</a>, which describes how to set up deployment for any project. The basic idea is to create a deployment script which will automatically generate your project, initialize a git repository with the generated files, and push to GitHub's special <code>gh-pages</code> branch.\n</p><p>To make this easy, Frog can be configured to output to a separate directory via the <code>.frogrc</code> configuration file. I chose to output to the <code>out</code> directory:\n</p><pre><code>output-dir = out\n</code></pre><p>I also configured my Gulp build to output my CSS into the same output directory. Now, all that's necessary in order to deploy the blog to GitHub is to initialize a Git repository in the output directory, and push the files to the remote branch.\n</p><pre><code>$ cd out\n$ git init\n$ git add .\n$ git commit -m \"Deploy to GitHub Pages\"\n$ git push --force \"$REMOTE_URL\" master:gh-pages\n</code></pre><p>The next step is to configure Travis so that it can securely push to the GitHub repository with the required credentials. This can be done with Travis's <a href=\"http://docs.travis-ci.com/user/encryption-keys/\">encryption keys</a> along with a GitHub <a href=\"https://github.com/settings/tokens\">personal access token</a>. Just install the Travis CLI client, copy the access token, and run a command:\n</p><pre><code>$ gem install travis\n$ travis encrypt GH_TOKEN=&lt;access token...&gt;\n</code></pre><p>The output of that command is an encrypted value to be placed in an environment variable in the project's <code>.travis.yml</code> configuration file. The URL for the repository on GitHub will also need to be specified as well:\n</p><pre><code class=\"pygments\"><span class=\"nt\">env</span><span class=\"p\">:</span>\n  <span class=\"nt\">global</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">GH_REF</span><span class=\"p\">:</span> <span class=\"s\">&#39;github.com/&lt;gh-username&gt;/&lt;gh-repo&gt;.git&#39;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">secure</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">&lt;encrypted data...&gt;</span></code></pre><p>Now all that's left is configuring the <code>.travis.yml</code> to run Frog. Since Travis doesn't natively support Racket at the time of this writing, the choice of \"language\" is somewhat arbitrary, but since I want Pygments installed for syntax highlighting, I set my project type to <code>python</code>, then installed Racket and Frog as pre-installation steps.\n</p><pre><code class=\"pygments\"><span class=\"nt\">env</span><span class=\"p\">:</span>\n  <span class=\"nt\">global</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">GH_REF</span><span class=\"p\">:</span> <span class=\"s\">&#39;github.com/&lt;gh-username&gt;/&lt;gh-repo&gt;.git&#39;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">secure</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">&lt;encrypted data...&gt;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">RACKET_DIR</span><span class=\"p\">:</span> <span class=\"s\">&#39;~/racket&#39;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">RACKET_VERSION</span><span class=\"p\">:</span> <span class=\"s\">&#39;6.2&#39;</span>\n\n<span class=\"nt\">before_install</span><span class=\"p\">:</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">git clone https://github.com/greghendershott/travis-racket.git</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">cat travis-racket/install-racket.sh | bash</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">export PATH=\"${RACKET_DIR}/bin:${PATH}\"</span>\n\n<span class=\"nt\">install</span><span class=\"p\">:</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">raco pkg install --deps search-auto frog</span></code></pre><p>(It might be worth noting that Greg Hendershott <em>also</em> maintains the repository that contains the above Travis build script!)\n</p><p>Finally, in my case, I wasn't deploying to a project-specific GitHub page. Instead, I wanted to deploy to my user page, which uses <code>master</code>, not <code>gh-pages</code>. Obviously, I didn't want Travis running on my <code>master</code> branch, since it would be deploying to that, so I added a branch whitelist:\n</p><pre><code class=\"pygments\"><span class=\"nt\">branches</span><span class=\"p\">:</span>\n  <span class=\"nt\">only</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">source</span></code></pre><p>All that was left to do was to write up the actual deployment script to be used by Travis. Based on the one provided in the above Gist, mine looked like this:\n</p><pre><code class=\"pygments\"><span class=\"ch\">#!/bin/bash</span>\n<span class=\"nb\">set</span> -ev <span class=\"c1\"># exit with nonzero exit code if anything fails</span>\n\n<span class=\"c1\"># clear the output directory</span>\nrm -rf out <span class=\"o\">||</span> <span class=\"nb\">exit</span> <span class=\"m\">0</span><span class=\"p\">;</span>\n\n<span class=\"c1\"># build the blog files + install pygments for highlighting support</span>\nnpm install\nnpm run build\npip install pygments\nraco frog --build\n\n<span class=\"c1\"># go to the out directory and create a *new* Git repo</span>\n<span class=\"nb\">cd</span> out\ngit init\n\n<span class=\"c1\"># inside this git repo we&#39;ll pretend to be a new user</span>\ngit config user.name <span class=\"s2\">\"Travis CI\"</span>\ngit config user.email <span class=\"s2\">\"&lt;your@email.here&gt;\"</span>\n\n<span class=\"c1\"># The first and only commit to this new Git repo contains all the</span>\n<span class=\"c1\"># files present with the commit message \"Deploy to GitHub Pages\".</span>\ngit add .\ngit commit -m <span class=\"s2\">\"Deploy to GitHub Pages\"</span>\n\n<span class=\"c1\"># Force push from the current repo&#39;s master branch to the remote</span>\n<span class=\"c1\"># repo. (All previous history on the branch will be lost, since we are</span>\n<span class=\"c1\"># overwriting it.) We redirect any output to /dev/null to hide any sensitive</span>\n<span class=\"c1\"># credential data that might otherwise be exposed.</span>\ngit push --force --quiet <span class=\"s2\">\"https://</span><span class=\"si\">${</span><span class=\"nv\">GH_TOKEN</span><span class=\"si\">}</span><span class=\"s2\">@</span><span class=\"si\">${</span><span class=\"nv\">GH_REF</span><span class=\"si\">}</span><span class=\"s2\">\"</span> master &gt; /dev/null <span class=\"m\">2</span>&gt;<span class=\"p\">&amp;</span><span class=\"m\">1</span></code></pre><p>For reference, my final <code>.travis.yml</code> looked like this:\n</p><pre><code class=\"pygments\"><span class=\"nt\">language</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">python</span>\n<span class=\"nt\">python</span><span class=\"p\">:</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"s\">&#39;3.4&#39;</span>\n\n<span class=\"nt\">branches</span><span class=\"p\">:</span>\n  <span class=\"nt\">only</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">source</span>\n\n<span class=\"nt\">env</span><span class=\"p\">:</span>\n  <span class=\"nt\">global</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">GH_REF</span><span class=\"p\">:</span> <span class=\"s\">&#39;github.com/lexi-lambda/lexi-lambda.github.io.git&#39;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">secure</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">&lt;long secure token...&gt;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">RACKET_DIR</span><span class=\"p\">:</span> <span class=\"s\">&#39;~/racket&#39;</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">RACKET_VERSION</span><span class=\"p\">:</span> <span class=\"s\">&#39;6.2&#39;</span>\n\n<span class=\"nt\">before_install</span><span class=\"p\">:</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">git clone https://github.com/greghendershott/travis-racket.git</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">cat travis-racket/install-racket.sh | bash</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">export PATH=\"${RACKET_DIR}/bin:${PATH}\"</span>\n\n<span class=\"nt\">install</span><span class=\"p\">:</span>\n<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">raco pkg install --deps search-auto frog</span>\n\n<span class=\"nt\">script</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">bash ./deploy.sh</span></code></pre><p>That's it! Now I have a working blog that I can publish just by pushing to the <code>source</code> branch on GitHub.\n</p><ol class=\"footnotes\"></ol></article>","contentSnippet":"So, I have a blog now. It's a simple static blog, but what's unique about it is that it's powered by Racket; specifically, it uses Greg Hendershott's fantastic Frog tool. I've taken this and moulded it to my tastes to build my blog, including configuring automatic deployment via Travis CI, so my blog is always up-to-date.\n\nSetting up Frog\nI should note that Frog itself was wonderfully easy to drop in and get running. Just following the readme, a simple raco pkg install frog followed by raco frog --init and raco frog -bp created a running blog and opened it in my web browser. There was nothing more to it. Once that's done, all it takes to write a blog post is raco frog -n \"Post Title\", and you're good to go.\n\nBy default, Frog uses Bootstrap, which provides a lot of the necessary scaffolding for you, but I opted to roll my own layout using flexbox. I also decided to use Sass for my stylesheets, potentially with support for CoffeeScript later, so I wanted to have a good flow for compiling all the resources for deployment. To do that, I used Gulp in conjunction with NPM for build and dependency management.\n\nGoing this route has a few advantages, primarily the fact that updating dependencies becomes much easier, and I can build and deploy my blog with just a couple of commands without needing to commit compiled or minified versions of my sources to version control.\n\nConfiguring automatic deployment with Travis\nOnce Frog itself was configured and my styling was finished, I started looking into how to deploy my blog to a GitHub page without needing to check in any of the generated files to source control. I found a couple of resources, the most useful one being this Gist, which describes how to set up deployment for any project. The basic idea is to create a deployment script which will automatically generate your project, initialize a git repository with the generated files, and push to GitHub's special gh-pages branch.\n\nTo make this easy, Frog can be configured to output to a separate directory via the .frogrc configuration file. I chose to output to the out directory:\n\noutput-dir = out\n\nI also configured my Gulp build to output my CSS into the same output directory. Now, all that's necessary in order to deploy the blog to GitHub is to initialize a Git repository in the output directory, and push the files to the remote branch.\n\n$ cd out\n$ git init\n$ git add .\n$ git commit -m \"Deploy to GitHub Pages\"\n$ git push --force \"$REMOTE_URL\" master:gh-pages\n\nThe next step is to configure Travis so that it can securely push to the GitHub repository with the required credentials. This can be done with Travis's encryption keys along with a GitHub personal access token. Just install the Travis CLI client, copy the access token, and run a command:\n\n$ gem install travis\n$ travis encrypt GH_TOKEN=<access token...>\n\nThe output of that command is an encrypted value to be placed in an environment variable in the project's .travis.yml configuration file. The URL for the repository on GitHub will also need to be specified as well:\n\nenv:\n  global:\n  - GH_REF: 'github.com/<gh-username>/<gh-repo>.git'\n  - secure: <encrypted data...>\nNow all that's left is configuring the .travis.yml to run Frog. Since Travis doesn't natively support Racket at the time of this writing, the choice of \"language\" is somewhat arbitrary, but since I want Pygments installed for syntax highlighting, I set my project type to python, then installed Racket and Frog as pre-installation steps.\n\nenv:\n  global:\n  - GH_REF: 'github.com/<gh-username>/<gh-repo>.git'\n  - secure: <encrypted data...>\n  - RACKET_DIR: '~/racket'\n  - RACKET_VERSION: '6.2'\n\nbefore_install:\n- git clone https://github.com/greghendershott/travis-racket.git\n- cat travis-racket/install-racket.sh | bash\n- export PATH=\"${RACKET_DIR}/bin:${PATH}\"\n\ninstall:\n- raco pkg install --deps search-auto frog\n(It might be worth noting that Greg Hendershott also maintains the repository that contains the above Travis build script!)\n\nFinally, in my case, I wasn't deploying to a project-specific GitHub page. Instead, I wanted to deploy to my user page, which uses master, not gh-pages. Obviously, I didn't want Travis running on my master branch, since it would be deploying to that, so I added a branch whitelist:\n\nbranches:\n  only:\n  - source\nAll that was left to do was to write up the actual deployment script to be used by Travis. Based on the one provided in the above Gist, mine looked like this:\n\n#!/bin/bash\nset -ev # exit with nonzero exit code if anything fails\n\n# clear the output directory\nrm -rf out || exit 0;\n\n# build the blog files + install pygments for highlighting support\nnpm install\nnpm run build\npip install pygments\nraco frog --build\n\n# go to the out directory and create a *new* Git repo\ncd out\ngit init\n\n# inside this git repo we'll pretend to be a new user\ngit config user.name \"Travis CI\"\ngit config user.email \"<your@email.here>\"\n\n# The first and only commit to this new Git repo contains all the\n# files present with the commit message \"Deploy to GitHub Pages\".\ngit add .\ngit commit -m \"Deploy to GitHub Pages\"\n\n# Force push from the current repo's master branch to the remote\n# repo. (All previous history on the branch will be lost, since we are\n# overwriting it.) We redirect any output to /dev/null to hide any sensitive\n# credential data that might otherwise be exposed.\ngit push --force --quiet \"https://${GH_TOKEN}@${GH_REF}\" master > /dev/null 2>&1\nFor reference, my final .travis.yml looked like this:\n\nlanguage: python\npython:\n- '3.4'\n\nbranches:\n  only:\n  - source\n\nenv:\n  global:\n  - GH_REF: 'github.com/lexi-lambda/lexi-lambda.github.io.git'\n  - secure: <long secure token...>\n  - RACKET_DIR: '~/racket'\n  - RACKET_VERSION: '6.2'\n\nbefore_install:\n- git clone https://github.com/greghendershott/travis-racket.git\n- cat travis-racket/install-racket.sh | bash\n- export PATH=\"${RACKET_DIR}/bin:${PATH}\"\n\ninstall:\n- raco pkg install --deps search-auto frog\n\nscript: bash ./deploy.sh\nThat's it! Now I have a working blog that I can publish just by pushing to the source branch on GitHub.","isoDate":"2015-07-18T00:00:00.000Z","timestamp":"7/17/2015"}],"link":"https://lexi-lambda.github.io/","feedUrl":"https://lexi-lambda.github.io/feeds/all.atom.xml","title":"Alexis King’s Blog","lastBuildDate":"2021-03-25T00:00:00Z","feed":"https://lexi-lambda.github.io/feeds/all.atom.xml"},{"items":[{"title":"Deno 1.13 released","link":"https://denoweekly.com/issues/31","pubDate":"Thu, 12 Aug 2021 00:00:00 +0000","content":"\n\n  \n\n    \n    \n    \n    \n    \n  \n\n\n\n\n<table border=0 cellpadding=0 cellspacing=0 align=\"center\" border=\"0\">\n  <tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <div>    \n    <table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr>\n<td align=\"left\" style=\"padding-left: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p>August 12, 2021</p></td>\n<td align=\"right\" style=\"padding-right: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p><a href=\"https://denoweekly.com/link/112323/rss\" style=\" color: #0c9d78;\">Read on the Web</a></p></td>\n</tr></table>\n<p><img src=\"https://res.cloudinary.com/cpress/image/upload/v1588847591/fpwgtmrg9m729db0lnwd.png\" width=\"250\" style=\"  margin-bottom: 0;     line-height: 100%; \"></p>\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112324/rss\" title=\"deno.com\" style=\" color: #0c9d78; font-size: 1.1em; line-height: 1.4em;\">Deno 1.13 Released</a></span> — This is truly a release of many small enhancements - enough so that we’re going to need some bulletpoints:\n</p>\n<ul>\n<li>V8 9.3 – more on that below.</li>\n<li>The native HTTP server API in now stable.</li>\n<li>Support for <code>self.structuredClone()</code>\n</li>\n<li>The system certificate support can now be used for TLS.</li>\n<li>TLS verification can be disabled if you need to.</li>\n<li>Improvements to the Deno language server and the VS Code extension.</li>\n<li>And, of course, <em>much more.</em>\n</li>\n</ul>\n  <p>The Deno Team </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112325/rss\" title=\"v8.dev\" style=\" color: #0c9d78; font-size: 1.05em;\">V8 Release v9.3</a></span> — Recent V8 releases have been reasonably lean on new features, and so it goes with 9.3 which mostly gets faster compilation, <code>Object.hasOwn</code> (an alias for <code>Object.prototype.​hasOwnProperty.​call</code>), and the ability to attach error ‘causes’ to <code>Error</code> instances. It’s in beta until Chrome 93 (due in the coming weeks) and while Node.js users have to wait a week or two, it's in Deno 1.13 right now!</p>\n  <p>Ingvar Stepanyan </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112326/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Pagic: A Static Site Generator Powered by Deno and React</a></span> — Aims to be simple to get up and running with a convention over configuration approach. <a href=\"https://denoweekly.com/link/112327/rss\" style=\" color: #0c9d78;\">Links to demos</a>.</p>\n  <p>xcatliu </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112328/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">gql: Universal GraphQL HTTP Middleware for Deno</a></span> — Well-tested, has examples and autogenerated docs. Unlike other sub middleware, this isn’t framework specific (it works with <code>std/http</code>, tinyhttp and Opine out of the box).</p>\n  <p>Deno Libraries </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112329/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">deno-dotenv 3.0: <code>.env</code> File Handling for Deno</a></span> — For when you want to dynamically load in environment variables.</p>\n  <p>Piet van Zoen </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112330/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Denoify 0.8.0: For NPM Module Authors Who Would Like to Support Deno</a></span> — Takes a TypeScript codebase targeting Node (or the Web) and returns a modified Deno module flavored version. 0.8 adds support for ES modules.</p>\n  <p>Garrone Joseph </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/112331/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Octokit.js 1.4.0: The All-Batteries-Included GitHub SDK</a></span> — Supports browsers, Node, and, yes, Deno.</p>\n  <p>Octokit </p>\n</td></tr></table>\n\n</div>\n  </td></tr>\n</table>\n\n\n\n\n<img src=\"https://denoweekly.com/open/31/rss\" width=\"1\" height=\"1\" />","contentSnippet":"August 12, 2021\n\n\nRead on the Web\n\n\n\n\n  \n  \nDeno 1.13 Released — This is truly a release of many small enhancements - enough so that we’re going to need some bulletpoints:\n\n\nV8 9.3 – more on that below.\nThe native HTTP server API in now stable.\nSupport for self.structuredClone()\n\nThe system certificate support can now be used for TLS.\nTLS verification can be disabled if you need to.\nImprovements to the Deno language server and the VS Code extension.\nAnd, of course, much more.\n\n\n  \nThe Deno Team \n\n\n  \n  \nV8 Release v9.3 — Recent V8 releases have been reasonably lean on new features, and so it goes with 9.3 which mostly gets faster compilation, Object.hasOwn (an alias for Object.prototype.​hasOwnProperty.​call), and the ability to attach error ‘causes’ to Error instances. It’s in beta until Chrome 93 (due in the coming weeks) and while Node.js users have to wait a week or two, it's in Deno 1.13 right now!\nIngvar Stepanyan \n\n\n  \n  \nPagic: A Static Site Generator Powered by Deno and React — Aims to be simple to get up and running with a convention over configuration approach. Links to demos.\nxcatliu \n\n\n  \n  \ngql: Universal GraphQL HTTP Middleware for Deno — Well-tested, has examples and autogenerated docs. Unlike other sub middleware, this isn’t framework specific (it works with std/http, tinyhttp and Opine out of the box).\nDeno Libraries \n\n\n  \n  \ndeno-dotenv 3.0: .env File Handling for Deno — For when you want to dynamically load in environment variables.\nPiet van Zoen \n\n\n  \n  \nDenoify 0.8.0: For NPM Module Authors Who Would Like to Support Deno — Takes a TypeScript codebase targeting Node (or the Web) and returns a modified Deno module flavored version. 0.8 adds support for ES modules.\nGarrone Joseph \n\n\n  \n  \nOctokit.js 1.4.0: The All-Batteries-Included GitHub SDK — Supports browsers, Node, and, yes, Deno.\nOctokit","guid":"https://denoweekly.com/issues/31","isoDate":"2021-08-12T00:00:00.000Z","timestamp":"8/11/2021"},{"title":"A fantastic Deno Deploy demo","link":"https://denoweekly.com/issues/30","pubDate":"Thu, 8 Jul 2021 00:00:00 +0000","content":"\n\n  \n\n    \n    \n    \n    \n    \n  \n\n\n\n\n<table border=0 cellpadding=0 cellspacing=0 align=\"center\" border=\"0\">\n  <tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <div>    \n    <table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr>\n<td align=\"left\" style=\"padding-left: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p>July 8, 2021</p></td>\n<td align=\"right\" style=\"padding-right: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p><a href=\"https://denoweekly.com/link/110817/rss\" style=\" color: #0c9d78;\">Read on the Web</a></p></td>\n</tr></table>\n<p><img src=\"https://res.cloudinary.com/cpress/image/upload/v1588847591/fpwgtmrg9m729db0lnwd.png\" width=\"250\" style=\"  margin-bottom: 0;     line-height: 100%; \"></p>\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <a href=\"https://denoweekly.com/link/110818/rss\" style=\" color: #0c9d78;\"><img src=\"https://res.cloudinary.com/cpress/image/upload/w_1280,e_sharpen:60/zvvmbvkdugzagvm3p77x.jpg\" width=\"640\" style=\"    line-height: 100%;    \"></a>\n</td></tr></table>\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\" font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"></td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\">▶  <a href=\"https://denoweekly.com/link/110818/rss\" title=\"www.youtube.com\" style=\" color: #0c9d78; font-size: 1.1em; line-height: 1.4em;\">Using Deno Deploy to Release Super Fast Cloud Functions</a></span> — Jack promises a look into the “potential JavaScript future” by building a chat app using Deno and deploying it on the <a href=\"https://denoweekly.com/link/110819/rss\" style=\" color: #0c9d78;\">Deno Deploy</a> platform. This is easy to understand and follow along with, and the approach taken feels so <em>natural.</em></p>\n  <p>Jack Herrington </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/110820/rss\" title=\"deno.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Deno Deploy Beta 1</a></span> — Deno Deploy is a multi-tenant JavaScript engine (running V8) operating in 25 data centers across the world to which you can quickly deploy Deno-based code.</p>\n  <p>Ryan Dahl </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/110821/rss\" title=\"justinwmckay.medium.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Obsidian 3.1: Native GraphQL Caching Client and Server Module</a></span> — Obsidian is Deno’s first native GraphQL caching client and server module. Boasting lightning-fast caching and fetching capabilities alongside headlining normalization and destructuring strategies, Obsidian is particularly optimized for use in server-side rendered React apps.</p>\n  <p>Justin McKay </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/110822/rss\" title=\"deno.com\" style=\" color: #0c9d78; font-size: 1.05em;\">How to Persist Data Using Firebase</a></span> — A new official tutorial on building a simple API that can persist data on Google’s Firebase platform.</p>\n  <p>Kitson Kelly </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/110823/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">DenoDB: A MySQL, SQLite, Postgres and MongoDB ORM</a></span></p>\n  <p>Arnaud Dellinger </p>\n</td></tr></table>\n\n</div>\n  </td></tr>\n</table>\n\n\n\n\n<img src=\"https://denoweekly.com/open/30/rss\" width=\"1\" height=\"1\" />","contentSnippet":"July 8, 2021\n\n\nRead on the Web\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n  \n▶  Using Deno Deploy to Release Super Fast Cloud Functions — Jack promises a look into the “potential JavaScript future” by building a chat app using Deno and deploying it on the Deno Deploy platform. This is easy to understand and follow along with, and the approach taken feels so natural.\nJack Herrington \n\n\n  \n  \nDeno Deploy Beta 1 — Deno Deploy is a multi-tenant JavaScript engine (running V8) operating in 25 data centers across the world to which you can quickly deploy Deno-based code.\nRyan Dahl \n\n\n  \n  \nObsidian 3.1: Native GraphQL Caching Client and Server Module — Obsidian is Deno’s first native GraphQL caching client and server module. Boasting lightning-fast caching and fetching capabilities alongside headlining normalization and destructuring strategies, Obsidian is particularly optimized for use in server-side rendered React apps.\nJustin McKay \n\n\n  \n  \nHow to Persist Data Using Firebase — A new official tutorial on building a simple API that can persist data on Google’s Firebase platform.\nKitson Kelly \n\n\n  \n  \nDenoDB: A MySQL, SQLite, Postgres and MongoDB ORM\nArnaud Dellinger","guid":"https://denoweekly.com/issues/30","isoDate":"2021-07-08T00:00:00.000Z","timestamp":"7/7/2021"},{"title":"Deno 1.11 brings a variety of improvements","link":"https://denoweekly.com/issues/29","pubDate":"Thu, 17 Jun 2021 00:00:00 +0000","content":"\n\n  \n\n    \n    \n    \n    \n    \n  \n\n\n\n\n<table border=0 cellpadding=0 cellspacing=0 align=\"center\" border=\"0\">\n  <tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <div>    \n    <table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr>\n<td align=\"left\" style=\"padding-left: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p>June 17, 2021</p></td>\n<td align=\"right\" style=\"padding-right: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p><a href=\"https://denoweekly.com/link/109798/rss\" style=\" color: #0c9d78;\">Read on the Web</a></p></td>\n</tr></table>\n<p><img src=\"https://res.cloudinary.com/cpress/image/upload/v1588847591/fpwgtmrg9m729db0lnwd.png\" width=\"250\" style=\"  margin-bottom: 0;     line-height: 100%; \"></p>\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/109799/rss\" title=\"deno.com\" style=\" color: #0c9d78; font-size: 1.1em; line-height: 1.4em;\">Deno 1.11 Released</a></span> — A variety of enhancements in this release:</p>\n<ul>\n   <li>The Deno project now supplies <a href=\"https://denoweekly.com/link/109800/rss\" style=\" color: #0c9d78;\">official Docker images</a>.</li>\n      <li>You can now abort <code>fetch</code> requests in a Web-compatible way.</li>\n         <li>Support for <code>crypto.subtle.digest</code> and <code>crypto.randomUUID</code>\n</li>\n            <li>\n<code>deno lint</code> is now considered stable.</li>\n               <li>\n<code>BroadcastChannel</code> brings support for broadcasting messages amongst Web Workers.</li>\n                  <li>\n<code>TextEncoderStream</code> and <code>TextDecoderStream</code> added.</li>\n      </ul>\n  <p>Deno Core Team </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\">▶  <a href=\"https://denoweekly.com/link/109801/rss\" title=\"changelog.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Exploring Deno Land 🦕 with Ryan Dahl</a></span> — Ryan Dahl, the original creator of Node.js and now Deno, went on the popular Changelog podcast to talk about how the success of Node changed his life and what led him to creating Deno.</p>\n  <p>The Changelog Podcast <span style=\"text-transform: uppercase; margin-left: 4px; font-size: 0.9em;  padding: 1px 4px; \">podcast</span></p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/109802/rss\" title=\"packup.deno.dev\" style=\" color: #0c9d78; font-size: 1.05em;\">Packup: A Web Application Bundler for Deno</a></span> — Formerly known as deno_parcel, this tool provides a Parcel-like bundling experience but for Deno.</p>\n  <p>Yoshiya Hinosawa </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/109804/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">milliparsec: A Small, Dependency Free Body Parsing Library</a></span> — Submitted by a reader, this originally for Node library came with the promise that <em>“Milliparsec is the tiniest body parser in the universe.”</em> Here’s the <a href=\"https://denoweekly.com/link/109803/rss\" style=\" color: #0c9d78;\">Node version.</a></p>\n  <p>v 1 r t l </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  <p><span style=\"font-weight: 600; font-size: 1.0em; color: #000;\"><a href=\"https://denoweekly.com/link/109806/rss\" style=\" color: #0c9d78;\">Velociraptor 1.0: <code>npm</code>-Style Script Runner for Deno</a></span> — <a href=\"https://denoweekly.com/link/109805/rss\" style=\" color: #0c9d78;\">GitHub repo.</a>\n  <br><span style=\"color: #5a5a5a; margin-top: 4px; text-transform: uppercase; font-size: 12px; line-height: 1.2em;\">JurassiScripts</span> \n  </p>\n</td></tr></table>\n\n</div>\n  </td></tr>\n</table>\n\n\n\n\n<img src=\"https://denoweekly.com/open/29/rss\" width=\"1\" height=\"1\" />","contentSnippet":"June 17, 2021\n\n\nRead on the Web\n\n\n\n\n  \n  \nDeno 1.11 Released — A variety of enhancements in this release:\nThe Deno project now supplies official Docker images.\nYou can now abort fetch requests in a Web-compatible way.\nSupport for crypto.subtle.digest and crypto.randomUUID\n\n            \ndeno lint is now considered stable.\nBroadcastChannel brings support for broadcasting messages amongst Web Workers.\nTextEncoderStream and TextDecoderStream added.\nDeno Core Team \n\n\n  \n  \n▶  Exploring Deno Land 🦕 with Ryan Dahl — Ryan Dahl, the original creator of Node.js and now Deno, went on the popular Changelog podcast to talk about how the success of Node changed his life and what led him to creating Deno.\nThe Changelog Podcast podcast\n\n\n  \n  \nPackup: A Web Application Bundler for Deno — Formerly known as deno_parcel, this tool provides a Parcel-like bundling experience but for Deno.\nYoshiya Hinosawa \n\n\n  \n  \nmilliparsec: A Small, Dependency Free Body Parsing Library — Submitted by a reader, this originally for Node library came with the promise that “Milliparsec is the tiniest body parser in the universe.” Here’s the Node version.\nv 1 r t l \n\n\n  \nVelociraptor 1.0: npm-Style Script Runner for Deno — GitHub repo.\n  \nJurassiScripts","guid":"https://denoweekly.com/issues/29","isoDate":"2021-06-17T00:00:00.000Z","timestamp":"6/16/2021"},{"title":"Deno 1.10 released","link":"https://denoweekly.com/issues/28","pubDate":"Thu, 13 May 2021 00:00:00 +0000","content":"\n\n  \n\n    \n    \n    \n    \n    \n  \n\n\n\n\n<table border=0 cellpadding=0 cellspacing=0 align=\"center\" border=\"0\">\n  <tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <div>    \n    <table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr>\n<td align=\"left\" style=\"padding-left: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p>May 13, 2021</p></td>\n<td align=\"right\" style=\"padding-right: 4px; font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \"><p><a href=\"https://denoweekly.com/link/107907/rss\" style=\" color: #0c9d78;\">Read on the Web</a></p></td>\n</tr></table>\n<p><img src=\"https://res.cloudinary.com/cpress/image/upload/v1588847591/fpwgtmrg9m729db0lnwd.png\" width=\"250\" style=\"  margin-bottom: 0;     line-height: 100%; \"></p>\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;   \">\n  <a href=\"https://denoweekly.com/link/107909/rss\" style=\" color: #0c9d78;\"><img src=\"https://res.cloudinary.com/cpress/image/upload/w_1280,e_sharpen:60/oyfssaormlrgidkzbdd8.jpg\" width=\"640\" style=\"    line-height: 100%;    \"></a>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107909/rss\" title=\"deno.com\" style=\" color: #0c9d78; font-size: 1.1em; line-height: 1.4em;\">Deno 1.10 Released</a></span> — A nice evolutionary bump for Deno this week:\n</p>\n<ul>\n<li>Web Storage API added. Yes, you now get <code>localStorage</code> and <code>sessionStorage</code> and they work much like in the browser.</li>\n<li>Support for remote import maps.</li>\n<li>Improvements to the test runner (more on that below).</li>\n</ul>\n  <p>The Deno Team </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107908/rss\" title=\"caspervonb.medium.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Rewriting Deno’s Testing Tools</a></span> — Casper has been busy “re-thinking Deno’s testing tools” and has some results to show us, including a parallel test runner (written in Rust), per test case permissions, improved output, and more - much of which shipped in Deno 1.10 (above).</p>\n  <p>Casper Beyer </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107910/rss\" title=\"www.reddit.com\" style=\" color: #0c9d78; font-size: 1.05em;\">How Has Your Experience with Deno Been So Far?</a></span> — A discussion on the /r/javascript subreddit.</p>\n  <p>Reddit </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107911/rss\" title=\"twitter.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Testable JavaScript/TypeScript Documentation Code Blocks Coming to Deno Soon</a></span></p>\n  <p>Casper Beyer on Twitter </p>\n</td></tr></table>\n<div style=\"   margin-top: 14px; margin-bottom: 8px;  \"></div>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n<p>Useful Resources</p>\n    <p>We're going to keep some links to perennially useful posts and resources down here just while everyone is getting up to speed with the Deno community. There's nothing new here, so if you want to skip them – no problem! :-)</p>\n    </td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107912/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">awesome-deno: A Curated List of Things Related to Deno</a></span></p>\n  <p>DenoLib </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107913/rss\" title=\"deno.land\" style=\" color: #0c9d78; font-size: 1.05em;\">The Deno Third Party Modules Directory</a></span> — Deno has its own official code hosting service for Deno libraries.</p>\n  <p>Deno </p>\n</td></tr></table>\n\n<table border=0 cellpadding=0 cellspacing=0 border=0 cellpadding=0 cellspacing=0><tr><td style=\"font-family: -apple-system,BlinkMacSystemFont,Helvetica,sans-serif; font-size: 15px; line-height: 1.55em;    padding: 0px 15px;\">\n  \n  <p><span style=\"font-weight: 600; font-size: 1.1em; color: #000;\"><a href=\"https://denoweekly.com/link/107914/rss\" title=\"github.com\" style=\" color: #0c9d78; font-size: 1.05em;\">Deno Docker: Latest Dockerfiles and Images for Deno</a></span> — Grab some Docker files here covering Alpine Linux, CentOS, Debian and Ubuntu.</p>\n  <p>Andy Hayden </p>\n</td></tr></table>\n\n</div>\n  </td></tr>\n</table>\n\n\n\n\n<img src=\"https://denoweekly.com/open/28/rss\" width=\"1\" height=\"1\" />","contentSnippet":"May 13, 2021\n\n\nRead on the Web\n\n\n\n\n  \n\n\n\n\n\n  \n  \nDeno 1.10 Released — A nice evolutionary bump for Deno this week:\n\n\nWeb Storage API added. Yes, you now get localStorage and sessionStorage and they work much like in the browser.\nSupport for remote import maps.\nImprovements to the test runner (more on that below).\nThe Deno Team \n\n\n  \n  \nRewriting Deno’s Testing Tools — Casper has been busy “re-thinking Deno’s testing tools” and has some results to show us, including a parallel test runner (written in Rust), per test case permissions, improved output, and more - much of which shipped in Deno 1.10 (above).\nCasper Beyer \n\n\n  \n  \nHow Has Your Experience with Deno Been So Far? — A discussion on the /r/javascript subreddit.\nReddit \n\n\n  \n  \nTestable JavaScript/TypeScript Documentation Code Blocks Coming to Deno Soon\nCasper Beyer on Twitter \n\n\n\n\n\nUseful Resources\nWe're going to keep some links to perennially useful posts and resources down here just while everyone is getting up to speed with the Deno community. There's nothing new here, so if you want to skip them – no problem! :-)\n\n\n  \n  \nawesome-deno: A Curated List of Things Related to Deno\nDenoLib \n\n\n  \n  \nThe Deno Third Party Modules Directory — Deno has its own official code hosting service for Deno libraries.\nDeno \n\n\n  \n  \nDeno Docker: Latest Dockerfiles and Images for Deno — Grab some Docker files here covering Alpine Linux, CentOS, Debian and Ubuntu.\nAndy Hayden","guid":"https://denoweekly.com/issues/28","isoDate":"2021-05-13T00:00:00.000Z","timestamp":"5/12/2021"}],"title":"Deno Weekly","description":"A weekly roundup of news, tutorials and projects from the land of <a href='https://deno.land/'>Deno</a>, the newest JavaScript runtime on the block.","link":"https://denoweekly.com/","feed":"https://cprss.s3.amazonaws.com/denoweekly.com.xml"},{"items":[{"title":"Ready, set, multi-platform","link":"https://increment.com/mobile/ready-set-multi-platform/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"Tips for picking your stack, shoring up your foundations, and scaling with grace.","contentSnippet":"Tips for picking your stack, shoring up your foundations, and scaling with grace.","guid":"https://increment.com/mobile/ready-set-multi-platform/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Meet the microapps architecture","link":"https://increment.com/mobile/microapps-architecture/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"How an emerging architecture pattern inspired by microservices can invigorate feature development and amplify developer velocity.","contentSnippet":"How an emerging architecture pattern inspired by microservices can invigorate feature development and amplify developer velocity.","guid":"https://increment.com/mobile/microapps-architecture/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"The building blocks of scale","link":"https://increment.com/mobile/scaling-mobile-development-teams/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"A discussion of the fundamentals of flexible, extensible mobile teams.","contentSnippet":"A discussion of the fundamentals of flexible, extensible mobile teams.","guid":"https://increment.com/mobile/scaling-mobile-development-teams/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"A primer on automated mobile testing","link":"https://increment.com/mobile/automated-mobile-testing/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"Insights for teams looking to tailor their test suites and build apps that just work.","contentSnippet":"Insights for teams looking to tailor their test suites and build apps that just work.","guid":"https://increment.com/mobile/automated-mobile-testing/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Write once, run anywhere?","link":"https://increment.com/mobile/write-once-run-anywhere/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"What a migration to Kotlin Multiplatform taught Quizlet about the nuances of cross-platform development.","contentSnippet":"What a migration to Kotlin Multiplatform taught Quizlet about the nuances of cross-platform development.","guid":"https://increment.com/mobile/write-once-run-anywhere/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Open-source excursions: Views from the mobile stack","link":"https://increment.com/mobile/open-source-mobile-technologies/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"Exploring the emerging possibilities for open-source mobile hardware and software.","contentSnippet":"Exploring the emerging possibilities for open-source mobile hardware and software.","guid":"https://increment.com/mobile/open-source-mobile-technologies/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Best practices for building accessible mobile apps","link":"https://increment.com/mobile/best-practices-for-building-accessible-mobile-apps/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"An overview of the mindset, strategies, and tools that will help you create apps that truly work for everyone.","contentSnippet":"An overview of the mindset, strategies, and tools that will help you create apps that truly work for everyone.","guid":"https://increment.com/mobile/best-practices-for-building-accessible-mobile-apps/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"The new shiny","link":"https://increment.com/mobile/the-shift-to-declarative-ui/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"On the shift from imperative to declarative UI, and what it might mean for the apps we build today and tomorrow.","contentSnippet":"On the shift from imperative to declarative UI, and what it might mean for the apps we build today and tomorrow.","guid":"https://increment.com/mobile/the-shift-to-declarative-ui/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"The process: Bringing Textio to the mobile web","link":"https://increment.com/mobile/bringing-textio-to-the-mobile-web/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"How engineers unraveled a glitchy Android experience and shipped an intuitive augmented writing tool for mobile browsers.","contentSnippet":"How engineers unraveled a glitchy Android experience and shipped an intuitive augmented writing tool for mobile browsers.","guid":"https://increment.com/mobile/bringing-textio-to-the-mobile-web/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"How to make games and influence the industry","link":"https://increment.com/mobile/china-mobile-game-industry/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"What can the success of China’s mobile gaming industry teach developers around the world? ","contentSnippet":"What can the success of China’s mobile gaming industry teach developers around the world?","guid":"https://increment.com/mobile/china-mobile-game-industry/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"And then there were smartphones","link":"https://increment.com/mobile/history-of-smartphones/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"A tale of battleship-gray bricks, stylus-operated PDAs, and successive momentous shifts in the mobile industry.","contentSnippet":"A tale of battleship-gray bricks, stylus-operated PDAs, and successive momentous shifts in the mobile industry.","guid":"https://increment.com/mobile/history-of-smartphones/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Of wireless telegraphy, Model Ts, and mobile devices","link":"https://increment.com/mobile/sociotechnical-change-and-mobile-innovation/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"To catalyze transformative innovation, consider the history of sociotechnical change, the user as innovator, and the impact of technologies’ relationships to the past. ","contentSnippet":"To catalyze transformative innovation, consider the history of sociotechnical change, the user as innovator, and the impact of technologies’ relationships to the past.","guid":"https://increment.com/mobile/sociotechnical-change-and-mobile-innovation/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Apps on demand","link":"https://increment.com/mobile/streaming-apps/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"Offering bite-sized, no-download access to key app features, streaming apps may be an idea whose time has come.","contentSnippet":"Offering bite-sized, no-download access to key app features, streaming apps may be an idea whose time has come.","guid":"https://increment.com/mobile/streaming-apps/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Mobile development at scale","link":"https://increment.com/mobile/mobile-development-at-scale/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"Engineering leaders at adidas Runtastic, Eventbrite, and Citymapper discuss app performance, how mobile fits into their org structures, and native versus cross-platform development.","contentSnippet":"Engineering leaders at adidas Runtastic, Eventbrite, and Citymapper discuss app performance, how mobile fits into their org structures, and native versus cross-platform development.","guid":"https://increment.com/mobile/mobile-development-at-scale/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Ask an expert: How can mobile teams best use feature flags?","link":"https://increment.com/mobile/feature-flags-mobile-development/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"CreatorStack’s Pooja Bhaumik shares how to reap the benefits—without the codebase bloat.","contentSnippet":"CreatorStack’s Pooja Bhaumik shares how to reap the benefits—without the codebase bloat.","guid":"https://increment.com/mobile/feature-flags-mobile-development/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Interview: Claire Sibthorpe","link":"https://increment.com/mobile/claire-sibthorpe-interview/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"The GSM Association’s head of connected women, connected society, and assistive technology discusses the impact mobile devices have had on the lives of marginalized women and what technology companies can do to further mobile equity.","contentSnippet":"The GSM Association’s head of connected women, connected society, and assistive technology discusses the impact mobile devices have had on the lives of marginalized women and what technology companies can do to further mobile equity.","guid":"https://increment.com/mobile/claire-sibthorpe-interview/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Letter from the editor","link":"https://increment.com/mobile/letter-from-the-editor/","pubDate":"Thu, 26 Aug 2021 10:00:00 GMT","content":"","contentSnippet":"","guid":"https://increment.com/mobile/letter-from-the-editor/","isoDate":"2021-08-26T10:00:00.000Z","timestamp":"8/26/2021"},{"title":"Containers in the keep","link":"https://increment.com/containers/defense-in-depth-container-security/","pubDate":"Thu, 27 May 2021 19:00:00 GMT","content":"Like the fortifications of a medieval castle, the multilayered practice of defense in depth can help protect your containers—no moats, drawbridges, or dragons required.","contentSnippet":"Like the fortifications of a medieval castle, the multilayered practice of defense in depth can help protect your containers—no moats, drawbridges, or dragons required.","guid":"https://increment.com/containers/defense-in-depth-container-security/","isoDate":"2021-05-27T19:00:00.000Z","timestamp":"5/27/2021"},{"title":"A primer on containers","link":"https://increment.com/containers/primer-on-containerization/","pubDate":"Thu, 27 May 2021 19:00:00 GMT","content":"On core technologies, the engineering needs they’re best suited to serve, and possibilities for the containerized future.","contentSnippet":"On core technologies, the engineering needs they’re best suited to serve, and possibilities for the containerized future.","guid":"https://increment.com/containers/primer-on-containerization/","isoDate":"2021-05-27T19:00:00.000Z","timestamp":"5/27/2021"},{"title":"Leadership as migration strategy","link":"https://increment.com/containers/container-migrations-and-leadership/","pubDate":"Thu, 27 May 2021 19:00:00 GMT","content":"People-centered considerations for teams discussing a container migration, and the leaders supporting them.","contentSnippet":"People-centered considerations for teams discussing a container migration, and the leaders supporting them.","guid":"https://increment.com/containers/container-migrations-and-leadership/","isoDate":"2021-05-27T19:00:00.000Z","timestamp":"5/27/2021"}],"feedUrl":"https://increment.com/feed.xml","paginationLinks":{"self":"https://increment.com/feed.xml"},"title":"Increment","description":"A digital magazine about how teams build and operate software systems at scale.","link":"https://increment.com","feed":"https://increment.com/feed.xml"},{"items":[{"title":"Fundamentals of music: week 3","link":"https://merelycurious.me/post/coursera-fundamentals-of-music-week-3","pubDate":"2020-04-18T16:00:00.000Z","author":"","content":"<p>Rhythm and form.\n<!--more--></p>\n\n<p>We can imagine pitch as Y axis and time as X axis.</p>\n\n<h2 id=\"note-durations\">Note durations</h2>\n\n<p>In western notation note duration is always expressed as fraction\nof beat rather than in seconds:</p>\n\n<p>(illustrations are from <a href=\"https://en.wikipedia.org/wiki/List_of_musical_symbols#Time_signatures\">Wikipedia</a>)</p>\n\n<ul>\n  <li>\n    <p>Semibreve (whole note in US) - full duration of one bar in 4/4 meter.\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/Music-wholenote.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>Minim (half note) - semibreve / 2\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-halfnote.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>Crotchet (quarter note) - semibreve / 4\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-quarternote.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>Quaver (eighth note) - semibreve / 8\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-eighthnote.svg.webp\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>Semiquaver (sixteenth note) - semibreve / 16\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-sixteenthnote.svg.webp\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>Demisemiquaver (thirty-second note) - semibreve / 32\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-thirtysecondnote.svg.webp\" alt=\"\" /></p>\n  </li>\n</ul>\n\n<p>The same we can do with pauses - rests:</p>\n\n<ul>\n  <li>\n    <p>1 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-wholerest.svg.webp\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>1/2 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-halfrest.svg.webp\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>1/4 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Crochet2.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>1/8 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-eighthrest.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>1/16 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-sixteenthrest.svg.png\" alt=\"\" /></p>\n  </li>\n  <li>\n    <p>1/32 - \n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-thirtysecondrest.svg.png\" alt=\"\" /></p>\n  </li>\n</ul>\n\n<h3 id=\"beams\">Beams</h3>\n\n<p>Notes with “flags” can be joined using a beam\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-beam.svg.webp\" alt=\"\" /></p>\n\n<p>This can ease reading.</p>\n\n<h3 id=\"tuplets\">Tuplets</h3>\n\n<p>Occasionally we need to subdivide rhythm differently, we can use\ntuples e.g. for 3 notes in 2:\n<img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-triplet.svg.png\" alt=\"\" /></p>\n\n<p>These actually changes duration of these notes. Basically this notation\nsays play 3 notes in 2 quarter notes, so duration of this modified\nquarter note is 2/3 of an ordinary one.</p>\n\n<h3 id=\"extensions\">Extensions</h3>\n\n<p>We can extend note duration.</p>\n\n<p>Either using a tie:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-tie.svg.png\" alt=\"\" /></p>\n\n<p>There can be multiple ties in a row. Tie means - play the first note\nwith the duration = sum of all tied notes.</p>\n\n<p>Or using dotted note:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-dotnote.svg.webp\" alt=\"\" /></p>\n\n<p>This means play the note with duration = its ordinary duration + half. One can\nuse multiple dots, each dot adds another halved period. It is important\nthat the dot is on the side (dots in other locations mean other stuff).</p>\n\n<p>One can mark a note using Fermata - out of time pause:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_3/100px-Music-fermata.svg.png\" alt=\"\" /></p>\n\n<p>The performer decides on their own how long the pause should be.\nRule of thumb - twice of the note duration.</p>\n\n<h2 id=\"meter\">Meter</h2>\n\n<h3 id=\"simple\">Simple</h3>\n\n<ul>\n  <li>Duple - 2 beats per bar.</li>\n  <li>Triple - 3 beats per bar.</li>\n  <li>Quadruple - 4 beats per bar (aka common time)</li>\n</ul>\n\n<p>Time signature is written as a fraction. Numerator is “beats per bar”\nand denominator is “beat type”. In other words denominator defines\nnote type (i.e. duration) by giving its bar fraction, e.g. 4 means\nquarter. Numerator tells how many such notes are there per one bar.</p>\n\n<p>Beats can be weak and strong. \nIn 4/4 usually 1 and 3 are strong.</p>\n\n<p>Beats are subdivided into two.</p>\n\n<h3 id=\"compound\">Compound</h3>\n\n<p>Beats are subdivided into three.</p>\n\n<p>Usually denominator is 8 and numerator mod 3 = 0.</p>\n\n<h2 id=\"form\">Form</h2>\n\n<p>Anacrusis - unstressed notes before the first bar line of a piece (can be one note aka pickup note).</p>\n\n<p>Phrase - complete piece (e.g. 4 bars or one breath etc).</p>\n\n<p>Rhythms are combined into beats, beats into bars, phrases,\nperiods, sections, movements (or songs), symphonies or concertos (or albums).</p>\n\n<p>Motive - is an isolated short musical phrase.</p>\n\n<h3 id=\"combining-sections\">Combining sections</h3>\n\n<p>Binary form - A B (usually B is in different key)</p>\n\n<p>Ternary - A B A or A B A’ (sonata, A’ means A modified).\nExposition -&gt; development -&gt; recapitulation</p>\n\n<p>Rondo form ABACA</p>\n\n<p>There is 12 bar blues.</p>","contentSnippet":"Rhythm and form.\n\nWe can imagine pitch as Y axis and time as X axis.\nNote durations\nIn western notation note duration is always expressed as fraction\nof beat rather than in seconds:\n(illustrations are from Wikipedia)\nSemibreve (whole note in US) - full duration of one bar in 4/4 meter.\n\nMinim (half note) - semibreve / 2\n\nCrotchet (quarter note) - semibreve / 4\n\nQuaver (eighth note) - semibreve / 8\n\nSemiquaver (sixteenth note) - semibreve / 16\n\nDemisemiquaver (thirty-second note) - semibreve / 32\n\nThe same we can do with pauses - rests:\n1 - \n\n1/2 - \n\n1/4 - \n\n1/8 - \n\n1/16 - \n\n1/32 - \n\nBeams\nNotes with “flags” can be joined using a beam\n\nThis can ease reading.\nTuplets\nOccasionally we need to subdivide rhythm differently, we can use\ntuples e.g. for 3 notes in 2:\n\nThese actually changes duration of these notes. Basically this notation\nsays play 3 notes in 2 quarter notes, so duration of this modified\nquarter note is 2/3 of an ordinary one.\nExtensions\nWe can extend note duration.\nEither using a tie:\n\nThere can be multiple ties in a row. Tie means - play the first note\nwith the duration = sum of all tied notes.\nOr using dotted note:\n\nThis means play the note with duration = its ordinary duration + half. One can\nuse multiple dots, each dot adds another halved period. It is important\nthat the dot is on the side (dots in other locations mean other stuff).\nOne can mark a note using Fermata - out of time pause:\n\nThe performer decides on their own how long the pause should be.\nRule of thumb - twice of the note duration.\nMeter\nSimple\nDuple - 2 beats per bar.\nTriple - 3 beats per bar.\nQuadruple - 4 beats per bar (aka common time)\nTime signature is written as a fraction. Numerator is “beats per bar”\nand denominator is “beat type”. In other words denominator defines\nnote type (i.e. duration) by giving its bar fraction, e.g. 4 means\nquarter. Numerator tells how many such notes are there per one bar.\nBeats can be weak and strong. \nIn 4/4 usually 1 and 3 are strong.\nBeats are subdivided into two.\nCompound\nBeats are subdivided into three.\nUsually denominator is 8 and numerator mod 3 = 0.\nForm\nAnacrusis - unstressed notes before the first bar line of a piece (can be one note aka pickup note).\nPhrase - complete piece (e.g. 4 bars or one breath etc).\nRhythms are combined into beats, beats into bars, phrases,\nperiods, sections, movements (or songs), symphonies or concertos (or albums).\nMotive - is an isolated short musical phrase.\nCombining sections\nBinary form - A B (usually B is in different key)\nTernary - A B A or A B A’ (sonata, A’ means A modified).\nExposition -> development -> recapitulation\nRondo form ABACA\nThere is 12 bar blues.","summary":"Rhythm and form.","id":"https://merelycurious.me/post/coursera_fundamentals_of_music_week_3","isoDate":"2020-04-18T16:00:00.000Z","timestamp":"4/18/2020"},{"title":"Unexpected lesson from checking portfolio in crisis","link":"https://merelycurious.me/post/checking-portfolio-in-crisis","pubDate":"2020-04-18T15:00:00.000Z","author":"","content":"<p>As you all know, the stock market is down. Even though I knew this,\nI’ve had a peculiar experience recently, when checking my portfolio.</p>\n\n<!--more-->\n\n<h2 id=\"happiness\">Happiness</h2>\n\n<p>Basically I knew that everything should be 20-30% down and this was\nperfectly fine with me. I obviously had nagging thoughts: “You should\ntime it, let’s sell, it’s going to fall more, let’s sell”, but I\nsuccessfully managed to shoo them away. Then one day I needed to log\nstate of my portfolio (I try to do this monthly). Once I did this,\nI was surprised how much money I was missing. It was much more than\nI expected. After a brief calculation, I confirmed that this was\naround 25% and then I understood that I just have a lot of money.\nSomehow my brain was ok with 30% down, but never translated that\ninto absolute amounts. Even though I was “missing” quite a chunk of my\nportfolio, understanding that I had money in the first place (and I still\nhave quite a lot left) made me super happy.</p>\n\n<h2 id=\"lesson\">Lesson</h2>\n\n<p>Try to find positive side. These are challenging times, but our \nhedonic adaptation will kick in very fast (mine has done so\nalready). In the end, it is a good opportunity to be even happier\nthan before, since you get a very different view. Even\nsmall stuff like having a walk feels super cool and makes me so\nhappy, especially when understanding that I may have no such\nopportunity in the future. The same can be applied in the future to everything you\nare missing now. Meeting friends? Going to restaurants? Yeap, it\nsucks, but once everything is back, it is will be super special and\npleasant.</p>\n\n<p>As a trick, I also suggest you to prepare yourself morally to \nliving in such mode e.g. for a year or two. This way it just becomes\nnew normal, you get used, everything becomes fine. Once there are \nimprovements you get happy, because stuff becomes better than your normal.\nIf you keep “when will this shit be over?” mode, this sets your mood to be negative.\nBasically, you say that this is not normal and even\nworse then normal and you are waiting (=suffer), i.e. unhappy. Once\nit gets back to normal, you will probably feel better, but not that\nmuch, since you just get back to your old normal.</p>\n\n<p>Happy setting proper reference points!</p>","contentSnippet":"As you all know, the stock market is down. Even though I knew this,\nI’ve had a peculiar experience recently, when checking my portfolio.\nHappiness\nBasically I knew that everything should be 20-30% down and this was\nperfectly fine with me. I obviously had nagging thoughts: “You should\ntime it, let’s sell, it’s going to fall more, let’s sell”, but I\nsuccessfully managed to shoo them away. Then one day I needed to log\nstate of my portfolio (I try to do this monthly). Once I did this,\nI was surprised how much money I was missing. It was much more than\nI expected. After a brief calculation, I confirmed that this was\naround 25% and then I understood that I just have a lot of money.\nSomehow my brain was ok with 30% down, but never translated that\ninto absolute amounts. Even though I was “missing” quite a chunk of my\nportfolio, understanding that I had money in the first place (and I still\nhave quite a lot left) made me super happy.\nLesson\nTry to find positive side. These are challenging times, but our \nhedonic adaptation will kick in very fast (mine has done so\nalready). In the end, it is a good opportunity to be even happier\nthan before, since you get a very different view. Even\nsmall stuff like having a walk feels super cool and makes me so\nhappy, especially when understanding that I may have no such\nopportunity in the future. The same can be applied in the future to everything you\nare missing now. Meeting friends? Going to restaurants? Yeap, it\nsucks, but once everything is back, it is will be super special and\npleasant.\nAs a trick, I also suggest you to prepare yourself morally to \nliving in such mode e.g. for a year or two. This way it just becomes\nnew normal, you get used, everything becomes fine. Once there are \nimprovements you get happy, because stuff becomes better than your normal.\nIf you keep “when will this shit be over?” mode, this sets your mood to be negative.\nBasically, you say that this is not normal and even\nworse then normal and you are waiting (=suffer), i.e. unhappy. Once\nit gets back to normal, you will probably feel better, but not that\nmuch, since you just get back to your old normal.\nHappy setting proper reference points!","summary":"As you all know, the stock market is down. Even though I knew this, I’ve had a peculiar experience recently, when checking my portfolio.","id":"https://merelycurious.me/post/checking_portfolio_in_crisis","isoDate":"2020-04-18T15:00:00.000Z","timestamp":"4/18/2020"},{"title":"Fundamentals of music: week 1","link":"https://merelycurious.me/post/coursera-fundamentals-of-music-week-1","pubDate":"2020-04-18T15:00:00.000Z","author":"","content":"<p>I started taking <a href=\"https://www.coursera.org/learn/edinburgh-music-theory\">“Fundamentals of Music Theory “ on Coursera</a>.\nSummary of week 1. So far there are a lot of stuff “just by definition”,\nso I honestly felt a need to wrote a summary to structure everything in\nmy head (since I already forgot quite a lot).</p>\n\n<!--more-->\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>We can compare sounds and we call them low and high. Some sounds\nwe can’t sing. For the ones we can, we say they have pitch.</p>\n\n<p>We denote notes using letters A, B, C, D, E, F, G.\nThis is our music alphabet.</p>\n\n<h3 id=\"notation\">Notation</h3>\n\n<p>One can write relative changes in pitch, but this is still ambiguous\nfor a reader, if they don’t know any absolute value. Thus, monks\nstruggled with writing down and transmitting melodies. As a result,\nstave notation was born.</p>\n\n<p>Stave is based on 5 horizontal lines. A symbol on the left\nis called G-clef or Treble-clef. It circles itself on line representing\nnote G. Each line and space between lines represent a note (a white\nkey on piano keyboard).</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/1_notes.png\" alt=\"stave with notes\" /></p>\n\n<p>Mnemonics:</p>\n<ul>\n  <li>spaces between lines starting from bottom - F A C E</li>\n  <li>lines starting from bottom - Every Good Boy Deserves Fruit</li>\n</ul>\n\n<p>One can add additional lines when leaving stave’s range.\nE.g. middle C is the first line under the stave.</p>\n\n<p>However, we have 12 pitches on guitar (i.e. also black keys on\npiano keyboard) in one octave.</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/2_piano_notes.png\" alt=\"stave with notes and piano keys\" /></p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/3_piano_notes_horizontal.png\" alt=\"stave with notes and piano keys (horizontal)\" /></p>\n\n<h2 id=\"intervals\">Intervals</h2>\n\n<p>Octave - interval between (and including) two notes, one having twice\nor half the vibration frequency of the other.</p>\n\n<p>Semitone - distance between two adjacent keys on piano.</p>\n\n<p>Tone = 2 semitones.</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/4_tones_semitones.png\" alt=\"tones and semitones on piano keys\" /></p>\n\n<p>Let’s call one line or space in stave - a unit. \nWe say that interval between two notes is “a second” if \nthere are no units between them on the stave (i.e. this is a line\nand its adjacent space).</p>\n\n<p>When there is one unit - “a third” (\ni.e. two lines with one space in between or two spaces with one line).</p>\n\n<p>Here comes a bit confusing part. F to G is a second. C to B is a\nsecond. There is a black key between F and G, but not between C &amp; B.\nNevertheless both are called - “a second”.</p>\n\n<h2 id=\"scales\">Scales</h2>\n\n<p>Scale - a pathway through octave.</p>\n\n<p>Example - C Major (we just go through notes one by one)</p>\n\n<p>C &lt;T&gt; D &lt;T&gt; E &lt;S&gt; F &lt;T&gt; G &lt;T&gt; A &lt;T&gt;&gt; B &lt;S&gt; C</p>\n\n<p>where &lt;T&gt; is a tone and &lt;S&gt; is a semitone.</p>\n\n<p>C is called a tonic.</p>\n\n<p>Sequence TTSTTTS defines “quality of scale”.\nThis one belongs to Diatonic Scale (because it has\n5 tones and 2 semitones).</p>\n\n<p>There are different approaches in the world, this one is so called\ncommon practice, i.e. Western Europe 1600-1900.</p>\n\n<p>If we take A as a tonic and again go through notes one by one, we get natural minor scale</p>\n\n<p>A &lt;T&gt; B &lt;S&gt; C &lt;T&gt; D &lt;T&gt; E &lt;S&gt; F &lt;T&gt; G &lt;T&gt; A</p>\n\n<p>i.e. the sequence of T’s and S’s is different from major\nThis is still Diatonic Scale (still 5 T and 2 S).\nThe sequence itself is called Aeolian mode.</p>\n\n<p>When starting from D, we get Dorian mode</p>\n\n<p>D &lt;T&gt; E &lt;S&gt; F &lt;T&gt; G &lt;T&gt; A &lt;T&gt; B &lt;S&gt; C &lt;T&gt; D</p>\n\n<p>E -&gt; Phrygian</p>\n\n<p>E &lt;S&gt; F &lt;T&gt; G &lt;T&gt; A &lt;T&gt; B &lt;S&gt; C &lt;T&gt; D &lt;T&gt; E</p>\n\n<p>Basically we just traverse the stave starting from a note and write\ndown all the notes we meet on our way.</p>\n\n<p>F -&gt; Lydian.</p>\n\n<p>G -&gt; Mixolydian (also 5th degree of C Major, interval between C and G\nis a fifth).</p>\n\n<p>B -&gt; Locrian mode.</p>\n\n<h2 id=\"chords\">Chords</h2>\n\n<p>Let’s take a piece of natural minor scale</p>\n\n<p>A B C D E</p>\n\n<p>and count semitones</p>\n\n<p>A &lt;T - 1 2&gt; B &lt;S - 3&gt; C &lt;T - 4 5&gt; D &lt;T - 6 7&gt; E</p>\n\n<p>We can do the same for C Major</p>\n\n<p>C &lt;T - 1 2&gt; D &lt;T 3 4&gt; E &lt;S 5&gt; F &lt;T 6 7&gt; G</p>\n\n<p>7 semitones = perfect fifth</p>\n\n<p>A -&gt; C = a minor third (3 semitones)</p>\n\n<p>C -&gt; E = a major third (4 semitones)</p>\n\n<p>C Major chord is C E G (C major triad).</p>\n\n<p>Triad = three notes.</p>\n\n<p>Abbreviations:</p>\n<ul>\n  <li>C Major = C, Cmaj, CM</li>\n  <li>A Minor = Amin, Am, A-</li>\n</ul>\n\n<p>One can construct a major triad by taking major third and perfect\nfifth (i.e. a note 4 semitones away and a note 7 semitones away).</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/5_c_maj.png\" alt=\"c maj on piano keys\" /></p>\n\n<p>For a minor triad - minor third (3 semitones) + perfect fifth\n(7 semitones).</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_1/6_a_min.png\" alt=\"a min on piano keys\" /></p>\n\n<p>There is also Diminished Triad (B0 Bdim) = Minor third (3 semitones) + Diminished Fifth (6 semitones).</p>\n\n<p>Note that “third” and “fifth” are taken from the stave, but whether\nit is “perfect”, “minor”, “diminished” is based on the underlying \nnotes. I.e. we take C, count one stave unit, get E, count another\nstave unit - get G. Now we can count semitones and identify whether\nthis is maj, min or dim.</p>\n\n<p>If we repeat taking third and fifth from every note, we get:</p>\n\n<p>Cmaj Dmin Emin Fmaj Gmaj Amin Bdim</p>\n\n<h3 id=\"three-chord-trick\">Three Chord Trick</h3>\n\n<p>C, F and G work well together.</p>\n\n<ul>\n  <li>C - tonic triad (I)</li>\n  <li>F - subdominant (IV) - the tonic is domimant of the subdomimant. It is\nas far below the tonic as domimant is above.</li>\n  <li>G - 5th degree (C -&gt; G is a fifth) - dominant (V)</li>\n</ul>\n\n<p>You can harmonize notes with chords which have it.</p>","contentSnippet":"I started taking “Fundamentals of Music Theory “ on Coursera.\nSummary of week 1. So far there are a lot of stuff “just by definition”,\nso I honestly felt a need to wrote a summary to structure everything in\nmy head (since I already forgot quite a lot).\nNotes\nWe can compare sounds and we call them low and high. Some sounds\nwe can’t sing. For the ones we can, we say they have pitch.\nWe denote notes using letters A, B, C, D, E, F, G.\nThis is our music alphabet.\nNotation\nOne can write relative changes in pitch, but this is still ambiguous\nfor a reader, if they don’t know any absolute value. Thus, monks\nstruggled with writing down and transmitting melodies. As a result,\nstave notation was born.\nStave is based on 5 horizontal lines. A symbol on the left\nis called G-clef or Treble-clef. It circles itself on line representing\nnote G. Each line and space between lines represent a note (a white\nkey on piano keyboard).\n\nMnemonics:\nspaces between lines starting from bottom - F A C E\nlines starting from bottom - Every Good Boy Deserves Fruit\nOne can add additional lines when leaving stave’s range.\nE.g. middle C is the first line under the stave.\nHowever, we have 12 pitches on guitar (i.e. also black keys on\npiano keyboard) in one octave.\n\n\nIntervals\nOctave - interval between (and including) two notes, one having twice\nor half the vibration frequency of the other.\nSemitone - distance between two adjacent keys on piano.\nTone = 2 semitones.\n\nLet’s call one line or space in stave - a unit. \nWe say that interval between two notes is “a second” if \nthere are no units between them on the stave (i.e. this is a line\nand its adjacent space).\nWhen there is one unit - “a third” (\ni.e. two lines with one space in between or two spaces with one line).\nHere comes a bit confusing part. F to G is a second. C to B is a\nsecond. There is a black key between F and G, but not between C & B.\nNevertheless both are called - “a second”.\nScales\nScale - a pathway through octave.\nExample - C Major (we just go through notes one by one)\nC <T> D <T> E <S> F <T> G <T> A <T>> B <S> C\nwhere <T> is a tone and <S> is a semitone.\nC is called a tonic.\nSequence TTSTTTS defines “quality of scale”.\nThis one belongs to Diatonic Scale (because it has\n5 tones and 2 semitones).\nThere are different approaches in the world, this one is so called\ncommon practice, i.e. Western Europe 1600-1900.\nIf we take A as a tonic and again go through notes one by one, we get natural minor scale\nA <T> B <S> C <T> D <T> E <S> F <T> G <T> A\ni.e. the sequence of T’s and S’s is different from major\nThis is still Diatonic Scale (still 5 T and 2 S).\nThe sequence itself is called Aeolian mode.\nWhen starting from D, we get Dorian mode\nD <T> E <S> F <T> G <T> A <T> B <S> C <T> D\nE -> Phrygian\nE <S> F <T> G <T> A <T> B <S> C <T> D <T> E\nBasically we just traverse the stave starting from a note and write\ndown all the notes we meet on our way.\nF -> Lydian.\nG -> Mixolydian (also 5th degree of C Major, interval between C and G\nis a fifth).\nB -> Locrian mode.\nChords\nLet’s take a piece of natural minor scale\nA B C D E\nand count semitones\nA <T - 1 2> B <S - 3> C <T - 4 5> D <T - 6 7> E\nWe can do the same for C Major\nC <T - 1 2> D <T 3 4> E <S 5> F <T 6 7> G\n7 semitones = perfect fifth\nA -> C = a minor third (3 semitones)\nC -> E = a major third (4 semitones)\nC Major chord is C E G (C major triad).\nTriad = three notes.\nAbbreviations:\nC Major = C, Cmaj, CM\nA Minor = Amin, Am, A-\nOne can construct a major triad by taking major third and perfect\nfifth (i.e. a note 4 semitones away and a note 7 semitones away).\n\nFor a minor triad - minor third (3 semitones) + perfect fifth\n(7 semitones).\n\nThere is also Diminished Triad (B0 Bdim) = Minor third (3 semitones) + Diminished Fifth (6 semitones).\nNote that “third” and “fifth” are taken from the stave, but whether\nit is “perfect”, “minor”, “diminished” is based on the underlying \nnotes. I.e. we take C, count one stave unit, get E, count another\nstave unit - get G. Now we can count semitones and identify whether\nthis is maj, min or dim.\nIf we repeat taking third and fifth from every note, we get:\nCmaj Dmin Emin Fmaj Gmaj Amin Bdim\nThree Chord Trick\nC, F and G work well together.\nC - tonic triad (I)\nF - subdominant (IV) - the tonic is domimant of the subdomimant. It is\nas far below the tonic as domimant is above.\nG - 5th degree (C -> G is a fifth) - dominant (V)\nYou can harmonize notes with chords which have it.","summary":"I started taking “Fundamentals of Music Theory “ on Coursera. Summary of week 1. So far there are a lot of stuff “just by definition”, so I honestly felt a need to wrote a summary to structure everything in my head (since I already forgot quite a lot).","id":"https://merelycurious.me/post/coursera_fundamentals_of_music_week_1","isoDate":"2020-04-18T15:00:00.000Z","timestamp":"4/18/2020"},{"title":"Fundamentals of music: week 2","link":"https://merelycurious.me/post/coursera-fundamentals-of-music-week-2","pubDate":"2020-04-18T15:00:00.000Z","author":"","content":"<p>Summary of week 2. Sharps, flats, keys, intervals, other clefs.\n<!--more--></p>\n\n<h2 id=\"sharps--flats\">Sharps &amp; flats.</h2>\n\n<p>We can play major scale starting from any note. When we start from C,\nwe use only white keys on the piano, but that’s not always the case.\nE.g. if we start from G, we use F# (“F sharp” - one semitone sharper\nthan F). F# can also be denoted as Gb (“G flat”).</p>\n\n<p>Black piano keys (notes) asymmetry (i.e. the fact that not between\nany two white keys there is a black key) creates landmarks for our ears.</p>\n\n<h2 id=\"key\">Key</h2>\n\n<p>If we use notes from some scale, we say that we are in the key of\nthis scale tonic, e.g. C-maj.</p>\n\n<p>Scale - ordered sequence of notes.\nKey - relationship, feelings, that pull us back to tonic.</p>\n\n<p>So far we can’t write sharp note on the stave (only white piano keys\nare represented). There is a way to define sharps as well. One can\nput sharp sign on a note in the stave (in the beginning) and now \nall occurrences of that note have to be sharp. Some selections of\nsharps actually represent a valid key. There is a mnemonic to\nrecognize such keys, called “Circle of fifths”:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/600px-Circle_of_fifths_deluxe_4.svg.png\" alt=\"circle of fifths\" /></p>\n\n<p><em>Circle of fifths. Author: <a href=\"https://en.wikipedia.org/wiki/en:User:Just_plain_Bill\">Just plain Bill</a>\n(<a href=\"https://en.wikipedia.org/wiki/File:Circle_of_fifths_deluxe_4.svg#filelinks\">Wikipedia</a>)</em></p>\n\n<p>Moving by a fifth adds one sharp. Moving by a fourth adds one flat.</p>\n\n<p>Mnemonic for remembering sharps: Father Christmas Gave Dad an Electric\nBlanket. For flats: Blanket Explodes And Dad Get Cold Feet.</p>\n\n<p>Sample usage - let’s say we see 5 flats. These means that first 5\nnotes on the left side of the circle (F, B, E, A, D) will be flattened\n(and this is key of Db).</p>\n\n<p>However, we may want to use non sharp or flat note. We can do this \nby using accidentals (inlined signs). These can be sharps or \nflats or a natural (♮, cancels out previous sharps and flats).\nAccidentals have their effect to the next vertical bar.</p>\n\n<h3 id=\"minor-keys\">Minor keys</h3>\n\n<h4 id=\"related-minor-key\">Related minor key</h4>\n\n<p>Each set of sharps or flats defining a major key, actually defines \nrelated minor key.</p>\n\n<p>To find a related minor key tonic, you need to take 6th degree\nof major scale.</p>\n\n<p>E.g. D maj = D E F# G A B C# D</p>\n\n<p>B is 6th degree, so it is relative minor for D.</p>\n\n<p>We can illustrate this visually in the following way. Let’s plot\nnote frequencies:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/1_non_log.svg\" alt=\"note frequencies\" /></p>\n\n<p>This does not give us much, since they grow multiplicatively, let’s\ndo a log plot instead:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/1_log.svg\" alt=\"log plot of note frequencies\" /></p>\n\n<p>Now we see that all notes are uniformly spaced in log space. This\nmeans that in log space, a semitone can be represented via a distance\non the picture. This allows us to represent a major scale as a \ntemplate with holes:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/2_log_major.svg\" alt=\"C maj on log plot\" /></p>\n\n<p>The same can be done for Natural Minor and we can see why there is\nalways a related minor to each major at 6th:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/3_log_minor.svg\" alt=\"A min with C maj on log plot\" /></p>\n\n<p>Basically when you take 2 major scales together, a natural minor is just\na subset of the resulting notes (on the picture A Natural Minor is\nbuilt using notes from C major).</p>\n\n<p>Similarly B natural minor = B C# D E F# G A B - all notes from D maj, just\nrearranged (the sequence just starts from B instead of D).</p>\n\n<h4 id=\"other-kinds-of-minor-scales\">Other kinds of minor scales</h4>\n\n<p>There are different types of minor scales. We already saw B natural\nminor, it still tends into D as a tonic.</p>\n\n<p>B <em>harmonic</em> minor = B C# D E F# G A# B - A# is 7th degree and it\nleads our ear to B being new tonic. You can get harmonic minor by\nraising 7th note by semitone in natural minor.</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/3_log_harmonic_minor.svg\" alt=\"A min harmonic with C maj on log plot\" /></p>\n\n<p>We already know that 1th is called Tonic, 5th - Dominant and now \nwe learned that 7th is called “Leading”.</p>\n\n<p>In harmonic minor there is 1.5 tone jump (from G to A#) and it can be hard for\npeople to sing.</p>\n\n<p>B <em>melodic</em> minor scale - B C# D E F# G# A# B and backward A G F# E D\nC# B. Backward is same as natural minor. To get melodic minor scale\nwe take natural minor and raise both sixth and seventh notes by a\nsemitone.</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/4_log_melodic_minor.svg\" alt=\"A min melodic with C maj on log plot\" /></p>\n\n<h2 id=\"intervals\">Intervals</h2>\n\n<p>You define interval by a number and its quality. The number is easy\nto get, we just count number of notes on a stave from the lowest\nnote to the highest (inclusive). As we already know, we can add\nsharps and flats to the stave, this won’t affect position of the note,\ni.e. the number for the interval will stay the same. In order to \ndistinguish such intervals, we define their quality. One cannot \ndetermine number or quality of an interval just by counting semitones.</p>\n\n<p>There are 5 qualities - Perfect, Diminished, Augmented, Major and\nMinor. Unison, fourth, fifth and octave are called perfect and they\ncan be diminished (semitone smaller) or augmented (semitone larger).\nThe remaining intervals (second, third, sixth, seventh) can be major\nor minor.</p>\n\n<p>Let’s start with perfect ones. We say that an interval is perfect\nif upper note is in the major key of the lower note. An interval, which is semitone lower\nthan perfect, is called diminished, if semitone higher - augmented.</p>\n\n<p>For seconds, thirds, sixths and seventh - if upper note is in the\nkey of the lower note, we say that interval is major. Semitone lower - minor, semitone higher - augmented</p>\n\n<h2 id=\"ledger-lines-and-clefs\">Ledger lines and clefs</h2>\n\n<p>We can extend the stave using ledger lines, but this becomes hard\nto read if you stay there for long time. So there are different\nclefs to use the stave in different ranges, e.g. bass, alto and \ntenor. You can combine G clef stave with bass clef stave to get\nGrand stave. The both staves “meet” at the first ledger line (i.e.\nmiddle C).</p>\n\n<p>Here is Grand stave on log plot:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/5_grand_stave_log.svg\" alt=\"Grand stave on log plot\" /></p>\n\n<p>As a mnemonic for other clefs - the center of the sign is always\nplaced at middle C (i.e. C4), e.g. tenor clef:</p>\n\n<p><img src=\"/assets/post_resources/coursera_fundamentals_of_music_week_2/405px-Tenor_clef_with_ref.svg.png\" alt=\"Grand stave on log plot\" /></p>","contentSnippet":"Summary of week 2. Sharps, flats, keys, intervals, other clefs.\n\nSharps & flats.\nWe can play major scale starting from any note. When we start from C,\nwe use only white keys on the piano, but that’s not always the case.\nE.g. if we start from G, we use F# (“F sharp” - one semitone sharper\nthan F). F# can also be denoted as Gb (“G flat”).\nBlack piano keys (notes) asymmetry (i.e. the fact that not between\nany two white keys there is a black key) creates landmarks for our ears.\nKey\nIf we use notes from some scale, we say that we are in the key of\nthis scale tonic, e.g. C-maj.\nScale - ordered sequence of notes.\nKey - relationship, feelings, that pull us back to tonic.\nSo far we can’t write sharp note on the stave (only white piano keys\nare represented). There is a way to define sharps as well. One can\nput sharp sign on a note in the stave (in the beginning) and now \nall occurrences of that note have to be sharp. Some selections of\nsharps actually represent a valid key. There is a mnemonic to\nrecognize such keys, called “Circle of fifths”:\n\nCircle of fifths. Author: Just plain Bill\n(Wikipedia)\nMoving by a fifth adds one sharp. Moving by a fourth adds one flat.\nMnemonic for remembering sharps: Father Christmas Gave Dad an Electric\nBlanket. For flats: Blanket Explodes And Dad Get Cold Feet.\nSample usage - let’s say we see 5 flats. These means that first 5\nnotes on the left side of the circle (F, B, E, A, D) will be flattened\n(and this is key of Db).\nHowever, we may want to use non sharp or flat note. We can do this \nby using accidentals (inlined signs). These can be sharps or \nflats or a natural (♮, cancels out previous sharps and flats).\nAccidentals have their effect to the next vertical bar.\nMinor keys\nRelated minor key\nEach set of sharps or flats defining a major key, actually defines \nrelated minor key.\nTo find a related minor key tonic, you need to take 6th degree\nof major scale.\nE.g. D maj = D E F# G A B C# D\nB is 6th degree, so it is relative minor for D.\nWe can illustrate this visually in the following way. Let’s plot\nnote frequencies:\n\nThis does not give us much, since they grow multiplicatively, let’s\ndo a log plot instead:\n\nNow we see that all notes are uniformly spaced in log space. This\nmeans that in log space, a semitone can be represented via a distance\non the picture. This allows us to represent a major scale as a \ntemplate with holes:\n\nThe same can be done for Natural Minor and we can see why there is\nalways a related minor to each major at 6th:\n\nBasically when you take 2 major scales together, a natural minor is just\na subset of the resulting notes (on the picture A Natural Minor is\nbuilt using notes from C major).\nSimilarly B natural minor = B C# D E F# G A B - all notes from D maj, just\nrearranged (the sequence just starts from B instead of D).\nOther kinds of minor scales\nThere are different types of minor scales. We already saw B natural\nminor, it still tends into D as a tonic.\nB harmonic minor = B C# D E F# G A# B - A# is 7th degree and it\nleads our ear to B being new tonic. You can get harmonic minor by\nraising 7th note by semitone in natural minor.\n\nWe already know that 1th is called Tonic, 5th - Dominant and now \nwe learned that 7th is called “Leading”.\nIn harmonic minor there is 1.5 tone jump (from G to A#) and it can be hard for\npeople to sing.\nB melodic minor scale - B C# D E F# G# A# B and backward A G F# E D\nC# B. Backward is same as natural minor. To get melodic minor scale\nwe take natural minor and raise both sixth and seventh notes by a\nsemitone.\n\nIntervals\nYou define interval by a number and its quality. The number is easy\nto get, we just count number of notes on a stave from the lowest\nnote to the highest (inclusive). As we already know, we can add\nsharps and flats to the stave, this won’t affect position of the note,\ni.e. the number for the interval will stay the same. In order to \ndistinguish such intervals, we define their quality. One cannot \ndetermine number or quality of an interval just by counting semitones.\nThere are 5 qualities - Perfect, Diminished, Augmented, Major and\nMinor. Unison, fourth, fifth and octave are called perfect and they\ncan be diminished (semitone smaller) or augmented (semitone larger).\nThe remaining intervals (second, third, sixth, seventh) can be major\nor minor.\nLet’s start with perfect ones. We say that an interval is perfect\nif upper note is in the major key of the lower note. An interval, which is semitone lower\nthan perfect, is called diminished, if semitone higher - augmented.\nFor seconds, thirds, sixths and seventh - if upper note is in the\nkey of the lower note, we say that interval is major. Semitone lower - minor, semitone higher - augmented\nLedger lines and clefs\nWe can extend the stave using ledger lines, but this becomes hard\nto read if you stay there for long time. So there are different\nclefs to use the stave in different ranges, e.g. bass, alto and \ntenor. You can combine G clef stave with bass clef stave to get\nGrand stave. The both staves “meet” at the first ledger line (i.e.\nmiddle C).\nHere is Grand stave on log plot:\n\nAs a mnemonic for other clefs - the center of the sign is always\nplaced at middle C (i.e. C4), e.g. tenor clef:","summary":"Summary of week 2. Sharps, flats, keys, intervals, other clefs.","id":"https://merelycurious.me/post/coursera_fundamentals_of_music_week_2","isoDate":"2020-04-18T15:00:00.000Z","timestamp":"4/18/2020"},{"title":"Timing 2008: what was the prize?","link":"https://merelycurious.me/post/timing-2008-best-outcomes","pubDate":"2020-02-09T11:00:00.000Z","author":"","content":"<p>With the bull market continuing, more and more people “predict” the\ncrisis. Obviously, there is a temptation to try to time the market.\nLet’s try to estimate the best outcome of timing the market by\nconsidering the 2008 crisis. Perhaps it is not worth it at all\n(spoiler: the returns of ideal timing are actually substantial).</p>\n\n<!--more-->\n\n<h2 id=\"getting-the-data\">Getting the data</h2>\n\n<p>Before simulating anything, we need the data. First, I arbitrarily\nselect the following companies to analyze:</p>\n\n<ul>\n  <li>\n    <p>‘AAPL’, ‘AMZN’, ‘GOOGL’ - Apple, Amazon and Google, since IT\ncompanies were not that much affected by the crisis from the\noperational perspective and if I were <em>hypothetically</em> timing the market buying them\nwould seem safer.</p>\n  </li>\n  <li>\n    <p>‘BAC’ - Bank of America as an example of a bank.</p>\n  </li>\n  <li>\n    <p>‘WMT’ - Walmart as an example of company which should not be\naffected much by the crisis (people still need their groceries).\nAt least <a href=\"https://www.fool.com/investing/2020/01/04/3-recession-proof-stocks-to-buy-now.aspx\">Motley Fool says so</a>.</p>\n  </li>\n  <li>\n    <p>‘^GSPC’ - S&amp;P500 index as a proxy for the US.</p>\n  </li>\n  <li>\n    <p>‘IWRD.AS’ - World index as a proxy for the world. Unfortunately\nplenty of world ETFs were created after the crisis, so this is the\nonly I found with enough data.</p>\n  </li>\n</ul>\n\n<p>Then I just manually downloaded daily prices for these tickers from\n<a href=\"https://finance.yahoo.com/\">https://finance.yahoo.com/</a> (dates: 1st of Jan 2006 - 1st of Jan 2014).</p>\n\n<p>You can get the same data by inserting the ticker in</p>\n\n<blockquote>\n  <p>https://finance.yahoo.com/quote/<ticker>/history?period1=1136073600&amp;period2=1388534400&amp;interval=1d&amp;filter=history&amp;frequency=1d</ticker></p>\n</blockquote>\n\n<p>and then manually clicking “Download Data”.</p>\n\n<h2 id=\"methodology\">Methodology</h2>\n\n<p>Let’s consider time period from 3rd of Jan 2006 to 3rd of Jan 2013.\nYou may be wondering why 3rd and not 1st - because there is no data\nfor 1st and 2nd.</p>\n\n<p>First, we consider buy&amp;hold outcome, i.e. one buys on 3rd of Jan 2006\nand then sells on 3rd of Jan 2013. When buying we take “high” price of\nthe day and when selling - “low”. This gives us baseline to compare to.\nI.e. if one does not time the market, this is their return.</p>\n\n<p>Second, let’s consider an investor who times the market, but only once. In\nother words they buy on 3rd of Jan 2006. Then at some point during the\ncrisis they sell. Then eventually they rebuy. Finally, they sell again\non 3rd of Jan 2013. Let’s enumerate all possibilities to sell and\nrebuy and find the best ones.</p>\n\n<p>When timing the market, I also take “high” price of\nthe day for buying and “low” for selling. This gives lower bound.</p>\n\n<h2 id=\"results\">Results</h2>\n\n<h3 id=\"world\">World</h3>\n\n<p>Buy&amp;hold investor’s ROI is -3.5% (bought @ 22.82$ on 2006/01/03, sold @ 22$\non 2013/01/03). Let’s have a look at daily prices during this period:</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/IWRD.AS_1_daily_prices.png\" alt=\"Daily prices for World Index\" /></p>\n\n<p>As we can see, the fall has started in 2007 and the recovery in 2009.\nIt is peculiar to observe how many times it grew during the crisis\nand then felt back again. Timing that wouldn’t be fun.</p>\n\n<p>If we time the world index once, our ROI becomes whooping 107.26% (sold @\n25.6$ on 2007/06/04, bought @ 11.91$ on 2009/03/09). Visually:</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/IWRD.AS_2_best_timing\n.png\" alt=\"Daily prices for World Index with the best time period for timing\nthe crisis\" /></p>\n\n<p>The red line connects sell and rebuy points.</p>\n\n<p>One can definitely see that figuring out when to rebuy in practice wouldn’t be\neasy at all. There are plenty of small recoveries before the actual\nminimum of 2009.</p>\n\n<p>Let’s now consider all possible scenarios:</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/IWRD.AS_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through World Index\" /></p>\n\n<p>This may be confusing to read, but please bear with me. Let’s say you\nsell in 2007. This corresponds to horizontal line at 2007 (i.e. pick\n2007 on the vertical axes). Then let’s say you rebuy in 2012. This\nmeans that you pick 2012 on horizontal axes. Your ROI is the\nintersection of the two. I.e. this plot represents all possible ways\nto time the market and their outcomes. As we can see, rebuying around\n2009 is generally better than others and selling around 2009 was a bad\nidea. Also if you misstimed the market, you would reach ~-40% ROI.</p>\n\n<p>Please note that I interpolate the missing days  (e.g. holidays) by taking\naverage of neighbors. This just fills the holes in the graph,\notherwise it is impossible to read (and if you don’t believe me <a href=\"/assets/post_resources/timing_2008/IWRD.AS_3_all_timing\n_no_interpolation.png\">here\nis an example</a>).</p>\n\n<p>As we can see, timing the market through World Index in the best case\nwould be very profitable (one could have 107.26% after 7\nyears instead of -3.5%). However, it is definitely not easy.\nWhen looking at all possible timing scenarios there is a lot of\nblue-purple (which is 0 or negative return). Another problem is that\nthere are plenty of smaller drops and recoveries during the crisis.</p>\n\n<h3 id=\"apple\">Apple</h3>\n\n<p>Buy&amp;hold investor got 623.74% return (bought @ 10.67$ on 2006/01/03,\nsold @ 77.28$ on 2013/01/03).</p>\n\n<p>Daily prices and best market timing:</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/AAPL_2_best_timing\n.png\" alt=\"Daily prices for Apple stock with the best time period for timing\nthe crisis\" /></p>\n\n<p>There was plenty of growth after the crisis. The best timing scenario\nreturn is 1645.81% (sell @ 28.25 on 2007/12/27, rebuy @ 11.71 on\n2009/01/20). In some sense by doing this, one doubles their holdings\nand thus boosts the effect of the great growth afterwards.</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/AAPL_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Apple stock\" /></p>\n\n<p>As we can see the “hot” area is much-much smaller than before.</p>\n\n<h3 id=\"amazon\">Amazon</h3>\n\n<p>You know the drill now, so I will just add the numbers and graphs without\ntoo many words.</p>\n\n<p>Buy&amp;hold: 435.77% return (bought @ 47.84$ on 2006/01/03,\nsold @ 256.36$ on 2013/01/03)</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/AMZN_2_best_timing\n.png\" alt=\"Daily prices for Amazon stock with the best time period for timing\nthe crisis\" /></p>\n\n<p>Best market timing: 1201.66% (sell @ 94.75$ on 2007/10/09, rebuy @ 39$ on\n2008/11/21).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/AMZN_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Amazon stock\" /></p>\n\n<p>The peak returns area is very small now.</p>\n\n<h3 id=\"google\">Google</h3>\n\n<p>Buy&amp;hold: 65.42% return (bought @ 218.05$ on 2006/01/03,\nsold @ 360.72$ on 2013/01/03)</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/GOOGL_2_best_timing\n.png\" alt=\"Daily prices for Google stock with the best time period for timing\nthe crisis\" /></p>\n\n<p>Best market timing: 345.24% (sell @ 362.86$ on 2007/11/06, rebuy @ 134.81$ on\n2008/11/21).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/GOOGL_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Google stock\" /></p>\n\n<p>I am surprised how small buy&amp;hold returns are.</p>\n\n<h3 id=\"bank-of-america\">Bank of America</h3>\n\n<p>Buy&amp;hold: -74.81% return (bought @ 47.18$ on 2006/01/03,\nsold @ 11.88$ on 2013/01/03)</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/BAC_2_best_timing\n.png\" alt=\"Daily prices for Bank of America stock with the best time period for timing\nthe crisis\" /></p>\n\n<p>Best market timing: 293.26% (sell @ 54.82$ on 2006/11/17, rebuy @ 3.51$ on\n2009/03/05).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/BAC_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Google stock\" /></p>\n\n<p>Oh, the buy&amp;hold return is scary and rebuying at 3$ per share is very\npeculiar.</p>\n\n<h3 id=\"walmart\">Walmart</h3>\n\n<p>Buy&amp;hold: 46.54% return (bought @ 46.66$ on 2006/01/03,\nsold @ 68.37$ on 2013/01/03)</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/WMT_2_best_timing\n.png\" alt=\"Daily prices for Walmart stock with the best time period for timing\nthe crisis\" /></p>\n\n<p>Best market timing: 91.92% (sell @ 61.58$ on 2008/09/12, rebuy @ 47.02$ on\n2009/02/02).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/WMT_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Walmart stock\" /></p>\n\n<p>This one looks surprisingly easy to time (probably, because the timing\ndoes not bring that much return anyway).</p>\n\n<h3 id=\"sp500\">S&amp;P500</h3>\n\n<p>Buy&amp;hold: 14.58% return (bought @ 1270.21$ on 2006/01/03,\nsold @ 1455.53$ on 2013/01/03).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/^GSPC_2_best_timing\n.png\" alt=\"Daily prices for S&amp;P500 with the best time period for timing\nthe crisis\" /></p>\n\n<p>Best market timing: 156.35% (sell @ 1545.45$ on 2007/10/10, rebuy @ 695.27$ on\n2009/03/09).</p>\n\n<p><img src=\"/assets/post_resources/timing_2008/^GSPC_3_all_timing\n.png\" alt=\"Outcomes of all possible ways to time the market through Walmart stock\" /></p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>Yes, timing 2008 well was a very profitable endeavor.</p>\n\n<h2 id=\"follow-ups\">Follow-ups</h2>\n\n<p>I am now curious to estimate how hard it was to time the market. In \nthe follow-up post I want to consider how badly could one time the market\nand still make reasonable profit. Also it makes sense to color all timing\nscenarios based on whether they outperform buy&amp;hold.</p>","contentSnippet":"With the bull market continuing, more and more people “predict” the\ncrisis. Obviously, there is a temptation to try to time the market.\nLet’s try to estimate the best outcome of timing the market by\nconsidering the 2008 crisis. Perhaps it is not worth it at all\n(spoiler: the returns of ideal timing are actually substantial).\nGetting the data\nBefore simulating anything, we need the data. First, I arbitrarily\nselect the following companies to analyze:\n‘AAPL’, ‘AMZN’, ‘GOOGL’ - Apple, Amazon and Google, since IT\ncompanies were not that much affected by the crisis from the\noperational perspective and if I were hypothetically timing the market buying them\nwould seem safer.\n‘BAC’ - Bank of America as an example of a bank.\n‘WMT’ - Walmart as an example of company which should not be\naffected much by the crisis (people still need their groceries).\nAt least Motley Fool says so.\n‘^GSPC’ - S&P500 index as a proxy for the US.\n‘IWRD.AS’ - World index as a proxy for the world. Unfortunately\nplenty of world ETFs were created after the crisis, so this is the\nonly I found with enough data.\nThen I just manually downloaded daily prices for these tickers from\nhttps://finance.yahoo.com/ (dates: 1st of Jan 2006 - 1st of Jan 2014).\nYou can get the same data by inserting the ticker in\nhttps://finance.yahoo.com/quote//history?period1=1136073600&period2=1388534400&interval=1d&filter=history&frequency=1d\nand then manually clicking “Download Data”.\nMethodology\nLet’s consider time period from 3rd of Jan 2006 to 3rd of Jan 2013.\nYou may be wondering why 3rd and not 1st - because there is no data\nfor 1st and 2nd.\nFirst, we consider buy&hold outcome, i.e. one buys on 3rd of Jan 2006\nand then sells on 3rd of Jan 2013. When buying we take “high” price of\nthe day and when selling - “low”. This gives us baseline to compare to.\nI.e. if one does not time the market, this is their return.\nSecond, let’s consider an investor who times the market, but only once. In\nother words they buy on 3rd of Jan 2006. Then at some point during the\ncrisis they sell. Then eventually they rebuy. Finally, they sell again\non 3rd of Jan 2013. Let’s enumerate all possibilities to sell and\nrebuy and find the best ones.\nWhen timing the market, I also take “high” price of\nthe day for buying and “low” for selling. This gives lower bound.\nResults\nWorld\nBuy&hold investor’s ROI is -3.5% (bought @ 22.82$ on 2006/01/03, sold @ 22$\non 2013/01/03). Let’s have a look at daily prices during this period:\n\nAs we can see, the fall has started in 2007 and the recovery in 2009.\nIt is peculiar to observe how many times it grew during the crisis\nand then felt back again. Timing that wouldn’t be fun.\nIf we time the world index once, our ROI becomes whooping 107.26% (sold @\n25.6$ on 2007/06/04, bought @ 11.91$ on 2009/03/09). Visually:\n\nThe red line connects sell and rebuy points.\nOne can definitely see that figuring out when to rebuy in practice wouldn’t be\neasy at all. There are plenty of small recoveries before the actual\nminimum of 2009.\nLet’s now consider all possible scenarios:\n\nThis may be confusing to read, but please bear with me. Let’s say you\nsell in 2007. This corresponds to horizontal line at 2007 (i.e. pick\n2007 on the vertical axes). Then let’s say you rebuy in 2012. This\nmeans that you pick 2012 on horizontal axes. Your ROI is the\nintersection of the two. I.e. this plot represents all possible ways\nto time the market and their outcomes. As we can see, rebuying around\n2009 is generally better than others and selling around 2009 was a bad\nidea. Also if you misstimed the market, you would reach ~-40% ROI.\nPlease note that I interpolate the missing days  (e.g. holidays) by taking\naverage of neighbors. This just fills the holes in the graph,\notherwise it is impossible to read (and if you don’t believe me here\nis an example).\nAs we can see, timing the market through World Index in the best case\nwould be very profitable (one could have 107.26% after 7\nyears instead of -3.5%). However, it is definitely not easy.\nWhen looking at all possible timing scenarios there is a lot of\nblue-purple (which is 0 or negative return). Another problem is that\nthere are plenty of smaller drops and recoveries during the crisis.\nApple\nBuy&hold investor got 623.74% return (bought @ 10.67$ on 2006/01/03,\nsold @ 77.28$ on 2013/01/03).\nDaily prices and best market timing:\n\nThere was plenty of growth after the crisis. The best timing scenario\nreturn is 1645.81% (sell @ 28.25 on 2007/12/27, rebuy @ 11.71 on\n2009/01/20). In some sense by doing this, one doubles their holdings\nand thus boosts the effect of the great growth afterwards.\n\nAs we can see the “hot” area is much-much smaller than before.\nAmazon\nYou know the drill now, so I will just add the numbers and graphs without\ntoo many words.\nBuy&hold: 435.77% return (bought @ 47.84$ on 2006/01/03,\nsold @ 256.36$ on 2013/01/03)\n\nBest market timing: 1201.66% (sell @ 94.75$ on 2007/10/09, rebuy @ 39$ on\n2008/11/21).\n\nThe peak returns area is very small now.\nGoogle\nBuy&hold: 65.42% return (bought @ 218.05$ on 2006/01/03,\nsold @ 360.72$ on 2013/01/03)\n\nBest market timing: 345.24% (sell @ 362.86$ on 2007/11/06, rebuy @ 134.81$ on\n2008/11/21).\n\nI am surprised how small buy&hold returns are.\nBank of America\nBuy&hold: -74.81% return (bought @ 47.18$ on 2006/01/03,\nsold @ 11.88$ on 2013/01/03)\n\nBest market timing: 293.26% (sell @ 54.82$ on 2006/11/17, rebuy @ 3.51$ on\n2009/03/05).\n\nOh, the buy&hold return is scary and rebuying at 3$ per share is very\npeculiar.\nWalmart\nBuy&hold: 46.54% return (bought @ 46.66$ on 2006/01/03,\nsold @ 68.37$ on 2013/01/03)\n\nBest market timing: 91.92% (sell @ 61.58$ on 2008/09/12, rebuy @ 47.02$ on\n2009/02/02).\n\nThis one looks surprisingly easy to time (probably, because the timing\ndoes not bring that much return anyway).\nS&P500\nBuy&hold: 14.58% return (bought @ 1270.21$ on 2006/01/03,\nsold @ 1455.53$ on 2013/01/03).\n\nBest market timing: 156.35% (sell @ 1545.45$ on 2007/10/10, rebuy @ 695.27$ on\n2009/03/09).\n\nConclusions\nYes, timing 2008 well was a very profitable endeavor.\nFollow-ups\nI am now curious to estimate how hard it was to time the market. In \nthe follow-up post I want to consider how badly could one time the market\nand still make reasonable profit. Also it makes sense to color all timing\nscenarios based on whether they outperform buy&hold.","summary":"With the bull market continuing, more and more people “predict” the crisis. Obviously, there is a temptation to try to time the market. Let’s try to estimate the best outcome of timing the market by considering the 2008 crisis. Perhaps it is not worth it at all (spoiler: the returns of ideal timing are actually substantial).","id":"https://merelycurious.me/post/timing_2008_best_outcomes","isoDate":"2020-02-09T11:00:00.000Z","timestamp":"2/9/2020"},{"title":"How much Europe is there in the World ETF?","link":"https://merelycurious.me/post/europe-in-world-etf","pubDate":"2020-02-09T10:00:00.000Z","author":"","content":"<p>I’ve had a peculiar puzzle recently. What is the percentage of \nEuropean companies in MSCI World index? Surprisingly I couldn’t find \nthis anywhere, so let’s calculate it on our own .</p>\n\n<!--more-->\n\n<h2 id=\"prelude\">Prelude</h2>\n\n<p>MSCI World publishes approximate country distribution\n<a href=\"https://www.msci.com/developed-markets\">here</a>, but it has 6% “other”\ncategory. Then one can see a list of all companies in the index with\ntheir weight <a href=\"https://www.msci.com/constituents\">here</a>, but this does\nnot help either, since mapping from “company” to “region” is non-\ntrivial.</p>\n\n<h2 id=\"solution\">Solution</h2>\n\n<p>There is MSCI World ex Europe index. Presumably it is the same as MSCI\nWorld above, but without Europe (at least that’s what name suggests). 80.37% of MSCI World ex Europe is the\nUS [<a href=\"https://www.msci.com/documents/10199/674e5774-727b-\n4e85-ad07-1be63cb1d075\">source</a>]. For the MSCI World it is 63.81%\n[<a href=\"https://www.msci.com/documents/10199/149ed7bc-316e-4b4c-8ea4-43fcb5bd6523\">source</a>]. Looks like the numbers in the PDFs change with time, so the state above is as of today (the PDFs say “Jan 31, 2020).\nNow we can build the following equation:</p>\n\n<script type=\"math/tex; mode=display\">0.8037 = \\frac{\\text{US}}{\\text{world} - \\text{Europe}}</script>\n\n<p>Let’s swap numerators and denominators</p>\n\n<script type=\"math/tex; mode=display\">\\frac{1}{0.8037} = \\frac{\\text{world} - \\text{Europe}}{\\text{US}} = \\frac{\\text{world}}{\\text{US}} - \\frac{\\text{Europe}}{\\text{US}}</script>\n\n<p>We know that \\(\\frac{\\text{US}}{\\text{world}}\\) is 0.6381 (just ratio of the US in MSCI World):</p>\n\n<script type=\"math/tex; mode=display\">\\frac{\\text{Europe}}{\\text{US}} = \\frac{\\text{world}}{\\text{US}} - \\frac{1}{0.8037} = \\frac{1}{0.6381} - \\frac{1}{0.8037} = 0.3410</script>\n\n<p>We want \\(\\frac{\\text{Europe}}{\\text{world}}\\)</p>\n\n<script type=\"math/tex; mode=display\">\\frac{\\text{Europe}}{\\text{world}} = \\frac{\\text{Europe}}{\\text{US}} \\cdot \\frac{\\text{US}}{\\text{world}} = 0.3410 \\cdot 0.6381 = 0.2176</script>\n\n<p>In other words, the ratio of Europe in MSCI World index is 21.8%.</p>\n\n<h2 id=\"sanity-checking\">Sanity checking</h2>\n\n<p>My first attempt at calculating this was actually wrong, so let’s\nsanity check. <a href=\"https://www.msci.com/developed-markets\">This page</a>\nsays (as of September 2019):</p>\n\n<ul>\n  <li>UK - 5.47%</li>\n  <li>France - 3.8%</li>\n  <li>Switzerland - 3.15%</li>\n  <li>Germany - 2.86%</li>\n  <li>Netherlands - 1.33%</li>\n  <li>Others - 6.27%</li>\n</ul>\n\n<p>\\( 5.47+3.8+3.15+2.86+1.33 = 16.61 \\) - looks plausible!</p>","contentSnippet":"I’ve had a peculiar puzzle recently. What is the percentage of \nEuropean companies in MSCI World index? Surprisingly I couldn’t find \nthis anywhere, so let’s calculate it on our own .\nPrelude\nMSCI World publishes approximate country distribution\nhere, but it has 6% “other”\ncategory. Then one can see a list of all companies in the index with\ntheir weight here, but this does\nnot help either, since mapping from “company” to “region” is non-\ntrivial.\nSolution\nThere is MSCI World ex Europe index. Presumably it is the same as MSCI\nWorld above, but without Europe (at least that’s what name suggests). 80.37% of MSCI World ex Europe is the\nUS [source]. For the MSCI World it is 63.81%\n[source]. Looks like the numbers in the PDFs change with time, so the state above is as of today (the PDFs say “Jan 31, 2020).\nNow we can build the following equation:\n0.8037 = \\frac{\\text{US}}{\\text{world} - \\text{Europe}}\n\nLet’s swap numerators and denominators\n\\frac{1}{0.8037} = \\frac{\\text{world} - \\text{Europe}}{\\text{US}} = \\frac{\\text{world}}{\\text{US}} - \\frac{\\text{Europe}}{\\text{US}}\n\nWe know that \\(\\frac{\\text{US}}{\\text{world}}\\) is 0.6381 (just ratio of the US in MSCI World):\n\\frac{\\text{Europe}}{\\text{US}} = \\frac{\\text{world}}{\\text{US}} - \\frac{1}{0.8037} = \\frac{1}{0.6381} - \\frac{1}{0.8037} = 0.3410\n\nWe want \\(\\frac{\\text{Europe}}{\\text{world}}\\)\n\\frac{\\text{Europe}}{\\text{world}} = \\frac{\\text{Europe}}{\\text{US}} \\cdot \\frac{\\text{US}}{\\text{world}} = 0.3410 \\cdot 0.6381 = 0.2176\n\nIn other words, the ratio of Europe in MSCI World index is 21.8%.\nSanity checking\nMy first attempt at calculating this was actually wrong, so let’s\nsanity check. This page\nsays (as of September 2019):\nUK - 5.47%\nFrance - 3.8%\nSwitzerland - 3.15%\nGermany - 2.86%\nNetherlands - 1.33%\nOthers - 6.27%\n\\( 5.47+3.8+3.15+2.86+1.33 = 16.61 \\) - looks plausible!","summary":"I’ve had a peculiar puzzle recently. What is the percentage of European companies in MSCI World index? Surprisingly I couldn’t find this anywhere, so let’s calculate it on our own .","id":"https://merelycurious.me/post/europe_in_world_etf","isoDate":"2020-02-09T10:00:00.000Z","timestamp":"2/9/2020"},{"title":"Summary of weeks 1&amp;2 of Coursera Songwriting","link":"https://merelycurious.me/post/coursera-songwriting-weeks-1-2","pubDate":"2020-02-08T12:01:00.000Z","author":"","content":"<p>I started to take <a href=\"https://www.coursera.org/learn/songwriting-lyrics\">Songwriting course on\nCoursera</a> (yeah,\nlife is unpredictable). Here are my notes for weeks 1&amp;2.</p>\n\n<!--more-->\n\n<h2 id=\"prelude\">Prelude</h2>\n\n<p>I always had interest in writing and music and even somewhat intuitive\nfeel for it. Thus, I would like to actually learn formal stuff and\ntools to be able to grow instead of blindly wandering around.</p>\n\n<p>I usually write notes for stuff I learn or read, because this helps\nme to structure the information much better and generally improves\nrecall.</p>\n\n<h2 id=\"week-1\">Week 1</h2>\n\n<h3 id=\"point-of-view\">Point of view</h3>\n\n<p>You have to decide who’s talking to whom and why. There are following\nrelationships between the singer and audience (perspectives):</p>\n\n<ol>\n  <li>\n    <p>storyteller (third person narrative), “he &amp; she” - the most\nobjective God-like mode.</p>\n  </li>\n  <li>\n    <p>first person, “I &amp; she” - the singer tells something about them.</p>\n  </li>\n  <li>\n    <p>second person, “you &amp; she”</p>\n  </li>\n  <li>\n    <p>direct address, “I &amp; you” - the most intimate.</p>\n  </li>\n</ol>\n\n<p>There are no rules in songwriting, only tools. Try different\napproaches for your song, e.g. rewrite it from different perspectives\nand see which sounds better.</p>\n\n<h3 id=\"progression--boxes\">Progression &amp; boxes</h3>\n\n<p>Keep your listeners interested. Don’t put everything into the first\nverse, create a journey instead. Producer usually creates a music journey\nwith energy increases &amp; decreases. You use words instead.</p>\n\n<p>You can use method of boxes to create the journey. Basically each next\nverse incorporates an idea of the previous ones (gains from them), but\nalso adds something (extends them). The last box is the largest and\nbrings the most important ideas.</p>\n\n<p>Each box can represent different time, e.g. past-present-future and create\na progression in this way. Or perspective can vary, e.g. you-I-we. Or \ntimes of the year - summer-fall-winter.</p>\n\n<h3 id=\"six-best-friends\">Six best friends</h3>\n\n<p>Who, what, when, where, why &amp; how.</p>\n\n<p>You can use them to explore inside each box (i.e. you already have a\nhigh level idea and want to develop it further). Each helps to elaborate on\nideas and gives some direction. E.g. when -&gt; spring, summer, morning,\nwhere -&gt; cafe, sidewalk.</p>\n\n<h3 id=\"song-structure\">Song structure</h3>\n\n<p>Boxes are used to develop ideas, the song itself is done via sections:</p>\n\n<ul>\n  <li>\n    <p>verse - overall story or feel of the song (basic information)</p>\n  </li>\n  <li>\n    <p>chorus - central idea (repeated) - the word literally means many\npeople singing together</p>\n  </li>\n  <li>\n    <p>bridge - connects sections</p>\n  </li>\n  <li>\n    <p>pre-chorus - little bridge from verse to chorus</p>\n  </li>\n</ul>\n\n<h2 id=\"week-2\">Week 2</h2>\n\n<h3 id=\"prosody\">Prosody</h3>\n\n<p>There is actually one rule - prosody - all elements of the song have\nto work together to support the central message. Prosody -\nan appropriate relationship between elements. This is actually common\nsense - why would you put something in your song that does not belong\nthere?</p>\n\n<h3 id=\"stable-vs-unstable\">Stable vs unstable</h3>\n\n<p>There are different vehicles to express prosody. E.g. the given unit\nof a song (line, section) can be stable or unstable. Stable is like a\nfact (“I’m so grateful that you are in my life”), unstable - something\nis missing (“I wish you were here”). Just a tone of voice can change\nthis, e.g. “I finished my song”.</p>\n\n<p>Often a song combines the two in different sections.</p>\n\n<h3 id=\"compositional-elements\">Compositional elements</h3>\n\n<ol>\n  <li>\n    <p>Number of lines</p>\n  </li>\n  <li>\n    <p>Matched or unmatched line lengths</p>\n  </li>\n  <li>\n    <p>Rhyme scheme</p>\n  </li>\n  <li>\n    <p>Rhyme types</p>\n  </li>\n  <li>\n    <p>Rhythm of lines</p>\n  </li>\n</ol>\n\n<h4 id=\"number-of-lines\">Number of lines</h4>\n\n<p>Can be used to:</p>\n\n<ol>\n  <li>\n    <p>spotlight an important idea (e.g. adding a line when one does not\nexpect it, this surprises and brings attention to it - see <a href=\"https://www.youtube.com/watch?v=IEzfhclKO8Q\">“The great\npretender”</a> - “Pretending that you’re still around” is unexpected)</p>\n  </li>\n  <li>\n    <p>stop motion (even number of lines -&gt; “I’m done”) or move one section into other (odd number of lines\n-&gt; “let’s keep going”)</p>\n  </li>\n  <li>\n    <p>create contrast between sections</p>\n  </li>\n</ol>\n\n<h4 id=\"line-length\">Line length</h4>\n\n<ul>\n  <li>\n    <p>Same length = stability (balanced, stable, resolved) = “stop”.</p>\n  </li>\n  <li>\n    <p>Different length = instability = “let’s keep going, something is missing”.</p>\n  </li>\n</ul>\n\n<p>If you have the second line longer than the first one, this create\nspotlight for the extended part. If it is shorter, this create longing.</p>\n\n<p>I.e. line lengths create expectations and one can use this.</p>\n\n<p>Line length can be used to create contrast between sections. At least\nthis is much easier than with the number of lines, because that you notice\nonly when the section is over. E.g. Paul Simon - <a href=\"https://www.youtube.com/watch?v=ABXtWqmArUU\">50 Ways to Leave Your\nLover</a> - the verse has\nlong lines, the chorus - very short with quick rhyme, which suggests\nthat you have to leave your lover fast.</p>","contentSnippet":"I started to take Songwriting course on\nCoursera (yeah,\nlife is unpredictable). Here are my notes for weeks 1&2.\nPrelude\nI always had interest in writing and music and even somewhat intuitive\nfeel for it. Thus, I would like to actually learn formal stuff and\ntools to be able to grow instead of blindly wandering around.\nI usually write notes for stuff I learn or read, because this helps\nme to structure the information much better and generally improves\nrecall.\nWeek 1\nPoint of view\nYou have to decide who’s talking to whom and why. There are following\nrelationships between the singer and audience (perspectives):\nstoryteller (third person narrative), “he & she” - the most\nobjective God-like mode.\nfirst person, “I & she” - the singer tells something about them.\nsecond person, “you & she”\ndirect address, “I & you” - the most intimate.\nThere are no rules in songwriting, only tools. Try different\napproaches for your song, e.g. rewrite it from different perspectives\nand see which sounds better.\nProgression & boxes\nKeep your listeners interested. Don’t put everything into the first\nverse, create a journey instead. Producer usually creates a music journey\nwith energy increases & decreases. You use words instead.\nYou can use method of boxes to create the journey. Basically each next\nverse incorporates an idea of the previous ones (gains from them), but\nalso adds something (extends them). The last box is the largest and\nbrings the most important ideas.\nEach box can represent different time, e.g. past-present-future and create\na progression in this way. Or perspective can vary, e.g. you-I-we. Or \ntimes of the year - summer-fall-winter.\nSix best friends\nWho, what, when, where, why & how.\nYou can use them to explore inside each box (i.e. you already have a\nhigh level idea and want to develop it further). Each helps to elaborate on\nideas and gives some direction. E.g. when -> spring, summer, morning,\nwhere -> cafe, sidewalk.\nSong structure\nBoxes are used to develop ideas, the song itself is done via sections:\nverse - overall story or feel of the song (basic information)\nchorus - central idea (repeated) - the word literally means many\npeople singing together\nbridge - connects sections\npre-chorus - little bridge from verse to chorus\nWeek 2\nProsody\nThere is actually one rule - prosody - all elements of the song have\nto work together to support the central message. Prosody -\nan appropriate relationship between elements. This is actually common\nsense - why would you put something in your song that does not belong\nthere?\nStable vs unstable\nThere are different vehicles to express prosody. E.g. the given unit\nof a song (line, section) can be stable or unstable. Stable is like a\nfact (“I’m so grateful that you are in my life”), unstable - something\nis missing (“I wish you were here”). Just a tone of voice can change\nthis, e.g. “I finished my song”.\nOften a song combines the two in different sections.\nCompositional elements\nNumber of lines\nMatched or unmatched line lengths\nRhyme scheme\nRhyme types\nRhythm of lines\nNumber of lines\nCan be used to:\nspotlight an important idea (e.g. adding a line when one does not\nexpect it, this surprises and brings attention to it - see “The great\npretender” - “Pretending that you’re still around” is unexpected)\nstop motion (even number of lines -> “I’m done”) or move one section into other (odd number of lines\n-> “let’s keep going”)\ncreate contrast between sections\nLine length\nSame length = stability (balanced, stable, resolved) = “stop”.\nDifferent length = instability = “let’s keep going, something is missing”.\nIf you have the second line longer than the first one, this create\nspotlight for the extended part. If it is shorter, this create longing.\nI.e. line lengths create expectations and one can use this.\nLine length can be used to create contrast between sections. At least\nthis is much easier than with the number of lines, because that you notice\nonly when the section is over. E.g. Paul Simon - 50 Ways to Leave Your\nLover - the verse has\nlong lines, the chorus - very short with quick rhyme, which suggests\nthat you have to leave your lover fast.","summary":"I started to take Songwriting course on Coursera (yeah, life is unpredictable). Here are my notes for weeks 1&amp;2.","id":"https://merelycurious.me/post/coursera_songwriting_weeks_1_2","isoDate":"2020-02-08T12:01:00.000Z","timestamp":"2/8/2020"},{"title":"Canceling Amazon Prime","link":"https://merelycurious.me/post/canceling-amazon-prime","pubDate":"2020-02-08T12:00:00.000Z","author":"","content":"<p>I canceled my free Amazon Prime trial recently. I was surprised how\nmany stages this required. Overall this looked like a dark UI\npattern.</p>\n\n<!--more-->\n\n<h2 id=\"process\">Process</h2>\n\n<p>It is non-obvious how to actually cancel the membership.</p>\n\n<p>The main page looks like:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/1_main_page.png\" alt=\"Main page\" /></p>\n\n<p>Fortunately there is “Prime” section, let’s go there:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/2_prime_page.png\" alt=\"Prime page\" /></p>\n\n<p>After some trial and error I landed at “Update your settings”:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/3_update.png\" alt=\"&quot;Update your settings&quot; dialog\" /></p>\n\n<p>Oh, “End Membership”, now we are talking. It is quite funny that this\nentire flow tries to tell me that I will lose all the benefits of\n“Prime” membership by canceling.</p>\n\n<p>However, this is definitely not the end of the story (probably more\nlike a middle point). The next screen gets more pushy and tries to\nhint me again that I will lose all my “benefits” if I cancel prime:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/4.png\" alt=\"List of benefits\" /></p>\n\n<p>The user is also presented with one bright blue button, which does not\nlead to cancellation and two very similar yellow buttons - only one of them\nis the correct one. Funny enough it is not the rightmost one. I think\nmost of the UI teaches the user to click rightmost one. Ok, I increase\nmy attention level to the maximum and click “I Do Not Want My\nBenefits”:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/5.png\" alt=\"Extend your membership?\" /></p>\n\n<p>I am pretty sure the though process was like “oh, looks like this guy\nis pretty serious, let’s use heavy artillery… and offer 7 days of\nPrime for 0.99 EUR”. WTH? I can’t imagine any use of 7 days of Prime\nfor 0.99 EUR. Again we see nice blue button, which does not lead to\ncancellation and now 3 yellow very similar ones. Only one of\nthem is the correct button and it is in the middle. At least I am still\nable to click it:</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/6.png\" alt=\"Really cancel?\" /></p>\n\n<p>Yet another screen. Again two very similar buttons. The upper one is\nthe correct one. For some reason they changed from horizontal button\nlayout to vertical. I am pretty sure this just adds confusion and\nleads to a few more people clicking the wrong button by mistake.</p>\n\n<p>Fortunately, this was the last step (but I already braced myself for more):</p>\n\n<p><img src=\"/assets/post_resources/canceling_amazon_prime/7.png\" alt=\"Cancellation message\" /></p>\n\n<h2 id=\"thoughts\">Thoughts</h2>\n\n<p>I am very curious why they stop at 3 screens and not like 10? I find 3\nscreens already awkward. Perhaps this is just to “protect a poor user\nfrom making a <em>wrong</em> choice” and 10 would be too scammy. Fortunately\nthey don’t require writing a poem in Chinese about why I want to\ncancel and lose “all the wonderful benefits”.</p>\n\n<p>Happy navigation in dark UIs!</p>","contentSnippet":"I canceled my free Amazon Prime trial recently. I was surprised how\nmany stages this required. Overall this looked like a dark UI\npattern.\nProcess\nIt is non-obvious how to actually cancel the membership.\nThe main page looks like:\n\nFortunately there is “Prime” section, let’s go there:\n\nAfter some trial and error I landed at “Update your settings”:\n\nOh, “End Membership”, now we are talking. It is quite funny that this\nentire flow tries to tell me that I will lose all the benefits of\n“Prime” membership by canceling.\nHowever, this is definitely not the end of the story (probably more\nlike a middle point). The next screen gets more pushy and tries to\nhint me again that I will lose all my “benefits” if I cancel prime:\n\nThe user is also presented with one bright blue button, which does not\nlead to cancellation and two very similar yellow buttons - only one of them\nis the correct one. Funny enough it is not the rightmost one. I think\nmost of the UI teaches the user to click rightmost one. Ok, I increase\nmy attention level to the maximum and click “I Do Not Want My\nBenefits”:\n\nI am pretty sure the though process was like “oh, looks like this guy\nis pretty serious, let’s use heavy artillery… and offer 7 days of\nPrime for 0.99 EUR”. WTH? I can’t imagine any use of 7 days of Prime\nfor 0.99 EUR. Again we see nice blue button, which does not lead to\ncancellation and now 3 yellow very similar ones. Only one of\nthem is the correct button and it is in the middle. At least I am still\nable to click it:\n\nYet another screen. Again two very similar buttons. The upper one is\nthe correct one. For some reason they changed from horizontal button\nlayout to vertical. I am pretty sure this just adds confusion and\nleads to a few more people clicking the wrong button by mistake.\nFortunately, this was the last step (but I already braced myself for more):\n\nThoughts\nI am very curious why they stop at 3 screens and not like 10? I find 3\nscreens already awkward. Perhaps this is just to “protect a poor user\nfrom making a wrong choice” and 10 would be too scammy. Fortunately\nthey don’t require writing a poem in Chinese about why I want to\ncancel and lose “all the wonderful benefits”.\nHappy navigation in dark UIs!","summary":"I canceled my free Amazon Prime trial recently. I was surprised how many stages this required. Overall this looked like a dark UI pattern.","id":"https://merelycurious.me/post/canceling_amazon_prime","isoDate":"2020-02-08T12:00:00.000Z","timestamp":"2/8/2020"},{"title":"How to tune 12 string guitar","link":"https://merelycurious.me/post/how-to-tune-12-string-guitar","pubDate":"2020-02-02T15:00:00.000Z","author":"","content":"<p>I recently needed to tune a 12 string guitar and this was less trivial\nthan I expected. Thus, here is my guide, which does not involve any\npayed apps.</p>\n\n<!--more-->\n\n<h2 id=\"prelude\">Prelude</h2>\n\n<p>When you install strings, try to keep the right order of pegs. In\nother words adjacent strings should be wired through adjacent pegs.\nThis will help you a lot during tuning and will prevent any confusion.</p>\n\n<h2 id=\"tuning\">Tuning</h2>\n\n<ol>\n  <li>\n    <p>Tune the lower string in each pair as if it is just a normal 6\nstring guitar.</p>\n  </li>\n  <li>\n    <p>Now we start tuning upper strings in each pair starting from the\nbottom.</p>\n\n    <ol>\n      <li>\n        <p>The two lowest are just the same as their paired string.</p>\n      </li>\n      <li>\n        <p>The remaining 4 should be one octave higher than the other\n string in the pair.</p>\n      </li>\n    </ol>\n  </li>\n</ol>\n\n<p>If you have a tuner for 6 string guitar, tuning one octave higher may\nbe non-trivial. However, you can use a tuner, which shows hertz\nmeasurements. I used an Android app\n<a href=\"https://play.google.com/store/apps/deta\nils?id=com.bork.dsp.datuna\">DaTuner</a> for this (I am not associated with this\napp in any way and find it quite confusing, but it shows Hz\nmeasurements which was enough for me).</p>\n\n<p>So the final tuning in herz should be:</p>\n\n<ol>\n  <li>\n    <p>(bottom most string) E4 – 329.6 Hz</p>\n  </li>\n  <li>\n    <p>E4 – 329.6 Hz (same as above)</p>\n  </li>\n  <li>\n    <p>B3 – 246.9 Hz</p>\n  </li>\n  <li>\n    <p>B3 – 246.9 Hz (same as above)</p>\n  </li>\n  <li>\n    <p>G3 – 196 Hz</p>\n  </li>\n  <li>\n    <p>G4 – 392 Hz (one octave higher)</p>\n  </li>\n  <li>\n    <p>D3 – 146.8 Hz</p>\n  </li>\n  <li>\n    <p>D4 – 293.7 Hz (one octave higher)</p>\n  </li>\n  <li>\n    <p>A2 – 110 Hz</p>\n  </li>\n  <li>\n    <p>A3 – 220 Hz (one octave higher)</p>\n  </li>\n  <li>\n    <p>E2 – 82.41 Hz</p>\n  </li>\n  <li>\n    <p>E3 – 164.81 Hz (one octave higher)</p>\n  </li>\n</ol>\n\n<p>You may ignore everything except the Hz numbers. Just make sure that\nthe app shows the given number for the given string.</p>\n\n<p>People in the Internet suggest to tune the 6th string (i.e. G4) slowly\nand letting it to “rest” in the process, since it is so high.</p>\n\n<p>Also the tension is high, so after tuning some strings, the later\nstrings will detune earlier ones a bit and you can to check them\nagain.</p>\n\n<p>Once you have a guitar more or less tuned, you don’t need to use Hz\nmeasurements anymore, since majority of tuners know all the notes and\nwill show you the distance to the closest note even if it is not one\nof 6 string guitar.</p>\n\n<p>Happy well tuned playing!</p>","contentSnippet":"I recently needed to tune a 12 string guitar and this was less trivial\nthan I expected. Thus, here is my guide, which does not involve any\npayed apps.\nPrelude\nWhen you install strings, try to keep the right order of pegs. In\nother words adjacent strings should be wired through adjacent pegs.\nThis will help you a lot during tuning and will prevent any confusion.\nTuning\nTune the lower string in each pair as if it is just a normal 6\nstring guitar.\nNow we start tuning upper strings in each pair starting from the\nbottom.\nThe two lowest are just the same as their paired string.\nThe remaining 4 should be one octave higher than the other\n string in the pair.\nIf you have a tuner for 6 string guitar, tuning one octave higher may\nbe non-trivial. However, you can use a tuner, which shows hertz\nmeasurements. I used an Android app\nDaTuner for this (I am not associated with this\napp in any way and find it quite confusing, but it shows Hz\nmeasurements which was enough for me).\nSo the final tuning in herz should be:\n(bottom most string) E4 – 329.6 Hz\nE4 – 329.6 Hz (same as above)\nB3 – 246.9 Hz\nB3 – 246.9 Hz (same as above)\nG3 – 196 Hz\nG4 – 392 Hz (one octave higher)\nD3 – 146.8 Hz\nD4 – 293.7 Hz (one octave higher)\nA2 – 110 Hz\nA3 – 220 Hz (one octave higher)\nE2 – 82.41 Hz\nE3 – 164.81 Hz (one octave higher)\nYou may ignore everything except the Hz numbers. Just make sure that\nthe app shows the given number for the given string.\nPeople in the Internet suggest to tune the 6th string (i.e. G4) slowly\nand letting it to “rest” in the process, since it is so high.\nAlso the tension is high, so after tuning some strings, the later\nstrings will detune earlier ones a bit and you can to check them\nagain.\nOnce you have a guitar more or less tuned, you don’t need to use Hz\nmeasurements anymore, since majority of tuners know all the notes and\nwill show you the distance to the closest note even if it is not one\nof 6 string guitar.\nHappy well tuned playing!","summary":"I recently needed to tune a 12 string guitar and this was less trivial than I expected. Thus, here is my guide, which does not involve any payed apps.","id":"https://merelycurious.me/post/how_to_tune_12_string_guitar","isoDate":"2020-02-02T15:00:00.000Z","timestamp":"2/2/2020"},{"title":"“Human Behavioral Biology” - course summary (lecture 18)","link":"https://merelycurious.me/post/human-behavioral-biology-sapolsky-course-summary-lecture-18-aggression","pubDate":"2020-01-25T19:00:00.000Z","author":"","content":"<p>Aggression - part 2.</p>\n\n<!--more-->\n\n<h2 id=\"amygdala\">Amygdala</h2>\n\n<p>As it was already mentioned before, when one has amygdala damage, they\nlook less into the eyes. In other words, amygdala also “looks” for\nsignals. Testosterone makes amygdala better at detecting fear and\nanger in faces. There is shortcut for visual information to amygdala\n(lateral geniculate). This is faster. E.g. cortex can still be\ndeciding whether it is a 2D or 3D object, but one has already stubbed\nother person due to the shortcut (i.e. you trade speed with analytical\naccuracy). This pathway is hyper excitable in individuals with post-\ntraumatic stress disorder.</p>\n\n<p>Williams syndrome - imprinted genetic disorder. Kids having this\ndisorder are facile with language and emotions, but cognitively\nimpaired (IQ approximately 70). They are extremely trustful and, as a\nresult, vulnerable. They can’t evoke amygdala activation through scary\nfaces.</p>\n\n<p>Social phobias - any face activates amygdala (i.e. any face is scary).\nUnder clinical depression, amygdala activates when one observes\nsomething sad, in other words amygdala is contextual (sad is scary,\nwhen you have a depression).</p>\n\n<p>Amygdala is also best at dichotomizing - us vs. them and responding to\nout-group stimuli. This will be considered in more details later.</p>\n\n<h2 id=\"frontal-cortex\">Frontal cortex</h2>\n\n<p>Responsible for appropriate behavior. When there is a choice between\ndoing something easy or hard (but better), frontal cortex makes us to\ndo the harder thing. It does not apply strong influence, instead it\nhas many weak and diffused projections. In other words, it gives bias\nvia slowly “massaging” the signal. This works like modulation. In\nother words frontal projections are very diffused and relatively weak,\nso they bias towards excitation rather than cause it. Frontal cortex\nalso has inhibitory projections.</p>\n\n<p>Dopamine is “fuel” for this activity. It is not only about\nanticipation, but also about driving the behavior needed.</p>\n\n<p>Frontal cortex also handles gratification postponement.</p>\n\n<p>Frontal cortex neurons have high metabolic rates (i.e. work hard), but are also very fragile, which leads to many frontal cortex disorders.</p>\n\n<h3 id=\"california-verbal-learning-test\">California Verbal Learning Test</h3>\n\n<p>There is a test for dementia - CVLT - California Verbal Learning Test.\nA tester tells one: “Today I bought [list of 16 unrelated items]” and\nthen asks to repeat the items. However, items can be separate into 4\ncategories, e.g. 4 fruits, 4 hardware etc. The tester repeats the\nsentence and one can remember more and more each time. However, one\nalso begins to group items into categories. E.g. they remember fruits\nfirst and name them and so on. This is executive function - notice\npatterns, try to keep track of categories. Frontal cortex handles\nthis. When there is frontal cortex damage, one remembers items as\nusual, but never does the grouping. In other words, frontal cortex\ndoes “I see a pattern, I suspect if I put effort to exploit it, this\nwill make me more productive”.</p>\n\n<p>There is also another test. One sees a circle and then is given time\nof the day like “11:10”. They are asked to draw the time as if the\ncircle is a clock. One draws hours at 11 and then minutes at number\n10, because this is the easiest interpretation.</p>\n\n<p>Another test is to name months backwards. One starts with December,\nthen November, October, September and then switches to go forward\nagain, i.e. October, November. They can’t hold off overlearned, more\nhabitual response.</p>\n\n<p>When then they are asked to count from 20 to 1, they do 20, 19, 18,\n17, September, October, i.e. slip into the previous task (it intrudes\nthe next one).</p>\n\n<h3 id=\"learning-rules\">Learning rules</h3>\n\n<p>Imagine there is a monkey. They need to pull a lever after seeing a\nvisual light signal to get food. You see visual system activity\nincrease during each signal. Frontal cortex gets activated after the\nfirst signal and stays activated - tries to learn the rule from\nindividual examples.</p>\n\n<p>At some point some rule becomes automatic, i.e. it gets stored\nsomewhere else in the brain. E.g. a demented person may be not able to\ntell names of their children, but be able to knit (since they learned\nthat as a kid). Cerebellum seems to play large role in this.</p>\n\n<h3 id=\"social-behavior\">Social behavior</h3>\n\n<p>Same applies to social behavior, e.g. Phineas Cage\n[<a href=\"https://en.wikipedia.org/wiki/Phineas_Gage\">wiki</a>] - foreman at a\nrailroad construction in 1840s. There was an explosion and a metal rod\nwent through Cage’s head damaging frontal cortex. It was hot due to\nexplosion, so it cauterized the blood vessels. Cage was conscious\nshortly after the impact. Before the event, he was sober, religious\nand highly reliable. After - abusive, sexually predatory, out of\ncontrol.</p>\n\n<p>Nowadays one can study frontal cortex via older people with natural\ndamage.</p>\n\n<p>25% of men on death row had a history of concussive head trauma to the\nfront of the head.</p>\n\n<p>There is Mc Naughton rule in the US - if individual can’t tell\ndifference between right and wrong, they are considered organically\nimpaired (i.e. this is insanity defense rule). Not seeing a difference\nbetween right and wrong implies e.g. not covering tracks after a\ncriminal act.</p>\n\n<p>E.g. John Hinckley (severe schizophrenic) tried to assassinate Reagan\nin 1981. He was found not guilty by reason of insanity. However then\nMc Naughton rule got implicitly banned, since people were unhappy that\nHinckley was “getting away”.</p>\n\n<p>However, there are people with frontal cortex damage, who can tell the\ndifference between right and wrong, but can’t control themselves. One\ncan suggest such a person 5 candies in one hand and 1 in other. When\nthe person chooses 5, they get the other hand, i.e. 1. They always\nchoose 5 and get 1. They can even explain you the rule and then choose\n5 anyway.</p>\n\n<p>Chimps fail this test too, but they pass when you give them wooden\npieces to choose from (but reward with candies). I.e. they can control\nthemselves enough when it is about wood (they don’t care much about\nit).</p>\n\n<p>For kids there is one classic developmental test with marshmallow. One\ngets left in a room with a marshmallow. If they don’t eat it, they\nwill get 2 instead. This test predicts frontal cortex metabolism as\nwell as SAT scores many years later.</p>\n\n<p>Little kids have not developed frontal cortex. As a result, when you\nplay hide and seek with them and ask “where are you?”, they reply\nbecause they can’t stop themselves. Also when they count, they do 7,8,\n9, 14, 17 - they can’t inhibit. At age 5 there is a relation between\nresting frontal cortex metabolism and socioeconomic status.\nGlucocorticoids atrophy neurons here (they have the most receptors\nhere). I.e. stress of poverty affects size and activity of frontal\ncortex.</p>\n\n<p>There was another example of a mass murdered, who had a massive car\naccident when he was 6 years old, which destroyed his frontal cortex.\nAs a result, in 11 years he committed the first murder. The last crime\nwas kidnapping a women. After holding her for a week, he just casually\nbrought her home and left his phone number suggesting to meet again,\nsince he had a great time with her. He got arrested in an hour.</p>\n\n<p>“Acquired sociopathy” - one get’s only some part of rules, especially\nwhen getting frontal cortex damage before 5-6 years of age.</p>\n\n<p>However, not all frontal cortex damage makes a person murderer. They\njust can be out of control. E.g. one can be playing piano at a social\ngathering for too long, not listening to anyone.</p>\n\n<p>In 18th century epilepsy was considered a demonic possession. The\nperson was considered a witch and burned. The legal test was - if they\ndon’t cry due to a story of crucifixion, they must be a witch. Then\nthere was a person noting that glands can atrophy, i.e. a person can\nbe organically impaired and won’t be able to cry at all. Does the same\napply to frontal cortex damage? What should the court do?</p>\n\n<h3 id=\"development\">Development</h3>\n\n<p>Frontal cortex is the last part of the brain to fully develop. On\naverage it matures around the age of 25. As a result, it is the least\nconstrained by genes (instead shaped by environment and experience).</p>\n\n<p>In teenagers - dopamine variation is much stronger (i.e. when adult\nhas low dopamine, teenager has even lower and otherwise). As a result\nthere is no death penalty for crimes made between 16 and 18 years,\nsince the brain is not fully mature yet. However, it is not clear what\nexactly happens to one’s brain on their 18th birthday, making death\npenalty ok.</p>\n\n<p>This is third most vulnerable region to normal aging.</p>\n\n<ol>\n  <li>\n    <p>Substantia nigra - motor system (thus, tremor of old age\nParkinson’s)</p>\n  </li>\n  <li>\n    <p>Hippocampus - memory problems</p>\n  </li>\n</ol>\n\n<p>Often people believe that older people accept how they are and listen\nless to opinion of others because of that, but this is due to frontal\ncortex damage.</p>\n\n<h3 id=\"resting-metabolism-variations\">Resting metabolism variations</h3>\n\n<p>People with elevated frontal cortex metabolism. Highly regimented,\ndisciplined, capable of controlling their behavior. Do not express\nemotions very readily, bad at reading emotions in other people. They\nhave extremely structured life. This is due to elevated resting\nmetabolism in frontal cortex.</p>\n\n<p>Thrill seekers and sociopaths e.g. have lower levels. For them it\ntakes more work to regulate (i.e. more frontal cortex gets involved).</p>\n\n<h3 id=\"relation-to-amygdala\">Relation to amygdala</h3>\n\n<p>Amygdala can regulate frontal cortex (both have inhibitory\nprojections). There is inverse correlation in activity. Without\nfrontal cortex amygdala can’t learn to stop being afraid. They can\nwork together e.g. when a harder behavior is scary (e.g. running\ntowards the enemy in a war).</p>\n\n<h2 id=\"other-parts\">Other parts</h2>\n\n<p>Septum - inhibits aggression.</p>\n\n<p>Lateral hypothalamus - predatory behavior (food acquisition).</p>\n\n<p>Anterior cingulate - empathy (feeling pain of others).</p>\n\n<p>Josh Green did the following test. Imagine you are a group of people\nhiding from enemy in a war and you have a crying baby in the group.\nDo you kill the baby? People who activate anterior cingulate less are\nmore likely to do so.</p>\n\n<p>Josh Green also did runaway trolley problem. You choose between “not\ndoing anything - 5 people die” and “pull a lever or push a person with\nyour hands - 1 person dies”. 75% are willing to pull the lever. Only\n25% are willing to push.</p>\n\n<p>There is transmagnetic stimulation which allows to turn parts of\nfrontal cortex on, this leads to more utilitarian and more selfish\ndecision making.</p>\n\n<h2 id=\"abstract-concepts\">Abstract concepts</h2>\n\n<p>We have a lot of metaphors in our life, e.g. reputation, plagiarism.\nHowever, we treat abstract concepts like real. E.g. the following\nstudy. One in an elevator. Another person comes with a drink in a cup\nand a bunch of books and asks the first person to hold the cup. There\nmay be a warm or a cold drink there. Afterwards the first person rates\nthe personality of the second person warmer if the drink was warm.\nI.e. we intermix warmth metaphor with actual temperature. In other\nwords, metaphor storage is based on hijacked pathways for storing\ntemperature.</p>\n\n<p>When you see something disgusting (e.g. rotted food), insular cortex\nactivates. When you hear a story of someone powerful mistreating\nsomeone else (in a really exploitative rotten manner), the same area\nalso activates. In other words, it handles cases of food being bad,\nmoral &amp; self disgust.</p>\n\n<p>This even can be seen in the language, e.g. “I am <em>disgusted</em> by\nwhat you did”. Also “nauseous”, “smells rotten” - i.e. terms intermix\nsensory disgust with moral disgust. I.e. moral disgust is shoehorned\nin this part of the brain.</p>\n\n<p>People thinking of their moral failings are more likely to choose soap\nas a reward afterwards to “wash their hands of their sins” (study).</p>\n\n<p>If one is allowed to wash their hands of their metaphorical sins, they\nare less likely to help the other person who dropped books (study).</p>\n\n<p>That’s how mammalian brain does abstract thinking.</p>\n\n<p>Jonathan Haidt did the following study. Ask people about</p>\n\n<ul>\n  <li>\n    <p>siblings having non-reproductive sexual relationship in private.</p>\n  </li>\n  <li>\n    <p>grandma asks to slap her</p>\n  </li>\n  <li>\n    <p>burn flag and step on it</p>\n  </li>\n  <li>\n    <p>eat your dead pet (when you are extremely hungry)</p>\n  </li>\n</ul>\n\n<p>All of these activate insular cortex, people can’t explain what’s\nwrong. I.e. cognitive decisions catch up afterwards.</p>\n\n<p>There are areas which activate in various contexts, e.g. for murder or\norgasm it can be increases heart rate (i.e. non-specificity of\narousal).</p>\n\n<p>Elli Wiesel said that opposite of love is not hate, but indifference.\nLove and hate are physiologically similar.</p>\n\n<h2 id=\"testosterone\">Testosterone</h2>\n\n<p>Testosterone (like in sexual behavior) is required for expressions of\naggression. The more prior experience one has, the more residual\nbehavior they have when testosterone is removed. Behavior drives\ntestosterone.</p>\n\n<p>E.g. take a rhesus monkey. They build dominance hierarchy. Pump rank 3\nout of 5 with testosterone. They start beating 4 and 5 more. I.e.\ntestosterone only exaggerates existing social structure.</p>\n\n<p>When testosterone is higher, amygdala threshold for a threatening face\nis lower.</p>\n\n<p>Testosterone shortens refractory period of single neurons in amygdala.\nI.e. it does not cause anything, it only amplifies.</p>\n\n<h3 id=\"hyenas\">Hyenas</h3>\n\n<p>In spotted hyenas - females dominate males. They are bigger, more\nmuscular, more aggressive, have more testosterone, androgenization.\nClitoris has size of male penises. They are hormonally more male than\nmales are.</p>\n\n<p>Most lions starve to death in the first year of life, because the\norder to eat is males, females, cubs. In hyenas it is cubs, females,\nmales.</p>\n\n<p>In primates, when one tries to dominate they get an erection. In\nhyenas males get erections when they are terrified (this is\nsubordinate gesture). Low ranking females also get clitoral erections.</p>\n\n<p>The lecturer told a story about his friend getting invited to a\nconference on predatory behavior organized by the military. The\nexplanation was that they wanted to teach tank corps to hunt like\ncarnivores (in a good tank). The exact reason is not known.</p>","contentSnippet":"Aggression - part 2.\nAmygdala\nAs it was already mentioned before, when one has amygdala damage, they\nlook less into the eyes. In other words, amygdala also “looks” for\nsignals. Testosterone makes amygdala better at detecting fear and\nanger in faces. There is shortcut for visual information to amygdala\n(lateral geniculate). This is faster. E.g. cortex can still be\ndeciding whether it is a 2D or 3D object, but one has already stubbed\nother person due to the shortcut (i.e. you trade speed with analytical\naccuracy). This pathway is hyper excitable in individuals with post-\ntraumatic stress disorder.\nWilliams syndrome - imprinted genetic disorder. Kids having this\ndisorder are facile with language and emotions, but cognitively\nimpaired (IQ approximately 70). They are extremely trustful and, as a\nresult, vulnerable. They can’t evoke amygdala activation through scary\nfaces.\nSocial phobias - any face activates amygdala (i.e. any face is scary).\nUnder clinical depression, amygdala activates when one observes\nsomething sad, in other words amygdala is contextual (sad is scary,\nwhen you have a depression).\nAmygdala is also best at dichotomizing - us vs. them and responding to\nout-group stimuli. This will be considered in more details later.\nFrontal cortex\nResponsible for appropriate behavior. When there is a choice between\ndoing something easy or hard (but better), frontal cortex makes us to\ndo the harder thing. It does not apply strong influence, instead it\nhas many weak and diffused projections. In other words, it gives bias\nvia slowly “massaging” the signal. This works like modulation. In\nother words frontal projections are very diffused and relatively weak,\nso they bias towards excitation rather than cause it. Frontal cortex\nalso has inhibitory projections.\nDopamine is “fuel” for this activity. It is not only about\nanticipation, but also about driving the behavior needed.\nFrontal cortex also handles gratification postponement.\nFrontal cortex neurons have high metabolic rates (i.e. work hard), but are also very fragile, which leads to many frontal cortex disorders.\nCalifornia Verbal Learning Test\nThere is a test for dementia - CVLT - California Verbal Learning Test.\nA tester tells one: “Today I bought [list of 16 unrelated items]” and\nthen asks to repeat the items. However, items can be separate into 4\ncategories, e.g. 4 fruits, 4 hardware etc. The tester repeats the\nsentence and one can remember more and more each time. However, one\nalso begins to group items into categories. E.g. they remember fruits\nfirst and name them and so on. This is executive function - notice\npatterns, try to keep track of categories. Frontal cortex handles\nthis. When there is frontal cortex damage, one remembers items as\nusual, but never does the grouping. In other words, frontal cortex\ndoes “I see a pattern, I suspect if I put effort to exploit it, this\nwill make me more productive”.\nThere is also another test. One sees a circle and then is given time\nof the day like “11:10”. They are asked to draw the time as if the\ncircle is a clock. One draws hours at 11 and then minutes at number\n10, because this is the easiest interpretation.\nAnother test is to name months backwards. One starts with December,\nthen November, October, September and then switches to go forward\nagain, i.e. October, November. They can’t hold off overlearned, more\nhabitual response.\nWhen then they are asked to count from 20 to 1, they do 20, 19, 18,\n17, September, October, i.e. slip into the previous task (it intrudes\nthe next one).\nLearning rules\nImagine there is a monkey. They need to pull a lever after seeing a\nvisual light signal to get food. You see visual system activity\nincrease during each signal. Frontal cortex gets activated after the\nfirst signal and stays activated - tries to learn the rule from\nindividual examples.\nAt some point some rule becomes automatic, i.e. it gets stored\nsomewhere else in the brain. E.g. a demented person may be not able to\ntell names of their children, but be able to knit (since they learned\nthat as a kid). Cerebellum seems to play large role in this.\nSocial behavior\nSame applies to social behavior, e.g. Phineas Cage\n[wiki] - foreman at a\nrailroad construction in 1840s. There was an explosion and a metal rod\nwent through Cage’s head damaging frontal cortex. It was hot due to\nexplosion, so it cauterized the blood vessels. Cage was conscious\nshortly after the impact. Before the event, he was sober, religious\nand highly reliable. After - abusive, sexually predatory, out of\ncontrol.\nNowadays one can study frontal cortex via older people with natural\ndamage.\n25% of men on death row had a history of concussive head trauma to the\nfront of the head.\nThere is Mc Naughton rule in the US - if individual can’t tell\ndifference between right and wrong, they are considered organically\nimpaired (i.e. this is insanity defense rule). Not seeing a difference\nbetween right and wrong implies e.g. not covering tracks after a\ncriminal act.\nE.g. John Hinckley (severe schizophrenic) tried to assassinate Reagan\nin 1981. He was found not guilty by reason of insanity. However then\nMc Naughton rule got implicitly banned, since people were unhappy that\nHinckley was “getting away”.\nHowever, there are people with frontal cortex damage, who can tell the\ndifference between right and wrong, but can’t control themselves. One\ncan suggest such a person 5 candies in one hand and 1 in other. When\nthe person chooses 5, they get the other hand, i.e. 1. They always\nchoose 5 and get 1. They can even explain you the rule and then choose\n5 anyway.\nChimps fail this test too, but they pass when you give them wooden\npieces to choose from (but reward with candies). I.e. they can control\nthemselves enough when it is about wood (they don’t care much about\nit).\nFor kids there is one classic developmental test with marshmallow. One\ngets left in a room with a marshmallow. If they don’t eat it, they\nwill get 2 instead. This test predicts frontal cortex metabolism as\nwell as SAT scores many years later.\nLittle kids have not developed frontal cortex. As a result, when you\nplay hide and seek with them and ask “where are you?”, they reply\nbecause they can’t stop themselves. Also when they count, they do 7,8,\n9, 14, 17 - they can’t inhibit. At age 5 there is a relation between\nresting frontal cortex metabolism and socioeconomic status.\nGlucocorticoids atrophy neurons here (they have the most receptors\nhere). I.e. stress of poverty affects size and activity of frontal\ncortex.\nThere was another example of a mass murdered, who had a massive car\naccident when he was 6 years old, which destroyed his frontal cortex.\nAs a result, in 11 years he committed the first murder. The last crime\nwas kidnapping a women. After holding her for a week, he just casually\nbrought her home and left his phone number suggesting to meet again,\nsince he had a great time with her. He got arrested in an hour.\n“Acquired sociopathy” - one get’s only some part of rules, especially\nwhen getting frontal cortex damage before 5-6 years of age.\nHowever, not all frontal cortex damage makes a person murderer. They\njust can be out of control. E.g. one can be playing piano at a social\ngathering for too long, not listening to anyone.\nIn 18th century epilepsy was considered a demonic possession. The\nperson was considered a witch and burned. The legal test was - if they\ndon’t cry due to a story of crucifixion, they must be a witch. Then\nthere was a person noting that glands can atrophy, i.e. a person can\nbe organically impaired and won’t be able to cry at all. Does the same\napply to frontal cortex damage? What should the court do?\nDevelopment\nFrontal cortex is the last part of the brain to fully develop. On\naverage it matures around the age of 25. As a result, it is the least\nconstrained by genes (instead shaped by environment and experience).\nIn teenagers - dopamine variation is much stronger (i.e. when adult\nhas low dopamine, teenager has even lower and otherwise). As a result\nthere is no death penalty for crimes made between 16 and 18 years,\nsince the brain is not fully mature yet. However, it is not clear what\nexactly happens to one’s brain on their 18th birthday, making death\npenalty ok.\nThis is third most vulnerable region to normal aging.\nSubstantia nigra - motor system (thus, tremor of old age\nParkinson’s)\nHippocampus - memory problems\nOften people believe that older people accept how they are and listen\nless to opinion of others because of that, but this is due to frontal\ncortex damage.\nResting metabolism variations\nPeople with elevated frontal cortex metabolism. Highly regimented,\ndisciplined, capable of controlling their behavior. Do not express\nemotions very readily, bad at reading emotions in other people. They\nhave extremely structured life. This is due to elevated resting\nmetabolism in frontal cortex.\nThrill seekers and sociopaths e.g. have lower levels. For them it\ntakes more work to regulate (i.e. more frontal cortex gets involved).\nRelation to amygdala\nAmygdala can regulate frontal cortex (both have inhibitory\nprojections). There is inverse correlation in activity. Without\nfrontal cortex amygdala can’t learn to stop being afraid. They can\nwork together e.g. when a harder behavior is scary (e.g. running\ntowards the enemy in a war).\nOther parts\nSeptum - inhibits aggression.\nLateral hypothalamus - predatory behavior (food acquisition).\nAnterior cingulate - empathy (feeling pain of others).\nJosh Green did the following test. Imagine you are a group of people\nhiding from enemy in a war and you have a crying baby in the group.\nDo you kill the baby? People who activate anterior cingulate less are\nmore likely to do so.\nJosh Green also did runaway trolley problem. You choose between “not\ndoing anything - 5 people die” and “pull a lever or push a person with\nyour hands - 1 person dies”. 75% are willing to pull the lever. Only\n25% are willing to push.\nThere is transmagnetic stimulation which allows to turn parts of\nfrontal cortex on, this leads to more utilitarian and more selfish\ndecision making.\nAbstract concepts\nWe have a lot of metaphors in our life, e.g. reputation, plagiarism.\nHowever, we treat abstract concepts like real. E.g. the following\nstudy. One in an elevator. Another person comes with a drink in a cup\nand a bunch of books and asks the first person to hold the cup. There\nmay be a warm or a cold drink there. Afterwards the first person rates\nthe personality of the second person warmer if the drink was warm.\nI.e. we intermix warmth metaphor with actual temperature. In other\nwords, metaphor storage is based on hijacked pathways for storing\ntemperature.\nWhen you see something disgusting (e.g. rotted food), insular cortex\nactivates. When you hear a story of someone powerful mistreating\nsomeone else (in a really exploitative rotten manner), the same area\nalso activates. In other words, it handles cases of food being bad,\nmoral & self disgust.\nThis even can be seen in the language, e.g. “I am disgusted by\nwhat you did”. Also “nauseous”, “smells rotten” - i.e. terms intermix\nsensory disgust with moral disgust. I.e. moral disgust is shoehorned\nin this part of the brain.\nPeople thinking of their moral failings are more likely to choose soap\nas a reward afterwards to “wash their hands of their sins” (study).\nIf one is allowed to wash their hands of their metaphorical sins, they\nare less likely to help the other person who dropped books (study).\nThat’s how mammalian brain does abstract thinking.\nJonathan Haidt did the following study. Ask people about\nsiblings having non-reproductive sexual relationship in private.\ngrandma asks to slap her\nburn flag and step on it\neat your dead pet (when you are extremely hungry)\nAll of these activate insular cortex, people can’t explain what’s\nwrong. I.e. cognitive decisions catch up afterwards.\nThere are areas which activate in various contexts, e.g. for murder or\norgasm it can be increases heart rate (i.e. non-specificity of\narousal).\nElli Wiesel said that opposite of love is not hate, but indifference.\nLove and hate are physiologically similar.\nTestosterone\nTestosterone (like in sexual behavior) is required for expressions of\naggression. The more prior experience one has, the more residual\nbehavior they have when testosterone is removed. Behavior drives\ntestosterone.\nE.g. take a rhesus monkey. They build dominance hierarchy. Pump rank 3\nout of 5 with testosterone. They start beating 4 and 5 more. I.e.\ntestosterone only exaggerates existing social structure.\nWhen testosterone is higher, amygdala threshold for a threatening face\nis lower.\nTestosterone shortens refractory period of single neurons in amygdala.\nI.e. it does not cause anything, it only amplifies.\nHyenas\nIn spotted hyenas - females dominate males. They are bigger, more\nmuscular, more aggressive, have more testosterone, androgenization.\nClitoris has size of male penises. They are hormonally more male than\nmales are.\nMost lions starve to death in the first year of life, because the\norder to eat is males, females, cubs. In hyenas it is cubs, females,\nmales.\nIn primates, when one tries to dominate they get an erection. In\nhyenas males get erections when they are terrified (this is\nsubordinate gesture). Low ranking females also get clitoral erections.\nThe lecturer told a story about his friend getting invited to a\nconference on predatory behavior organized by the military. The\nexplanation was that they wanted to teach tank corps to hunt like\ncarnivores (in a good tank). The exact reason is not known.","summary":"Aggression - part 2.","id":"https://merelycurious.me/post/human_behavioral_biology_sapolsky_course_summary_lecture_18_aggression","isoDate":"2020-01-25T19:00:00.000Z","timestamp":"1/25/2020"}],"link":"https://merelycurious.me/","feedUrl":"https://merelycurious.me/feed.xml","title":"Merely curious","lastBuildDate":"2020-04-18T18:26:05+02:00","feed":"https://merelycurious.me/feed.xml"},{"items":[{"title":"Are Dockerfiles good enough, and Containers Don't Solve Everything","link":"https://plurrrr.com/archive/2021/09/10.html","pubDate":"Fri, 10 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"are-dockerfiles-good-enough?\"><a href=\"https://plurrrr.com/archive/2021/09/10.html#are-dockerfiles-good-enough?\">Are Dockerfiles good enough?</a></h2>\n<blockquote>\n<p>Containers have quickly become the favorite way to deploy software,\nfor a lot of good reasons. They have allowed, for the first time,\ndevelopers to test &quot;as close to production&quot; as possible. Unlike say,\nVMs, containers have a minimal performance hit and overhead. Almost\nall of the new orchestration technology like Kubernetes relies on\nthem and they are an open standard, with a diverse range of\ncorporate rulers overseeing them. In terms of the sky-high view,\ncontainers have never been in a better place.</p>\n<p>I would argue though that in our haste to adopt this new workflow,\nwe missed some steps. To be clear, this is not to say containers are\nbad (they aren't) or that they aren't working correctly (they are\nworking mostly as advertised). However many of the benefits to\ncontainers aren't being used by organizations correctly, resulting\nin a worse situation than before. While it is possible to use\ncontainers in a stable and easy-to-replicate workflow across a fleet\nof servers, most businesses don't.</p>\n</blockquote>\n<p>Source: <a href=\"https://matduggan.com/are-dockerfiles-good-enough/\">Are Dockerfiles good\nenough?</a>, an\narticle by Mathew Duggan.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/docker.html\">docker</a></li></ul>\n</article>\n<article>\n<h2 id=\"containers-don&#x27;t-solve-everything\"><a href=\"https://plurrrr.com/archive/2021/09/10.html#containers-don't-solve-everything\">Containers Don't Solve Everything</a></h2>\n<blockquote>\n<p>Our industry has made incredible strides in the past decade, thanks\nin part to technologies like Docker, Docker Compose, and\nKubernetes. However, we are still figuring out how to do development\nin the heterogeneous environments in which we live.</p>\n</blockquote>\n<p>Source: <a href=\"https://blog.deref.io/containers-dont-solve-everything/\">Containers Don't Solve\nEverything</a>,\nan article by Andrew Meredith.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/container.html\">container</a></li></ul>\n</article>\n","contentSnippet":"Are Dockerfiles good enough?\nContainers have quickly become the favorite way to deploy software,\nfor a lot of good reasons. They have allowed, for the first time,\ndevelopers to test \"as close to production\" as possible. Unlike say,\nVMs, containers have a minimal performance hit and overhead. Almost\nall of the new orchestration technology like Kubernetes relies on\nthem and they are an open standard, with a diverse range of\ncorporate rulers overseeing them. In terms of the sky-high view,\ncontainers have never been in a better place.\nI would argue though that in our haste to adopt this new workflow,\nwe missed some steps. To be clear, this is not to say containers are\nbad (they aren't) or that they aren't working correctly (they are\nworking mostly as advertised). However many of the benefits to\ncontainers aren't being used by organizations correctly, resulting\nin a worse situation than before. While it is possible to use\ncontainers in a stable and easy-to-replicate workflow across a fleet\nof servers, most businesses don't.\nSource: Are Dockerfiles good\nenough?, an\narticle by Mathew Duggan.\ndocker\n\n\n\nContainers Don't Solve Everything\nOur industry has made incredible strides in the past decade, thanks\nin part to technologies like Docker, Docker Compose, and\nKubernetes. However, we are still figuring out how to do development\nin the heterogeneous environments in which we live.\nSource: Containers Don't Solve\nEverything,\nan article by Andrew Meredith.\ncontainer","guid":"https://plurrrr.com/archive/2021/09/10.html","isoDate":"2021-09-10T21:59:59.000Z","timestamp":"9/10/2021"},{"title":"Type Level Programming, distroless images, and Code Review","link":"https://plurrrr.com/archive/2021/09/09.html","pubDate":"Thu, 09 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"an-introduction-to-type-level-programming\"><a href=\"https://plurrrr.com/archive/2021/09/09.html#an-introduction-to-type-level-programming\">An Introduction to Type Level Programming</a></h2>\n<blockquote>\n<p>In this article you’ll learn how to build programs that make heavy\nuse of type-level programming by working through building a theming\nsystem. I originally developed the ideas behind this talk and\narticle when trying to write something to unify the various themes\nand configurations for my own xmonad desktop setup, but the theming\nsystem you’ll build as you work through this article can be equally\napplied to theming web content, desktop or command line\napplications, or really anything that needs configurable theming.</p>\n</blockquote>\n<p>Source: <a href=\"https://rebeccaskinner.net/posts/2021-08-25-introduction-to-type-level-programming.html\">An Introduction to Type Level\nProgramming</a>,\nan article by Rebecca Skinner.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/haskell.html\">haskell</a></li></ul>\n</article>\n<article>\n<h2 id=\"tools-for-building-distroless-images-with-alpine\"><a href=\"https://plurrrr.com/archive/2021/09/09.html#tools-for-building-distroless-images-with-alpine\">Tools for building distroless images with Alpine</a></h2>\n<blockquote>\n<p>As I noted <a href=\"https://ariadne.space/2021/09/07/bits-relating-to-alpine-security-initiatives-in-august/\">in my last\nblog</a>,\nI have been working on a set of tools which enable the building of\nso-called “distroless” images based on Alpine.  These tools have now\nevolved to a point where they are usable for testing in lab\nenvironments, thus I am happy to announce <a href=\"https://github.com/kaniini/witchery\">the witchery\nproject</a>.</p>\n</blockquote>\n<p>Source: <a href=\"https://ariadne.space/2021/09/09/introducing-witchery-tools-for-building-distroless-images-with-alpine/\">introducing witchery: tools for building distroless images\nwith alpine – Ariadne's\nSpace</a>,\nan article by Ariadne Conill.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/container.html\">container</a></li><li><a href=\"https://plurrrr.com/tags/2021/docker.html\">docker</a></li></ul>\n</article>\n<article>\n<h2 id=\"ten-things-i-look-for-in-a-code-review\"><a href=\"https://plurrrr.com/archive/2021/09/09.html#ten-things-i-look-for-in-a-code-review\">Ten Things I Look For In a Code Review</a></h2>\n<blockquote>\n<p>Feedback is critical in any engineering organization – and that\nfeedback often comes through code reviews. Junior engineers learn\nhow to manage complexity, simplify the logic, and to develop the\ncodebase from senior engineers. But, on the other hand, even the\nmost senior engineers benefit from having a second pair of eyes on\ntheir code.</p>\n<p>Yet, very few organizations set standards around their code\nreviews. By using a checklist, you can increase code quality across\nthe entire organization. Better yet, it serves as an excellent\nonboarding document to train new reviewers, expanding the pool of\nreviewers and expediting the review pipeline.</p>\n<p>I've compiled a starting point of 10 questions to ask when reviewing\ncode.</p>\n</blockquote>\n<p>Source: <a href=\"https://matt-rickard.com/code-review-checklist/\">Ten Things I Look For In a Code\nReview</a>, an article\nby Matt Rickard.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/software-development.html\">software development</a></li></ul>\n</article>\n","contentSnippet":"An Introduction to Type Level Programming\nIn this article you’ll learn how to build programs that make heavy\nuse of type-level programming by working through building a theming\nsystem. I originally developed the ideas behind this talk and\narticle when trying to write something to unify the various themes\nand configurations for my own xmonad desktop setup, but the theming\nsystem you’ll build as you work through this article can be equally\napplied to theming web content, desktop or command line\napplications, or really anything that needs configurable theming.\nSource: An Introduction to Type Level\nProgramming,\nan article by Rebecca Skinner.\nhaskell\n\n\n\nTools for building distroless images with Alpine\nAs I noted in my last\nblog,\nI have been working on a set of tools which enable the building of\nso-called “distroless” images based on Alpine.  These tools have now\nevolved to a point where they are usable for testing in lab\nenvironments, thus I am happy to announce the witchery\nproject.\nSource: introducing witchery: tools for building distroless images\nwith alpine – Ariadne's\nSpace,\nan article by Ariadne Conill.\ncontainer\ndocker\n\n\n\nTen Things I Look For In a Code Review\nFeedback is critical in any engineering organization – and that\nfeedback often comes through code reviews. Junior engineers learn\nhow to manage complexity, simplify the logic, and to develop the\ncodebase from senior engineers. But, on the other hand, even the\nmost senior engineers benefit from having a second pair of eyes on\ntheir code.\nYet, very few organizations set standards around their code\nreviews. By using a checklist, you can increase code quality across\nthe entire organization. Better yet, it serves as an excellent\nonboarding document to train new reviewers, expanding the pool of\nreviewers and expediting the review pipeline.\nI've compiled a starting point of 10 questions to ask when reviewing\ncode.\nSource: Ten Things I Look For In a Code\nReview, an article\nby Matt Rickard.\nsoftware development","guid":"https://plurrrr.com/archive/2021/09/09.html","isoDate":"2021-09-09T21:59:59.000Z","timestamp":"9/9/2021"},{"title":"What is a monad, ZFS Channel Programs, and Preventing Data Races","link":"https://plurrrr.com/archive/2021/09/08.html","pubDate":"Wed, 08 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"monads,-part-six:-but,-really,-what-is-a-monad?\"><a href=\"https://plurrrr.com/archive/2021/09/08.html#monads,-part-six:-but,-really,-what-is-a-monad?\">Monads, part six: But, really, what is a monad?</a></h2>\n<blockquote>\n<p>In the <a href=\"https://cuddly-octo-palm-tree.com/posts/2021-04-11-monads-0\">first\nentry</a>\nin this\n<a href=\"https://cuddly-octo-palm-tree.com/tags/monad-tutorial\">series</a>, I\nargued that &quot;what is a monad?&quot; is not a useful question for the\nworking programmer. In the rest of the\n<a href=\"https://cuddly-octo-palm-tree.com/tags/monad-tutorial\">series</a> so\nfar, I have explained how to recognize situations in which a monad\ncould be useful, how to apply monads, and how to create bespoke\nones.</p>\n<p>But I still have not really defined what a monad <em>is</em>, and, while I\nstand by the argument that the answer is not <em>useful</em>, I can imagine\nthat <em>not having the answer</em> may be a bit frustrating. In this post,\nI'll try to explain what a monad is, as best I can.</p>\n</blockquote>\n<p>Source: <a href=\"https://cuddly-octo-palm-tree.com/posts/2021-09-05-monads-6/\">Monads, part six: But, really, what is a\nmonad?</a>,\nan article by Gary Verhaegen.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/functional-programming.html\">functional programming</a></li></ul>\n</article>\n<article>\n<h2 id=\"understanding-zfs-channel-programs\"><a href=\"https://plurrrr.com/archive/2021/09/08.html#understanding-zfs-channel-programs\">Understanding ZFS Channel Programs</a></h2>\n<blockquote>\n<p>One of the new OpenZFS features that became available with FreeBSD\n12.0 is ZFS Channel Programs. Today’s article answers some common\nquestions regarding ZFS Channel Programs and provides some resources\nfor learning how to create your own Channel Programs.</p>\n</blockquote>\n<p>Source: <a href=\"https://klarasystems.com/articles/understanding-zfs-channel-programs/\">Understanding ZFS Channel\nPrograms</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/zfs.html\">zfs</a></li></ul>\n</article>\n<article>\n<h2 id=\"preventing-data-races-using-actors-in-swift\"><a href=\"https://plurrrr.com/archive/2021/09/08.html#preventing-data-races-using-actors-in-swift\">Preventing Data Races Using Actors in Swift</a></h2>\n<blockquote>\n<p>Data races — the worst nightmare of all developers! They are hard to\ndetect, very unpredictable, and extremely difficult to fix. Apple\nhas given developers various toolsets such as NSLock and serial\nqueues to prevent data races from happening during runtime, however,\nnone of them are capable of catching race conditions during\ncompile-time. With the release of Swift 5.5, this will no longer be\nthe case!</p>\n<p>Introducing <strong>Actor</strong>, the new Swift language feature that can help\ndevelopers to catch any possible race conditions during development\ntime. In this article, we will first look at how a data race occurs\nwhen using dispatch queues and asynchronous tasks. After that, we\nwill look at how actors can help us to identify race conditions in\nour code and prevent them from happening once and for all!</p>\n</blockquote>\n<p>Source: <a href=\"https://swiftsenpai.com/swift/actor-prevent-data-race/\">Preventing Data Races Using Actors in\nSwift</a>, an\narticle by Lee Kah Seng.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/swift.html\">swift</a></li></ul>\n</article>\n","contentSnippet":"Monads, part six: But, really, what is a monad?\nIn the first\nentry\nin this\nseries, I\nargued that \"what is a monad?\" is not a useful question for the\nworking programmer. In the rest of the\nseries so\nfar, I have explained how to recognize situations in which a monad\ncould be useful, how to apply monads, and how to create bespoke\nones.\nBut I still have not really defined what a monad is, and, while I\nstand by the argument that the answer is not useful, I can imagine\nthat not having the answer may be a bit frustrating. In this post,\nI'll try to explain what a monad is, as best I can.\nSource: Monads, part six: But, really, what is a\nmonad?,\nan article by Gary Verhaegen.\nfunctional programming\n\n\n\nUnderstanding ZFS Channel Programs\nOne of the new OpenZFS features that became available with FreeBSD\n12.0 is ZFS Channel Programs. Today’s article answers some common\nquestions regarding ZFS Channel Programs and provides some resources\nfor learning how to create your own Channel Programs.\nSource: Understanding ZFS Channel\nPrograms.\nzfs\n\n\n\nPreventing Data Races Using Actors in Swift\nData races — the worst nightmare of all developers! They are hard to\ndetect, very unpredictable, and extremely difficult to fix. Apple\nhas given developers various toolsets such as NSLock and serial\nqueues to prevent data races from happening during runtime, however,\nnone of them are capable of catching race conditions during\ncompile-time. With the release of Swift 5.5, this will no longer be\nthe case!\nIntroducing Actor, the new Swift language feature that can help\ndevelopers to catch any possible race conditions during development\ntime. In this article, we will first look at how a data race occurs\nwhen using dispatch queues and asynchronous tasks. After that, we\nwill look at how actors can help us to identify race conditions in\nour code and prevent them from happening once and for all!\nSource: Preventing Data Races Using Actors in\nSwift, an\narticle by Lee Kah Seng.\nswift","guid":"https://plurrrr.com/archive/2021/09/08.html","isoDate":"2021-09-08T21:59:59.000Z","timestamp":"9/8/2021"},{"title":"Awk: The Power and Promise, and Kubernetes CI/CD pipelines","link":"https://plurrrr.com/archive/2021/09/07.html","pubDate":"Tue, 07 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"awk:-the-power-and-promise-of-a-40-year-old-language\"><a href=\"https://plurrrr.com/archive/2021/09/07.html#awk:-the-power-and-promise-of-a-40-year-old-language\">Awk: The Power and Promise of a 40-Year-Old Language</a></h2>\n<blockquote>\n<p>Languages don't enjoy long lives. Very few people still code with\nthe legacies of the 1970s: ML, Pascal, Scheme, Smalltalk. (The C\nlanguage is still widely used but in significantly updated\nversions.) Bucking that trend, the 1977 Unix utility Awk can boast\nof a loyal band of users and seems poised to continue far into the\nfuture. In this article, I’ll explain what makes Awk special and\nkeeps it relevant.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.fosslife.org/awk-power-and-promise-40-year-old-language\">Awk: The Power and Promise of a 40-Year-Old\nLanguage</a>,\nan article by Andy Oram.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n<article>\n<h2 id=\"kubernetes-ci/cd-pipelines:-what,-why,-and-how\"><a href=\"https://plurrrr.com/archive/2021/09/07.html#kubernetes-ci/cd-pipelines:-what,-why,-and-how\">Kubernetes CI/CD pipelines: What, why, and how</a></h2>\n<blockquote>\n<p>This blog can provide you with useful information on how to set up a\nKubernetes CI/CD workflow using state-of-the-art of open source\nDevOps tools, whether you are:</p>\n<ul>\n<li>A developer at the start of your journey with enterprise software</li>\n<li>An experienced software engineer working on your company’s applications, or</li>\n<li>An engineering lead trying to improve your team’s productivity</li>\n</ul>\n</blockquote>\n<p>Source: <a href=\"https://ubuntu.com/blog/kubernetes-ci-cd-pipelines-what-why-and-how\">Kubernetes CI/CD pipelines: What, why, and\nhow</a>,\nan article by Alex Chalkias.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/kubernetes.html\">kubernetes</a></li></ul>\n</article>\n<article>\n<h2 id=\"http/3:-practical-deployment-options\"><a href=\"https://plurrrr.com/archive/2021/09/07.html#http/3:-practical-deployment-options\">HTTP/3: Practical Deployment Options</a></h2>\n<blockquote>\n<p>After almost five years in development, the new HTTP/3 protocol is\nnearing its final form. Let’s take a close look at the challenges\ninvolved in deploying and testing HTTP/3, and how and if you should\nchange your websites and resources as well.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.smashingmagazine.com/2021/09/http3-practical-deployment-options-part3/\">HTTP/3: Practical Deployment Options (Part\n3)</a>,\nan article by Robin Marx.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/internet.html\">internet</a></li></ul>\n</article>\n","contentSnippet":"Awk: The Power and Promise of a 40-Year-Old Language\nLanguages don't enjoy long lives. Very few people still code with\nthe legacies of the 1970s: ML, Pascal, Scheme, Smalltalk. (The C\nlanguage is still widely used but in significantly updated\nversions.) Bucking that trend, the 1977 Unix utility Awk can boast\nof a loyal band of users and seems poised to continue far into the\nfuture. In this article, I’ll explain what makes Awk special and\nkeeps it relevant.\nSource: Awk: The Power and Promise of a 40-Year-Old\nLanguage,\nan article by Andy Oram.\ncommand line\n\n\n\nKubernetes CI/CD pipelines: What, why, and how\nThis blog can provide you with useful information on how to set up a\nKubernetes CI/CD workflow using state-of-the-art of open source\nDevOps tools, whether you are:\nA developer at the start of your journey with enterprise software\nAn experienced software engineer working on your company’s applications, or\nAn engineering lead trying to improve your team’s productivity\nSource: Kubernetes CI/CD pipelines: What, why, and\nhow,\nan article by Alex Chalkias.\nkubernetes\n\n\n\nHTTP/3: Practical Deployment Options\nAfter almost five years in development, the new HTTP/3 protocol is\nnearing its final form. Let’s take a close look at the challenges\ninvolved in deploying and testing HTTP/3, and how and if you should\nchange your websites and resources as well.\nSource: HTTP/3: Practical Deployment Options (Part\n3),\nan article by Robin Marx.\ninternet","guid":"https://plurrrr.com/archive/2021/09/07.html","isoDate":"2021-09-07T21:59:59.000Z","timestamp":"9/7/2021"},{"title":"The Bodies Left Behind, don't parse output of ls, and The Broken Eye","link":"https://plurrrr.com/archive/2021/09/06.html","pubDate":"Mon, 06 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"the-bodies-left-behind:-excellent\"><a href=\"https://plurrrr.com/archive/2021/09/06.html#the-bodies-left-behind:-excellent\">The Bodies Left Behind: Excellent</a></h2>\n<p>In the afternoon I finished <a href=\"https://www.amazon.com/Bodies-Left-Behind-Novel-ebook/dp/B001KM0Y0I\">The Bodies Left\nBehind</a>\nby Jeffery Deaver. An excellent read, highly recommended.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/crime-fiction.html\">crime fiction</a></li></ul>\n</article>\n<article>\n<h2 id=\"why-you-shouldn&#x27;t-parse-the-output-of-ls(1)\"><a href=\"https://plurrrr.com/archive/2021/09/06.html#why-you-shouldn't-parse-the-output-of-ls(1)\">Why you shouldn't parse the output of ls(1)</a></h2>\n<blockquote>\n<p>The <code>ls(1)</code> command is pretty good at showing you the attributes of\na single file (at least in some cases), but when you ask it for a\n<em>list</em> of files, there's a huge problem: Unix allows almost any\ncharacter in a filename, including whitespace, newlines, commas,\npipe symbols, and pretty much anything else you'd ever try to use as\na delimiter except NUL. There are\n<a href=\"http://www.dwheeler.com/essays/fixing-unix-linux-filenames.html\">proposals</a>\nto try and &quot;fix&quot; this within POSIX, but they won't help in dealing\nwith the current situation (see also <a href=\"http://www.dwheeler.com/essays/filenames-in-shell.html\">how to deal with filenames\ncorrectly</a>). In\nits default mode, if standard output isn't a terminal, <code>ls</code>\nseparates filenames with newlines. This is fine until you have a\nfile with a newline in its name. And since I don't know of any\nimplementation of <code>ls</code> that allows you to terminate filenames with\nNUL characters instead of newlines, this leaves us unable to get a\nlist of filenames safely with <code>ls</code>.</p>\n</blockquote>\n<p>Source: <a href=\"https://mywiki.wooledge.org/ParsingLs\">Why you shouldn't parse the output of ls(1)</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li><li><a href=\"https://plurrrr.com/tags/2021/shell.html\">shell</a></li></ul>\n</article>\n<article>\n<h2 id=\"the-broken-eye\"><a href=\"https://plurrrr.com/archive/2021/09/06.html#the-broken-eye\">The Broken Eye</a></h2>\n<blockquote>\n<p>As the old gods awaken and satrapies splinter, the Chromeria races\nto find the only man who can still end a civil war before it engulfs\nthe known world. But Gavin Guile has been captured by an old enemy\nand enslaved on a pirate galley. Worse still, Gavin has lost more\nthan his powers as Prism -- he can't use magic at all.</p>\n<p>Without the protection of his father, Kip Guile will face a master\nof shadows as his grandfather moves to choose a new Prism and put\nhimself in power. With Teia and Karris, Kip will have to use all his\nwits to survive a secret war between noble houses, religious\nfactions, rebels, and an ascendant order of hidden assassins called\nThe Broken Eye.</p>\n</blockquote>\n<p>In the evening I started in <a href=\"https://www.amazon.com/Broken-Eye-Lightbringer-Book-ebook/dp/B00H25FCNG\">The Broken\nEye</a>,\nLightbringer Book 3 by Brent Weeks. I enjoyed the previous books a\nlot, especially the second one.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/book.html\">book</a></li><li><a href=\"https://plurrrr.com/tags/2021/fantasy.html\">fantasy</a></li></ul>\n</article>\n","contentSnippet":"The Bodies Left Behind: Excellent\nIn the afternoon I finished The Bodies Left\nBehind\nby Jeffery Deaver. An excellent read, highly recommended.\ncrime fiction\n\n\n\nWhy you shouldn't parse the output of ls(1)\nThe ls(1) command is pretty good at showing you the attributes of\na single file (at least in some cases), but when you ask it for a\nlist of files, there's a huge problem: Unix allows almost any\ncharacter in a filename, including whitespace, newlines, commas,\npipe symbols, and pretty much anything else you'd ever try to use as\na delimiter except NUL. There are\nproposals\nto try and \"fix\" this within POSIX, but they won't help in dealing\nwith the current situation (see also how to deal with filenames\ncorrectly). In\nits default mode, if standard output isn't a terminal, ls\nseparates filenames with newlines. This is fine until you have a\nfile with a newline in its name. And since I don't know of any\nimplementation of ls that allows you to terminate filenames with\nNUL characters instead of newlines, this leaves us unable to get a\nlist of filenames safely with ls.\nSource: Why you shouldn't parse the output of ls(1).\ncommand line\nshell\n\n\n\nThe Broken Eye\nAs the old gods awaken and satrapies splinter, the Chromeria races\nto find the only man who can still end a civil war before it engulfs\nthe known world. But Gavin Guile has been captured by an old enemy\nand enslaved on a pirate galley. Worse still, Gavin has lost more\nthan his powers as Prism -- he can't use magic at all.\nWithout the protection of his father, Kip Guile will face a master\nof shadows as his grandfather moves to choose a new Prism and put\nhimself in power. With Teia and Karris, Kip will have to use all his\nwits to survive a secret war between noble houses, religious\nfactions, rebels, and an ascendant order of hidden assassins called\nThe Broken Eye.\nIn the evening I started in The Broken\nEye,\nLightbringer Book 3 by Brent Weeks. I enjoyed the previous books a\nlot, especially the second one.\nbook\nfantasy","guid":"https://plurrrr.com/archive/2021/09/06.html","isoDate":"2021-09-06T21:59:59.000Z","timestamp":"9/6/2021"},{"title":"Fast Rust Builds, and Reproducible Data Science Environment with Nix","link":"https://plurrrr.com/archive/2021/09/05.html","pubDate":"Sun, 05 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"fast-rust-builds\"><a href=\"https://plurrrr.com/archive/2021/09/05.html#fast-rust-builds\">Fast Rust Builds</a></h2>\n<blockquote>\n<p>It’s common knowledge that Rust code is slow to compile. But I have\na strong gut feeling that most Rust code out there compiles much\nslower than it could.</p>\n</blockquote>\n<p>Source: <a href=\"https://matklad.github.io/2021/09/04/fast-rust-builds.html\">Fast Rust\nBuilds</a>,\nan article by Aleksey Kladov.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n<article>\n<h2 id=\"building-a-reproducible-data-science-environment-with-nix\"><a href=\"https://plurrrr.com/archive/2021/09/05.html#building-a-reproducible-data-science-environment-with-nix\">Building a Reproducible Data Science Environment with Nix</a></h2>\n<blockquote>\n<p>Nix is a 100% reproducible package manager, for all languages and\nall things. This means your python environment, your R environment,\nyour models, your <em><strong>entire computer</strong></em> can be completely\nreproduced, all using the magic of nix. In this article, we will\nwalk through setting up a simple, reproducible, and failproof data\nscience stack with nix, including importing packages not found on\nnixpkgs and caching the builds online</p>\n</blockquote>\n<p>Source: <a href=\"https://josephsdavid.github.io/nix.html\">Building a Reproducible Data Science Environment with\nNix</a>, an article by David Josephs.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/nix.html\">nix</a></li></ul>\n</article>\n","contentSnippet":"Fast Rust Builds\nIt’s common knowledge that Rust code is slow to compile. But I have\na strong gut feeling that most Rust code out there compiles much\nslower than it could.\nSource: Fast Rust\nBuilds,\nan article by Aleksey Kladov.\nrust\n\n\n\nBuilding a Reproducible Data Science Environment with Nix\nNix is a 100% reproducible package manager, for all languages and\nall things. This means your python environment, your R environment,\nyour models, your entire computer can be completely\nreproduced, all using the magic of nix. In this article, we will\nwalk through setting up a simple, reproducible, and failproof data\nscience stack with nix, including importing packages not found on\nnixpkgs and caching the builds online\nSource: Building a Reproducible Data Science Environment with\nNix, an article by David Josephs.\nnix","guid":"https://plurrrr.com/archive/2021/09/05.html","isoDate":"2021-09-05T21:59:59.000Z","timestamp":"9/5/2021"},{"title":"Slow SQL Queries, Understanding Git Merge, and Fantastic Beasts","link":"https://plurrrr.com/archive/2021/09/04.html","pubDate":"Sat, 04 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"optimizing-slow-sql-queries\"><a href=\"https://plurrrr.com/archive/2021/09/04.html#optimizing-slow-sql-queries\">Optimizing Slow SQL Queries</a></h2>\n<blockquote>\n<p>Most database problems go unnoticed during development, because we\ntend to code our applications using small datasets. It is when the\napplication has been on production for some time that database\nperformance issues start to appear, causing parts of the application\nto become slower and slower as the database continues to grow.</p>\n<p>How do you debug and identify this type of problems? In this article\nI'm going to show you how to fix the most common database\nperformance problems, which are those that are caused by improper\nindexing. Examples for Postgres, MySQL and SQLite are included!</p>\n</blockquote>\n<p>Source: <a href=\"https://blog.miguelgrinberg.com/post/optimizing-slow-sql-queries\">Optimizing Slow SQL\nQueries</a>,\nan article by Miguel Grinberg.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/database.html\">database</a></li></ul>\n</article>\n<article>\n<h2 id=\"understanding-git-merge\"><a href=\"https://plurrrr.com/archive/2021/09/04.html#understanding-git-merge\">Understanding Git Merge</a></h2>\n<blockquote>\n<p>Carrying on from my <a href=\"https://www.biteinteractive.com/picturing-git-conceptions-and-misconceptions/\">earlier\narticle</a>\nabout some ways in which Git is commonly misunderstood — and how I\nthink one <em>should</em> understand Git — I’d like to dive a bit deeper\ninto one of the most important things Git knows how to do: merging.</p>\n<p>If Git is often misunderstood, merging is one of the most\nmisunderstood things about it! In this article, I’ll try to clear up\nsome misunderstandings about merging with Git.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.biteinteractive.com/understanding-git-merge/\">Understanding Git\nMerge</a>, an\narticle by Matt Neuburg.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/git.html\">git</a></li></ul>\n</article>\n<article>\n<h2 id=\"fantastic-beasts-and-where-to-find-them\"><a href=\"https://plurrrr.com/archive/2021/09/04.html#fantastic-beasts-and-where-to-find-them\">Fantastic Beasts and Where to Find Them</a></h2>\n<blockquote>\n<p>The adventures of writer Newt Scamander in New York's secret\ncommunity of witches and wizards seventy years before Harry Potter\nreads his book in school.</p>\n</blockquote>\n<p>In the evening Esme and I watched <a href=\"https://www.imdb.com/title/tt3183660/\">Fantastic Beasts and Where to Find\nThem</a>. I didn't like the movie\nthat much and give it a 6 out of 10.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/movie.html\">movie</a></li><li><a href=\"https://plurrrr.com/tags/2021/fantasy.html\">fantasy</a></li></ul>\n</article>\n","contentSnippet":"Optimizing Slow SQL Queries\nMost database problems go unnoticed during development, because we\ntend to code our applications using small datasets. It is when the\napplication has been on production for some time that database\nperformance issues start to appear, causing parts of the application\nto become slower and slower as the database continues to grow.\nHow do you debug and identify this type of problems? In this article\nI'm going to show you how to fix the most common database\nperformance problems, which are those that are caused by improper\nindexing. Examples for Postgres, MySQL and SQLite are included!\nSource: Optimizing Slow SQL\nQueries,\nan article by Miguel Grinberg.\ndatabase\n\n\n\nUnderstanding Git Merge\nCarrying on from my earlier\narticle\nabout some ways in which Git is commonly misunderstood — and how I\nthink one should understand Git — I’d like to dive a bit deeper\ninto one of the most important things Git knows how to do: merging.\nIf Git is often misunderstood, merging is one of the most\nmisunderstood things about it! In this article, I’ll try to clear up\nsome misunderstandings about merging with Git.\nSource: Understanding Git\nMerge, an\narticle by Matt Neuburg.\ngit\n\n\n\nFantastic Beasts and Where to Find Them\nThe adventures of writer Newt Scamander in New York's secret\ncommunity of witches and wizards seventy years before Harry Potter\nreads his book in school.\nIn the evening Esme and I watched Fantastic Beasts and Where to Find\nThem. I didn't like the movie\nthat much and give it a 6 out of 10.\nmovie\nfantasy","guid":"https://plurrrr.com/archive/2021/09/04.html","isoDate":"2021-09-04T21:59:59.000Z","timestamp":"9/4/2021"},{"title":"JSON Within PostgreSQL, Graph Neural Networks, and Linting","link":"https://plurrrr.com/archive/2021/09/03.html","pubDate":"Fri, 03 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"storing-and-using-json-within-postgresql-part-one\"><a href=\"https://plurrrr.com/archive/2021/09/03.html#storing-and-using-json-within-postgresql-part-one\">Storing and Using JSON Within PostgreSQL Part One</a></h2>\n<blockquote>\n<p>Continuing our series on storing JSON directly within your database,\nwe are now looking at the JSON functionality built into PostgreSQL.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.percona.com/blog/storing-and-using-json-within-postgresql-part-one/\">Storing and Using JSON Within PostgreSQL Part\nOne</a>,\nan article by Matt Yonkovit.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/json.html\">json</a></li><li><a href=\"https://plurrrr.com/tags/2021/postgres.html\">postgres</a></li></ul>\n</article>\n<article>\n<h2 id=\"a-gentle-introduction-to-graph-neural-networks\"><a href=\"https://plurrrr.com/archive/2021/09/03.html#a-gentle-introduction-to-graph-neural-networks\">A Gentle Introduction to Graph Neural Networks</a></h2>\n<blockquote>\n<p>Neural networks have been adapted to leverage the structure and\nproperties of graphs. We explore the components needed for building\na graph neural network - and motivate the design choices behind\nthem.</p>\n</blockquote>\n<p>Source: <a href=\"https://distill.pub/2021/gnn-intro/\">A Gentle Introduction to Graph Neural\nNetworks</a>, an article by Benjamin\nSanchez-Lengeling, Emily Reif, Adam Pearce, and Alex Wiltschko.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/machine-learning.html\">machine learning</a></li></ul>\n</article>\n<article>\n<h2 id=\"exciting-new-ways-to-be-told-that-your-python-code-is-bad\"><a href=\"https://plurrrr.com/archive/2021/09/03.html#exciting-new-ways-to-be-told-that-your-python-code-is-bad\">Exciting New Ways To Be Told That Your Python Code is Bad</a></h2>\n<blockquote>\n<p><strong>I love linters</strong>. A linter is a program that looks for problems in\ncode without running it. There is something gratifying about running\na linter on a codebase and seeing a big list of warnings and\nerrors. Sometimes it can even be fun to fix them!</p>\n</blockquote>\n<p>Source: <a href=\"https://nickdrozd.github.io/2021/09/02/new-pylint-checks.html\">Exciting New Ways To Be Told That Your Python Code is\nBad</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n","contentSnippet":"Storing and Using JSON Within PostgreSQL Part One\nContinuing our series on storing JSON directly within your database,\nwe are now looking at the JSON functionality built into PostgreSQL.\nSource: Storing and Using JSON Within PostgreSQL Part\nOne,\nan article by Matt Yonkovit.\njson\npostgres\n\n\n\nA Gentle Introduction to Graph Neural Networks\nNeural networks have been adapted to leverage the structure and\nproperties of graphs. We explore the components needed for building\na graph neural network - and motivate the design choices behind\nthem.\nSource: A Gentle Introduction to Graph Neural\nNetworks, an article by Benjamin\nSanchez-Lengeling, Emily Reif, Adam Pearce, and Alex Wiltschko.\nmachine learning\n\n\n\nExciting New Ways To Be Told That Your Python Code is Bad\nI love linters. A linter is a program that looks for problems in\ncode without running it. There is something gratifying about running\na linter on a codebase and seeing a big list of warnings and\nerrors. Sometimes it can even be fun to fix them!\nSource: Exciting New Ways To Be Told That Your Python Code is\nBad.\npython","guid":"https://plurrrr.com/archive/2021/09/03.html","isoDate":"2021-09-03T21:59:59.000Z","timestamp":"9/3/2021"},{"title":"Scorplings, Picturing Git, Light Chaser, and The Bodies Left Behind","link":"https://plurrrr.com/archive/2021/09/02.html","pubDate":"Thu, 02 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"liocheles-australasiae-scorplings\"><a href=\"https://plurrrr.com/archive/2021/09/02.html#liocheles-australasiae-scorplings\"><em>Liocheles australasiae</em> Scorplings</a></h2>\n<p>In the afternoon I could take a few photos of the <em>Liocheles\naustralasiae</em> scorpion I keep with her 1<sup>st</sup> instar brood. I\npost-processed the image in Pixelmator to remove the blurring effect\nof the plastic container.</p>\n<figure>\n<img src=\"https://plurrrr.com/images/liocheles-australasiae-with-1st-instar-brood.jpg\" alt=\"Liocheles australasiae with 1st instar brood\" />\n<figcaption>\n<em>Liocheles australasiae</em> with 1<sup>st</sup> instar brood.\n</figcaption>\n</figure>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/scorpion.html\">scorpion</a></li></ul>\n</article>\n<article>\n<h2 id=\"picturing-git:-conceptions-and-misconceptions\"><a href=\"https://plurrrr.com/archive/2021/09/02.html#picturing-git:-conceptions-and-misconceptions\">Picturing Git: Conceptions and Misconceptions</a></h2>\n<blockquote>\n<p>There’s an odd thing I’ve noticed about the way many developers use\nGit. Often, they don’t really have an accurate mental model of what\nGit is and what it does. It’s surprisingly easy to get used to\nemploying a few basic Git commands without having any real idea of\nwhat they mean.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.biteinteractive.com/picturing-git-conceptions-and-misconceptions/\">Picturing Git: Conceptions and\nMisconceptions</a>,\nan article by Matt Neuburg.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/git.html\">git</a></li></ul>\n</article>\n<article>\n<h2 id=\"light-chaser:-good\"><a href=\"https://plurrrr.com/archive/2021/09/02.html#light-chaser:-good\">Light Chaser: Good</a></h2>\n<p>In the early evening I finished <a href=\"https://www.amazon.com/Light-Chaser-Peter-F-Hamilton-ebook/dp/B088Q9CQZ4\">Light\nChaser</a>\nby Peter F. Hamilton and Gareth L. Powell. I enjoyed reading this,\nrelatively short, story.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/science-fiction.html\">science fiction</a></li></ul>\n</article>\n<article>\n<h2 id=\"the-bodies-left-behind\"><a href=\"https://plurrrr.com/archive/2021/09/02.html#the-bodies-left-behind\">The Bodies Left Behind</a></h2>\n<blockquote>\n<p>When a night-time call to 911 from a secluded Wisconsin vacation\nhouse is cut short, offduty deputy Brynn McKenzie leaves her husband\nand son at the dinner table and drives up to Lake Mondac to\ninvestigate. Was it a misdial or an aborted crime report?</p>\n<p>Brynn stumbles onto a scene of true horror and narrowly escapes from\ntwo professional criminals. She and a terrified visitor to the\nweekend house, Michelle, flee into the woods in a race for their\nlives. As different as night and day, and stripped of modern-day\nresources, Brynn, a tough deputy with a difficult past, and\nMichelle, a pampered city girl, must overcome their natural\nreluctance to trust each other and learn to use their wits and\ncourage to survive the relentless pursuit. The deputy's\ndisappearance spurs both her troubled son and her new husband into\naction, while the incident sets in motion Brynn's loyal fellow\ndeputies and elements from Milwaukee's underside. These various\nforces race along inexorably toward the novel's gritty and stunning\nconclusion.</p>\n</blockquote>\n<p>In the evening I started in <a href=\"https://www.amazon.com/Bodies-Left-Behind-Novel-ebook/dp/B001KM0Y0I\">The Bodies Left\nBehind</a>\nby Jeffery Deaver.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/crime-fiction.html\">crime fiction</a></li></ul>\n</article>\n","contentSnippet":"Liocheles australasiae Scorplings\nIn the afternoon I could take a few photos of the Liocheles\naustralasiae scorpion I keep with her 1st instar brood. I\npost-processed the image in Pixelmator to remove the blurring effect\nof the plastic container.\nLiocheles australasiae with 1st instar brood.\n\n\n\nscorpion\n\n\n\nPicturing Git: Conceptions and Misconceptions\nThere’s an odd thing I’ve noticed about the way many developers use\nGit. Often, they don’t really have an accurate mental model of what\nGit is and what it does. It’s surprisingly easy to get used to\nemploying a few basic Git commands without having any real idea of\nwhat they mean.\nSource: Picturing Git: Conceptions and\nMisconceptions,\nan article by Matt Neuburg.\ngit\n\n\n\nLight Chaser: Good\nIn the early evening I finished Light\nChaser\nby Peter F. Hamilton and Gareth L. Powell. I enjoyed reading this,\nrelatively short, story.\nscience fiction\n\n\n\nThe Bodies Left Behind\nWhen a night-time call to 911 from a secluded Wisconsin vacation\nhouse is cut short, offduty deputy Brynn McKenzie leaves her husband\nand son at the dinner table and drives up to Lake Mondac to\ninvestigate. Was it a misdial or an aborted crime report?\nBrynn stumbles onto a scene of true horror and narrowly escapes from\ntwo professional criminals. She and a terrified visitor to the\nweekend house, Michelle, flee into the woods in a race for their\nlives. As different as night and day, and stripped of modern-day\nresources, Brynn, a tough deputy with a difficult past, and\nMichelle, a pampered city girl, must overcome their natural\nreluctance to trust each other and learn to use their wits and\ncourage to survive the relentless pursuit. The deputy's\ndisappearance spurs both her troubled son and her new husband into\naction, while the incident sets in motion Brynn's loyal fellow\ndeputies and elements from Milwaukee's underside. These various\nforces race along inexorably toward the novel's gritty and stunning\nconclusion.\nIn the evening I started in The Bodies Left\nBehind\nby Jeffery Deaver.\ncrime fiction","guid":"https://plurrrr.com/archive/2021/09/02.html","isoDate":"2021-09-02T21:59:59.000Z","timestamp":"9/2/2021"},{"title":"Apple Private Relay, Perl to Raku, ‘Junk DNA’, and baby scorpions","link":"https://plurrrr.com/archive/2021/09/01.html","pubDate":"Wed, 01 Sep 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"how-does-apple-private-relay-work?\"><a href=\"https://plurrrr.com/archive/2021/09/01.html#how-does-apple-private-relay-work?\">How does Apple Private Relay Work?</a></h2>\n<blockquote>\n<p>Private Relay is an attempt by Apple to change the way traffic is\nrouted from user to internet service and back. This is designed to\nbreak the relationship between user IP address and information about\nthat user, reducing the digital footprint of that user and\neliminating certain venues of advertising information.</p>\n<p>It is a new feature in the latest version of iOS and MacOS that will\nbe launching in &quot;beta mode&quot;. It is available to all users who pay\nApple for iCloud storage and I became interested in it after\nwatching the WWDC session about preparing for it.</p>\n</blockquote>\n<p>Source: <a href=\"https://matduggan.com/how-does-apple-private-relay-work/\">How does Apple Private Relay\nWork?</a>, an\narticle by Mathew Duggan.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/networking.html\">networking</a></li><li><a href=\"https://plurrrr.com/tags/2021/security.html\">security</a></li></ul>\n</article>\n<article>\n<h2 id=\"perl-&amp;-raku:-best-frenemies\"><a href=\"https://plurrrr.com/archive/2021/09/01.html#perl-&-raku:-best-frenemies\">Perl &amp; Raku: Best frenemies</a></h2>\n<blockquote>\n<p>Although the two languages aren’t source-compatible, the\n<a href=\"https://modules.raku.org/dist/Inline::Perl5:cpan:NINE\">Inline::Perl5</a>\nmodule does enable Raku developers to run Perl code and use Perl\nmodules within Raku, You can even subclass Perl classes in Raku and\ncall Raku methods from Perl code. I hadn’t realized until recently\nthat the Perl support was so strong in Raku despite them being so\ndifferent, and so I thought I’d take the opportunity to write some\nsample code in both languages to better understand the Raku way of\ndoing things.</p>\n</blockquote>\n<p>Source: <a href=\"https://phoenixtrap.com/2021/08/17/perl-raku-best-frenemies/\">Perl &amp; Raku: Best\nfrenemies</a>,\nan article by Mark Gardner.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/perl.html\">perl</a></li><li><a href=\"https://plurrrr.com/tags/2021/raku.html\">raku</a></li></ul>\n</article>\n<article>\n<h2 id=\"the-complex-truth-about-‘junk-dna’\"><a href=\"https://plurrrr.com/archive/2021/09/01.html#the-complex-truth-about-%E2%80%98junk-dna%E2%80%99\">The Complex Truth About ‘Junk DNA’</a></h2>\n<blockquote>\n<p>Genomes hold immense quantities of noncoding DNA. Some is essential\nfor life, some seems useless, and some of it has its own agenda.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.quantamagazine.org/the-complex-truth-about-junk-dna-20210901/\">The Complex Truth About ‘Junk\nDNA’</a>,\nan article by Jake Buehler.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/science.html\">science</a></li></ul>\n</article>\n<article>\n<h2 id=\"baby-scorpions\"><a href=\"https://plurrrr.com/archive/2021/09/01.html#baby-scorpions\">Baby Scorpions</a></h2>\n<p>In the evening I noticed that the <em>Liocheles australasiae</em> I keep\nsince <a href=\"https://plurrrr.com/archive/2021/05/27.html\">May the\n27<sup>th</sup></a> had\ngiven birth. As this species is parthenogenetic I was hoping the adult\nfemale scorpion I keep would give birth someday.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/scorpion.html\">scorpion</a></li></ul>\n</article>\n","contentSnippet":"How does Apple Private Relay Work?\nPrivate Relay is an attempt by Apple to change the way traffic is\nrouted from user to internet service and back. This is designed to\nbreak the relationship between user IP address and information about\nthat user, reducing the digital footprint of that user and\neliminating certain venues of advertising information.\nIt is a new feature in the latest version of iOS and MacOS that will\nbe launching in \"beta mode\". It is available to all users who pay\nApple for iCloud storage and I became interested in it after\nwatching the WWDC session about preparing for it.\nSource: How does Apple Private Relay\nWork?, an\narticle by Mathew Duggan.\nnetworking\nsecurity\n\n\n\nPerl & Raku: Best frenemies\nAlthough the two languages aren’t source-compatible, the\nInline::Perl5\nmodule does enable Raku developers to run Perl code and use Perl\nmodules within Raku, You can even subclass Perl classes in Raku and\ncall Raku methods from Perl code. I hadn’t realized until recently\nthat the Perl support was so strong in Raku despite them being so\ndifferent, and so I thought I’d take the opportunity to write some\nsample code in both languages to better understand the Raku way of\ndoing things.\nSource: Perl & Raku: Best\nfrenemies,\nan article by Mark Gardner.\nperl\nraku\n\n\n\nThe Complex Truth About ‘Junk DNA’\nGenomes hold immense quantities of noncoding DNA. Some is essential\nfor life, some seems useless, and some of it has its own agenda.\nSource: The Complex Truth About ‘Junk\nDNA’,\nan article by Jake Buehler.\nscience\n\n\n\nBaby Scorpions\nIn the evening I noticed that the Liocheles australasiae I keep\nsince May the\n27th had\ngiven birth. As this species is parthenogenetic I was hoping the adult\nfemale scorpion I keep would give birth someday.\nscorpion","guid":"https://plurrrr.com/archive/2021/09/01.html","isoDate":"2021-09-01T21:59:59.000Z","timestamp":"9/1/2021"},{"title":"Method modifiers, Tor is a Great SysAdmin Tool, and CLI wizardry","link":"https://plurrrr.com/archive/2021/08/31.html","pubDate":"Tue, 31 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"method-modifiers-instead-of-overrides-in-object-oriented-perl\"><a href=\"https://plurrrr.com/archive/2021/08/31.html#method-modifiers-instead-of-overrides-in-object-oriented-perl\">Method modifiers instead of overrides in object-oriented Perl</a></h2>\n<blockquote>\n<p>Last month [I wrote about using Moose’s <code>override</code> function] to,\nwell, override a superclass’s method. <a href=\"https://chris.prather.org/\">Chris\nPrather</a> on the <a href=\"https://kiwiirc.com/nextclient/#irc://irc.perl.org/moose\">#moose IRC\nchannel</a>\nsuggested soon after that the <a href=\"https://metacpan.org/dist/Moose/view/lib/Moose/Manual/MethodModifiers.pod#Around-modifiers\"><code>around</code> method\nmodifier</a>\n(or its little sisters <a href=\"https://metacpan.org/dist/Moose/view/lib/Moose/Manual/MethodModifiers.pod#Before-and-after-Modifiers\"><code>before</code> and\n<code>after</code></a>)\nmight be a better choice if you’re also calling the original method\ninside. He noted that “at a minimum <code>override</code> only works if you’re\nsubclassing, <code>around</code> will apply to composed methods too.”</p>\n</blockquote>\n<p>Source: <a href=\"https://phoenixtrap.com/2021/08/31/taming-the-moose-method-modifiers-instead-of-overrides-in-object-oriented-perl/\">Taming the Moose: Method modifiers instead of overrides in\nobject-oriented\nPerl</a>,\nan article by Mark Gardner.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/perl.html\">perl</a></li></ul>\n</article>\n<article>\n<h2 id=\"tor-is-a-great-sysadmin-tool\"><a href=\"https://plurrrr.com/archive/2021/08/31.html#tor-is-a-great-sysadmin-tool\">Tor is a Great SysAdmin Tool</a></h2>\n<blockquote>\n<p>Tor is a fantastic networking and privacy technology that makes\nprivate and anonymous browsing available to millions. Despite this,\nit is unfortunately seen by some people as a system that solely\nexists to facilitate an illegal criminal underground,</p>\n<p>However, to take a literal view, <em>Tor is just a networking tool</em>,\nand it can be used in any way that you want. The features that\nenable privacy and anonymity are also extremely useful for many of\nthe tasks carried out by Network Engineers and Systems\nAdministrators on a daily basis. For example:</p>\n<ul>\n<li><a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/#testing-ip-address-based-access-rules\">Testing IP address based access rules</a></li>\n<li><a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/#testing-internally-hosted-services-from-an-external-perspective\">Testing internally-hosted services from an external perspective</a></li>\n<li><a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/#making-reliable-external-dns-lookups-when-operating-in-a-split-horizon-dns-environment\">Making reliable external DNS lookups when operating in a split-horizon DNS environment</a></li>\n<li><a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/#bypassing-blocked-outbound-ports\">Bypassing blocked outbound ports</a></li>\n<li><a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/#exposing-services-when-behind-nat-or-cgnat\">Exposing services when behind NAT or CGNAT</a></li>\n</ul>\n</blockquote>\n<p>Source: <a href=\"https://www.jamieweb.net/blog/tor-is-a-great-sysadmin-tool/\">Tor is a Great SysAdmin\nTool</a>, an\narticle by Jamie Scaife.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/tor.html\">tor</a></li><li><a href=\"https://plurrrr.com/tags/2021/networking.html\">networking</a></li></ul>\n</article>\n<article>\n<h2 id=\"linux/bsd-command-line-wizardry\"><a href=\"https://plurrrr.com/archive/2021/08/31.html#linux/bsd-command-line-wizardry\">Linux/BSD command line wizardry</a></h2>\n<blockquote>\n<p>As a relatively isolated junior sysadmin, I remember seeing answers\non Experts Exchange and later Stack Exchange that baffled\nme. Authors and commenters might chain 10 commands together with\npipes and angle brackets—something I never did in day-to-day system\nadministration. Honestly, I doubted the real-world value of\nthat. Surely, this was just an exercise in e-braggadocio, right?</p>\n</blockquote>\n<p>Source: <a href=\"https://arstechnica.com/gadgets/2021/08/linux-bsd-command-line-101-using-awk-sed-and-grep-in-the-terminal/\">Linux/BSD command line wizardry: Learn to think in sed, awk,\nand\ngrep</a>,\nan article by Jim Salter.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n","contentSnippet":"Method modifiers instead of overrides in object-oriented Perl\nLast month [I wrote about using Moose’s override function] to,\nwell, override a superclass’s method. Chris\nPrather on the #moose IRC\nchannel\nsuggested soon after that the around method\nmodifier\n(or its little sisters before and\nafter)\nmight be a better choice if you’re also calling the original method\ninside. He noted that “at a minimum override only works if you’re\nsubclassing, around will apply to composed methods too.”\nSource: Taming the Moose: Method modifiers instead of overrides in\nobject-oriented\nPerl,\nan article by Mark Gardner.\nperl\n\n\n\nTor is a Great SysAdmin Tool\nTor is a fantastic networking and privacy technology that makes\nprivate and anonymous browsing available to millions. Despite this,\nit is unfortunately seen by some people as a system that solely\nexists to facilitate an illegal criminal underground,\nHowever, to take a literal view, Tor is just a networking tool,\nand it can be used in any way that you want. The features that\nenable privacy and anonymity are also extremely useful for many of\nthe tasks carried out by Network Engineers and Systems\nAdministrators on a daily basis. For example:\nTesting IP address based access rules\nTesting internally-hosted services from an external perspective\nMaking reliable external DNS lookups when operating in a split-horizon DNS environment\nBypassing blocked outbound ports\nExposing services when behind NAT or CGNAT\nSource: Tor is a Great SysAdmin\nTool, an\narticle by Jamie Scaife.\ntor\nnetworking\n\n\n\nLinux/BSD command line wizardry\nAs a relatively isolated junior sysadmin, I remember seeing answers\non Experts Exchange and later Stack Exchange that baffled\nme. Authors and commenters might chain 10 commands together with\npipes and angle brackets—something I never did in day-to-day system\nadministration. Honestly, I doubted the real-world value of\nthat. Surely, this was just an exercise in e-braggadocio, right?\nSource: Linux/BSD command line wizardry: Learn to think in sed, awk,\nand\ngrep,\nan article by Jim Salter.\ncommand line","guid":"https://plurrrr.com/archive/2021/08/31.html","isoDate":"2021-08-31T21:59:59.000Z","timestamp":"8/31/2021"},{"title":"Modern Neovim, pass-by-value, and Optimizing Immutable Strings","link":"https://plurrrr.com/archive/2021/08/30.html","pubDate":"Mon, 30 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"moving-to-modern-neovim\"><a href=\"https://plurrrr.com/archive/2021/08/30.html#moving-to-modern-neovim\">Moving to modern Neovim</a></h2>\n<blockquote>\n<p>I installed <a href=\"https://neovim.io/news/2021/07\">Neovim v0.5</a> when it\nwas released last month, and used it for a few weeks while reading\nabout all the new features in it. Last weekend, I felt an\nuncharacteristic urge to try them out, and I'm glad I did. Here's a\nquick overview of what I learned.</p>\n</blockquote>\n<p>Source: <a href=\"https://toroid.org/modern-neovim\">Moving to modern Neovim</a>,\nan article by Abhijit Menon-Sen.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/vim.html\">vim</a></li></ul>\n</article>\n<article>\n<h2 id=\"go-is-pass-by-value-—-but-it-might-not-always-feel-like-it\"><a href=\"https://plurrrr.com/archive/2021/08/30.html#go-is-pass-by-value-%E2%80%94-but-it-might-not-always-feel-like-it\">Go is pass-by-value — but it might not always feel like it</a></h2>\n<blockquote>\n<p>Go is a programming language which passes by value, which\neffectively means that if you give a value as a parameter to a\nfunction, the received value within the function is actually a\n<em>copy</em> of the original. You can modify it however you wish and your\nchanges will not affect the original value or escape the function\nscope. This is in contrast to some languages which pass values by\nreference instead of copying them.</p>\n</blockquote>\n<p>Source: <a href=\"https://neilalexander.dev/2021/08/29/go-pass-by-value.html\">Go is pass-by-value — but it might not always feel like\nit</a>, an\narticle by Neil Alexander.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/go.html\">go</a></li></ul>\n</article>\n<article>\n<h2 id=\"optimizing-immutable-strings-in-rust\"><a href=\"https://plurrrr.com/archive/2021/08/30.html#optimizing-immutable-strings-in-rust\">Optimizing Immutable Strings in Rust</a></h2>\n<blockquote>\n<p>In this article, we will discuss certain ways to optimize the way we\nallocate and clone data in <em>immutable</em> contexts. Throughout this\narticle, we will be using the <code>String</code> type as a particular example,\nbut <em>please do keep in mind that the concepts are generally\napplicable elsewhere</em>.</p>\n</blockquote>\n<p>Source: <a href=\"https://dev.to/somedood/optimizing-immutable-strings-in-rust-2ahj\">Optimizing Immutable Strings in\nRust</a>,\nan article by Basti Ortiz.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n","contentSnippet":"Moving to modern Neovim\nI installed Neovim v0.5 when it\nwas released last month, and used it for a few weeks while reading\nabout all the new features in it. Last weekend, I felt an\nuncharacteristic urge to try them out, and I'm glad I did. Here's a\nquick overview of what I learned.\nSource: Moving to modern Neovim,\nan article by Abhijit Menon-Sen.\nvim\n\n\n\nGo is pass-by-value — but it might not always feel like it\nGo is a programming language which passes by value, which\neffectively means that if you give a value as a parameter to a\nfunction, the received value within the function is actually a\ncopy of the original. You can modify it however you wish and your\nchanges will not affect the original value or escape the function\nscope. This is in contrast to some languages which pass values by\nreference instead of copying them.\nSource: Go is pass-by-value — but it might not always feel like\nit, an\narticle by Neil Alexander.\ngo\n\n\n\nOptimizing Immutable Strings in Rust\nIn this article, we will discuss certain ways to optimize the way we\nallocate and clone data in immutable contexts. Throughout this\narticle, we will be using the String type as a particular example,\nbut please do keep in mind that the concepts are generally\napplicable elsewhere.\nSource: Optimizing Immutable Strings in\nRust,\nan article by Basti Ortiz.\nrust","guid":"https://plurrrr.com/archive/2021/08/30.html","isoDate":"2021-08-30T21:59:59.000Z","timestamp":"8/30/2021"},{"title":"Develop a Go app with Docker Compose, and async/await in Python","link":"https://plurrrr.com/archive/2021/08/29.html","pubDate":"Sun, 29 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"develop-a-go-app-with-docker-compose\"><a href=\"https://plurrrr.com/archive/2021/08/29.html#develop-a-go-app-with-docker-compose\">Develop a Go app with Docker Compose</a></h2>\n<blockquote>\n<p>Writing Go applications in an isolated environment with Docker comes\nwith some great advantages. You get the bare essentials for\ndeveloping, and you can easily change which Go version you’re\ndeveloping against.</p>\n<p>In this tutorial, we’re going to show you how to structure a Go\napplication with Docker Compose as your development environment.</p>\n<p>In the end you'll have:</p>\n<ol>\n<li>A docker compose setup to develop in</li>\n<li>An HTTP server written in Go that is connected to Postgres</li>\n<li>An auto-reloading server that compiles when you change a file</li>\n</ol>\n</blockquote>\n<p>Source: <a href=\"https://firehydrant.io/blog/develop-a-go-app-with-docker-compose/\">Develop a Go app with Docker\nCompose</a>,\nan article by Robert Ross.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/go.html\">go</a></li><li><a href=\"https://plurrrr.com/tags/2021/docker.html\">docker</a></li></ul>\n</article>\n<article>\n<h2 id=\"how-async/await-works-in-python\"><a href=\"https://plurrrr.com/archive/2021/08/29.html#how-async/await-works-in-python\">How async/await works in Python</a></h2>\n<blockquote>\n<p>Mark functions as <code>async</code>. Call them with <code>await</code>. All of a sudden,\nyour program becomes asynchronous – it can do useful things while it\nwaits for other things, such as I/O operations, to complete.</p>\n</blockquote>\n<p>Source: <a href=\"https://tenthousandmeters.com/blog/python-behind-the-scenes-12-how-asyncawait-works-in-python/\">Python behind the scenes #12: how async/await works in\nPython</a>,\nan article by Victor Skvortsov.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n<article>\n<h2 id=\"css-masonry\"><a href=\"https://plurrrr.com/archive/2021/08/29.html#css-masonry\">CSS masonry</a></h2>\n<blockquote>\n<p>On the surface it seems fairly easy to create a masonry layout with\n<a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox\">flexbox</a>;\nall you need to do is set <code>flex-flow</code> to <code>column</code> wrap and voilà,\nyou have a masonry layout. Sort of. The problem with this approach\nis that it produces a grid with a seemingly shuffled and obscure\norder. Items will be (unbeknownst to the user) rendered from top to\nbottom and someone parsing the grid from left to right will read the\nboxes in a somewhat arbitrary order, for example 1, 3, 6, 2, 4, 7,\n8, 5, and so on so forth.</p>\n</blockquote>\n<p>Source: <a href=\"https://tobiasahlin.com/blog/masonry-with-css/\">CSS masonry with flexbox, :nth-child(), and\norder</a>, an article by\nTobias Ahlin.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/css.html\">css</a></li></ul>\n</article>\n<article>\n<h2 id=\"light-chaser\"><a href=\"https://plurrrr.com/archive/2021/08/29.html#light-chaser\">Light Chaser</a></h2>\n<blockquote>\n<p>Amahle is a Light Chaser – one of a number of explorers, who travel\nthe universe alone (except for their onboard AI), trading trinkets\nfor life stories.</p>\n<p>But when she listens to the stories sent down through the ages she\nhears the same voice talking directly to her from different times\nand on different worlds. She comes to understand that something\nterrible is happening, and only she is in a position to do anything\nabout it.</p>\n<p>And it will cost everything to put it right.</p>\n</blockquote>\n<p>In the evening I started in <a href=\"https://www.amazon.com/Light-Chaser-Peter-F-Hamilton-ebook/dp/B088Q9CQZ4\">Light\nChaser</a>\nby Peter F. Hamilton and Gareth L. Powell.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/science-fiction.html\">science fiction</a></li></ul>\n</article>\n","contentSnippet":"Develop a Go app with Docker Compose\nWriting Go applications in an isolated environment with Docker comes\nwith some great advantages. You get the bare essentials for\ndeveloping, and you can easily change which Go version you’re\ndeveloping against.\nIn this tutorial, we’re going to show you how to structure a Go\napplication with Docker Compose as your development environment.\nIn the end you'll have:\nA docker compose setup to develop in\nAn HTTP server written in Go that is connected to Postgres\nAn auto-reloading server that compiles when you change a file\nSource: Develop a Go app with Docker\nCompose,\nan article by Robert Ross.\ngo\ndocker\n\n\n\nHow async/await works in Python\nMark functions as async. Call them with await. All of a sudden,\nyour program becomes asynchronous – it can do useful things while it\nwaits for other things, such as I/O operations, to complete.\nSource: Python behind the scenes #12: how async/await works in\nPython,\nan article by Victor Skvortsov.\npython\n\n\n\nCSS masonry\nOn the surface it seems fairly easy to create a masonry layout with\nflexbox;\nall you need to do is set flex-flow to column wrap and voilà,\nyou have a masonry layout. Sort of. The problem with this approach\nis that it produces a grid with a seemingly shuffled and obscure\norder. Items will be (unbeknownst to the user) rendered from top to\nbottom and someone parsing the grid from left to right will read the\nboxes in a somewhat arbitrary order, for example 1, 3, 6, 2, 4, 7,\n8, 5, and so on so forth.\nSource: CSS masonry with flexbox, :nth-child(), and\norder, an article by\nTobias Ahlin.\ncss\n\n\n\nLight Chaser\nAmahle is a Light Chaser – one of a number of explorers, who travel\nthe universe alone (except for their onboard AI), trading trinkets\nfor life stories.\nBut when she listens to the stories sent down through the ages she\nhears the same voice talking directly to her from different times\nand on different worlds. She comes to understand that something\nterrible is happening, and only she is in a position to do anything\nabout it.\nAnd it will cost everything to put it right.\nIn the evening I started in Light\nChaser\nby Peter F. Hamilton and Gareth L. Powell.\nscience fiction","guid":"https://plurrrr.com/archive/2021/08/29.html","isoDate":"2021-08-29T21:59:59.000Z","timestamp":"8/29/2021"},{"title":"jsc, Plugins in Go, errors as values, and Solo","link":"https://plurrrr.com/archive/2021/08/28.html","pubDate":"Sat, 28 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"jsc:-my-new-best-friend\"><a href=\"https://plurrrr.com/archive/2021/08/28.html#jsc:-my-new-best-friend\">jsc: My New Best Friend</a></h2>\n<blockquote>\n<p>A <a href=\"https://twitter.com/danielpunkass\">friend of mine</a> recently\npointed me at a well hidden command line tool. In the JavaScript\nframework used by Safari and other parts of Apple’s products, there\nis a tool called <code>jsc</code>. It’s a command line interface for JavaScript\nthat uses the same code as the rest of the system.</p>\n</blockquote>\n<p>Source: <a href=\"https://furbo.org/2021/08/25/jsc-my-new-best-friend/\">jsc: My New Best\nFriend</a>, an\narticle by Craig Hockenberry.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/macos.html\">macos</a></li><li><a href=\"https://plurrrr.com/tags/2021/javascript.html\">javascript</a></li></ul>\n</article>\n<article>\n<h2 id=\"plugins-in-go\"><a href=\"https://plurrrr.com/archive/2021/08/28.html#plugins-in-go\">Plugins in Go</a></h2>\n<blockquote>\n<p>Several years ago I started writing a <a href=\"https://eli.thegreenplace.net/tag/plugins\">series of\nposts</a> on <em>plugins</em>: how\nthey are designed and implemented in various systems and programming\nlanguages. In this, I'll extend the series by providing some\nexamples of plugins in Go.</p>\n<p>As a reminder, <a href=\"https://eli.thegreenplace.net/2012/08/07/fundamental-concepts-of-plugin-infrastructures\">the original\npost</a>\nin this series identifies four fundamental plugin concepts, and\nclaims that nearly all plugin systems can be characterized and\nunderstood by mapping their design to these concepts:</p>\n<ul>\n<li>Discovery</li>\n<li>Registration</li>\n<li>Application hooks to which plugins attach (aka. &quot;mount points&quot;)</li>\n<li>Exposing application capabilities back to plugins (aka. extension API)</li>\n</ul>\n</blockquote>\n<p>Source: <a href=\"https://eli.thegreenplace.net/2021/plugins-in-go/\">Plugins in\nGo</a>, an article by Eli Bendersky.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/go.html\">go</a></li></ul>\n</article>\n<article>\n<h2 id=\"away-from-exceptions:-errors-as-values\"><a href=\"https://plurrrr.com/archive/2021/08/28.html#away-from-exceptions:-errors-as-values\">Away from exceptions: errors as values</a></h2>\n<blockquote>\n<p>Programming with exceptions is difficult and inelegant. Learn how to\nhandle errors better by representing them as values.</p>\n<p>In <a href=\"https://humanlytyped.hashnode.dev/smelly-exceptions\">Smelly\nExceptions</a>, I\nlaid out 3 practices to avoid when programming with exceptions. My\ngoal there was to help you write more maintainable code. We saw that\nmisuse of exceptions make programs brittle, tightly coupled, and\ndifficult to reason about. The common factor in all three\nanti-patterns we discussed was exceptions. They are hard to use\ncorrectly. Even when used correctly, they don't compose, so the\nprogram flow is unnatural. In short, they are <em>exceptions</em>.</p>\n</blockquote>\n<p>Source: <a href=\"https://humanlytyped.hashnode.dev/away-from-exceptions-errors-as-values\">Away from exceptions: errors as\nvalues</a>,\nan article by Barisere Jonathan.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/software-development.html\">software development</a></li></ul>\n</article>\n<article>\n<h2 id=\"solo:-a-star-wars-story-(2018)\"><a href=\"https://plurrrr.com/archive/2021/08/28.html#solo:-a-star-wars-story-(2018)\">Solo: A Star Wars Story (2018)</a></h2>\n<blockquote>\n<p>Board the Millennium Falcon and journey to a galaxy far, far away in\nan epic action-adventure that will set the course of one of the Star\nWars saga's most unlikely heroes.</p>\n</blockquote>\n<p>In the evening Adam, Esme, and I watched <a href=\"https://www.imdb.com/title/tt3778644/\">Solo: A Star Wars\nStory</a>. I liked the movie and\ngive it a 7.5 out of 10.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/movie.html\">movie</a></li><li><a href=\"https://plurrrr.com/tags/2021/science-fiction.html\">science fiction</a></li></ul>\n</article>\n","contentSnippet":"jsc: My New Best Friend\nA friend of mine recently\npointed me at a well hidden command line tool. In the JavaScript\nframework used by Safari and other parts of Apple’s products, there\nis a tool called jsc. It’s a command line interface for JavaScript\nthat uses the same code as the rest of the system.\nSource: jsc: My New Best\nFriend, an\narticle by Craig Hockenberry.\nmacos\njavascript\n\n\n\nPlugins in Go\nSeveral years ago I started writing a series of\nposts on plugins: how\nthey are designed and implemented in various systems and programming\nlanguages. In this, I'll extend the series by providing some\nexamples of plugins in Go.\nAs a reminder, the original\npost\nin this series identifies four fundamental plugin concepts, and\nclaims that nearly all plugin systems can be characterized and\nunderstood by mapping their design to these concepts:\nDiscovery\nRegistration\nApplication hooks to which plugins attach (aka. \"mount points\")\nExposing application capabilities back to plugins (aka. extension API)\nSource: Plugins in\nGo, an article by Eli Bendersky.\ngo\n\n\n\nAway from exceptions: errors as values\nProgramming with exceptions is difficult and inelegant. Learn how to\nhandle errors better by representing them as values.\nIn Smelly\nExceptions, I\nlaid out 3 practices to avoid when programming with exceptions. My\ngoal there was to help you write more maintainable code. We saw that\nmisuse of exceptions make programs brittle, tightly coupled, and\ndifficult to reason about. The common factor in all three\nanti-patterns we discussed was exceptions. They are hard to use\ncorrectly. Even when used correctly, they don't compose, so the\nprogram flow is unnatural. In short, they are exceptions.\nSource: Away from exceptions: errors as\nvalues,\nan article by Barisere Jonathan.\nsoftware development\n\n\n\nSolo: A Star Wars Story (2018)\nBoard the Millennium Falcon and journey to a galaxy far, far away in\nan epic action-adventure that will set the course of one of the Star\nWars saga's most unlikely heroes.\nIn the evening Adam, Esme, and I watched Solo: A Star Wars\nStory. I liked the movie and\ngive it a 7.5 out of 10.\nmovie\nscience fiction","guid":"https://plurrrr.com/archive/2021/08/28.html","isoDate":"2021-08-28T21:59:59.000Z","timestamp":"8/28/2021"},{"title":"Illustrated Redirection, enable type checking, and Cropping using PIL","link":"https://plurrrr.com/archive/2021/08/27.html","pubDate":"Fri, 27 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"illustrated-redirection-tutorial\"><a href=\"https://plurrrr.com/archive/2021/08/27.html#illustrated-redirection-tutorial\">Illustrated Redirection Tutorial</a></h2>\n<blockquote>\n<p>This tutorial is not a complete guide to redirection, it will not\ncover here docs, here strings, name pipes etc… I just hope it'll\nhelp you to understand what things like <code>3&gt;&amp;2</code>, <code>2&gt;&amp;1</code> or <code>1&gt;&amp;3-</code>\ndo.</p>\n</blockquote>\n<p>Source: <a href=\"https://wiki.bash-hackers.org/howto/redirection_tutorial\">Illustrated Redirection\nTutorial</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/shell.html\">shell</a></li><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n<article>\n<h2 id=\"how-to-enable-python-type-checking-in-vscode\"><a href=\"https://plurrrr.com/archive/2021/08/27.html#how-to-enable-python-type-checking-in-vscode\">How to enable Python type checking in VSCode</a></h2>\n<blockquote>\n<p>Since version 3.5, Python now has <a href=\"https://docs.python.org/3/library/typing.html\">support for type\nhints</a>. This typing\nis a cool new feature allowing type checking across your code for\nmore quality and also help when you are using some packages or call\nsome functions your colleague did in a large codebase. In this\narticle, we will see how to enable type IntelliSense and type\nchecking analysis in Visual Studio Code editor.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.emmanuelgautier.com/blog/enable-vscode-python-type-checking/\">How to enable Python type checking in\nVSCode</a>,\nan article by Emmanuel Gautier.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n<article>\n<h2 id=\"cropping-model-images-using-pil\"><a href=\"https://plurrrr.com/archive/2021/08/27.html#cropping-model-images-using-pil\">Cropping model images using PIL</a></h2>\n<blockquote>\n<p>We love to use model images at Wehkamp. This year we've switched\nfrom overviews with <em>product</em> images to overviews with <em>model</em> images. A\nlot of photography is shot by our own photo studio. I love this,\nbecause it gives us control over the process and the tone. But as\nour assortment grows, it is not feasible to shoot all the products\non our website. That is why we use images from our\nsuppliers. Unfortunately, we have no control over the conditions of\nthe photo.</p>\n</blockquote>\n<p>Source: <a href=\"https://keestalkstech.com/2020/05/cropping-model-images-using-pil/\">Cropping model images using\nPIL</a>,\nan article by Kees C. Bakker.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n<article>\n<h2 id=\"the-blinding-knife:-very-good\"><a href=\"https://plurrrr.com/archive/2021/08/27.html#the-blinding-knife:-very-good\">The Blinding Knife: very good</a></h2>\n<p>In the evening I finished <a href=\"https://www.amazon.com/Blinding-Knife-Lightbringer-Book-ebook/dp/B0076DDFCO\">The Blinding\nKnife</a>,\nBook 2 of Lightbringer series by Brent Weeks. I liked the book a lot;\npacked with action. I consider the book better than the first one. A\nrecommended read.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/book.html\">book</a></li><li><a href=\"https://plurrrr.com/tags/2021/fantasy.html\">fantasy</a></li></ul>\n</article>\n","contentSnippet":"Illustrated Redirection Tutorial\nThis tutorial is not a complete guide to redirection, it will not\ncover here docs, here strings, name pipes etc… I just hope it'll\nhelp you to understand what things like 3>&2, 2>&1 or 1>&3-\ndo.\nSource: Illustrated Redirection\nTutorial.\nshell\ncommand line\n\n\n\nHow to enable Python type checking in VSCode\nSince version 3.5, Python now has support for type\nhints. This typing\nis a cool new feature allowing type checking across your code for\nmore quality and also help when you are using some packages or call\nsome functions your colleague did in a large codebase. In this\narticle, we will see how to enable type IntelliSense and type\nchecking analysis in Visual Studio Code editor.\nSource: How to enable Python type checking in\nVSCode,\nan article by Emmanuel Gautier.\npython\n\n\n\nCropping model images using PIL\nWe love to use model images at Wehkamp. This year we've switched\nfrom overviews with product images to overviews with model images. A\nlot of photography is shot by our own photo studio. I love this,\nbecause it gives us control over the process and the tone. But as\nour assortment grows, it is not feasible to shoot all the products\non our website. That is why we use images from our\nsuppliers. Unfortunately, we have no control over the conditions of\nthe photo.\nSource: Cropping model images using\nPIL,\nan article by Kees C. Bakker.\npython\n\n\n\nThe Blinding Knife: very good\nIn the evening I finished The Blinding\nKnife,\nBook 2 of Lightbringer series by Brent Weeks. I liked the book a lot;\npacked with action. I consider the book better than the first one. A\nrecommended read.\nbook\nfantasy","guid":"https://plurrrr.com/archive/2021/08/27.html","isoDate":"2021-08-27T21:59:59.000Z","timestamp":"8/27/2021"},{"title":"C++20 Concepts, no glibc based alpine, and Pin, Unpin","link":"https://plurrrr.com/archive/2021/08/26.html","pubDate":"Thu, 26 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"c++20-concepts\"><a href=\"https://plurrrr.com/archive/2021/08/26.html#c++20-concepts\">C++20 Concepts</a></h2>\n<blockquote>\n<p>C++20 introduced the\n<a href=\"https://en.cppreference.com/w/cpp/concepts\">Concepts</a> library and\nthe corresponding <a href=\"https://en.cppreference.com/w/cpp/language/constraints\">language extensions to template\nmetaprogramming</a>. This\npost will be a brief introduction to the topic for people already\nwell versed in C++ templates.</p>\n</blockquote>\n<p>Source: <a href=\"https://vorbrodt.blog/2021/08/25/c20-concepts/\">C++20\nConcepts</a>, an article\nby Martin Vorbrodt.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/cpp.html\">cpp</a></li></ul>\n</article>\n<article>\n<h2 id=\"there-is-no-such-thing-as-a-“glibc-based-alpine-image”\"><a href=\"https://plurrrr.com/archive/2021/08/26.html#there-is-no-such-thing-as-a-%E2%80%9Cglibc-based-alpine-image%E2%80%9D\">There is no such thing as a “glibc based alpine image”</a></h2>\n<blockquote>\n<p>For whatever reason, <a href=\"https://github.com/sgerrand/alpine-pkg-glibc\">the <code>alpine-glibc</code>\nproject</a> is\n<a href=\"https://github.com/adoptium/containers/issues/1#issuecomment-905522460\">apparently being used in\nproduction</a>.\nWorse yet, some are led to believe that Alpine officially supports\nor at least approves of its usage.  For the reasons I am about to\noutline, we don’t.</p>\n</blockquote>\n<p>Source: <a href=\"https://ariadne.space/2021/08/26/there-is-no-such-thing-as-a-glibc-based-alpine-image/\">there is no such thing as a “glibc based alpine\nimage”</a>,\nan article by Ariadne Conill.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/alpine.html\">alpine</a></li><li><a href=\"https://plurrrr.com/tags/2021/container.html\">container</a></li></ul>\n</article>\n<article>\n<h2 id=\"pin,-unpin,-and-why-rust-needs-them\"><a href=\"https://plurrrr.com/archive/2021/08/26.html#pin,-unpin,-and-why-rust-needs-them\">Pin, Unpin, and why Rust needs them</a></h2>\n<blockquote>\n<p>Using async Rust libraries is usually easy. It's just like using\nnormal Rust code, with a little <code>async</code> or <code>.await</code> here and\nthere. But writing your own async libraries can be hard. The first\ntime I tried this, I got really confused by arcane, esoteric syntax\nlike <code>T: ?Unpin</code> and <code>Pin&lt;&amp;mut Self&gt;</code>. I had never seen these types\nbefore, and I didn't understand what they were doing. Now that I\nunderstand them, I've written the explainer I wish I could have read\nback then. In this post, we're gonna learn</p>\n<ul>\n<li>What Futures are</li>\n<li>What self-referential types are</li>\n<li>Why they were unsafe</li>\n<li>How Pin/Unpin made them safe</li>\n<li>Using Pin/Unpin to write tricky nested futures</li>\n</ul>\n</blockquote>\n<p>Source: <a href=\"https://blog.cloudflare.com/pin-and-unpin-in-rust/\">Pin, Unpin, and why Rust needs\nthem</a>, an article\nby Adam Chalmers.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n","contentSnippet":"C++20 Concepts\nC++20 introduced the\nConcepts library and\nthe corresponding language extensions to template\nmetaprogramming. This\npost will be a brief introduction to the topic for people already\nwell versed in C++ templates.\nSource: C++20\nConcepts, an article\nby Martin Vorbrodt.\ncpp\n\n\n\nThere is no such thing as a “glibc based alpine image”\nFor whatever reason, the alpine-glibc\nproject is\napparently being used in\nproduction.\nWorse yet, some are led to believe that Alpine officially supports\nor at least approves of its usage.  For the reasons I am about to\noutline, we don’t.\nSource: there is no such thing as a “glibc based alpine\nimage”,\nan article by Ariadne Conill.\nalpine\ncontainer\n\n\n\nPin, Unpin, and why Rust needs them\nUsing async Rust libraries is usually easy. It's just like using\nnormal Rust code, with a little async or .await here and\nthere. But writing your own async libraries can be hard. The first\ntime I tried this, I got really confused by arcane, esoteric syntax\nlike T: ?Unpin and Pin<&mut Self>. I had never seen these types\nbefore, and I didn't understand what they were doing. Now that I\nunderstand them, I've written the explainer I wish I could have read\nback then. In this post, we're gonna learn\nWhat Futures are\nWhat self-referential types are\nWhy they were unsafe\nHow Pin/Unpin made them safe\nUsing Pin/Unpin to write tricky nested futures\nSource: Pin, Unpin, and why Rust needs\nthem, an article\nby Adam Chalmers.\nrust","guid":"https://plurrrr.com/archive/2021/08/26.html","isoDate":"2021-08-26T21:59:59.000Z","timestamp":"8/26/2021"},{"title":"An Introduction to JQ, Distributed Crawling, and attrs vs pydantic","link":"https://plurrrr.com/archive/2021/08/25.html","pubDate":"Wed, 25 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"an-introduction-to-jq\"><a href=\"https://plurrrr.com/archive/2021/08/25.html#an-introduction-to-jq\">An Introduction to JQ</a></h2>\n<blockquote>\n<p>In this article, I’m going to go over the basics building blocks of\n<code>jq</code> in enough depth that you will be able to understand how <code>jq</code> works.</p>\n</blockquote>\n<p>Source: <a href=\"https://earthly.dev/blog/jq-select/\">JQ Select Explained: Selecting elements from JSON with\nExamples</a>, an article by Adam Gordon Bell.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/json.html\">json</a></li><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n<article>\n<h2 id=\"scaling-to-distributed-crawling\"><a href=\"https://plurrrr.com/archive/2021/08/25.html#scaling-to-distributed-crawling\">Scaling to Distributed Crawling</a></h2>\n<blockquote>\n<p>Wondering how to build a website crawler and parser at scale?\nImplement a project to crawl, scrape, extract content, and store it\nat scale in a distributed and fault-tolerant manner. We will take\nall the knowledge from previous posts and combine it.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.zenrows.com/blog/mastering-web-scraping-in-python-scaling-to-distributed-crawling\">Mastering Web Scraping in Python: Scaling to Distributed\nCrawling</a>,\nan article by Ander Rodríguez.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li><li><a href=\"https://plurrrr.com/tags/2021/web-scraping.html\">web scraping</a></li></ul>\n</article>\n<article>\n<h2 id=\"why-i-use-attrs-instead-of-pydantic\"><a href=\"https://plurrrr.com/archive/2021/08/25.html#why-i-use-attrs-instead-of-pydantic\">Why I use attrs instead of pydantic</a></h2>\n<blockquote>\n<p>This post is an account of why I prefer using the attrs library over\nPydantic. I'm writing it since I am often asked this question and I\nwant to have something concrete to link to. This is not meant to be\nan objective comparison of attrs and Pydantic; I'm not interested in\ncomparing bullet points of features, nor can I be unbiased since I'm\na major contributor to attrs (at time of writing, second by commit\ncount, after Hynek) and the author of one of its unofficial\ncompanion libraries,\n<a href=\"https://cattrs.readthedocs.io/en/latest/\">cattrs</a>.</p>\n</blockquote>\n<p>Source: <a href=\"https://threeofwands.com/why-i-use-attrs-instead-of-pydantic/\">Why I use attrs instead of\npydantic</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n<article>\n<h2 id=\"creating-pdf-invoices-in-python-with-borb\"><a href=\"https://plurrrr.com/archive/2021/08/25.html#creating-pdf-invoices-in-python-with-borb\">Creating PDF Invoices in Python with borb</a></h2>\n<blockquote>\n<p>In this guide, we'll be using <a href=\"https://borbpdf.com/\"><em>borb</em></a> - a\nPython library dedicated to reading, manipulating and generating PDF\ndocuments. It offers both a low-level model (allowing you access to\nthe exact coordinates and layout if you choose to use those) and a\nhigh-level model (where you can delegate the precise calculations of\nmargins, positions, etc to a layout manager).</p>\n<p>We'll take a look at <em>how to create a PDF invoice in Python using borb</em>.</p>\n</blockquote>\n<p>Source: <a href=\"https://stackabuse.com/creating-pdf-invoices-in-python-with-borb/\">Creating PDF Invoices in Python with\nborb</a>,\nan article by Joris Schellekens.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/python.html\">python</a></li></ul>\n</article>\n","contentSnippet":"An Introduction to JQ\nIn this article, I’m going to go over the basics building blocks of\njq in enough depth that you will be able to understand how jq works.\nSource: JQ Select Explained: Selecting elements from JSON with\nExamples, an article by Adam Gordon Bell.\njson\ncommand line\n\n\n\nScaling to Distributed Crawling\nWondering how to build a website crawler and parser at scale?\nImplement a project to crawl, scrape, extract content, and store it\nat scale in a distributed and fault-tolerant manner. We will take\nall the knowledge from previous posts and combine it.\nSource: Mastering Web Scraping in Python: Scaling to Distributed\nCrawling,\nan article by Ander Rodríguez.\npython\nweb scraping\n\n\n\nWhy I use attrs instead of pydantic\nThis post is an account of why I prefer using the attrs library over\nPydantic. I'm writing it since I am often asked this question and I\nwant to have something concrete to link to. This is not meant to be\nan objective comparison of attrs and Pydantic; I'm not interested in\ncomparing bullet points of features, nor can I be unbiased since I'm\na major contributor to attrs (at time of writing, second by commit\ncount, after Hynek) and the author of one of its unofficial\ncompanion libraries,\ncattrs.\nSource: Why I use attrs instead of\npydantic.\npython\n\n\n\nCreating PDF Invoices in Python with borb\nIn this guide, we'll be using borb - a\nPython library dedicated to reading, manipulating and generating PDF\ndocuments. It offers both a low-level model (allowing you access to\nthe exact coordinates and layout if you choose to use those) and a\nhigh-level model (where you can delegate the precise calculations of\nmargins, positions, etc to a layout manager).\nWe'll take a look at how to create a PDF invoice in Python using borb.\nSource: Creating PDF Invoices in Python with\nborb,\nan article by Joris Schellekens.\npython","guid":"https://plurrrr.com/archive/2021/08/25.html","isoDate":"2021-08-25T21:59:59.000Z","timestamp":"8/25/2021"},{"title":"Hash Functions, Emacs in an IDE world, and Daily Rust: Iterators","link":"https://plurrrr.com/archive/2021/08/24.html","pubDate":"Tue, 24 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"programmers-don’t-understand-hash-functions\"><a href=\"https://plurrrr.com/archive/2021/08/24.html#programmers-don%E2%80%99t-understand-hash-functions\">Programmers Don’t Understand Hash Functions</a></h2>\n<blockquote>\n<p>Programmers don’t understand hash functions, and I can demonstrate\nthis to most of the people that will read this with a single\nobservation:</p>\n<p>When you saw the words “hash function” in the title, you might have\nassumed this was going to be a blog post about password storage.</p>\n</blockquote>\n<p>Source: <a href=\"https://soatok.blog/2021/08/24/programmers-dont-understand-hash-functions/\">Programmers Don’t Understand Hash\nFunctions</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/computer-science.html\">computer science</a></li><li><a href=\"https://plurrrr.com/tags/2021/cryptography.html\">cryptography</a></li></ul>\n</article>\n<article>\n<h2 id=\"using-emacs-in-an-ide-world\"><a href=\"https://plurrrr.com/archive/2021/08/24.html#using-emacs-in-an-ide-world\">Using Emacs in an IDE world</a></h2>\n<blockquote>\n<p>I remember the sad day that I finally gave up on using Emacs for\nJava development at work. I had spent hours trying to configure it\nto properly index all of the files so that I could go to definition\neasily. My mentor, the old Lisp guy with the insane init.el file who\nI would pester with questions, told me: “Just use IntelliJ”.</p>\n</blockquote>\n<p>Source: <a href=\"https://andrewjudson.com/emacs/2021/08/23/emacs.html\">Using Emacs in an IDE\nworld</a>, an\narticle by Andrew Judson.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/emacs.html\">emacs</a></li></ul>\n</article>\n<article>\n<h2 id=\"daily-rust:-iterators\"><a href=\"https://plurrrr.com/archive/2021/08/24.html#daily-rust:-iterators\">Daily Rust: Iterators</a></h2>\n<blockquote>\n<p>Iterators are part of Rust’s secret sauce. They power things from\nthe humble for-loop to the elegant iterator chain, but have you ever\nstopped to think how they work?</p>\n<p>Let’s find out more about Rust’s iterators by implementing our own\nversions of common iterators and reading the standard library’s\nsource code.</p>\n</blockquote>\n<p>Source: <a href=\"https://adventures.michaelfbryan.com/posts/daily/iterators/\">Daily Rust:\nIterators</a>,\nan article by Michael F. Bryan.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n","contentSnippet":"Programmers Don’t Understand Hash Functions\nProgrammers don’t understand hash functions, and I can demonstrate\nthis to most of the people that will read this with a single\nobservation:\nWhen you saw the words “hash function” in the title, you might have\nassumed this was going to be a blog post about password storage.\nSource: Programmers Don’t Understand Hash\nFunctions.\ncomputer science\ncryptography\n\n\n\nUsing Emacs in an IDE world\nI remember the sad day that I finally gave up on using Emacs for\nJava development at work. I had spent hours trying to configure it\nto properly index all of the files so that I could go to definition\neasily. My mentor, the old Lisp guy with the insane init.el file who\nI would pester with questions, told me: “Just use IntelliJ”.\nSource: Using Emacs in an IDE\nworld, an\narticle by Andrew Judson.\nemacs\n\n\n\nDaily Rust: Iterators\nIterators are part of Rust’s secret sauce. They power things from\nthe humble for-loop to the elegant iterator chain, but have you ever\nstopped to think how they work?\nLet’s find out more about Rust’s iterators by implementing our own\nversions of common iterators and reading the standard library’s\nsource code.\nSource: Daily Rust:\nIterators,\nan article by Michael F. Bryan.\nrust","guid":"https://plurrrr.com/archive/2021/08/24.html","isoDate":"2021-08-24T21:59:59.000Z","timestamp":"8/24/2021"},{"title":"Conditional includes, The Essence of Datalog, and protocol APIs","link":"https://plurrrr.com/archive/2021/08/23.html","pubDate":"Mon, 23 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"conditionally-setting-your-gitconfig\"><a href=\"https://plurrrr.com/archive/2021/08/23.html#conditionally-setting-your-gitconfig\">Conditionally setting your gitconfig</a></h2>\n<blockquote>\n<p>Thanks to <a href=\"https://git-scm.com/docs/git-config#_conditional_includes\">conditional\nincludes</a>,\nyou can dynamically switch instances of your <code>.gitconfig</code> on the\nfly.</p>\n</blockquote>\n<p>Source: <a href=\"https://utf9k.net/blog/conditional-gitconfig/\">Conditionally setting your\ngitconfig</a>, an article\nby Marcus Crane.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/git.html\">git</a></li></ul>\n</article>\n<article>\n<h2 id=\"the-essence-of-datalog\"><a href=\"https://plurrrr.com/archive/2021/08/23.html#the-essence-of-datalog\">The Essence of Datalog</a></h2>\n<blockquote>\n<p>In which we implement a simple Datalog engine in not many lines of\nHaskell to understand its semantics.</p>\n</blockquote>\n<p>Source: <a href=\"https://dodisturb.me/posts/2018-12-25-The-Essence-of-Datalog.html\">The Essence of\nDatalog</a>,\nan article by Mistral Contrastin.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/haskell.html\">haskell</a></li></ul>\n</article>\n<article>\n<h2 id=\"using-static-protocol-apis-to-create-conforming-instances\"><a href=\"https://plurrrr.com/archive/2021/08/23.html#using-static-protocol-apis-to-create-conforming-instances\">Using static protocol APIs to create conforming instances</a></h2>\n<blockquote>\n<p><strong>New in Swift 5.5:</strong> It’s now possible to define protoddcol APIs that\nlet us use Swift’s very convenient “dot syntax” to create conforming\ninstances, which in turn can make certain protocols act more like\nenums, while still retaining all of the flexibility that protocols\ngive us.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.swiftbysundell.com/articles/using-static-protocol-apis-to-create-conforming-instances/\">Using static protocol APIs to create conforming\ninstances</a>,\nan article by John Sundell.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/swift.html\">swift</a></li></ul>\n</article>\n<article>\n<h2 id=\"10-usability-heuristics-for-user-interface-design\"><a href=\"https://plurrrr.com/archive/2021/08/23.html#10-usability-heuristics-for-user-interface-design\">10 Usability Heuristics for User Interface Design</a></h2>\n<blockquote>\n<p>Jakob Nielsen's 10 general principles for interaction design. They\nare called &quot;heuristics&quot; because they are broad rules of thumb and\nnot specific usability guidelines.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.nngroup.com/articles/ten-usability-heuristics/\">10 Usability Heuristics for User Interface\nDesign</a>,\nan article by Jakob Nielsen.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/ux.html\">ux</a></li></ul>\n</article>\n","contentSnippet":"Conditionally setting your gitconfig\nThanks to conditional\nincludes,\nyou can dynamically switch instances of your .gitconfig on the\nfly.\nSource: Conditionally setting your\ngitconfig, an article\nby Marcus Crane.\ngit\n\n\n\nThe Essence of Datalog\nIn which we implement a simple Datalog engine in not many lines of\nHaskell to understand its semantics.\nSource: The Essence of\nDatalog,\nan article by Mistral Contrastin.\nhaskell\n\n\n\nUsing static protocol APIs to create conforming instances\nNew in Swift 5.5: It’s now possible to define protoddcol APIs that\nlet us use Swift’s very convenient “dot syntax” to create conforming\ninstances, which in turn can make certain protocols act more like\nenums, while still retaining all of the flexibility that protocols\ngive us.\nSource: Using static protocol APIs to create conforming\ninstances,\nan article by John Sundell.\nswift\n\n\n\n10 Usability Heuristics for User Interface Design\nJakob Nielsen's 10 general principles for interaction design. They\nare called \"heuristics\" because they are broad rules of thumb and\nnot specific usability guidelines.\nSource: 10 Usability Heuristics for User Interface\nDesign,\nan article by Jakob Nielsen.\nux","guid":"https://plurrrr.com/archive/2021/08/23.html","isoDate":"2021-08-23T21:59:59.000Z","timestamp":"8/23/2021"},{"title":"C++20 Concepts, Gitfs, Large Rust Workspaces, and Taint support","link":"https://plurrrr.com/archive/2021/08/22.html","pubDate":"Sun, 22 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"c++20-concepts:-the-definitive-guide\"><a href=\"https://plurrrr.com/archive/2021/08/22.html#c++20-concepts:-the-definitive-guide\">C++20 Concepts: The Definitive Guide</a></h2>\n<blockquote>\n<p>C++20 introduces concepts as a way to write powerful\nself-documenting templates. At their core, concepts are logical\nbinary expressions that can be used to constrain the template\nparameters of any class or function template. These logical\nexpressions are evaluated at compile time to determine whether the\ntemplate parameters satisfy the given constraints.</p>\n</blockquote>\n<p>Source: <a href=\"https://thecodepad.com/cpp/c20-concepts-the-definitive-guide/\">C++20 Concepts: The Definitive\nGuide</a>,\nan article by Rajat Jain.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/cpp.html\">cpp</a></li></ul>\n</article>\n<article>\n<h2 id=\"gitfs\"><a href=\"https://plurrrr.com/archive/2021/08/22.html#gitfs\">Gitfs</a></h2>\n<blockquote>\n<p>gitfs is a <a href=\"http://fuse.sourceforge.net/\">FUSE</a> file system that\nfully integrates with git. You can mount a remote repository’s\nbranch locally, and any subsequent changes made to the files will be\nautomatically committed to the remote.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.presslabs.com/docs/code/gitfs/\">What is Gitfs</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/git.html\">git</a></li></ul>\n</article>\n<article>\n<h2 id=\"large-rust-workspaces\"><a href=\"https://plurrrr.com/archive/2021/08/22.html#large-rust-workspaces\">Large Rust Workspaces</a></h2>\n<blockquote>\n<p>In this article, I’ll share my experience with organizing large Rust\nprojects. This is in no way authoritative — just some tips I’ve\ndiscovered through trial and error.</p>\n</blockquote>\n<p>Source: <a href=\"https://matklad.github.io/2021/08/22/large-rust-workspaces.html\">Large Rust\nWorkspaces</a>,\nan article by Aleksey Kladov.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n<article>\n<h2 id=\"making-taint-support-optional-in-perl\"><a href=\"https://plurrrr.com/archive/2021/08/22.html#making-taint-support-optional-in-perl\">Making Taint support optional in Perl</a></h2>\n<blockquote>\n<p>One of the changes to Perl that we're considering on p5p (the\n<a href=\"https://lists.perl.org/list/perl5-porters.html\">perl5-porters mailing\nlist</a>) is the\nremoval of taint support. The first step towards that is to add a\nConfigure option that lets you build a Perl without taint support.</p>\n<p>In this post I'll explain what we're considering, and why. The\npurpose of this post is to let everyone beyond p5p know about this,\nand give you a chance to comment.</p>\n</blockquote>\n<p>Source: <a href=\"http://blogs.perl.org/users/neilb/2021/08/making-taint-support-optional-in-perl.html\">Making Taint support optional in\nPerl</a>,\nan article by Neil Bowers.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/perl.html\">perl</a></li></ul>\n</article>\n","contentSnippet":"C++20 Concepts: The Definitive Guide\nC++20 introduces concepts as a way to write powerful\nself-documenting templates. At their core, concepts are logical\nbinary expressions that can be used to constrain the template\nparameters of any class or function template. These logical\nexpressions are evaluated at compile time to determine whether the\ntemplate parameters satisfy the given constraints.\nSource: C++20 Concepts: The Definitive\nGuide,\nan article by Rajat Jain.\ncpp\n\n\n\nGitfs\ngitfs is a FUSE file system that\nfully integrates with git. You can mount a remote repository’s\nbranch locally, and any subsequent changes made to the files will be\nautomatically committed to the remote.\nSource: What is Gitfs.\ngit\n\n\n\nLarge Rust Workspaces\nIn this article, I’ll share my experience with organizing large Rust\nprojects. This is in no way authoritative — just some tips I’ve\ndiscovered through trial and error.\nSource: Large Rust\nWorkspaces,\nan article by Aleksey Kladov.\nrust\n\n\n\nMaking Taint support optional in Perl\nOne of the changes to Perl that we're considering on p5p (the\nperl5-porters mailing\nlist) is the\nremoval of taint support. The first step towards that is to add a\nConfigure option that lets you build a Perl without taint support.\nIn this post I'll explain what we're considering, and why. The\npurpose of this post is to let everyone beyond p5p know about this,\nand give you a chance to comment.\nSource: Making Taint support optional in\nPerl,\nan article by Neil Bowers.\nperl","guid":"https://plurrrr.com/archive/2021/08/22.html","isoDate":"2021-08-22T21:59:59.000Z","timestamp":"8/22/2021"},{"title":"Guide to xargs, hidden security improvements, and Rogue One","link":"https://plurrrr.com/archive/2021/08/21.html","pubDate":"Sat, 21 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"an-opinionated-guide-to-xargs\"><a href=\"https://plurrrr.com/archive/2021/08/21.html#an-opinionated-guide-to-xargs\">An Opinionated Guide to xargs</a></h2>\n<blockquote>\n<p>This post has everything you need to know about\n<a href=\"https://www.oilshell.org/cross-ref.html?tag=xargs#xargs\">xargs</a>, an\nessential tool for shell programming.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.oilshell.org/blog/2021/08/xargs.html\">An Opinionated Guide to\nxargs</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n<article>\n<h2 id=\"macos-11’s-hidden-security-improvements\"><a href=\"https://plurrrr.com/archive/2021/08/21.html#macos-11%E2%80%99s-hidden-security-improvements\">macOS 11’s hidden security improvements</a></h2>\n<blockquote>\n<p>A deep dive into macOS 11’s internals reveals some security\nsurprises that deserve to be more widely known.</p>\n</blockquote>\n<p>Source: <a href=\"https://blog.malwarebytes.com/mac/2021/08/macos-11s-hidden-security-improvements/\">macOS 11's hidden security\nimprovements</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/macos.html\">macos</a></li><li><a href=\"https://plurrrr.com/tags/2021/security.html\">security</a></li></ul>\n</article>\n<article>\n<h2 id=\"rogue-one:-a-star-wars-story-(2016)\"><a href=\"https://plurrrr.com/archive/2021/08/21.html#rogue-one:-a-star-wars-story-(2016)\">Rogue One: A Star Wars Story (2016)</a></h2>\n<blockquote>\n<p>In a time of conflict, a group of unlikely heroes band together on a\nmission to steal the plans to the Death Star, the Empire's ultimate\nweapon of destruction.</p>\n</blockquote>\n<p>In the evening, Adam, Esme, and I watched <a href=\"https://www.imdb.com/title/tt3748528/\">Rogue One: A Star Wars\nStory</a>. I like this movie a\nlot, and give it a solid 8 out of 10.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/movie.html\">movie</a></li><li><a href=\"https://plurrrr.com/tags/2021/science-fiction.html\">science fiction</a></li></ul>\n</article>\n","contentSnippet":"An Opinionated Guide to xargs\nThis post has everything you need to know about\nxargs, an\nessential tool for shell programming.\nSource: An Opinionated Guide to\nxargs.\ncommand line\n\n\n\nmacOS 11’s hidden security improvements\nA deep dive into macOS 11’s internals reveals some security\nsurprises that deserve to be more widely known.\nSource: macOS 11's hidden security\nimprovements.\nmacos\nsecurity\n\n\n\nRogue One: A Star Wars Story (2016)\nIn a time of conflict, a group of unlikely heroes band together on a\nmission to steal the plans to the Death Star, the Empire's ultimate\nweapon of destruction.\nIn the evening, Adam, Esme, and I watched Rogue One: A Star Wars\nStory. I like this movie a\nlot, and give it a solid 8 out of 10.\nmovie\nscience fiction","guid":"https://plurrrr.com/archive/2021/08/21.html","isoDate":"2021-08-21T21:59:59.000Z","timestamp":"8/21/2021"},{"title":"PostgreSQL count(*), Rust Macros, and building a CLI tool","link":"https://plurrrr.com/archive/2021/08/20.html","pubDate":"Fri, 20 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"postgresql-count(*)-made-fast\"><a href=\"https://plurrrr.com/archive/2021/08/20.html#postgresql-count(*)-made-fast\">PostgreSQL count(*) made fast</a></h2>\n<blockquote>\n<p>It is a frequent complaint that <code>count(*)</code> is so slow on PostgreSQL.</p>\n<p>In this article I want to explore the options you have get your\nresult as fast as possible.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.cybertec-postgresql.com/en/postgresql-count-made-fast/\">PostgreSQL count(*) made\nfast</a>,\nan article by Laurenz Albe.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/postgres.html\">postgres</a></li></ul>\n</article>\n<article>\n<h2 id=\"complex-procedural-rust-macros\"><a href=\"https://plurrrr.com/archive/2021/08/20.html#complex-procedural-rust-macros\">Complex Procedural Rust Macros</a></h2>\n<blockquote>\n<p>I recently wrote the most complex procedural Rust macro I’ve ever\nattempted. This post tries to outline the problems I’ve encountered\nand tells how I overcame them.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.getsynth.com/docs/blog/2021/08/09/macro\">Complex Procedural Rust\nMacros</a>, an\narticle by Andre Bogus.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n<article>\n<h2 id=\"learning-rust-by-building-a-cli-tool\"><a href=\"https://plurrrr.com/archive/2021/08/20.html#learning-rust-by-building-a-cli-tool\">Learning Rust by building a CLI tool</a></h2>\n<blockquote>\n<p>Creating small CLI tools is a fun way to get more familiar with a\nprogramming language. If you are coming from an infrastructure\nbackground, a CLI tool that you can use to send commands to\ndevices/servers might be considered a neat starting point getting\ninto Rust. This is how I started off learning Python, by writing\nsmall things that were usefull in a context that I was familiar\nwith. Back then, I used <code>argparse</code>, <code>getpass</code> and\n<code>netmiko</code>. Starting with Rust is pretty daunting, and I have found\nthat using similar tactic used to learn Python can also be applied\nwhen learning Rust.</p>\n</blockquote>\n<p>Source: <a href=\"http://saidvandeklundert.net/learn/2021-08-06-rust-ssh-cli-tool/\">Learning Rust by building a CLI\ntool</a>,\nan article by Said van de Klundert.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n<article>\n<h2 id=\"jurassic-world:-fallen-kingdom-(2018)\"><a href=\"https://plurrrr.com/archive/2021/08/20.html#jurassic-world:-fallen-kingdom-(2018)\">Jurassic World: Fallen Kingdom (2018)</a></h2>\n<blockquote>\n<p>When the island's dormant volcano begins roaring to life, Owen and\nClaire mount a campaign to rescue the remaining dinosaurs from this\nextinction-level event.</p>\n</blockquote>\n<p>In the evening Esme, Alice, and I watched <a href=\"https://www.imdb.com/title/tt4881806/\">Jurassic World: Fallen\nKingdom</a>. Esme and Alice fell\nasleep halfway. Not a great movie; nothing new. I give it a 6 out of 10.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/movie.html\">movie</a></li><li><a href=\"https://plurrrr.com/tags/2021/science-fiction.html\">science fiction</a></li></ul>\n</article>\n","contentSnippet":"PostgreSQL count(*) made fast\nIt is a frequent complaint that count(*) is so slow on PostgreSQL.\nIn this article I want to explore the options you have get your\nresult as fast as possible.\nSource: PostgreSQL count(*) made\nfast,\nan article by Laurenz Albe.\npostgres\n\n\n\nComplex Procedural Rust Macros\nI recently wrote the most complex procedural Rust macro I’ve ever\nattempted. This post tries to outline the problems I’ve encountered\nand tells how I overcame them.\nSource: Complex Procedural Rust\nMacros, an\narticle by Andre Bogus.\nrust\n\n\n\nLearning Rust by building a CLI tool\nCreating small CLI tools is a fun way to get more familiar with a\nprogramming language. If you are coming from an infrastructure\nbackground, a CLI tool that you can use to send commands to\ndevices/servers might be considered a neat starting point getting\ninto Rust. This is how I started off learning Python, by writing\nsmall things that were usefull in a context that I was familiar\nwith. Back then, I used argparse, getpass and\nnetmiko. Starting with Rust is pretty daunting, and I have found\nthat using similar tactic used to learn Python can also be applied\nwhen learning Rust.\nSource: Learning Rust by building a CLI\ntool,\nan article by Said van de Klundert.\nrust\n\n\n\nJurassic World: Fallen Kingdom (2018)\nWhen the island's dormant volcano begins roaring to life, Owen and\nClaire mount a campaign to rescue the remaining dinosaurs from this\nextinction-level event.\nIn the evening Esme, Alice, and I watched Jurassic World: Fallen\nKingdom. Esme and Alice fell\nasleep halfway. Not a great movie; nothing new. I give it a 6 out of 10.\nmovie\nscience fiction","guid":"https://plurrrr.com/archive/2021/08/20.html","isoDate":"2021-08-20T21:59:59.000Z","timestamp":"8/20/2021"},{"title":"Get Started With tmux, throwing properties, and the git index","link":"https://plurrrr.com/archive/2021/08/19.html","pubDate":"Thu, 19 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"gentle-guide-to-get-started-with-tmux\"><a href=\"https://plurrrr.com/archive/2021/08/19.html#gentle-guide-to-get-started-with-tmux\">Gentle Guide to Get Started With tmux</a></h2>\n<blockquote>\n<p>tmux is a terminal multiplexer, meaning it is a window manager\nwithin your terminal. It allows you to open multiple windows\n(sessions) within one terminal window (session). So it enables other\nprograms to run from it, allowing you to manipulate them\neasily. Most of the folks find that one of the features to use tmux\non a daily basis.</p>\n</blockquote>\n<p>Source: <a href=\"https://pragmaticpineapple.com/gentle-guide-to-get-started-with-tmux/\">Gentle Guide to Get Started With\ntmux</a>,\nan article by Nikola Đuza.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/tmux.html\">tmux</a></li><li><a href=\"https://plurrrr.com/tags/2021/command-line.html\">command line</a></li></ul>\n</article>\n<article>\n<h2 id=\"how-to-use-throwing-properties-to-catch-failures-in-swift\"><a href=\"https://plurrrr.com/archive/2021/08/19.html#how-to-use-throwing-properties-to-catch-failures-in-swift\">How to use throwing properties to catch failures in Swift</a></h2>\n<blockquote>\n<p>Throwing properties allow defining <a href=\"https://www.avanderlee.com/swift/computed-property/\">computed\nproperties</a>\nthat throw an error on\nfailure. <a href=\"https://github.com/apple/swift-evolution/blob/main/proposals/0310-effectful-readonly-properties.md\">SE-310</a>\nintroduced this feature in Swift 5.5 and is part of the\n<a href=\"https://www.avanderlee.com/swift/async-await/\">async-await</a>\nconcurrency changes allowing async properties to throw errors.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.avanderlee.com/swift/throwing-properties/\">How to use throwing properties to catch failures in\nSwift</a>, an\narticle by Antoine van der Lee.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/swift.html\">swift</a></li></ul>\n</article>\n<article>\n<h2 id=\"it-never-had-to-be-like-this:-the-git-“index”\"><a href=\"https://plurrrr.com/archive/2021/08/19.html#it-never-had-to-be-like-this:-the-git-%E2%80%9Cindex%E2%80%9D\">It never had to be like this: the git “index”</a></h2>\n<blockquote>\n<p>Hot on the heels of <a href=\"https://felipec.wordpress.com/2021/08/10/git-staging-area-rename/\">another Git-related\narticle</a>\nthat was making the rounds recently, I was reminded of Git’s own\nstructure and how it influences user experience. Specifically what\nwe assume is part of how Git works, is actually a part of the\nporcelain (in Git speak, the user interface and commands that back\nit). As someone developing <a href=\"https://visualgit.io/\">a Git client</a>,\nit’s interesting to think Git’s user experience could be\nsignificantly different with a different interface, particularly\nbecause people have a particular mental model of Git influenced by\nthe default interface. Said influence is enough that <a href=\"https://libgit2.org/libgit2/#HEAD\">libgit2’s\nAPI</a> emulates the porcelain’s\nsemantics, in-process.</p>\n</blockquote>\n<p>Source: <a href=\"https://sporks.space/2021/08/18/it-never-had-to-be-like-this-the-git-index/\">It never had to be like this: the git &quot;index&quot;</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/git.html\">git</a></li></ul>\n</article>\n","contentSnippet":"Gentle Guide to Get Started With tmux\ntmux is a terminal multiplexer, meaning it is a window manager\nwithin your terminal. It allows you to open multiple windows\n(sessions) within one terminal window (session). So it enables other\nprograms to run from it, allowing you to manipulate them\neasily. Most of the folks find that one of the features to use tmux\non a daily basis.\nSource: Gentle Guide to Get Started With\ntmux,\nan article by Nikola Đuza.\ntmux\ncommand line\n\n\n\nHow to use throwing properties to catch failures in Swift\nThrowing properties allow defining computed\nproperties\nthat throw an error on\nfailure. SE-310\nintroduced this feature in Swift 5.5 and is part of the\nasync-await\nconcurrency changes allowing async properties to throw errors.\nSource: How to use throwing properties to catch failures in\nSwift, an\narticle by Antoine van der Lee.\nswift\n\n\n\nIt never had to be like this: the git “index”\nHot on the heels of another Git-related\narticle\nthat was making the rounds recently, I was reminded of Git’s own\nstructure and how it influences user experience. Specifically what\nwe assume is part of how Git works, is actually a part of the\nporcelain (in Git speak, the user interface and commands that back\nit). As someone developing a Git client,\nit’s interesting to think Git’s user experience could be\nsignificantly different with a different interface, particularly\nbecause people have a particular mental model of Git influenced by\nthe default interface. Said influence is enough that libgit2’s\nAPI emulates the porcelain’s\nsemantics, in-process.\nSource: It never had to be like this: the git \"index\".\ngit","guid":"https://plurrrr.com/archive/2021/08/19.html","isoDate":"2021-08-19T21:59:59.000Z","timestamp":"8/19/2021"},{"title":"Fantasy, Retire the CSV, B-Trees, and Modern LZ Compression","link":"https://plurrrr.com/archive/2021/08/18.html","pubDate":"Wed, 18 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"the-blinding-knife\"><a href=\"https://plurrrr.com/archive/2021/08/18.html#the-blinding-knife\">The Blinding Knife</a></h2>\n<blockquote>\n<p>Gavin Guile is dying.</p>\n<p>He'd thought he had five years left - now he's got less than\none. With fifty thousand refugees, a bastard son and an ex-fiancée\nwho may have learned his darkest secret, Gavin's got problems on\nevery side.</p>\n<p>As he loses control, the world's magic runs wild, threatening to\ndestroy the Seven Satrapies. The old gods are being reborn and their\narmy of colour wights is unstoppable.</p>\n<p>The only salvation may be the brother whose freedom and life Gavin\nstole sixteen years ago.</p>\n</blockquote>\n<p>In the morning I started in <a href=\"https://www.amazon.com/Blinding-Knife-Lightbringer-Book-ebook/dp/B0076DDFCO\">The Blinding\nKnife</a>,\nBook 2 of Lightbringer series by Brent Weeks.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/book.html\">book</a></li><li><a href=\"https://plurrrr.com/tags/2021/fantasy.html\">fantasy</a></li></ul>\n</article>\n<article>\n<h2 id=\"harry-potter-and-the-deathly-hallows:-part-2-(2011)\"><a href=\"https://plurrrr.com/archive/2021/08/18.html#harry-potter-and-the-deathly-hallows:-part-2-(2011)\">Harry Potter and the Deathly Hallows: Part 2 (2011)</a></h2>\n<blockquote>\n<p>Harry, Ron, and Hermione search for Voldemort's remaining Horcruxes\nin their effort to destroy the Dark Lord as the final battle rages\non at Hogwarts.</p>\n</blockquote>\n<p>In the afternoon Esme, Alice, and I watched <a href=\"https://www.imdb.com/title/tt1201607/\">Harry Potter and the\nDeathly Hallows: Part 2</a>. I\nliked this part more than the previous one and give it a solid 8 out\nof 10.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/movie.html\">movie</a></li><li><a href=\"https://plurrrr.com/tags/2021/fantasy.html\">fantasy</a></li></ul>\n</article>\n<article>\n<h2 id=\"it&#x27;s-time-to-retire-the-csv\"><a href=\"https://plurrrr.com/archive/2021/08/18.html#it's-time-to-retire-the-csv\">It's Time to Retire the CSV</a></h2>\n<blockquote>\n<p>If you’ve worked with data for any length of time, you’ve come\nacross the Comma-Separated Values (CSV) format. Its simplicity and\nubiquity make CSV an extremely popular way for organizations to\nexchange data both internally and externally. While many programs\ncan’t read or write Excel spreadsheets, almost anything can read and\nwrite CSVs, and a human can open a CSV file in any text editor and\nunderstand roughly what it contains.</p>\n<p>Despite this ubiquity and ease of access, CSV is a wretched way to\nexchange data. The CSV format itself is notoriously inconsistent,\nwith myriad competing and mutually-exclusive formats that often\ncoexist within a single dataset (or, if you’re particularly unlucky,\na single file). Exporting a dataset as a CSV robs it of a wealth of\nmetadata that is very hard for the reader to reconstruct accurately,\nand many programs’ naïve CSV parsers ignore the metadata\nreconstruction problem entirely as a result. In practice, CSV’s\nhuman-readability is more of a liability than an asset.</p>\n</blockquote>\n<p>Source: <a href=\"https://www.bitsondisk.com/writing/2021/retire-the-csv/\">It's Time to Retire the\nCSV</a>, an\narticle by Alex Rasmussen.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/csv.html\">csv</a></li></ul>\n</article>\n<article>\n<h2 id=\"b-trees:-more-than-i-thought-i&#x27;d-want-to-know\"><a href=\"https://plurrrr.com/archive/2021/08/18.html#b-trees:-more-than-i-thought-i'd-want-to-know\">B-Trees: More Than I Thought I'd Want to Know</a></h2>\n<blockquote>\n<p>Recently, I’ve been reading through the excellent <a href=\"https://www.goodreads.com/book/show/44647144-database-internals\"><em>Database\nInternals</em></a>\n(Alex Petrov, 2019). The first half of the book is dedicated to the\nimplementation of database storage engines – the subsystem(s) of a\nDBMS that handles long-term persistence of data. A surprising amount\nof this section discusses the implementation and optimization of\nvarious B-Tree data structures.</p>\n</blockquote>\n<p>Source: <a href=\"https://benjamincongdon.me/blog/2021/08/17/B-Trees-More-Than-I-Thought-Id-Want-to-Know/\">B-Trees: More Than I Thought I'd Want to\nKnow</a>,\nan article by Ben Congdon.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/database.html\">database</a></li><li><a href=\"https://plurrrr.com/tags/2021/computer-science.html\">computer science</a></li></ul>\n</article>\n<article>\n<h2 id=\"modern-lz-compression\"><a href=\"https://plurrrr.com/archive/2021/08/18.html#modern-lz-compression\">Modern LZ Compression</a></h2>\n<blockquote>\n<p>This article walks through the components of a modern LZ\ncompressor. It's amazing how rich and deep the compression field\nis. If you enjoy algorithms and data structures, there are not too\nmany better places to play. I hope you enjoy reading it as much as I\nenjoyed writing it!</p>\n<p>By the end, we will have a compressor that can beat gzip while\ndecompressing at almost the same speed — in less than 1000 lines.</p>\n</blockquote>\n<p>Source: <a href=\"https://glinscott.github.io/lz/index.html\">Modern LZ\nCompression</a>, an article by\nGary Linscott.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/compression.html\">compression</a></li><li><a href=\"https://plurrrr.com/tags/2021/cpp.html\">cpp</a></li><li><a href=\"https://plurrrr.com/tags/2021/computer-science.html\">computer science</a></li></ul>\n</article>\n","contentSnippet":"The Blinding Knife\nGavin Guile is dying.\nHe'd thought he had five years left - now he's got less than\none. With fifty thousand refugees, a bastard son and an ex-fiancée\nwho may have learned his darkest secret, Gavin's got problems on\nevery side.\nAs he loses control, the world's magic runs wild, threatening to\ndestroy the Seven Satrapies. The old gods are being reborn and their\narmy of colour wights is unstoppable.\nThe only salvation may be the brother whose freedom and life Gavin\nstole sixteen years ago.\nIn the morning I started in The Blinding\nKnife,\nBook 2 of Lightbringer series by Brent Weeks.\nbook\nfantasy\n\n\n\nHarry Potter and the Deathly Hallows: Part 2 (2011)\nHarry, Ron, and Hermione search for Voldemort's remaining Horcruxes\nin their effort to destroy the Dark Lord as the final battle rages\non at Hogwarts.\nIn the afternoon Esme, Alice, and I watched Harry Potter and the\nDeathly Hallows: Part 2. I\nliked this part more than the previous one and give it a solid 8 out\nof 10.\nmovie\nfantasy\n\n\n\nIt's Time to Retire the CSV\nIf you’ve worked with data for any length of time, you’ve come\nacross the Comma-Separated Values (CSV) format. Its simplicity and\nubiquity make CSV an extremely popular way for organizations to\nexchange data both internally and externally. While many programs\ncan’t read or write Excel spreadsheets, almost anything can read and\nwrite CSVs, and a human can open a CSV file in any text editor and\nunderstand roughly what it contains.\nDespite this ubiquity and ease of access, CSV is a wretched way to\nexchange data. The CSV format itself is notoriously inconsistent,\nwith myriad competing and mutually-exclusive formats that often\ncoexist within a single dataset (or, if you’re particularly unlucky,\na single file). Exporting a dataset as a CSV robs it of a wealth of\nmetadata that is very hard for the reader to reconstruct accurately,\nand many programs’ naïve CSV parsers ignore the metadata\nreconstruction problem entirely as a result. In practice, CSV’s\nhuman-readability is more of a liability than an asset.\nSource: It's Time to Retire the\nCSV, an\narticle by Alex Rasmussen.\ncsv\n\n\n\nB-Trees: More Than I Thought I'd Want to Know\nRecently, I’ve been reading through the excellent Database\nInternals\n(Alex Petrov, 2019). The first half of the book is dedicated to the\nimplementation of database storage engines – the subsystem(s) of a\nDBMS that handles long-term persistence of data. A surprising amount\nof this section discusses the implementation and optimization of\nvarious B-Tree data structures.\nSource: B-Trees: More Than I Thought I'd Want to\nKnow,\nan article by Ben Congdon.\ndatabase\ncomputer science\n\n\n\nModern LZ Compression\nThis article walks through the components of a modern LZ\ncompressor. It's amazing how rich and deep the compression field\nis. If you enjoy algorithms and data structures, there are not too\nmany better places to play. I hope you enjoy reading it as much as I\nenjoyed writing it!\nBy the end, we will have a compressor that can beat gzip while\ndecompressing at almost the same speed — in less than 1000 lines.\nSource: Modern LZ\nCompression, an article by\nGary Linscott.\ncompression\ncpp\ncomputer science","guid":"https://plurrrr.com/archive/2021/08/18.html","isoDate":"2021-08-18T21:59:59.000Z","timestamp":"8/18/2021"},{"title":"Double Homicide: Good, Free Monads, and Slice Patterns","link":"https://plurrrr.com/archive/2021/08/17.html","pubDate":"Tue, 17 Aug 2021 23:59:59 +0200","content":"<article>\n<h2 id=\"double-homicide:-good\"><a href=\"https://plurrrr.com/archive/2021/08/17.html#double-homicide:-good\">Double Homicide: Good</a></h2>\n<p>In the afternoon I finished <a href=\"https://www.amazon.com/Double-Homicide-Jonathan-Kellerman-ebook/dp/B000FC2J2K\">Double\nHomicide</a>. I\nliked both stories; recommended.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/book.html\">book</a></li><li><a href=\"https://plurrrr.com/tags/2021/crime-fiction.html\">crime fiction</a></li></ul>\n</article>\n<article>\n<h2 id=\"how-free-monads-yield-extensible-effects\"><a href=\"https://plurrrr.com/archive/2021/08/17.html#how-free-monads-yield-extensible-effects\">How Free Monads Yield Extensible Effects</a></h2>\n<blockquote>\n<p>The <code>Free</code> monad gives you a <code>Monad</code> for any <code>Functor</code>. The <code>Free</code>\nmonad can also be used to construct extensible effect systems. I\nnever understood why <code>Free</code> why this was the case. It turns out it\nis deeply connected to their ability to yield monads for functors.</p>\n</blockquote>\n<p>Source: <a href=\"https://blog.cofree.coffee/2021-08-16-how-free-monads-yield-extensible-effects/\">How Free Monads Yield Extensible\nEffects</a>.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/haskell.html\">haskell</a></li></ul>\n</article>\n<article>\n<h2 id=\"slice-patterns\"><a href=\"https://plurrrr.com/archive/2021/08/17.html#slice-patterns\">Slice Patterns</a></h2>\n<blockquote>\n<p><a href=\"https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#basic-slice-patterns\">Rust\n1.26</a>\nintroduced a nifty little feature called Basic Slice Patterns which\nlets you pattern match on slices with a known length. Later on in\n<a href=\"https://blog.rust-lang.org/2020/03/12/Rust-1.42.html#subslice-patterns\">Rust\n1.42</a>,\nthis was extended to allow using <code>..</code> to match on “everything else”.</p>\n<p>As features go this may seem like a small addition, but it gives\ndevelopers an opportunity to write much more expressive code.</p>\n</blockquote>\n<p>Source: <a href=\"https://adventures.michaelfbryan.com/posts/daily/slice-patterns/\">Slice\nPatterns</a>,\nan article by Michael F. Bryan.</p>\n<ul class=\"tl-tags\"><li><a href=\"https://plurrrr.com/tags/2021/rust.html\">rust</a></li></ul>\n</article>\n","contentSnippet":"Double Homicide: Good\nIn the afternoon I finished Double\nHomicide. I\nliked both stories; recommended.\nbook\ncrime fiction\n\n\n\nHow Free Monads Yield Extensible Effects\nThe Free monad gives you a Monad for any Functor. The Free\nmonad can also be used to construct extensible effect systems. I\nnever understood why Free why this was the case. It turns out it\nis deeply connected to their ability to yield monads for functors.\nSource: How Free Monads Yield Extensible\nEffects.\nhaskell\n\n\n\nSlice Patterns\nRust\n1.26\nintroduced a nifty little feature called Basic Slice Patterns which\nlets you pattern match on slices with a known length. Later on in\nRust\n1.42,\nthis was extended to allow using .. to match on “everything else”.\nAs features go this may seem like a small addition, but it gives\ndevelopers an opportunity to write much more expressive code.\nSource: Slice\nPatterns,\nan article by Michael F. Bryan.\nrust","guid":"https://plurrrr.com/archive/2021/08/17.html","isoDate":"2021-08-17T21:59:59.000Z","timestamp":"8/17/2021"}],"feedUrl":"https://plurrrr.com/feed.rss","paginationLinks":{"self":"https://plurrrr.com/feed.rss"},"title":"Plurrrr","description":"John Bokma's tumblelog","link":"https://plurrrr.com/","feed":"https://plurrrr.com/feed.rss"},{"items":[{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"640 Pages in 15 Months","link":"http://journal.stuffwithstuff.com/2021/07/29/640-pages-in-15-months/","pubDate":"Thu, 29 Jul 2021 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>My book <a href=\"http://craftinginterpreters.com/\"><em>Crafting Interpreters</em></a> on programming languages is done. OK, OK.\nI know <a href=\"/2020/04/05/crafting-crafting-interpreters/\">I said it was done like fifteen months ago</a>. But now it&rsquo;s <em>really</em>\ndone. And by that I mean, the print, ebook and PDF versions are done. <strong>You can\n<a href=\"http://craftinginterpreters.com/\">buy it</a>.</strong> You can hold it in your hands. And I do mean &ldquo;hands&rdquo; plural.\nBecause this little &ldquo;handbook&rdquo; turned out way larger than I anticipated:</p>\n\n<figure>\n  <a href=\"http://craftinginterpreters.com/\"><img class=\"framed\" src=\"/image/2021/07/book.jpg\"></a>\n  <figcaption>This is a proof copy, so it looks a little different than the final design.</figcaption>\n</figure>\n\n<p>Look at that thing. 640 pages, eight inches wide, ten inches tall. If you get\ntired of reading it, it can serve as a doorstop or protect you from small-arms\nfire.</p>\n\n<p>Remember back on Mr. Roger&rsquo;s Neighborhood when he would take you to a factory\nand show you how pencils or umbrellas are made? I love that stuff, so I thought\nmaybe you might like to see what I spent the past year on. You can read this as\na peek behind the curtain, or maybe a long apology for why it took so long.</p>\n\n<h2>Where I left off</h2>\n\n<p>What I said in my last post was that <em>Crafting Interpreters</em> was <em>finished</em>, and\nby that I meant that I&rsquo;d written all the code, dotted the last sentence, and\nscanned the last illustration. The <em>content</em> of the book was complete. But it\nwasn&rsquo;t a book yet. Just a pile of Markdown and PNG files that my embarrassingly\nbad Python code would begrudgingly turn into a website.</p>\n\n<p>My original goal was always to make a real book, with pages and everything.\nCompleting the content was just one (granted, the most important) step in that\njourney. Once I finished the last chapter and put it online, I took about a\nmonth-long break. I had been writing <a href=\"https://github.com/munificent/craftinginterpreters/blob/master/note/log.txt\">every single day for almost four\nyears</a> and I was <em>fried</em>. Also, in case you don&rsquo;t remember, early 2020 was\nnot exactly a Totally Fine Time in World History.</p>\n\n<h2>A new build system</h2>\n\n<p>After a few weeks, my desire to have this project completely done returned and I\neased my way back into working on it. I fixed a whole pile of typos and other\nmistakes that readers <a href=\"https://github.com/munificent/craftinginterpreters/issues\">filed bugs for</a> (thanks!).</p>\n\n<p>Then, for no real good reason at all, I decided to rewrite the whole build\nsystem for the book in Dart. The build script I wrote for <a href=\"http://gameprogrammingpatterns.com/\">my first book</a>\nwas dead simple. <a href=\"https://github.com/munificent/game-programming-patterns/blob/master/script/format.py\">Literally a single Python script</a> that took a Markdown\nfile for each book chapter and rendered it to HTML while weaving in the code\nsnippets. The world&rsquo;s dumbest static site generator.</p>\n\n<p>I started with that for <em>Crafting Interpreters</em> but then it grew and grew. My\nsecond book includes every single line of code for two complete interpreters,\nwhich it builds up incrementally across thirty chapters. I needed to not just\nbuild the HTML for the book&rsquo;s website, but also make sure the code really did\nwork. I gave the build system the ability to not only generate the site for the\nbook, but also to slice and dice the code. Given a chapter, or even a single\npoint within a chapter, it can output a program containing all of the code for\nthe interpreters up to that point. Then I can take that code, compile it, and\nrun it through my automated test suite to make sure the code I&rsquo;m showing you\ndoes what it&rsquo;s supposed to.</p>\n\n<p>Useful, but really straining the limits of how much code I want to maintain in a\ndynamically typed language like Python, at least, with my (low) level of Python\nexpertise. Also, it was, frankly, really slow. So over a period of a couple of\nweeks, I rewrote the whole thing in Dart.</p>\n\n<p>I work at Google on the <a href=\"https://dart.dev/\">Dart language</a> team as my day job, so picking\nDart was not an unbiased choice. But it&rsquo;s my build system for my book, and I\nknow Dart and many of its core libraries and packages like the back of my hand.\nHell, I personally wrote the initial version of the canonical <a href=\"https://pub.dev/packages/markdown\">markdown\npackage</a>.</p>\n\n<p>I found a pretty nice <a href=\"https://pub.dev/packages/mustache_template\">package for mustache templates</a>, so I converted\nthe book&rsquo;s old Liquid templates to that. I didn&rsquo;t find a good syntax\nhighlighter. But it&rsquo;s not like I looked very hard either. It seemed like just\nthe kind of fun thing to implement from scratch, so I whipped one up loosely\nbased on Pygments.</p>\n\n<p>The end result is a new build system that generates <em>exactly</em> the HTML and\nsyntax-highlighted code that I want. Also, it is literally ten <em>times</em> faster\nthan the old Python one. As you&rsquo;ll see, it turned out to be handy that I had\nbetter control over the Markdown processing, but at the time I was basically\njust doing this for fun and to procrastinate the real work.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/speed.png\">\n  <figcaption>I planned to implement some clever incremental rebuild logic in\n  the dev server, but it builds so fast that I just rebuild everything on every\n  refresh.</figcaption>\n</figure>\n\n<p>Once I had the new build system outputting nice clean HTML and I&rsquo;d deleted the\nold Python stuff, it was time to get started.</p>\n\n<h2>Designing the book</h2>\n\n<p>Doing a large graphic design project like a book works a lot like web dev or\ngame programming where it sort of has two levels. First you set up your\n&ldquo;framework&rdquo; or &ldquo;engine&rdquo;. On the web, this is your web framework and all of your\nCSS and HTML templates. In games, it&rsquo;s your game engine. Then you pour content\ninto that structure. With the right framework, adding content is easy.</p>\n\n<p>For graphic design using a program like Adobe InDesign, the way it works is you\nset up styles and masters. A master defines the margins and grid lines for a\npage. It&rsquo;s the fences that corral all the text to keep those feral letters from\nrunning around eating all the whitespace. Styles are like CSS: they let you take\na semantic kind of text or object and associate specific fonts, styles and\ncolors for it.</p>\n\n<p>In theory, you get the masters and styles right and then typesetting is pretty\neasy and mechanical. Now, I did <em>not</em> make my life easy when it comes to book\ndesign. Book design is literally a two-dimensional spatial exercise and I made\nmy job harder both horizontally and vertically. If you&rsquo;ve read any of it on the\nweb, you know my book has:</p>\n\n<ul>\n<li><p>Prose, of course. So many words.</p></li>\n<li><p>A lot of asides that need to be right next to certain pieces of text, code\nor illustrations that they refer to. Some of these can get pretty long.</p></li>\n<li><p>Plenty of code. Also, each code snippet has a little location blurb next to\nit telling you where the code goes in the resulting program.</p></li>\n</ul>\n\n<h2>How wide?</h2>\n\n<p>Horizontally, the main text column needs to be wide enough to fit the longest\nline of code. I can use shorter lines and wrap the snippets more, but that makes\nthem harder to read. It also makes them vertically taller, which causes its own\nproblem.</p>\n\n<p>Then I need room next to that for the asides, since they often remark directly\non specific sentences. I can make <em>those</em> narrower too, of course. But then they\nwrap and get taller. Some asides are fairly long and if they get too tall, they\nstart colliding with each other or overlapping location snippets.</p>\n\n<p>Oh, and since I ended up writing a 200k+ word book, it&rsquo;s going to have a high\npage count. That means a thick book. Thick books need wider inner margins so the\ntext doesn&rsquo;t disappear into the spine.</p>\n\n<p>All of this points towards a pretty wide page. Most CS textbooks&mdash;at least\nthe ones on my bookshelf&mdash;are 7.5 inches wide. I tried hard to come up with\na design that fit the code, asides, and healthy margins in that width while\nstill giving a text size that didn&rsquo;t require a magnifying glass. Eventually, I\nconceded defeat.</p>\n\n<p>Once I tried designing a set of metrics for an 8 inch wide page, everything fell\ninto place. I could have enough breathing room around the text to make it\nenjoyable to read, a decent length for the code snippets, and plenty of room for\nthe asides. (Using a narrower font for the asides helped too).</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/metrics.png\">\n  <figcaption>Here are the final horizontal metrics.</figcaption>\n</figure>\n\n<h2>How tall?</h2>\n\n<p>That left the other dimension. If I were going with a real publisher doing a\nfull offset print run, I could pick whatever page size I wanted. But since I&rsquo;m\nself publishing, that would mean paying up front for thousands of copies to be\nprinted and, I don&rsquo;t know, storing all the boxes in my garage or something.</p>\n\n<p>Print on demand worked great for my last book, and I planned to do the same\nthing for this one. That meant sticking to the limited set of page sizes that\nKDP and IngramSpark support. The only reasonable one that is 8 inches wide is\n8&quot;×10&quot;, so that&rsquo;s what I picked. The end result is a book that feels big, but\nhopefully not awkwardly huge. I&rsquo;m sorry. I promise to write a smaller book if I\never write another.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/master.png\">\n  <figcaption>The metrics for a complete chapter spread. Vertically, text is\n  aligned to a classic 12pt baseline grid.</figcaption>\n</figure>\n\n<p>The whole time I was picking these margins and metrics, I was also selecting\nfonts and building styles. You can&rsquo;t do graphic design in a vacuum, so I picked\na test chapter and just typeset it and tweaked the fonts over and over again.\nEventually I got a set of fonts and styles I liked, some masters that seemed\nworkable, and I was ready to go. The framework was done and now it was time to\nopen the content hose.</p>\n\n<h2>XML, like its 1999</h2>\n\n<p>Of course, problem #1 is that there <em>is</em> no content hose. I have to build one.\nInDesign doesn&rsquo;t know what the hell Markdown or my weird ass build system is.\nI sure as hell didn&rsquo;t want to, like, copy every chapter from my browser, paste\nit into InDesign and then manually apply all the styles. I have a high pain\ntolerance, but I&rsquo;m not a masochist.</p>\n\n<p>What InDesign <em>can</em> do is import XML. Even better, you can set it up to\nautomatically apply certain paragraph or character styles to certain tag names.\nInDesign&rsquo;s XML support, alas, has not matured much since the time I described it\nas <a href=\"/2014/11/03/bringing-my-web-book-to-print-and-ebook/\">being implemented by a narcoleptic intern</a>. For example, in HTML\nyou can italicize a word in a header by taking an italics tag and nesting it\ninside a header tag. InDesign cannot comprehend such advanced data modeling. It\nneeds a flat series of unnested tags and if you need italics in your header, you\ndamn well better have a unique <code>&lt;italics-header&gt;</code> tag for it.</p>\n\n<p>But now I had an ace up my sleeve. Since I had microscopic control over my build\nsystem and its Markdown processing, I could write my own <a href=\"https://github.com/munificent/craftinginterpreters/blob/master/tool/bin/build_xml.dart\">custom XML exporter</a>\nthat generated <em>exactly</em> the tags that would make InDesign not cry and avoid as\nmany InDesign XML import bugs as possible.</p>\n\n<h2>JavaScript, in <em>my</em> InDesign?</h2>\n\n<p>Even so, XML import only gets you so far. Specifically, it gets you a &ldquo;story&rdquo; in\nInDesign terms: a single continuous narrative of text that fills the main text\nbox and spans multiple pages:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/convert-before.png\">\n  <figcaption>What the initial XML import looks like. The pink text is where\n  an illustration goes and the &ldquo;@&rdquo; tells me where to anchor the aside.</figcaption>\n</figure>\n\n<p>The main story is where the prose and code snippets go, but the asides and the\nlocation markers need to be pulled out float off to the side. With my last book,\nI yanked those out manually. I literally cut each aside from the main text\ncolumn and pasted it into a new text box. It took forever, and that book was\nless than half as long as this one with <em>way</em> fewer code snippets.</p>\n\n<p>There are <em>1,133</em> code snippets in <em>Crafting Interpreters</em>. If I had to manually\ncut and paste the location markers for each of those, I would lose my mind.\nWorse, I would make a lot of mistakes, which would just create more work for\nmyself.</p>\n\n<p>I&rsquo;m an engineer so I am morally opposed to error-prone manual effort that can be\nautomated. Did you know that InDesign can be scripted using JavaScript? Well,\nyou do now, which apparently places you in a tiny minority because there are,\nlike, <em>no</em> docs for it out there. You can find a couple of auto-generated\nreferences, a few sad cries for help from graphic designers clearly out of\ntheir element with no responses, and that&rsquo;s it.</p>\n\n<p>JavaScripting InDesign is a special kind of pain. There is no debugger. There\nare no stack traces. There aren&rsquo;t even <em>debug prints</em>. There is literally just\n<code>alert()</code>, and you can only call it <em>once</em>. And it halts your script.\nFortunately, I actually learned JavaScript back when that&rsquo;s all <em>browsers</em> gave\nyou, so I can hack it.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/debug-js.png\">\n  <figcaption>Just like developing for IE6.</figcaption>\n</figure>\n\n<p>I managed to cobble together a horrific script that would find all of the asides\nand location markers, pull them out of the main text flow, and leave them off to\nthe side:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/convert-after.png\">\n  <figcaption>Asides and location markers are pulled out of the main flow and\n  into their own text boxes.</figcaption>\n</figure>\n\n<p>What I wasn&rsquo;t able to get the script to do was <em>position</em> the boxes correctly.\nBut InDesign has a thing called &ldquo;anchors&rdquo; where you can lock the position of an\nelement relative to another. A couple of carefully crafted Object Styles would\neven set the horizontal metrics correctly and align the text to the right\nbaseline. All I had to do was anchor each text box and it worked perfectly!</p>\n\n<p>Wait, did I say &ldquo;perfectly&rdquo;? I meant  it worked right about half the time and\nthe other half the time InDesign would inexplicably <em>turn off the fucking\nborders of nearby code snippets</em>.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/anchor.gif\">\n  <figcaption>What it looks like when InDesign hates you.</figcaption>\n</figure>\n\n<p>I lost hours of my life to this stupid bug. Eventually, I realized that some\ncompletely random subset of location tags would have to be manually positioned\nbecause anchoring invariably broke some borders.</p>\n\n<h2>Editing, again</h2>\n\n<p>All of the above took me a good month or so and then it was time to stop\nfiddling around and get to work on the actual content. The first thing I did was\nanother editing pass of the entire book, front to back. I had already done three\ndrafts of each chapter as I was writing them, but I wanted to do one more now\nthat it was done so that I could get a better feel for continuity. It turns out\nI repeated the same dumb jokes a lot. I fixed (most of) those.</p>\n\n<p>This took five months. There&rsquo;s nothing fun to say about this, it was just a\nchore.</p>\n\n<h2>Copy editing</h2>\n\n<p>Next I hired an actual professional copy editor, <a href=\"https://karisomerton.com/\">Kari Somerton</a>, to go\nthrough and do the same thing. She was great. Most of the editing world uses\nMicrosoft Word and &ldquo;Track Changes&rdquo; to handle the editing process. Like most\nsoftware engineers, I live and breathe plaintext and Git. That way I can see\ndiffs of the changes, and go back through history.</p>\n\n<p>I didn&rsquo;t want to abandon my workflow so I asked Kari to ramp up on Git and my\nweird completely bespoke build system. She handled it with aplomb and churned\nthrough the book in no time. She found hundreds and hundreds of mistakes. This\ndespite me doing four drafts and readers filing hundreds of issues already.\nProfessional copy editors are worth every penny.</p>\n\n<h2>Typesetting the whole thing</h2>\n\n<p>Once the words were as good as they were gonna get, it was time to get them onto\npages. The process went like this:</p>\n\n<ol>\n<li><p>Create a new InDesign file for the next chapter.</p></li>\n<li><p>Export it to XML.</p></li>\n<li><p>Import the XML into InDesign.</p></li>\n<li><p>Run my little JavaScript script to pull out the asides and location markers.</p></li>\n<li><p>Go through and anchor the side bar stuff.</p></li>\n<li><p>Fix up whitespace at the end of pages.</p></li>\n</ol>\n\n<p>The first five steps are a piece of cake. I&rsquo;d wake up in the morning, brew a cup\nof coffee, shamble upstairs to the iMac, and get started. I could grind through\nthose steps while half awake and get a chapter done in half an hour or so. It\nwas peaceful. Almost meditative.</p>\n\n<p>And then step six. You see, that right there is the hard thing about typesetting\na book. And it&rsquo;s the really hard thing about typesetting <em>this</em> book. Because it\nturns out there are a bunch of constraints on how content can be fit vertically\nin a page. Obviously, we can&rsquo;t slice an illustration in half and put the top\nhalf on one page and the bottom half on the next. The asides also really need to\nfit on one page too, or it gets confusing to keep track of what they refer to.</p>\n\n<p>Whenever possible, it&rsquo;s nice for the code snippets to not get split across pages\ntoo. Some of those can be over a dozen lines long. (This is another reason why\nwider horizontal metrics helped. Because if I had made the code snippets\nnarrower, they would end up taller, which would make them harder to fit on the\npage.) And you don&rsquo;t want a header alone at the end of a page with no content\nafter it. And it&rsquo;s good to avoid <a href=\"https://en.wikipedia.org/wiki/Widows_and_orphans\">widows and orphans</a>&hellip;</p>\n\n<p>Take all of those rules and restrictions, and mix in the completely fixed height\nof a page and you got yourself a real constraint solving problem. Or, in my\ncase, 640 of them, all interwoven with each other. Because, you see, InDesign is\nhappy to solve all of this for you by just pushing content to later pages. Code\nsnippet too long? Move it to the next page. No room for prose under the header?\nMove it all to the next page. What that gives you is a ton of dead white space\nat the bottom of pages. It looks terrible and wastes space, like this:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/typeset.png\">\n  <figcaption>I thoughtfully left room on the page for your own doodles.</figcaption>\n</figure>\n\n<h2>Speaking of illustrations&hellip;</h2>\n\n<p>At one level, the illustrations were easy. I specifically chose black and white\npen and ink because it&rsquo;s print friendly. When I first scanned the images as I\nwrote each chapter, I brought them in at glorious 1200 DPI. Here&rsquo;s a crop:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/scan.png\">\n</figure>\n\n<p>A little level adjustment in Photoshop produces:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/illustration.png\">\n</figure>\n\n<p>So detailed! Exporting these to high resolution bitmaps that print well was a\nsnap, and they look great. (Well, as great as my handwriting looks, I guess.)</p>\n\n<p>Incorporating the illustrations into the page layout was another story. Halfway\nthrough typesetting, a lightbulb went off and I finally realized why most books\nsay, &ldquo;Refer to Figure 123 to see blah blah blah&hellip;&rdquo; That gives the typesetter\nfreedom to put Figure 123 wherever the hell it fits on any nearby page.</p>\n\n<p>In my dumb book, because I am an idiot, the prose just refers directly to the\nillustration. The illustration needs to be <em>right there</em> or the text doesn&rsquo;t\nmake sense. I didn&rsquo;t think about that when each chapter was an infinitely\nscrolling web page, and by the time I realized, it was too late.</p>\n\n<p>With the hundreds of illustrations and thousand-plus code snippets, I had given\nmyself thirty giant interrelated bin-packing exercises. The hard part of\ntypesetting was figuring out how to adjust things to minimize that dead space.\nSometimes I&rsquo;d split a code snippet in two. Maybe add a little extra padding\naround one image to spread stuff across the page a little. Or crowd another one\nso that it <em>just</em> fits on the page. Sometimes I&rsquo;d tweak an illustration to make\nit shorter to fit on a page or taller to eat up some whitespace.</p>\n\n<p>This was the real challenge of typesetting the book and why it took me two\nmonths to get through all the chapters.</p>\n\n<h2>Frontmatter and backmatter</h2>\n\n<p>Did you know that there are professional indexers? People whose job it is to\nwrite indexes for books? They even <a href=\"https://press.uchicago.edu/ucp/books/book/chicago/I/bo3625262.html\">write books</a> about how to write\nindexes. (One would presume that these books have truly superb indexes.)</p>\n\n<p>I did not hire one of those eminently skilled professionals. Instead, I spent\ntwo weeks going through every damn chapter <em>again</em> doing my best to pretend that\nI know what I&rsquo;m doing. InDesign&rsquo;s support for indexes is actually pretty nice.\nYou can basically just select some text and say, &ldquo;Make an index entry for this.&rdquo;\nThen it collects all of those and generates an index for the whole book. But\nactually <em>adding</em> all of those entries is a mind-numbing chore.</p>\n\n<p>The index is the main piece of &ldquo;backmatter&rdquo;&mdash;the stuff at the end of a book\nafter its main content. There is also &ldquo;frontmatter&rdquo;. You&rsquo;ll never guess where\nthat goes. I put together a title page, copyright page, dedication, and\nacknowledgements. Then I let InDesign generate a table of contents for me.</p>\n\n<p>This was a magical moment. At this point, I had a complete book:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/inside.jpg\">\n  <figcaption>Here&rsquo;s what the inside looks like.</figcaption>\n</figure>\n\n<p>Or, at least, I had the <em>inside</em> of one.</p>\n\n<h2>Cover design</h2>\n\n<p>A lot of authors obsess over their cover and envision it the whole time they are\nwriting. Despite what the aphorism says, people <em>do</em> judge books by their cover\nand a good one makes a big difference. At least, that&rsquo;s the case over in fiction\nland. In computer science, judging by the other books I have laying around, the\nartistic merit of the cover appears to be somewhat less critical. I guess when\nthe prof says you have to buy the book to pass the class, a clip art cover is\nsufficiently compelling.</p>\n\n<p>Since I am <em>not</em> a professor who can garner sales by fiat, I spent a lot of time\non the cover design. I take photos, so I thought it could look nice to put\nsomething detailed on the cover to liven it up. I went through my thousands of\nphotos trying to find something that fit. And, while I have some pretty\npictures, none of them felt like they worked as covers. They felt arbitrary.</p>\n\n<p>Eventually I realized that the visual language of the book is those pen and ink\nillustrations. So I drew a bigger more detailed version of <a href=\"http://craftinginterpreters.com/a-map-of-the-territory.html#the-parts-of-a-language\">the mountain\nillustration I use as a metaphor for the compilation process</a>. I also\nhand-lettered a new title:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/cover-trace.jpg\">\n</figure>\n\n<p>It&rsquo;s a real typeface (Acumin Pro Extra Condensed) but I hand-traced a printout\nto give it some imperfect charm. I picked a color palette to try to give it a\nsort of a mimeographed 1950s scouting manual vibe.</p>\n\n<h2>Proofreading the proof</h2>\n\n<p>Now I really had a book. I uploaded the PDF exports to KDP and ordered a proof\ncopy. A week later, a surprisingly heavy box arrived. This was the first moment\nI really understood just how <em>big</em> this book I wrote is. Up until this point, it\nwas just data files. But seeing it fill up an Amazon box clarified the scale of\nthe project in a way that the time I spent never quite did.</p>\n\n<p>So I had a book, but it <em>still</em> wasn&rsquo;t done. Because the typesetting process\ninvolved a lot of manual labor. To err is human, so now I had to\n<em>proofread</em>&mdash;to literally go through the proof and read it looking for\nmistakes. I marked them all with sticky notes:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/edits.jpg\">\n  <figcaption>I put an &ldquo;x&rdquo; on each sticky note to mark when I had applied the\n  fix to the InDesign files.</figcaption>\n</figure>\n\n<p>Here&rsquo;s where it got stressful. If you&rsquo;re a programmer, then source control and\ndiff is deeply ingrained in your workflow. Whenever I make a change, I take for\ngranted that I can then see a diff in the commit to verify that I changed only\nwhat I intended and nothing else.</p>\n\n<p>I did put the InDesign files in a Git repo, but they are giant opaque binary\nfiles. Also, InDesign has a habit of changing them even when it doesn&rsquo;t seem\nlike I&rsquo;ve actually made any real changes. There&rsquo;s nothing quite like syncing all\nthe styles across the chapters, seeing every single file marked changed and\nwondering, &ldquo;Did I just accidentally move every bullet list item 3 points to the\nleft?&rdquo; It felt like flying blind at exactly the stage in the process where I\nreally wanted to see <em>exactly</em> what was happening.</p>\n\n<p>Did I engineer my way out of this problem? You&rsquo;re <a href=\"https://github.com/munificent/craftinginterpreters/blob/master/tool/bin/tile_pages.dart\">damn right I did</a>. I\nwrote a Dart script that would take a PDF of the book, extract every page, and\nthen generate a single huge PNG file with every page tiled across it. It looks\nlike this:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/pages.png\">\n</figure>\n\n<p>If you zoom in, each page is about this big:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/pages-zoom.png\">\n  <figcaption>If you&rsquo;re on a retina display, this is a 100% zoom.</figcaption>\n</figure>\n\n<p>Every time I changed the InDesign files and committed them, I exported a PDF\nfor that commit and generated a tile image. Then I wrote a little Photoshop\naction that would take two of those and draw a big red border around any pixels\nthat differed. Here is what all of the proofreading changes look like:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/diff.png\">\n</figure>\n\n<p>And zoomed in:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2021/07/diff-zoom.png\">\n</figure>\n\n<p>There isn&rsquo;t enough detail in the tile image to tell exactly what changed, but\nthe red tells me which pages need a visual inspection. I know I should be proud\nof, like, writing an entire textbook on programming languages. But, honestly, I\nthink I&rsquo;m most proud of this dumb little script. It was <em>such</em> a relief to be\nable to programmatically verify that, yes, this PDF looks exactly like the last\none except for the one expected change.</p>\n\n<h2>Ebooks are also books</h2>\n\n<p>Once I incorporated all the proofreading fixes, the print edition was really\nfor real totally done. But people also like reading ebooks and Kindle, so I\nneeded to make those too.</p>\n\n<p>Again, writing my own build system helped. I tweaked it to be able to export the\nantiquated XHTML that EPUB requires as well as all the weird metadata and\nmanifest stuff that goes into one. A few command-line invocations later and I\nhad Kindle and EPUB ebooks. I tested in a bunch of readers and tweaked the CCS\nto try to find a compromise between all of their renderers.</p>\n\n<h2>Updating the site and launching</h2>\n\n<p>At this point&mdash;and now we&rsquo;re talking this past weekend as I write this\nsentence&mdash;I had a folder with all of the final files for every edition of\nthe book. All that remained was to update the front page of the book&rsquo;s website\nto point to where people can get them. I took some photos and put on my web\ndesigner hat for a while. I tried to make it tolerably responsive.</p>\n\n<p>Then I wrote this blog post. It&rsquo;s weird to put that in the past tense since I\njust wrote it. But I guess it&rsquo;s in the past now.</p>\n\n<p>Tomorrow, I&rsquo;m going to upload the files to the various sites and stores. I&rsquo;ll\nupdate the site to have links to all of those as they go live. Once the stores\nhave processed the uploads and everything is available, I&rsquo;ll publish this post\nand update the site. I&rsquo;ll write a note for the mailing list and feel nervous\nemailing that many people. If you&rsquo;re reading this, I already did all that and\nthe book is really, really done.</p>\n\n<h2>What next?</h2>\n\n<p>Ever since I finished the last chapter, people have been asking me what I&rsquo;m\ngoing to do next. I have people I consider close friends now who have never\nknown me when I <em>wasn&rsquo;t</em> writing this book.</p>\n\n<p>Many ask what I&rsquo;m going to write next, or suggest a topic. I interpret this as a\ncompliment: They like my writing and want more. But it also feels like asking a\nmom in labor whether she plans to have more kids. I&rsquo;ve had my legs in the\nstirrups for six years, so I&rsquo;m gonna just relax a bit after all the pushing is\nover before I even <em>think</em> about another book baby.</p>\n\n<p>What I really plan to do is&hellip; not <em>plan</em> to do anything. This writing project\nhas been an enormous exercise in self-applied delayed gratification. On top of\nthat, the pandemic brought its own basket of deferred dreams. I&rsquo;ve gotten so\nskilled at denying myself and postponing, so good at tuning out what I <em>feel</em>\nlike doing, that it&rsquo;s hard to even hear it any more. I don&rsquo;t remember what my\nown joy sounds like.</p>\n\n<p>So I&rsquo;m gonna check out for a while and go hunting for my pleasure centers. Maybe\n<a href=\"https://www.youtube.com/channel/UCSMJ0iRwAhIFYSpntOEtn2g\">make some more music</a>. Maybe go fishing. Probably spend more time with\nfriends and family (safely). I might get back to working on <a href=\"https://github.com/munificent/hauberk\">my\nroguelike</a>. Or maybe I won&rsquo;t do any of those. Maybe I&rsquo;ll just go out in\nthe backyard and bask mindlessly in the sun like a lizard. The important part is\nI won&rsquo;t decide until I feel like it.</p>\n\n<p>I&rsquo;m sure eventually I&rsquo;ll get the itch to work on something more sizeable again.\n(But, God-willing, I will never spend six years on a single project again in my\nlife.) Until then, I hope you enjoy the book. Despite all the work, I had a lot\nof fun making it, and it was <em>always</em> a joy to hear from readers who liked it.\nIt&rsquo;s the only thing that kept me going this long and enabled me to get it done.</p>\n","contentSnippet":"My book Crafting Interpreters on programming languages is done. OK, OK.\nI know I said it was done like fifteen months ago. But now it’s really\ndone. And by that I mean, the print, ebook and PDF versions are done. You can\nbuy it. You can hold it in your hands. And I do mean “hands” plural.\nBecause this little “handbook” turned out way larger than I anticipated:\n\n  This is a proof copy, so it looks a little different than the final design.\n\n\nLook at that thing. 640 pages, eight inches wide, ten inches tall. If you get\ntired of reading it, it can serve as a doorstop or protect you from small-arms\nfire.\nRemember back on Mr. Roger’s Neighborhood when he would take you to a factory\nand show you how pencils or umbrellas are made? I love that stuff, so I thought\nmaybe you might like to see what I spent the past year on. You can read this as\na peek behind the curtain, or maybe a long apology for why it took so long.\nWhere I left off\nWhat I said in my last post was that Crafting Interpreters was finished, and\nby that I meant that I’d written all the code, dotted the last sentence, and\nscanned the last illustration. The content of the book was complete. But it\nwasn’t a book yet. Just a pile of Markdown and PNG files that my embarrassingly\nbad Python code would begrudgingly turn into a website.\nMy original goal was always to make a real book, with pages and everything.\nCompleting the content was just one (granted, the most important) step in that\njourney. Once I finished the last chapter and put it online, I took about a\nmonth-long break. I had been writing every single day for almost four\nyears and I was fried. Also, in case you don’t remember, early 2020 was\nnot exactly a Totally Fine Time in World History.\nA new build system\nAfter a few weeks, my desire to have this project completely done returned and I\neased my way back into working on it. I fixed a whole pile of typos and other\nmistakes that readers filed bugs for (thanks!).\nThen, for no real good reason at all, I decided to rewrite the whole build\nsystem for the book in Dart. The build script I wrote for my first book\nwas dead simple. Literally a single Python script that took a Markdown\nfile for each book chapter and rendered it to HTML while weaving in the code\nsnippets. The world’s dumbest static site generator.\nI started with that for Crafting Interpreters but then it grew and grew. My\nsecond book includes every single line of code for two complete interpreters,\nwhich it builds up incrementally across thirty chapters. I needed to not just\nbuild the HTML for the book’s website, but also make sure the code really did\nwork. I gave the build system the ability to not only generate the site for the\nbook, but also to slice and dice the code. Given a chapter, or even a single\npoint within a chapter, it can output a program containing all of the code for\nthe interpreters up to that point. Then I can take that code, compile it, and\nrun it through my automated test suite to make sure the code I’m showing you\ndoes what it’s supposed to.\nUseful, but really straining the limits of how much code I want to maintain in a\ndynamically typed language like Python, at least, with my (low) level of Python\nexpertise. Also, it was, frankly, really slow. So over a period of a couple of\nweeks, I rewrote the whole thing in Dart.\nI work at Google on the Dart language team as my day job, so picking\nDart was not an unbiased choice. But it’s my build system for my book, and I\nknow Dart and many of its core libraries and packages like the back of my hand.\nHell, I personally wrote the initial version of the canonical markdown\npackage.\nI found a pretty nice package for mustache templates, so I converted\nthe book’s old Liquid templates to that. I didn’t find a good syntax\nhighlighter. But it’s not like I looked very hard either. It seemed like just\nthe kind of fun thing to implement from scratch, so I whipped one up loosely\nbased on Pygments.\nThe end result is a new build system that generates exactly the HTML and\nsyntax-highlighted code that I want. Also, it is literally ten times faster\nthan the old Python one. As you’ll see, it turned out to be handy that I had\nbetter control over the Markdown processing, but at the time I was basically\njust doing this for fun and to procrastinate the real work.\nI planned to implement some clever incremental rebuild logic in\n  the dev server, but it builds so fast that I just rebuild everything on every\n  refresh.\n\n\nOnce I had the new build system outputting nice clean HTML and I’d deleted the\nold Python stuff, it was time to get started.\nDesigning the book\nDoing a large graphic design project like a book works a lot like web dev or\ngame programming where it sort of has two levels. First you set up your\n“framework” or “engine”. On the web, this is your web framework and all of your\nCSS and HTML templates. In games, it’s your game engine. Then you pour content\ninto that structure. With the right framework, adding content is easy.\nFor graphic design using a program like Adobe InDesign, the way it works is you\nset up styles and masters. A master defines the margins and grid lines for a\npage. It’s the fences that corral all the text to keep those feral letters from\nrunning around eating all the whitespace. Styles are like CSS: they let you take\na semantic kind of text or object and associate specific fonts, styles and\ncolors for it.\nIn theory, you get the masters and styles right and then typesetting is pretty\neasy and mechanical. Now, I did not make my life easy when it comes to book\ndesign. Book design is literally a two-dimensional spatial exercise and I made\nmy job harder both horizontally and vertically. If you’ve read any of it on the\nweb, you know my book has:\nProse, of course. So many words.\n\n\nA lot of asides that need to be right next to certain pieces of text, code\nor illustrations that they refer to. Some of these can get pretty long.\n\n\nPlenty of code. Also, each code snippet has a little location blurb next to\nit telling you where the code goes in the resulting program.\n\n\n\nHow wide?\nHorizontally, the main text column needs to be wide enough to fit the longest\nline of code. I can use shorter lines and wrap the snippets more, but that makes\nthem harder to read. It also makes them vertically taller, which causes its own\nproblem.\nThen I need room next to that for the asides, since they often remark directly\non specific sentences. I can make those narrower too, of course. But then they\nwrap and get taller. Some asides are fairly long and if they get too tall, they\nstart colliding with each other or overlapping location snippets.\nOh, and since I ended up writing a 200k+ word book, it’s going to have a high\npage count. That means a thick book. Thick books need wider inner margins so the\ntext doesn’t disappear into the spine.\nAll of this points towards a pretty wide page. Most CS textbooks—at least\nthe ones on my bookshelf—are 7.5 inches wide. I tried hard to come up with\na design that fit the code, asides, and healthy margins in that width while\nstill giving a text size that didn’t require a magnifying glass. Eventually, I\nconceded defeat.\nOnce I tried designing a set of metrics for an 8 inch wide page, everything fell\ninto place. I could have enough breathing room around the text to make it\nenjoyable to read, a decent length for the code snippets, and plenty of room for\nthe asides. (Using a narrower font for the asides helped too).\nHere are the final horizontal metrics.\n\n\nHow tall?\nThat left the other dimension. If I were going with a real publisher doing a\nfull offset print run, I could pick whatever page size I wanted. But since I’m\nself publishing, that would mean paying up front for thousands of copies to be\nprinted and, I don’t know, storing all the boxes in my garage or something.\nPrint on demand worked great for my last book, and I planned to do the same\nthing for this one. That meant sticking to the limited set of page sizes that\nKDP and IngramSpark support. The only reasonable one that is 8 inches wide is\n8\"×10\", so that’s what I picked. The end result is a book that feels big, but\nhopefully not awkwardly huge. I’m sorry. I promise to write a smaller book if I\never write another.\nThe metrics for a complete chapter spread. Vertically, text is\n  aligned to a classic 12pt baseline grid.\n\n\nThe whole time I was picking these margins and metrics, I was also selecting\nfonts and building styles. You can’t do graphic design in a vacuum, so I picked\na test chapter and just typeset it and tweaked the fonts over and over again.\nEventually I got a set of fonts and styles I liked, some masters that seemed\nworkable, and I was ready to go. The framework was done and now it was time to\nopen the content hose.\nXML, like its 1999\nOf course, problem #1 is that there is no content hose. I have to build one.\nInDesign doesn’t know what the hell Markdown or my weird ass build system is.\nI sure as hell didn’t want to, like, copy every chapter from my browser, paste\nit into InDesign and then manually apply all the styles. I have a high pain\ntolerance, but I’m not a masochist.\nWhat InDesign can do is import XML. Even better, you can set it up to\nautomatically apply certain paragraph or character styles to certain tag names.\nInDesign’s XML support, alas, has not matured much since the time I described it\nas being implemented by a narcoleptic intern. For example, in HTML\nyou can italicize a word in a header by taking an italics tag and nesting it\ninside a header tag. InDesign cannot comprehend such advanced data modeling. It\nneeds a flat series of unnested tags and if you need italics in your header, you\ndamn well better have a unique <italics-header> tag for it.\nBut now I had an ace up my sleeve. Since I had microscopic control over my build\nsystem and its Markdown processing, I could write my own custom XML exporter\nthat generated exactly the tags that would make InDesign not cry and avoid as\nmany InDesign XML import bugs as possible.\nJavaScript, in my InDesign?\nEven so, XML import only gets you so far. Specifically, it gets you a “story” in\nInDesign terms: a single continuous narrative of text that fills the main text\nbox and spans multiple pages:\nWhat the initial XML import looks like. The pink text is where\n  an illustration goes and the “@” tells me where to anchor the aside.\n\n\nThe main story is where the prose and code snippets go, but the asides and the\nlocation markers need to be pulled out float off to the side. With my last book,\nI yanked those out manually. I literally cut each aside from the main text\ncolumn and pasted it into a new text box. It took forever, and that book was\nless than half as long as this one with way fewer code snippets.\nThere are 1,133 code snippets in Crafting Interpreters. If I had to manually\ncut and paste the location markers for each of those, I would lose my mind.\nWorse, I would make a lot of mistakes, which would just create more work for\nmyself.\nI’m an engineer so I am morally opposed to error-prone manual effort that can be\nautomated. Did you know that InDesign can be scripted using JavaScript? Well,\nyou do now, which apparently places you in a tiny minority because there are,\nlike, no docs for it out there. You can find a couple of auto-generated\nreferences, a few sad cries for help from graphic designers clearly out of\ntheir element with no responses, and that’s it.\nJavaScripting InDesign is a special kind of pain. There is no debugger. There\nare no stack traces. There aren’t even debug prints. There is literally just\nalert(), and you can only call it once. And it halts your script.\nFortunately, I actually learned JavaScript back when that’s all browsers gave\nyou, so I can hack it.\nJust like developing for IE6.\n\n\nI managed to cobble together a horrific script that would find all of the asides\nand location markers, pull them out of the main text flow, and leave them off to\nthe side:\nAsides and location markers are pulled out of the main flow and\n  into their own text boxes.\n\n\nWhat I wasn’t able to get the script to do was position the boxes correctly.\nBut InDesign has a thing called “anchors” where you can lock the position of an\nelement relative to another. A couple of carefully crafted Object Styles would\neven set the horizontal metrics correctly and align the text to the right\nbaseline. All I had to do was anchor each text box and it worked perfectly!\nWait, did I say “perfectly”? I meant  it worked right about half the time and\nthe other half the time InDesign would inexplicably turn off the fucking\nborders of nearby code snippets.\nWhat it looks like when InDesign hates you.\n\n\nI lost hours of my life to this stupid bug. Eventually, I realized that some\ncompletely random subset of location tags would have to be manually positioned\nbecause anchoring invariably broke some borders.\nEditing, again\nAll of the above took me a good month or so and then it was time to stop\nfiddling around and get to work on the actual content. The first thing I did was\nanother editing pass of the entire book, front to back. I had already done three\ndrafts of each chapter as I was writing them, but I wanted to do one more now\nthat it was done so that I could get a better feel for continuity. It turns out\nI repeated the same dumb jokes a lot. I fixed (most of) those.\nThis took five months. There’s nothing fun to say about this, it was just a\nchore.\nCopy editing\nNext I hired an actual professional copy editor, Kari Somerton, to go\nthrough and do the same thing. She was great. Most of the editing world uses\nMicrosoft Word and “Track Changes” to handle the editing process. Like most\nsoftware engineers, I live and breathe plaintext and Git. That way I can see\ndiffs of the changes, and go back through history.\nI didn’t want to abandon my workflow so I asked Kari to ramp up on Git and my\nweird completely bespoke build system. She handled it with aplomb and churned\nthrough the book in no time. She found hundreds and hundreds of mistakes. This\ndespite me doing four drafts and readers filing hundreds of issues already.\nProfessional copy editors are worth every penny.\nTypesetting the whole thing\nOnce the words were as good as they were gonna get, it was time to get them onto\npages. The process went like this:\nCreate a new InDesign file for the next chapter.\n\n\nExport it to XML.\n\n\nImport the XML into InDesign.\n\n\nRun my little JavaScript script to pull out the asides and location markers.\n\n\nGo through and anchor the side bar stuff.\n\n\nFix up whitespace at the end of pages.\n\n\n\nThe first five steps are a piece of cake. I’d wake up in the morning, brew a cup\nof coffee, shamble upstairs to the iMac, and get started. I could grind through\nthose steps while half awake and get a chapter done in half an hour or so. It\nwas peaceful. Almost meditative.\nAnd then step six. You see, that right there is the hard thing about typesetting\na book. And it’s the really hard thing about typesetting this book. Because it\nturns out there are a bunch of constraints on how content can be fit vertically\nin a page. Obviously, we can’t slice an illustration in half and put the top\nhalf on one page and the bottom half on the next. The asides also really need to\nfit on one page too, or it gets confusing to keep track of what they refer to.\nWhenever possible, it’s nice for the code snippets to not get split across pages\ntoo. Some of those can be over a dozen lines long. (This is another reason why\nwider horizontal metrics helped. Because if I had made the code snippets\nnarrower, they would end up taller, which would make them harder to fit on the\npage.) And you don’t want a header alone at the end of a page with no content\nafter it. And it’s good to avoid widows and orphans…\nTake all of those rules and restrictions, and mix in the completely fixed height\nof a page and you got yourself a real constraint solving problem. Or, in my\ncase, 640 of them, all interwoven with each other. Because, you see, InDesign is\nhappy to solve all of this for you by just pushing content to later pages. Code\nsnippet too long? Move it to the next page. No room for prose under the header?\nMove it all to the next page. What that gives you is a ton of dead white space\nat the bottom of pages. It looks terrible and wastes space, like this:\nI thoughtfully left room on the page for your own doodles.\n\n\nSpeaking of illustrations…\nAt one level, the illustrations were easy. I specifically chose black and white\npen and ink because it’s print friendly. When I first scanned the images as I\nwrote each chapter, I brought them in at glorious 1200 DPI. Here’s a crop:\nA little level adjustment in Photoshop produces:\nSo detailed! Exporting these to high resolution bitmaps that print well was a\nsnap, and they look great. (Well, as great as my handwriting looks, I guess.)\nIncorporating the illustrations into the page layout was another story. Halfway\nthrough typesetting, a lightbulb went off and I finally realized why most books\nsay, “Refer to Figure 123 to see blah blah blah…” That gives the typesetter\nfreedom to put Figure 123 wherever the hell it fits on any nearby page.\nIn my dumb book, because I am an idiot, the prose just refers directly to the\nillustration. The illustration needs to be right there or the text doesn’t\nmake sense. I didn’t think about that when each chapter was an infinitely\nscrolling web page, and by the time I realized, it was too late.\nWith the hundreds of illustrations and thousand-plus code snippets, I had given\nmyself thirty giant interrelated bin-packing exercises. The hard part of\ntypesetting was figuring out how to adjust things to minimize that dead space.\nSometimes I’d split a code snippet in two. Maybe add a little extra padding\naround one image to spread stuff across the page a little. Or crowd another one\nso that it just fits on the page. Sometimes I’d tweak an illustration to make\nit shorter to fit on a page or taller to eat up some whitespace.\nThis was the real challenge of typesetting the book and why it took me two\nmonths to get through all the chapters.\nFrontmatter and backmatter\nDid you know that there are professional indexers? People whose job it is to\nwrite indexes for books? They even write books about how to write\nindexes. (One would presume that these books have truly superb indexes.)\nI did not hire one of those eminently skilled professionals. Instead, I spent\ntwo weeks going through every damn chapter again doing my best to pretend that\nI know what I’m doing. InDesign’s support for indexes is actually pretty nice.\nYou can basically just select some text and say, “Make an index entry for this.”\nThen it collects all of those and generates an index for the whole book. But\nactually adding all of those entries is a mind-numbing chore.\nThe index is the main piece of “backmatter”—the stuff at the end of a book\nafter its main content. There is also “frontmatter”. You’ll never guess where\nthat goes. I put together a title page, copyright page, dedication, and\nacknowledgements. Then I let InDesign generate a table of contents for me.\nThis was a magical moment. At this point, I had a complete book:\nHere’s what the inside looks like.\n\n\nOr, at least, I had the inside of one.\nCover design\nA lot of authors obsess over their cover and envision it the whole time they are\nwriting. Despite what the aphorism says, people do judge books by their cover\nand a good one makes a big difference. At least, that’s the case over in fiction\nland. In computer science, judging by the other books I have laying around, the\nartistic merit of the cover appears to be somewhat less critical. I guess when\nthe prof says you have to buy the book to pass the class, a clip art cover is\nsufficiently compelling.\nSince I am not a professor who can garner sales by fiat, I spent a lot of time\non the cover design. I take photos, so I thought it could look nice to put\nsomething detailed on the cover to liven it up. I went through my thousands of\nphotos trying to find something that fit. And, while I have some pretty\npictures, none of them felt like they worked as covers. They felt arbitrary.\nEventually I realized that the visual language of the book is those pen and ink\nillustrations. So I drew a bigger more detailed version of the mountain\nillustration I use as a metaphor for the compilation process. I also\nhand-lettered a new title:\nIt’s a real typeface (Acumin Pro Extra Condensed) but I hand-traced a printout\nto give it some imperfect charm. I picked a color palette to try to give it a\nsort of a mimeographed 1950s scouting manual vibe.\nProofreading the proof\nNow I really had a book. I uploaded the PDF exports to KDP and ordered a proof\ncopy. A week later, a surprisingly heavy box arrived. This was the first moment\nI really understood just how big this book I wrote is. Up until this point, it\nwas just data files. But seeing it fill up an Amazon box clarified the scale of\nthe project in a way that the time I spent never quite did.\nSo I had a book, but it still wasn’t done. Because the typesetting process\ninvolved a lot of manual labor. To err is human, so now I had to\nproofread—to literally go through the proof and read it looking for\nmistakes. I marked them all with sticky notes:\nI put an “x” on each sticky note to mark when I had applied the\n  fix to the InDesign files.\n\n\nHere’s where it got stressful. If you’re a programmer, then source control and\ndiff is deeply ingrained in your workflow. Whenever I make a change, I take for\ngranted that I can then see a diff in the commit to verify that I changed only\nwhat I intended and nothing else.\nI did put the InDesign files in a Git repo, but they are giant opaque binary\nfiles. Also, InDesign has a habit of changing them even when it doesn’t seem\nlike I’ve actually made any real changes. There’s nothing quite like syncing all\nthe styles across the chapters, seeing every single file marked changed and\nwondering, “Did I just accidentally move every bullet list item 3 points to the\nleft?” It felt like flying blind at exactly the stage in the process where I\nreally wanted to see exactly what was happening.\nDid I engineer my way out of this problem? You’re damn right I did. I\nwrote a Dart script that would take a PDF of the book, extract every page, and\nthen generate a single huge PNG file with every page tiled across it. It looks\nlike this:\nIf you zoom in, each page is about this big:\nIf you’re on a retina display, this is a 100% zoom.\n\n\nEvery time I changed the InDesign files and committed them, I exported a PDF\nfor that commit and generated a tile image. Then I wrote a little Photoshop\naction that would take two of those and draw a big red border around any pixels\nthat differed. Here is what all of the proofreading changes look like:\nAnd zoomed in:\nThere isn’t enough detail in the tile image to tell exactly what changed, but\nthe red tells me which pages need a visual inspection. I know I should be proud\nof, like, writing an entire textbook on programming languages. But, honestly, I\nthink I’m most proud of this dumb little script. It was such a relief to be\nable to programmatically verify that, yes, this PDF looks exactly like the last\none except for the one expected change.\nEbooks are also books\nOnce I incorporated all the proofreading fixes, the print edition was really\nfor real totally done. But people also like reading ebooks and Kindle, so I\nneeded to make those too.\nAgain, writing my own build system helped. I tweaked it to be able to export the\nantiquated XHTML that EPUB requires as well as all the weird metadata and\nmanifest stuff that goes into one. A few command-line invocations later and I\nhad Kindle and EPUB ebooks. I tested in a bunch of readers and tweaked the CCS\nto try to find a compromise between all of their renderers.\nUpdating the site and launching\nAt this point—and now we’re talking this past weekend as I write this\nsentence—I had a folder with all of the final files for every edition of\nthe book. All that remained was to update the front page of the book’s website\nto point to where people can get them. I took some photos and put on my web\ndesigner hat for a while. I tried to make it tolerably responsive.\nThen I wrote this blog post. It’s weird to put that in the past tense since I\njust wrote it. But I guess it’s in the past now.\nTomorrow, I’m going to upload the files to the various sites and stores. I’ll\nupdate the site to have links to all of those as they go live. Once the stores\nhave processed the uploads and everything is available, I’ll publish this post\nand update the site. I’ll write a note for the mailing list and feel nervous\nemailing that many people. If you’re reading this, I already did all that and\nthe book is really, really done.\nWhat next?\nEver since I finished the last chapter, people have been asking me what I’m\ngoing to do next. I have people I consider close friends now who have never\nknown me when I wasn’t writing this book.\nMany ask what I’m going to write next, or suggest a topic. I interpret this as a\ncompliment: They like my writing and want more. But it also feels like asking a\nmom in labor whether she plans to have more kids. I’ve had my legs in the\nstirrups for six years, so I’m gonna just relax a bit after all the pushing is\nover before I even think about another book baby.\nWhat I really plan to do is… not plan to do anything. This writing project\nhas been an enormous exercise in self-applied delayed gratification. On top of\nthat, the pandemic brought its own basket of deferred dreams. I’ve gotten so\nskilled at denying myself and postponing, so good at tuning out what I feel\nlike doing, that it’s hard to even hear it any more. I don’t remember what my\nown joy sounds like.\nSo I’m gonna check out for a while and go hunting for my pleasure centers. Maybe\nmake some more music. Maybe go fishing. Probably spend more time with\nfriends and family (safely). I might get back to working on my\nroguelike. Or maybe I won’t do any of those. Maybe I’ll just go out in\nthe backyard and bask mindlessly in the sun like a lizard. The important part is\nI won’t decide until I feel like it.\nI’m sure eventually I’ll get the itch to work on something more sizeable again.\n(But, God-willing, I will never spend six years on a single project again in my\nlife.) Until then, I hope you enjoy the book. Despite all the work, I had a lot\nof fun making it, and it was always a joy to hear from readers who liked it.\nIt’s the only thing that kept me going this long and enabled me to get it done.","guid":"http://journal.stuffwithstuff.com/2021/07/29/640-pages-in-15-months","isoDate":"2021-07-29T07:00:00.000Z","timestamp":"7/29/2021"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"Crafting \"Crafting Interpreters\"","link":"http://journal.stuffwithstuff.com/2020/04/05/crafting-crafting-interpreters/","pubDate":"Sun, 05 Apr 2020 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>It took three years and 200,000 words more than I expected, but my second\nbook, <a href=\"http://craftinginterpreters.com/\">Crafting Interpreters</a>, is complete. I finished the third draft of\nthe last chapter today, marking the last of around 1,400 days of continuous\nwriting.</p>\n\n<p>This book was <em>much</em> harder than my <a href=\"http://gameprogrammingpatterns.com/\">first book</a>, along every axis. It&rsquo;s\nlarger, more technically complex, much more deeply intertwined, and it had the\nmisfortune of aligning with a really difficult period in my life. Today feels\nless like coasting past the finish line at the Tour de France, arms raised in\ntriumph, and more like dragging myself onto the beach, clutching sand in relief\nafter a storm-thrashed ordeal at sea.</p>\n\n<p>Before I get into all that, I have a minor confession to make. When I finished\nmy first book, I wrote <a href=\"/2014/04/22/zero-to-95688-how-i-wrote-game-programming-patterns/\">a long post</a> about how I cobbled together enough\nwillpower to reach the end of the last page. Everything in there is true, but\nthere is one fact I superstitiously omitted.</p>\n\n<p>Halfway through writing Game Programming Patterns, I discovered a new passion:\nprogramming languages. It had been a long time since a topic ignited my brain to\nthe same degree, and I was <em>on fire</em>. I spent basically every free hour (and\nmany not-so-free hours &ndash; sorry, family) designing and hacking on programming\nlanguages. I read <a href=\"https://twitter.com/munificentbob/status/901543375945388032\">every book I could get my hands on</a>, <a href=\"/2010/07/23/what-i-learned-at-the-emerging-languages-camp/\">went to\nconferences</a>, <a href=\"/category/language/\">blogged</a>, I even <em>dreamed</em> about programming languages.\nThis infatuation was the main reason I stopped working on my first book for two\nyears.</p>\n\n<p>I have a personality quirk where when I&rsquo;m excited about something I just <em>have</em>\nto teach it to other people. Hermione Granger, arm waving feverishly to get the\nteacher&rsquo;s attention, is my spirit animal. It was inevitable that I would write\nsomething about interpreters. But I couldn&rsquo;t just drop one half-finished book to\nstart another. I have gigs of unfinished projects laying around, but &ndash; maybe\nbecause the completed chapters were already online &ndash; I couldn&rsquo;t bear to\nabandon Game Programming Patterns.</p>\n\n<p>So I made a promise to myself. If I finished that book, then I would let myself\nwrite a second book on interpreters. In part because of that promise, I <em>did</em>\nmanage to complete the chapters, and then <a href=\"/2014/11/03/bringing-my-web-book-to-print-and-ebook/\">the print and eBook editions</a>.\nWhat I thought was merely a hobby and personal goal turned out to be a\n<a href=\"/2014/11/20/how-my-book-launch-went/\">life-changing experience</a>. My little self-published vanity project has\n<a href=\"https://www.amazon.com/dp/0990582906\">hundreds of five-star reviews</a>, and has been translated to Korean,\nJapanese, Chinese, German, and Polish. The book did so much better than I\nexpected that I&rsquo;m still not sure how to process it, beyond feeling immense\ngratitude to everyone who read it, bought a copy, or cheered me on.</p>\n\n<h2>The Seed of a Book</h2>\n\n<p>Once I finished the print edition of &ldquo;Game Programming Patterns&rdquo;, I took some\ntime off. But it didn&rsquo;t take too long for that itch to write about interpreters\nto come back. I knew exactly what I was getting into with writing a book now,\nhow hard the grind can be. At first, I just noodled around. I wasn&rsquo;t committed\nto doing anything. It was more just a sort of recreational intellectual\nexercise. If I <em>were</em> to do a book, what would it look like? You know,\n<em>hypothetically speaking</em>.</p>\n\n<p>The very first note I wrote to myself said:</p>\n<div class=\"highlight\"><pre><code class=\"language-text\" data-lang=\"text\"><span></span>high-level goal: a *small* book that builds a complete, efficient\ninterpreter. instead of a wide text about programming language*s*,\nit is a single path through the language space. aim for 60k words.\n</code></pre></div>\n<p>My first book was almost 90,000 words, and I didn&rsquo;t want to hike a trail that\nlong again. I also had a meta-goal to make programming languages more\napproachable, and I figured a short text would help. I had this vision of\nsomething you could literally hold in your hand or have open next to your laptop\nwhile you followed along.</p>\n\n<p>To make a small book, I needed a small language and a small implementation. One\nof my other side projects was <a href=\"http://wren.io/\">a scripting language named Wren</a>. Wren is\nwritten in C, with a simple single-pass bytecode compiler inspired by Lua.\nBuilding Wren taught me how much functionality you can pack into a few thousand\nlines of clean C code.</p>\n\n<p>For this hypothetical book, I figured a bytecode VM in C like that would be a\ngreat fit. It would also give me the chance to cover a bunch of really fun\ntopics like stack-based VMs, object representation, and garbage collection. But\nWren wasn&rsquo;t the right language. I like Wren (obviously), but it has some design\nquirks that I think make it a better language for <em>users</em> but maybe not for\nteaching. For the book, I wanted a dynamically-typed scripting language in the\nvein of languages like JavaScript, Python, and Lua.</p>\n\n<p>I started tinkering on a new toy language, tentatively named &ldquo;Vox&rdquo;. The goal was\nto keep things as simple as possible without taking any shortcuts around the\nhard problems in implementing a language. I wanted a rich expression and\nstatement syntax to cover parsing. First-class functions and closures because\nthey are powerful and challenging to implement efficiently. Classes and methods\nbecause that paradigm is so prevalent but omitted by many compiler books.</p>\n\n<p>At some point, I realized that dropping readers straight into C was too\nunfriendly of an introduction. It&rsquo;s hard to teach high-level concepts like\nparsing and name resolution while also tracking pointers and managing memory.\nOK, so we&rsquo;ll build <em>two</em> interpreters. First a simple one in a high-level\nlanguage, focused on concepts. Then a second bytecode VM in C to focus on\nperformance and low-level implementation techniques.</p>\n\n<p>Somehow, I didn&rsquo;t notice that maybe this &ldquo;handbook&rdquo; wasn&rsquo;t going to be as\npocket-sized as I hoped.</p>\n\n<p>My first choice for the high-level implementation language was JavaScript. I\nimplemented most of a Vox interpreter in JS, but never really liked it. I wanted\nto write the interpreter in an object-oriented style because there are\ntechniques like the visitor pattern for doing language stuff in OOP that aren&rsquo;t\ncovered well elsewhere. Doing OOP in JS means deciding whether to use classes or\na prototypal style. The former is cleaner but infuriates some segment of\nreaders. The latter is verbose and confusing to those not already steeped in\nprototypes.</p>\n\n<p>Also, I missed static types. People reading code in a book don&rsquo;t get the luxury\nof seeing the code in a debugger where they can see what values are in various\nvariables. Static type annotations in the code help.</p>\n\n<p>So I switched to Java. I don&rsquo;t love Java but it seemed like the least biased\nchoice for a statically typed object-oriented language. I found you can tame a\nlot of its infamous verbosity by simply not programming in 1990s enterprise Java\nstyle. Maybe it&rsquo;s not idiomatic to have public fields, but it&rsquo;s a hell of a lot\nshorter.</p>\n\n<p>In parallel, I started building the bytecode VM in C, porting over bits of\nWren&rsquo;s implementation and stripping out the Wren-specific stuff. I spent the\nspring and summer of 2016 circling between these three pieces &ndash; the design of\nVox itself, the Java interpreter, and the C bytecode VM. This was a delightful,\nsatisfying period of time. The three parts played off each other in challenging\nways. Sometimes I would change the language to make one interpreter simpler, but\nfind doing so made the other interpreter more complex. Other times I&rsquo;d hit on\nsome trick that made everything get smaller and cleaner.</p>\n\n<h2>Getting Back on the Horse</h2>\n\n<p>I remember the exact moment I committed to writing the book. I was stuck on a\ntricky language design problem: constructor syntax. I knew I wanted classes,\nwhich meant some way to construct instances. Adding a <code>new</code> keyword felt too\nspecial-purpose for my minimal language. I like Smalltalk and Ruby&rsquo;s approach of\nmaking <code>new</code> be a method on the class object itself, but that requires\nmetaclasses and a lot of other machinery.</p>\n\n<p>I was struggling to find a way to add instantiation without making the language\nmuch bigger. Then I remembered JavaScript&rsquo;s thing where you can simply invoke a\n&ldquo;class&rdquo; as if it were a function to create new instances. That has all sorts of\nweird baggage in JavaScript because everything does in JS, but the concept and\nsyntax were perfect. I already had first-class classes. And I already had\nclosures which meant a function call syntax that could be applied to arbitrary\nexpressions. So &ldquo;constructors&rdquo; just became what you got when you invoked a\nclass.</p>\n\n<p>I felt like Vox had gelled, like it <em>was</em> a language now. And my two\nimplementations were coming along well too. I was surprised by how few hacks or\nugly corners I ran into. The codebases kind of fell together and the more I\ntweaked them, the nicer they got. It felt more like I had discovered them than\nthat I had created them. It would be a shame to <em>not</em> write the book and put\nthem out there into the world. They wanted me to.</p>\n\n<p>I committed to writing the book, and I restarted my rule of writing every single\nday.</p>\n\n<p>I had a few thousand lines of pretty Java and C code, but how do I turn that\ninto a book that can be read in linear order? Compact codebases tend to be\nhighly intertwined with many cyclic dependencies. I didn&rsquo;t want readers to have\nto slog through ten chapters before they could even run <code>main()</code>.</p>\n\n<p>This was the real technical challenge of writing the book &ndash; how do I take two\nimplementations of the same language, and break them into incremental pieces\nthat I can build up a chapter at a time?</p>\n\n<p>I made this problem harder for myself because of the meta-goal I had. One reason\nI didn&rsquo;t get into languages until later in my career was because I was\nintimidated by the reputation compilers have as being only for hardcore computer\nscience wizard types. I&rsquo;m a college dropout, so I felt I wasn&rsquo;t smart enough, or\nat least wasn&rsquo;t educated enough to hack it. Eventually I discovered that those\nbarriers existed only in my mind and that anyone <em>can</em> learn this.</p>\n\n<p>My main overarching goal of the book is to pass on that feeling, to get readers\nto understand there&rsquo;s no magic in there and nothing keeping them out. To nail\nthat conceit, I wanted to include <em>every single line of code</em> used by the\ninterpreters in the book. No parser generators, nothing left as an exercise for\nthe reader. If you type in all of the code in the book, you get two complete,\nworking interpreters. No tricks.</p>\n\n<p>So not only did I need to break these two interpreters into chapters, I needed\nto do it without any cheating. I wanted a hard guarantee that at the end of each\nchapter, you had a program that you could type in, compile, run, and do\nsomething with. I knew I wouldn&rsquo;t be able to verify this manually, so it was\ntime to create some tools.</p>\n\n<h2>A Bespoke Build System</h2>\n\n<p>I <a href=\"https://github.com/munificent/game-programming-patterns/tree/master/book\">wrote my first book in Markdown</a>. I slapped together <a href=\"https://github.com/munificent/game-programming-patterns/blob/master/script/format.py\">a tiny Python\nscript</a> that converts the Markdown to HTML and transcludes the code\nsnippets which are stored in separate C++ files. When I started my second book,\nI took that script and started growing it. It evolved throughout writing the\nbook, but in the end, here is how it works.</p>\n\n<p>All of the code for the interpreters are stored in separate source files. I have\na <a href=\"https://github.com/munificent/craftinginterpreters/tree/master/java/com/craftinginterpreters\">Java project</a> that contains the complete Java interpreter that you get\nby the end of that part of the book. Likewise, there&rsquo;s a <a href=\"https://github.com/munificent/craftinginterpreters/tree/master/c\">C project</a> for the\nbytecode VM. I can edit and build those in an IDE, run tests, debug them, etc.\nThey&rsquo;re real programs.</p>\n\n<p>Meanwhile, the text of the book is <a href=\"https://github.com/munificent/craftinginterpreters/tree/master/book\">authored in Markdown</a>, one file per\nchapter, just like my first book. To include a snippet of code in the book, I\nput a tag in the Markdown like this:</p>\n<div class=\"highlight\"><pre><code class=\"language-md\" data-lang=\"md\"><span></span>Which can be any of:\n\n^code is-alpha\n\nOnce we&#39;ve found an identifier, we scan the rest of it using:\n</code></pre></div>\n<p>Here, the <code>^code</code> line says &ldquo;look up the snippet named &lsquo;is-alpha&rsquo; and insert it\nhere.&rdquo; When the build script generates the HTML for this chapter, it goes off\nand hunts through the code for that snippet. Over in the code, special comments\ndelimit snippets. The one included here looks like this:</p>\n<div class=\"highlight\"><pre><code class=\"language-c\" data-lang=\"c\"><span></span><span class=\"c1\">//&gt; Scanning on Demand is-alpha</span>\n<span class=\"k\">static</span> <span class=\"kt\">bool</span> <span class=\"nf\">isAlpha</span><span class=\"p\">(</span><span class=\"kt\">char</span> <span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"o\">&gt;=</span> <span class=\"sc\">&#39;a&#39;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">c</span> <span class=\"o\">&lt;=</span> <span class=\"sc\">&#39;z&#39;</span><span class=\"p\">)</span> <span class=\"o\">||</span>\n         <span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"o\">&gt;=</span> <span class=\"sc\">&#39;A&#39;</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">c</span> <span class=\"o\">&lt;=</span> <span class=\"sc\">&#39;Z&#39;</span><span class=\"p\">)</span> <span class=\"o\">||</span>\n          <span class=\"n\">c</span> <span class=\"o\">==</span> <span class=\"sc\">&#39;_&#39;</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n<span class=\"c1\">//&lt; Scanning on Demand is-alpha</span>\n</code></pre></div>\n<p>The <code>//&gt;</code> line begins the snippet and says what chapter the snippet appears in and the name of the snippet. The <code>//&lt;</code> line ends the snippet. Pretty straightforward.</p>\n\n<p>This let me build the book, but didn&rsquo;t ensure that the thing I built actually\nworked. So I wrote a separate script that instead of building the <em>book</em>, builds\n<em>programs</em>. For each chapter, it collects <em>all</em> of the snippets that appear in\nthat chapter and the previous ones and writes them out to separate source files.\nIn other words, it produces a separate interpreter, one for each chapter,\ncontaining only the code that readers have seen so far.</p>\n\n<p>I put together a Makefile to build those per-chapter versions of each\ninterpreter to make sure they compiled. Of course, compiling successfully\ndoesn&rsquo;t mean they do anything <em>useful</em>. Writing a single correct interpreter is\nhard. Writing thirty of them &ndash; there are <a href=\"http://craftinginterpreters.com/contents.html\">thirty chapters</a> in the\nbook &ndash; is much harder.</p>\n\n<p>I had already harvested a little <a href=\"https://github.com/munificent/craftinginterpreters/blob/master/util/test.py\">test runner</a> from Wren and ported most of\nWren&rsquo;s tests over to be <a href=\"https://github.com/munificent/craftinginterpreters/tree/master/test\">Lox tests</a>. (I changed the name of the language in\nthe book since there was already a language out there named &ldquo;Vox.&rdquo;). I took that\ntest runner and extended it to be able to run the tests on each chapter&rsquo;s\nversion of the interpreters. Of course, the tests don&rsquo;t all pass &ndash; the\ninterpreters aren&rsquo;t complete! So I added metadata to track which tests I\nexpected to pass by which point in the book. With this in place, I could\nautomatically verify that the code I was showing readers did exactly what I\nexpected.</p>\n\n<h3>More Complex Snippets</h3>\n\n<p>The snippet markers look pretty straightforward, and in many cases they are. But\nreality tends to get messier and I didn&rsquo;t allow myself to sweep any of that mess\nunder nearby rugs. Some changes don&rsquo;t just <em>add</em> code to the interpreter. I try\nto minimize it, but often you need to <em>replace</em> some existing code. A few lines\nof code may appear in chapter 5 and then later get superseded in chapter 9 by\nsomething more powerful.</p>\n\n<p>Obviously, I can&rsquo;t jam both of those snippets into the same source file and\nexpect it to compile. Remember, the source files that I hand author are\nthemselves valid Java and C programs that I can build and run. If a function\ncontained several versions of its body mixed together, odds are slim that the\ncompiler will like what it sees.</p>\n\n<p>So, for any piece of code that later gets replaced &ndash; in other words code that\nis not part of the very final version of each interpreter &ndash; there is a\ndifferent snippet syntax:</p>\n<div class=\"highlight\"><pre><code class=\"language-c\" data-lang=\"c\"><span></span><span class=\"k\">static</span> <span class=\"kt\">void</span> <span class=\"nf\">concatenate</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n<span class=\"cm\">/* Strings concatenate &lt; Garbage Collection concatenate-peek</span>\n<span class=\"cm\">  ObjString* b = AS_STRING(pop());</span>\n<span class=\"cm\">  ObjString* a = AS_STRING(pop());</span>\n<span class=\"cm\">*/</span>\n<span class=\"c1\">//&gt; Garbage Collection concatenate-peek</span>\n  <span class=\"n\">ObjString</span><span class=\"o\">*</span> <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">AS_STRING</span><span class=\"p\">(</span><span class=\"n\">peek</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">));</span>\n  <span class=\"n\">ObjString</span><span class=\"o\">*</span> <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">AS_STRING</span><span class=\"p\">(</span><span class=\"n\">peek</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">));</span>\n<span class=\"c1\">//&lt; Garbage Collection concatenate-peek</span>\n\n  <span class=\"kt\">int</span> <span class=\"n\">length</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"o\">-&gt;</span><span class=\"n\">length</span> <span class=\"o\">+</span> <span class=\"n\">b</span><span class=\"o\">-&gt;</span><span class=\"n\">length</span><span class=\"p\">;</span>\n  <span class=\"kt\">char</span><span class=\"o\">*</span> <span class=\"n\">chars</span> <span class=\"o\">=</span> <span class=\"n\">ALLOCATE</span><span class=\"p\">(</span><span class=\"kt\">char</span><span class=\"p\">,</span> <span class=\"n\">length</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">);</span>\n  <span class=\"n\">memcpy</span><span class=\"p\">(</span><span class=\"n\">chars</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"o\">-&gt;</span><span class=\"n\">chars</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"o\">-&gt;</span><span class=\"n\">length</span><span class=\"p\">);</span>\n  <span class=\"n\">memcpy</span><span class=\"p\">(</span><span class=\"n\">chars</span> <span class=\"o\">+</span> <span class=\"n\">a</span><span class=\"o\">-&gt;</span><span class=\"n\">length</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"o\">-&gt;</span><span class=\"n\">chars</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"o\">-&gt;</span><span class=\"n\">length</span><span class=\"p\">);</span>\n  <span class=\"n\">chars</span><span class=\"p\">[</span><span class=\"n\">length</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"sc\">&#39;\\0&#39;</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>This block comment contains a snippet of code. The header indicates that this\nsnippet is named &ldquo;concatenate&rdquo; and first appears in the &ldquo;Strings&rdquo; chapter. Then,\nlater, it gets removed when the &ldquo;concatenate-peek&rdquo; snippet in the &ldquo;Garbage\nCollection&rdquo; chapter appears. In other words, that latter snippet replaces the\nprevious two lines.</p>\n\n<p>By storing the code for this snippet inside a block comment, I ensure that the\ncode as it is in the raw source file is still valid. In some places where the\ninterpreter gets revised multiple times, the code can get pretty complex. Here\nis the <code>main()</code> function of the bytecode VM:</p>\n<div class=\"highlight\"><pre><code class=\"language-c\" data-lang=\"c\"><span></span><span class=\"kt\">int</span> <span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">argc</span><span class=\"p\">,</span> <span class=\"k\">const</span> <span class=\"kt\">char</span><span class=\"o\">*</span> <span class=\"n\">argv</span><span class=\"p\">[])</span> <span class=\"p\">{</span>\n<span class=\"c1\">//&gt; A Virtual Machine main-init-vm</span>\n  <span class=\"n\">initVM</span><span class=\"p\">();</span>\n\n<span class=\"c1\">//&lt; A Virtual Machine main-init-vm</span>\n<span class=\"cm\">/* Chunks of Bytecode main-chunk &lt; Scanning on Demand args</span>\n<span class=\"cm\">  Chunk chunk;</span>\n<span class=\"cm\">  initChunk(&amp;chunk);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-constant &lt; Scanning on Demand args</span>\n\n<span class=\"cm\">  int constant = addConstant(&amp;chunk, 1.2);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-constant &lt; Chunks of Bytecode main-chunk-line</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_CONSTANT);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, constant);</span>\n\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-chunk-line &lt; Scanning on Demand args</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_CONSTANT, 123);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, constant, 123);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* A Virtual Machine main-chunk &lt; Scanning on Demand args</span>\n\n<span class=\"cm\">  constant = addConstant(&amp;chunk, 3.4);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_CONSTANT, 123);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, constant, 123);</span>\n\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_ADD, 123);</span>\n\n<span class=\"cm\">  constant = addConstant(&amp;chunk, 5.6);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_CONSTANT, 123);</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, constant, 123);</span>\n\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_DIVIDE, 123);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* A Virtual Machine main-negate &lt; Scanning on Demand args</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_NEGATE, 123);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-chunk &lt; Chunks of Bytecode main-chunk-line</span>\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_RETURN);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-chunk-line &lt; Scanning on Demand args</span>\n\n<span class=\"cm\">  writeChunk(&amp;chunk, OP_RETURN, 123);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-disassemble-chunk &lt; Scanning on Demand args</span>\n\n<span class=\"cm\">  disassembleChunk(&amp;chunk, &quot;test chunk&quot;);</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* A Virtual Machine main-interpret &lt; Scanning on Demand args</span>\n<span class=\"cm\">  interpret(&amp;chunk);</span>\n<span class=\"cm\">*/</span>\n<span class=\"c1\">//&gt; Scanning on Demand args</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">argc</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">repl</span><span class=\"p\">();</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">argc</span> <span class=\"o\">==</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">runFile</span><span class=\"p\">(</span><span class=\"n\">argv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]);</span>\n  <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span> <span class=\"s\">&quot;Usage: clox [path]</span><span class=\"se\">\\n</span><span class=\"s\">&quot;</span><span class=\"p\">);</span>\n    <span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"n\">freeVM</span><span class=\"p\">();</span>\n<span class=\"c1\">//&lt; Scanning on Demand args</span>\n<span class=\"cm\">/* A Virtual Machine main-free-vm &lt; Scanning on Demand args</span>\n<span class=\"cm\">  freeVM();</span>\n<span class=\"cm\">*/</span>\n<span class=\"cm\">/* Chunks of Bytecode main-chunk &lt; Scanning on Demand args</span>\n<span class=\"cm\">  freeChunk(&amp;chunk);</span>\n<span class=\"cm\">*/</span>\n  <span class=\"k\">return</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Maintaining this is not super fun. But, thankfully, I have a build and test\nsystem to tell me when I break something.</p>\n\n<h2>Slicing Up the Interpreters</h2>\n\n<p>So I had a tool that could let me split the interpreters across the chapters.\nIf it was possible to break these interpreters into chapters at all, it would\nlet me do so. Now I just had to figure out where to carve the seams. This was\nthe most technically challenging part of the book writing process. I wasn&rsquo;t sure\nif it was going to work at all.</p>\n\n<p>I spent several weeks sketching out potential lists of chapters, sprinkling\nsnippet markers throughout the code, and seeing if the result built. I&rsquo;d get a\ncompile error because a snippet in an early chapter tried to call a function in\nsome later chapter and I would have to go back and reorganize things. I\nhand-drew dependency graphs between language features and tried to untangle\nthem.</p>\n\n<p>Here&rsquo;s an example of what this was like:</p>\n\n<ol>\n<li><p>To teach functions I want show that recursion works.</p></li>\n<li><p>But to have recursive functions I need control flow. Otherwise, every\nrecursive function recurses infinitely without a base case. So control flow\nhas to come before functions.</p></li>\n<li><p>For control flow, I need side effects so that I can show that a certain code\npath is <em>not</em> taken. The obvious way to do side effects is to have a\n<code>print()</code> function that displays output.</p></li>\n<li><p>But I don&rsquo;t have functions yet. That&rsquo;s a cycle. Crap.</p></li>\n</ol>\n\n<p>Sometimes I had to change the language itself to break cycles. The above example\nis why Lox has a built in print <em>statement</em> instead of a print <em>function</em>.\nBecause that way we can introduce the print statement before control flow, which\nis in turn before functions.</p>\n\n<p>I had to break a couple of cycles like that but, eventually, to my surprise, I\ngot it all sorted out. I had a complete list of chapters for both interpreters.\nEvery line of code was sorted into a snippet that belonged to one of those\nchapters. I could build and run each chapter&rsquo;s code. Best of all, each chapter\nhad a reasonably coherent concept and a roughly similar amount of code.</p>\n\n<p>Before, I felt like I had a language and code that wanted to get out there into\nthe world. Now I felt like I had a book.</p>\n\n<p>Or, at least, I had all of the <em>code</em> for a book.</p>\n\n<h2>A Chapter at a Time</h2>\n\n<p>I wrote my first book one chapter at a time. I drafted, edited, illustrated each\nchapter and put it online before moving to the next one. Serial publishing for\nthe digital age. I really loved that process. It helped build an audience for\nthe book and gave me incremental feedback which made the book better and kept me\ngoing. I don&rsquo;t think I could write a whole book in the dark.</p>\n\n<p>I intended to publish this book the same way, but the deeply interconnected\nnature of the chapters made that much harder. I didn&rsquo;t want to discover a\nproblem with the code in chapter 28 that forced me to tweak things in an earlier\nchapter that readers had already read. I didn&rsquo;t want to paint myself into a\ncorner or invalidate any previously-published material.</p>\n\n<p>The entire time I was designing the language, coding the interpreters, and\nsplitting the codebases into chapters, I had not done any actual writing. Just\nlots of hacking on code through the summer of 2016. It was, honestly, a blast.\nThe programming part is definitely the fun part, and it was a joy to tinker on\nthe code and figure out how to break it into chapters. Sort of like making a\njigsaw puzzle and solving it at the same time.</p>\n\n<p>After a few months, it was all there. Every single line of code for the entire\nbook. A complete list of chapters. And I hadn&rsquo;t written a single word of prose.\nIn theory, &ldquo;all&rdquo; that remained was writing some text to explain the code I had\nalready written along with some pictures. But, for me at least, English is a\nmuch more taxing language to write than C or Java. I had all of the difficult\nwork ahead of me, and all of the fun was done.</p>\n\n<h2>Illustrating by Hand</h2>\n\n<p>Well, not all of the fun. I did still have the illustrations to do. With my last\nbook, I hand-drew little sketchy diagrams to show various bits of architecture.\nI wanted even more illustrations for this book to make the concepts less\nabstract, less opaque. Unlike a videogame, you can&rsquo;t <em>see</em> a garbage collector\ndoing its thing. Visual metaphors really help.</p>\n\n<p>I liked the hand-drawn look. It furthered my meta-goal of making the material\nmore approachable, more human. But I wanted to up the quality. I wanted them to\nbe more intricate and contain more information. I wanted the drawings to be more\ndetailed. Less like margin doodles and more like, well, <em>illustrations</em>. Maybe\neven some lowercase letters.</p>\n\n<p>The ultimate goal for me is a print book, so I stuck with black and white ink. I\nwanted a tighter, more &ldquo;spidery&rdquo; style, so I got some technical pens. People\noften ask me what programs I used for the illustrations, assuming I did them all\ndigitally. Here are the main tools I used:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/tools.jpg\">\n  <figcaption>I went with Pigma Microns in 01 and 005. If I were doing it\n  again, I think I&rsquo;d do Faber-Castell Pitt pens.</figcaption>\n</figure>\n\n<p>There are two kinds of illustrations in the books: diagram-like ones that show\nmeaningful information, and drawings that are for metaphors or just to be silly\njokes. The process is different for each.</p>\n\n<p>I draw each diagram in pencil on graph paper. That lets me erase and move things\naround until I get it where I like:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/pencil.jpg\">\n  <figcaption>All of the vertical and horizontal lines in the illustrations\n  generally fall on the graph paper rules or halfway between them.</figcaption>\n</figure>\n\n<p>Then I tape a piece of tracing paper on top and draw over it in ink:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/ink.jpg\">\n  <figcaption>I make mistakes sometimes, usually when lettering like &ldquo;upvaluels&rdquo;\n  here. I fix that in Photoshop after scanning.</figcaption>\n</figure>\n\n<p>I hand letter everything. It takes a <em>long</em> time. I used to do graphic design,\nand I have this weird tic where any time I see something that looks handwritten,\nI look for multiple instances of the same letter to see if they are different or\nif the design just used a handwriting font. It&rsquo;s almost always a handwriting\nfont and I die a little inside to see the illusion evaporate.</p>\n\n<p>Well, this is <em>my</em> damned book and no reader will ever feel that disappointment.\nEvery single fucking letter in every one of the illustrations was hand lettered\nand is unique.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/title.jpg\">\n  <figcaption>Here is the hand-lettered logotype for the book. Each &ldquo;R&rdquo; is\n  different!</figcaption>\n</figure>\n\n<p>Also, if that&rsquo;s not obsessive enough, I spent time <em>changing my own handwriting</em>\nto better match the text font of the book. I taught myself to\nwrite double-story &ldquo;a&rdquo; and &ldquo;g&rdquo; letters and practiced by filling pages of paper\nwith the same letter over and over.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/lettering.jpg\">\n  <figcaption>Look at the loop under the &ldquo;g&rdquo; in &ldquo;filling&rdquo; and the finial on the\n  &ldquo;a&rdquo; in &ldquo;apples&rdquo;.</figcaption>\n</figure>\n\n<p>I also wanted to make sure that the illustrations and text matched each other\nacross the book. To give the text a consistent size, I printed a little height\nguide:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/metrics.jpg\">\n  <figcaption>The dotted line indicates the x-height. I picked a ratio for that\n  to match the fonts I use for text and code.</figcaption>\n</figure>\n\n<p>I slid this paper under the tracing paper and lettered on top of those lines to\nkeep the metrics the same across the book.</p>\n\n<p>To keep the diagram size and line thickness consistent, each illustration has a\npair of registration marks a fixed distance apart:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/registration.jpg\">\n  <figcaption>The little marks that the pencils are pointing at.</figcaption>\n</figure>\n\n<p>I scan each illustration into Photoshop for clean up and processing. I use those\nmarks when cropping to ensure that the image maintains the right size relative\nto other images.</p>\n\n<p>I recorded a video of the whole process if you want to see it in action:</p>\n\n<figure>\n  <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iN1MsCXkPSA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n  <figcaption>Even in timelapse, it takes a long time.</figcaption>\n</figure>\n\n<p>Writing this all out makes me sound like a crazy person. What the hell am I\ndoing with my life? Or, more importantly, what <em>could I have been doing</em> instead\nof doing all that?</p>\n\n<p>Too late now, I guess. The picture-like drawings have a different workflow since\nthey don&rsquo;t have a lot of straight lines or align to a grid.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/drawing.jpg\">\n  <figcaption>How will readers understand what a stack is without this helpful\n  illustration?</figcaption>\n</figure>\n\n<p>I draw those on regular sketch paper using a non-photo blue pencil. Then I ink\non top of that. I scan the paper in RGB and use the blue channel, which mostly\nmakes the blue pencil marks disappear.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/blue.jpg\">\n  <figcaption>The sketch paper bleeds the ink more than I like but I didn&rsquo;t\n  want to change paper partway through the book, so I stuck with it.</figcaption>\n</figure>\n\n<p>It&rsquo;s a lot of work for each image, and this doesn&rsquo;t include all of the work\nafter scanning it. And I wanted a lot of them. By the end, I had this stack of\npaper:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2020/04/stack.jpg\">\n  <figcaption>Such a small image for so much work.</figcaption>\n</figure>\n\n<p>I went through two full pads of tracing paper, two pads of graph paper, a\nsketch pad, and several pens. I drew 181 illustrations.</p>\n\n<h2>Writing is Suffering</h2>\n\n<p>I had the code, and I had a process for illustrations. The remaining work was\njust writing all the words and drawing all the pictures. So that&rsquo;s what I did. I\nstarted at chapter one and started writing. For each chapter, I wrote an outline\nand then a first draft. I did an editing pass over that to fix all the major\nproblems. Then a second pass where I read the whole chapter out loud to fix\ncadence and other stuff.</p>\n\n<p>This is the same process I used for the first book. I stumbled onto something\nthat worked, so I wasn&rsquo;t about to mess it up. I posted each chapter online, and\nthen spent a day fixing bugs that readers noticed. Then I moved on to the next\nchapter.</p>\n\n<p>I wrote. And wrote. And wrote. Every single day. Every now and then I would have\na trip or something where I couldn&rsquo;t write. As with my first book, I would bank\ndays by writing multiple sessions per day beforehand and then spend those banked\ndays on days that I didn&rsquo;t write. But for the most part, I wrote every day.</p>\n\n<p>In the blog post I wrote after my first book, I whined about how I had to write\non days when I traveled for work, on holidays, when the kids had sniffles. At\nthe time, it truly was one of the hardest things I&rsquo;ve ever done.</p>\n\n<p>This time was something else entirely. I wrote the day my grandfather died\n(peacefully, unsurprisingly) and the day my aunt died (tragically, days after\nretiring). I wrote the day I found out my Mom had cancer and my children saw me\ncry for the first time. I was flying to Louisiana to keep my Mom company when I\nturned on my phone during the layover and discovered a dear friend had had a\nstroke. I wrote that evening. I woke up the next day and found out she had died.\nI wrote that morning sitting next to my brother in the waiting room of the\nhospital while my Mom got her PET scan.</p>\n\n<p>The morning of my friend&rsquo;s memorial service, I wrote in the hotel. Later that\nday, I openly sobbed in front of a room full of people. The next day, my wife\nfound out her aunt had terminal cancer. I wrote on the flight home.</p>\n\n<p>See that dog up there in my profile photo? That&rsquo;s Ginny. She&rsquo;s on the back cover\nof my first book. Her myriad health problems finally <a href=\"https://twitter.com/munificentbob/status/1100898048811491328\">caught up with her</a>\nlast spring. People sometimes ask, &ldquo;When did you know you were an adult?&rdquo; For me\nit was the day I made the call to put my dog down. The hardest part was watching\nmy kids say goodbye to her. I&rsquo;m tearing up now writing about it. I ran my\nfingers through Ginny&rsquo;s silky fur as the sedatives took her away. I only got\nthrough 59 words that afternoon.</p>\n\n<p>I wrote the day the US somehow elected a racist, abusive, corrupt demagogue, and\nevery day afterwards as I saw my country and others turn towards hate and\nauthoritarianism. I wrote while climate change and income inequality worsened.\nAnd now here I am writing at home on the same desk where I work now, quarantined\nlike most of you all, hoping to survive the worst pandemic the world has seen in\na century.</p>\n\n<p>This is not about how disciplined I was. Because during what have been some of\nthe worst years of my life, a weird inversion happened. It&rsquo;s not that I was\ngoing through that shit and still writing <em>in addition to</em> it. I <em>had</em> to keep\nwriting. Writing was one thing I could still control in the face of many things\nI could not. If I could make it through the book, maybe I could make it through\nthe other things too. If I had skipped a day it would have meant that the cancer\nor the deaths beat me that day, that they were stronger than me. I feared what\nit would mean to me to let go.</p>\n\n<p>I got through these four years and kept writing, but I paid a price. When I read\nthe earlier chapters, they have a whimsy and light-heartedness that later\nchapters lack. We&rsquo;re all going through dark times, and I don&rsquo;t <em>feel</em> light. The\npast few years left a mark on me, and that mark shows up in the book. I miss the\ngoofier person I used to be, sometimes. But I&rsquo;d like to believe that maybe the\nperson I am now is a little more honest. Maybe some of those jokes were a mask.</p>\n\n<p>And, thankfully, Mom is in remission.</p>\n\n<p>Psychological self examination aside, I did keep up the writing. Which is good\nbecause, <em>man</em> did I underestimate this book. I was aiming for 60,000 words and\nhoped to get it done in about a year. Here I am four years later sitting on a\nquarter of a million words.</p>\n\n<p>People sometimes ask what it&rsquo;s like writing something that big. I&rsquo;ve been asking\nmyself that for the past couple of weeks. And the weird thing is, <em>I don&rsquo;t\nknow.</em> I&rsquo;ve had my head down for the past four years and haven&rsquo;t looked past the\nnext paragraph or two the entire time. What does it feel like to write an email\nor draw a picture? Writing the book felt like that. I just happened to do it\nover and over again. I feel like a marathon runner who&rsquo;s been watching his feet\nthe whole time and didn&rsquo;t even notice when he stumbled over the finish line.</p>\n\n<h2>And Now What?</h2>\n\n<p>&ldquo;Crafting Interpreters&rdquo; is complete now. I had to stop here for a minute and\nlook at that sentence. I&rsquo;ve been working on this book every day for around\n1,400 days. I can&rsquo;t <em>wait</em> to take a break. So that&rsquo;s the next step. My plan\nwas to finish the book right before spring break and enjoy a week on the beach\nwith family.</p>\n\n<p>That beach trip went the way of so many other plans in early 2020, but I still\nintend to take a long break. I don&rsquo;t know if you noticed, but we all have a lot\nof other shit to deal with right now. I&rsquo;m going to relax.</p>\n\n<p>Every morning since 2016, I&rsquo;ve woken up with a task I had to do. Until I got my\nwriting done for the day, it was on my mind, weighing me down. Writing left me\ndrained. If you&rsquo;ve ever had a newborn, you know the feeling of always having to\ncarry the baby around. After a while, it&rsquo;s like you forget what it&rsquo;s like to\nhave <em>two</em> free arms. I&rsquo;ve been carrying this baby for four years, so I&rsquo;m\nlooking forward to having both arms for a while.</p>\n\n<p>Once I&rsquo;m recharged, the real fun starts. Having the book online is important,\nbut for me, &ldquo;Crafting Interpreters&rdquo; was always meant to be a <em>book</em> with pages\nand a cover. So after a long bout of editing and bug fixing, I&rsquo;m going to get\nstarted doing the page layout for the print edition. I love graphic design, and\nI can&rsquo;t wait to hold it in my hands.</p>\n\n<p>If you&rsquo;d like to hold it in <em>your</em> hands when it comes out, I have <a href=\"https://mailchi.mp/afd054e73140/robertnystrom\">a mailing\nlist</a> where I&rsquo;ll let you know when the book is done. In the meantime, I\nthink I&rsquo;ve earned some rest.</p>\n","contentSnippet":"It took three years and 200,000 words more than I expected, but my second\nbook, Crafting Interpreters, is complete. I finished the third draft of\nthe last chapter today, marking the last of around 1,400 days of continuous\nwriting.\nThis book was much harder than my first book, along every axis. It’s\nlarger, more technically complex, much more deeply intertwined, and it had the\nmisfortune of aligning with a really difficult period in my life. Today feels\nless like coasting past the finish line at the Tour de France, arms raised in\ntriumph, and more like dragging myself onto the beach, clutching sand in relief\nafter a storm-thrashed ordeal at sea.\nBefore I get into all that, I have a minor confession to make. When I finished\nmy first book, I wrote a long post about how I cobbled together enough\nwillpower to reach the end of the last page. Everything in there is true, but\nthere is one fact I superstitiously omitted.\nHalfway through writing Game Programming Patterns, I discovered a new passion:\nprogramming languages. It had been a long time since a topic ignited my brain to\nthe same degree, and I was on fire. I spent basically every free hour (and\nmany not-so-free hours – sorry, family) designing and hacking on programming\nlanguages. I read every book I could get my hands on, went to\nconferences, blogged, I even dreamed about programming languages.\nThis infatuation was the main reason I stopped working on my first book for two\nyears.\nI have a personality quirk where when I’m excited about something I just have\nto teach it to other people. Hermione Granger, arm waving feverishly to get the\nteacher’s attention, is my spirit animal. It was inevitable that I would write\nsomething about interpreters. But I couldn’t just drop one half-finished book to\nstart another. I have gigs of unfinished projects laying around, but – maybe\nbecause the completed chapters were already online – I couldn’t bear to\nabandon Game Programming Patterns.\nSo I made a promise to myself. If I finished that book, then I would let myself\nwrite a second book on interpreters. In part because of that promise, I did\nmanage to complete the chapters, and then the print and eBook editions.\nWhat I thought was merely a hobby and personal goal turned out to be a\nlife-changing experience. My little self-published vanity project has\nhundreds of five-star reviews, and has been translated to Korean,\nJapanese, Chinese, German, and Polish. The book did so much better than I\nexpected that I’m still not sure how to process it, beyond feeling immense\ngratitude to everyone who read it, bought a copy, or cheered me on.\nThe Seed of a Book\nOnce I finished the print edition of “Game Programming Patterns”, I took some\ntime off. But it didn’t take too long for that itch to write about interpreters\nto come back. I knew exactly what I was getting into with writing a book now,\nhow hard the grind can be. At first, I just noodled around. I wasn’t committed\nto doing anything. It was more just a sort of recreational intellectual\nexercise. If I were to do a book, what would it look like? You know,\nhypothetically speaking.\nThe very first note I wrote to myself said:\nhigh-level goal: a *small* book that builds a complete, efficient\ninterpreter. instead of a wide text about programming language*s*,\nit is a single path through the language space. aim for 60k words.\n\n\nMy first book was almost 90,000 words, and I didn’t want to hike a trail that\nlong again. I also had a meta-goal to make programming languages more\napproachable, and I figured a short text would help. I had this vision of\nsomething you could literally hold in your hand or have open next to your laptop\nwhile you followed along.\nTo make a small book, I needed a small language and a small implementation. One\nof my other side projects was a scripting language named Wren. Wren is\nwritten in C, with a simple single-pass bytecode compiler inspired by Lua.\nBuilding Wren taught me how much functionality you can pack into a few thousand\nlines of clean C code.\nFor this hypothetical book, I figured a bytecode VM in C like that would be a\ngreat fit. It would also give me the chance to cover a bunch of really fun\ntopics like stack-based VMs, object representation, and garbage collection. But\nWren wasn’t the right language. I like Wren (obviously), but it has some design\nquirks that I think make it a better language for users but maybe not for\nteaching. For the book, I wanted a dynamically-typed scripting language in the\nvein of languages like JavaScript, Python, and Lua.\nI started tinkering on a new toy language, tentatively named “Vox”. The goal was\nto keep things as simple as possible without taking any shortcuts around the\nhard problems in implementing a language. I wanted a rich expression and\nstatement syntax to cover parsing. First-class functions and closures because\nthey are powerful and challenging to implement efficiently. Classes and methods\nbecause that paradigm is so prevalent but omitted by many compiler books.\nAt some point, I realized that dropping readers straight into C was too\nunfriendly of an introduction. It’s hard to teach high-level concepts like\nparsing and name resolution while also tracking pointers and managing memory.\nOK, so we’ll build two interpreters. First a simple one in a high-level\nlanguage, focused on concepts. Then a second bytecode VM in C to focus on\nperformance and low-level implementation techniques.\nSomehow, I didn’t notice that maybe this “handbook” wasn’t going to be as\npocket-sized as I hoped.\nMy first choice for the high-level implementation language was JavaScript. I\nimplemented most of a Vox interpreter in JS, but never really liked it. I wanted\nto write the interpreter in an object-oriented style because there are\ntechniques like the visitor pattern for doing language stuff in OOP that aren’t\ncovered well elsewhere. Doing OOP in JS means deciding whether to use classes or\na prototypal style. The former is cleaner but infuriates some segment of\nreaders. The latter is verbose and confusing to those not already steeped in\nprototypes.\nAlso, I missed static types. People reading code in a book don’t get the luxury\nof seeing the code in a debugger where they can see what values are in various\nvariables. Static type annotations in the code help.\nSo I switched to Java. I don’t love Java but it seemed like the least biased\nchoice for a statically typed object-oriented language. I found you can tame a\nlot of its infamous verbosity by simply not programming in 1990s enterprise Java\nstyle. Maybe it’s not idiomatic to have public fields, but it’s a hell of a lot\nshorter.\nIn parallel, I started building the bytecode VM in C, porting over bits of\nWren’s implementation and stripping out the Wren-specific stuff. I spent the\nspring and summer of 2016 circling between these three pieces – the design of\nVox itself, the Java interpreter, and the C bytecode VM. This was a delightful,\nsatisfying period of time. The three parts played off each other in challenging\nways. Sometimes I would change the language to make one interpreter simpler, but\nfind doing so made the other interpreter more complex. Other times I’d hit on\nsome trick that made everything get smaller and cleaner.\nGetting Back on the Horse\nI remember the exact moment I committed to writing the book. I was stuck on a\ntricky language design problem: constructor syntax. I knew I wanted classes,\nwhich meant some way to construct instances. Adding a new keyword felt too\nspecial-purpose for my minimal language. I like Smalltalk and Ruby’s approach of\nmaking new be a method on the class object itself, but that requires\nmetaclasses and a lot of other machinery.\nI was struggling to find a way to add instantiation without making the language\nmuch bigger. Then I remembered JavaScript’s thing where you can simply invoke a\n“class” as if it were a function to create new instances. That has all sorts of\nweird baggage in JavaScript because everything does in JS, but the concept and\nsyntax were perfect. I already had first-class classes. And I already had\nclosures which meant a function call syntax that could be applied to arbitrary\nexpressions. So “constructors” just became what you got when you invoked a\nclass.\nI felt like Vox had gelled, like it was a language now. And my two\nimplementations were coming along well too. I was surprised by how few hacks or\nugly corners I ran into. The codebases kind of fell together and the more I\ntweaked them, the nicer they got. It felt more like I had discovered them than\nthat I had created them. It would be a shame to not write the book and put\nthem out there into the world. They wanted me to.\nI committed to writing the book, and I restarted my rule of writing every single\nday.\nI had a few thousand lines of pretty Java and C code, but how do I turn that\ninto a book that can be read in linear order? Compact codebases tend to be\nhighly intertwined with many cyclic dependencies. I didn’t want readers to have\nto slog through ten chapters before they could even run main().\nThis was the real technical challenge of writing the book – how do I take two\nimplementations of the same language, and break them into incremental pieces\nthat I can build up a chapter at a time?\nI made this problem harder for myself because of the meta-goal I had. One reason\nI didn’t get into languages until later in my career was because I was\nintimidated by the reputation compilers have as being only for hardcore computer\nscience wizard types. I’m a college dropout, so I felt I wasn’t smart enough, or\nat least wasn’t educated enough to hack it. Eventually I discovered that those\nbarriers existed only in my mind and that anyone can learn this.\nMy main overarching goal of the book is to pass on that feeling, to get readers\nto understand there’s no magic in there and nothing keeping them out. To nail\nthat conceit, I wanted to include every single line of code used by the\ninterpreters in the book. No parser generators, nothing left as an exercise for\nthe reader. If you type in all of the code in the book, you get two complete,\nworking interpreters. No tricks.\nSo not only did I need to break these two interpreters into chapters, I needed\nto do it without any cheating. I wanted a hard guarantee that at the end of each\nchapter, you had a program that you could type in, compile, run, and do\nsomething with. I knew I wouldn’t be able to verify this manually, so it was\ntime to create some tools.\nA Bespoke Build System\nI wrote my first book in Markdown. I slapped together a tiny Python\nscript that converts the Markdown to HTML and transcludes the code\nsnippets which are stored in separate C++ files. When I started my second book,\nI took that script and started growing it. It evolved throughout writing the\nbook, but in the end, here is how it works.\nAll of the code for the interpreters are stored in separate source files. I have\na Java project that contains the complete Java interpreter that you get\nby the end of that part of the book. Likewise, there’s a C project for the\nbytecode VM. I can edit and build those in an IDE, run tests, debug them, etc.\nThey’re real programs.\nMeanwhile, the text of the book is authored in Markdown, one file per\nchapter, just like my first book. To include a snippet of code in the book, I\nput a tag in the Markdown like this:\nWhich can be any of:\n\n^code is-alpha\n\nOnce we've found an identifier, we scan the rest of it using:\n\n\nHere, the ^code line says “look up the snippet named ‘is-alpha’ and insert it\nhere.” When the build script generates the HTML for this chapter, it goes off\nand hunts through the code for that snippet. Over in the code, special comments\ndelimit snippets. The one included here looks like this:\n//> Scanning on Demand is-alpha\nstatic bool isAlpha(char c) {\n  return (c >= 'a' && c <= 'z') ||\n         (c >= 'A' && c <= 'Z') ||\n          c == '_';\n}\n//< Scanning on Demand is-alpha\n\n\nThe //> line begins the snippet and says what chapter the snippet appears in and the name of the snippet. The //< line ends the snippet. Pretty straightforward.\nThis let me build the book, but didn’t ensure that the thing I built actually\nworked. So I wrote a separate script that instead of building the book, builds\nprograms. For each chapter, it collects all of the snippets that appear in\nthat chapter and the previous ones and writes them out to separate source files.\nIn other words, it produces a separate interpreter, one for each chapter,\ncontaining only the code that readers have seen so far.\nI put together a Makefile to build those per-chapter versions of each\ninterpreter to make sure they compiled. Of course, compiling successfully\ndoesn’t mean they do anything useful. Writing a single correct interpreter is\nhard. Writing thirty of them – there are thirty chapters in the\nbook – is much harder.\nI had already harvested a little test runner from Wren and ported most of\nWren’s tests over to be Lox tests. (I changed the name of the language in\nthe book since there was already a language out there named “Vox.”). I took that\ntest runner and extended it to be able to run the tests on each chapter’s\nversion of the interpreters. Of course, the tests don’t all pass – the\ninterpreters aren’t complete! So I added metadata to track which tests I\nexpected to pass by which point in the book. With this in place, I could\nautomatically verify that the code I was showing readers did exactly what I\nexpected.\nMore Complex Snippets\nThe snippet markers look pretty straightforward, and in many cases they are. But\nreality tends to get messier and I didn’t allow myself to sweep any of that mess\nunder nearby rugs. Some changes don’t just add code to the interpreter. I try\nto minimize it, but often you need to replace some existing code. A few lines\nof code may appear in chapter 5 and then later get superseded in chapter 9 by\nsomething more powerful.\nObviously, I can’t jam both of those snippets into the same source file and\nexpect it to compile. Remember, the source files that I hand author are\nthemselves valid Java and C programs that I can build and run. If a function\ncontained several versions of its body mixed together, odds are slim that the\ncompiler will like what it sees.\nSo, for any piece of code that later gets replaced – in other words code that\nis not part of the very final version of each interpreter – there is a\ndifferent snippet syntax:\nstatic void concatenate() {\n/* Strings concatenate < Garbage Collection concatenate-peek\n  ObjString* b = AS_STRING(pop());\n  ObjString* a = AS_STRING(pop());\n*/\n//> Garbage Collection concatenate-peek\n  ObjString* b = AS_STRING(peek(0));\n  ObjString* a = AS_STRING(peek(1));\n//< Garbage Collection concatenate-peek\n\n  int length = a->length + b->length;\n  char* chars = ALLOCATE(char, length + 1);\n  memcpy(chars, a->chars, a->length);\n  memcpy(chars + a->length, b->chars, b->length);\n  chars[length] = '\\0';\n}\n\n\nThis block comment contains a snippet of code. The header indicates that this\nsnippet is named “concatenate” and first appears in the “Strings” chapter. Then,\nlater, it gets removed when the “concatenate-peek” snippet in the “Garbage\nCollection” chapter appears. In other words, that latter snippet replaces the\nprevious two lines.\nBy storing the code for this snippet inside a block comment, I ensure that the\ncode as it is in the raw source file is still valid. In some places where the\ninterpreter gets revised multiple times, the code can get pretty complex. Here\nis the main() function of the bytecode VM:\nint main(int argc, const char* argv[]) {\n//> A Virtual Machine main-init-vm\n  initVM();\n\n//< A Virtual Machine main-init-vm\n/* Chunks of Bytecode main-chunk < Scanning on Demand args\n  Chunk chunk;\n  initChunk(&chunk);\n*/\n/* Chunks of Bytecode main-constant < Scanning on Demand args\n\n  int constant = addConstant(&chunk, 1.2);\n*/\n/* Chunks of Bytecode main-constant < Chunks of Bytecode main-chunk-line\n  writeChunk(&chunk, OP_CONSTANT);\n  writeChunk(&chunk, constant);\n\n*/\n/* Chunks of Bytecode main-chunk-line < Scanning on Demand args\n  writeChunk(&chunk, OP_CONSTANT, 123);\n  writeChunk(&chunk, constant, 123);\n*/\n/* A Virtual Machine main-chunk < Scanning on Demand args\n\n  constant = addConstant(&chunk, 3.4);\n  writeChunk(&chunk, OP_CONSTANT, 123);\n  writeChunk(&chunk, constant, 123);\n\n  writeChunk(&chunk, OP_ADD, 123);\n\n  constant = addConstant(&chunk, 5.6);\n  writeChunk(&chunk, OP_CONSTANT, 123);\n  writeChunk(&chunk, constant, 123);\n\n  writeChunk(&chunk, OP_DIVIDE, 123);\n*/\n/* A Virtual Machine main-negate < Scanning on Demand args\n  writeChunk(&chunk, OP_NEGATE, 123);\n*/\n/* Chunks of Bytecode main-chunk < Chunks of Bytecode main-chunk-line\n  writeChunk(&chunk, OP_RETURN);\n*/\n/* Chunks of Bytecode main-chunk-line < Scanning on Demand args\n\n  writeChunk(&chunk, OP_RETURN, 123);\n*/\n/* Chunks of Bytecode main-disassemble-chunk < Scanning on Demand args\n\n  disassembleChunk(&chunk, \"test chunk\");\n*/\n/* A Virtual Machine main-interpret < Scanning on Demand args\n  interpret(&chunk);\n*/\n//> Scanning on Demand args\n  if (argc == 1) {\n    repl();\n  } else if (argc == 2) {\n    runFile(argv[1]);\n  } else {\n    fprintf(stderr, \"Usage: clox [path]\\n\");\n    exit(64);\n  }\n\n  freeVM();\n//< Scanning on Demand args\n/* A Virtual Machine main-free-vm < Scanning on Demand args\n  freeVM();\n*/\n/* Chunks of Bytecode main-chunk < Scanning on Demand args\n  freeChunk(&chunk);\n*/\n  return 0;\n}\n\n\nMaintaining this is not super fun. But, thankfully, I have a build and test\nsystem to tell me when I break something.\nSlicing Up the Interpreters\nSo I had a tool that could let me split the interpreters across the chapters.\nIf it was possible to break these interpreters into chapters at all, it would\nlet me do so. Now I just had to figure out where to carve the seams. This was\nthe most technically challenging part of the book writing process. I wasn’t sure\nif it was going to work at all.\nI spent several weeks sketching out potential lists of chapters, sprinkling\nsnippet markers throughout the code, and seeing if the result built. I’d get a\ncompile error because a snippet in an early chapter tried to call a function in\nsome later chapter and I would have to go back and reorganize things. I\nhand-drew dependency graphs between language features and tried to untangle\nthem.\nHere’s an example of what this was like:\nTo teach functions I want show that recursion works.\n\n\nBut to have recursive functions I need control flow. Otherwise, every\nrecursive function recurses infinitely without a base case. So control flow\nhas to come before functions.\n\n\nFor control flow, I need side effects so that I can show that a certain code\npath is not taken. The obvious way to do side effects is to have a\nprint() function that displays output.\n\n\nBut I don’t have functions yet. That’s a cycle. Crap.\n\n\n\nSometimes I had to change the language itself to break cycles. The above example\nis why Lox has a built in print statement instead of a print function.\nBecause that way we can introduce the print statement before control flow, which\nis in turn before functions.\nI had to break a couple of cycles like that but, eventually, to my surprise, I\ngot it all sorted out. I had a complete list of chapters for both interpreters.\nEvery line of code was sorted into a snippet that belonged to one of those\nchapters. I could build and run each chapter’s code. Best of all, each chapter\nhad a reasonably coherent concept and a roughly similar amount of code.\nBefore, I felt like I had a language and code that wanted to get out there into\nthe world. Now I felt like I had a book.\nOr, at least, I had all of the code for a book.\nA Chapter at a Time\nI wrote my first book one chapter at a time. I drafted, edited, illustrated each\nchapter and put it online before moving to the next one. Serial publishing for\nthe digital age. I really loved that process. It helped build an audience for\nthe book and gave me incremental feedback which made the book better and kept me\ngoing. I don’t think I could write a whole book in the dark.\nI intended to publish this book the same way, but the deeply interconnected\nnature of the chapters made that much harder. I didn’t want to discover a\nproblem with the code in chapter 28 that forced me to tweak things in an earlier\nchapter that readers had already read. I didn’t want to paint myself into a\ncorner or invalidate any previously-published material.\nThe entire time I was designing the language, coding the interpreters, and\nsplitting the codebases into chapters, I had not done any actual writing. Just\nlots of hacking on code through the summer of 2016. It was, honestly, a blast.\nThe programming part is definitely the fun part, and it was a joy to tinker on\nthe code and figure out how to break it into chapters. Sort of like making a\njigsaw puzzle and solving it at the same time.\nAfter a few months, it was all there. Every single line of code for the entire\nbook. A complete list of chapters. And I hadn’t written a single word of prose.\nIn theory, “all” that remained was writing some text to explain the code I had\nalready written along with some pictures. But, for me at least, English is a\nmuch more taxing language to write than C or Java. I had all of the difficult\nwork ahead of me, and all of the fun was done.\nIllustrating by Hand\nWell, not all of the fun. I did still have the illustrations to do. With my last\nbook, I hand-drew little sketchy diagrams to show various bits of architecture.\nI wanted even more illustrations for this book to make the concepts less\nabstract, less opaque. Unlike a videogame, you can’t see a garbage collector\ndoing its thing. Visual metaphors really help.\nI liked the hand-drawn look. It furthered my meta-goal of making the material\nmore approachable, more human. But I wanted to up the quality. I wanted them to\nbe more intricate and contain more information. I wanted the drawings to be more\ndetailed. Less like margin doodles and more like, well, illustrations. Maybe\neven some lowercase letters.\nThe ultimate goal for me is a print book, so I stuck with black and white ink. I\nwanted a tighter, more “spidery” style, so I got some technical pens. People\noften ask me what programs I used for the illustrations, assuming I did them all\ndigitally. Here are the main tools I used:\nI went with Pigma Microns in 01 and 005. If I were doing it\n  again, I think I’d do Faber-Castell Pitt pens.\n\n\nThere are two kinds of illustrations in the books: diagram-like ones that show\nmeaningful information, and drawings that are for metaphors or just to be silly\njokes. The process is different for each.\nI draw each diagram in pencil on graph paper. That lets me erase and move things\naround until I get it where I like:\nAll of the vertical and horizontal lines in the illustrations\n  generally fall on the graph paper rules or halfway between them.\n\n\nThen I tape a piece of tracing paper on top and draw over it in ink:\nI make mistakes sometimes, usually when lettering like “upvaluels”\n  here. I fix that in Photoshop after scanning.\n\n\nI hand letter everything. It takes a long time. I used to do graphic design,\nand I have this weird tic where any time I see something that looks handwritten,\nI look for multiple instances of the same letter to see if they are different or\nif the design just used a handwriting font. It’s almost always a handwriting\nfont and I die a little inside to see the illusion evaporate.\nWell, this is my damned book and no reader will ever feel that disappointment.\nEvery single fucking letter in every one of the illustrations was hand lettered\nand is unique.\nHere is the hand-lettered logotype for the book. Each “R” is\n  different!\n\n\nAlso, if that’s not obsessive enough, I spent time changing my own handwriting\nto better match the text font of the book. I taught myself to\nwrite double-story “a” and “g” letters and practiced by filling pages of paper\nwith the same letter over and over.\nLook at the loop under the “g” in “filling” and the finial on the\n  “a” in “apples”.\n\n\nI also wanted to make sure that the illustrations and text matched each other\nacross the book. To give the text a consistent size, I printed a little height\nguide:\nThe dotted line indicates the x-height. I picked a ratio for that\n  to match the fonts I use for text and code.\n\n\nI slid this paper under the tracing paper and lettered on top of those lines to\nkeep the metrics the same across the book.\nTo keep the diagram size and line thickness consistent, each illustration has a\npair of registration marks a fixed distance apart:\nThe little marks that the pencils are pointing at.\n\n\nI scan each illustration into Photoshop for clean up and processing. I use those\nmarks when cropping to ensure that the image maintains the right size relative\nto other images.\nI recorded a video of the whole process if you want to see it in action:\n\n  Even in timelapse, it takes a long time.\n\n\nWriting this all out makes me sound like a crazy person. What the hell am I\ndoing with my life? Or, more importantly, what could I have been doing instead\nof doing all that?\nToo late now, I guess. The picture-like drawings have a different workflow since\nthey don’t have a lot of straight lines or align to a grid.\nHow will readers understand what a stack is without this helpful\n  illustration?\n\n\nI draw those on regular sketch paper using a non-photo blue pencil. Then I ink\non top of that. I scan the paper in RGB and use the blue channel, which mostly\nmakes the blue pencil marks disappear.\nThe sketch paper bleeds the ink more than I like but I didn’t\n  want to change paper partway through the book, so I stuck with it.\n\n\nIt’s a lot of work for each image, and this doesn’t include all of the work\nafter scanning it. And I wanted a lot of them. By the end, I had this stack of\npaper:\nSuch a small image for so much work.\n\n\nI went through two full pads of tracing paper, two pads of graph paper, a\nsketch pad, and several pens. I drew 181 illustrations.\nWriting is Suffering\nI had the code, and I had a process for illustrations. The remaining work was\njust writing all the words and drawing all the pictures. So that’s what I did. I\nstarted at chapter one and started writing. For each chapter, I wrote an outline\nand then a first draft. I did an editing pass over that to fix all the major\nproblems. Then a second pass where I read the whole chapter out loud to fix\ncadence and other stuff.\nThis is the same process I used for the first book. I stumbled onto something\nthat worked, so I wasn’t about to mess it up. I posted each chapter online, and\nthen spent a day fixing bugs that readers noticed. Then I moved on to the next\nchapter.\nI wrote. And wrote. And wrote. Every single day. Every now and then I would have\na trip or something where I couldn’t write. As with my first book, I would bank\ndays by writing multiple sessions per day beforehand and then spend those banked\ndays on days that I didn’t write. But for the most part, I wrote every day.\nIn the blog post I wrote after my first book, I whined about how I had to write\non days when I traveled for work, on holidays, when the kids had sniffles. At\nthe time, it truly was one of the hardest things I’ve ever done.\nThis time was something else entirely. I wrote the day my grandfather died\n(peacefully, unsurprisingly) and the day my aunt died (tragically, days after\nretiring). I wrote the day I found out my Mom had cancer and my children saw me\ncry for the first time. I was flying to Louisiana to keep my Mom company when I\nturned on my phone during the layover and discovered a dear friend had had a\nstroke. I wrote that evening. I woke up the next day and found out she had died.\nI wrote that morning sitting next to my brother in the waiting room of the\nhospital while my Mom got her PET scan.\nThe morning of my friend’s memorial service, I wrote in the hotel. Later that\nday, I openly sobbed in front of a room full of people. The next day, my wife\nfound out her aunt had terminal cancer. I wrote on the flight home.\nSee that dog up there in my profile photo? That’s Ginny. She’s on the back cover\nof my first book. Her myriad health problems finally caught up with her\nlast spring. People sometimes ask, “When did you know you were an adult?” For me\nit was the day I made the call to put my dog down. The hardest part was watching\nmy kids say goodbye to her. I’m tearing up now writing about it. I ran my\nfingers through Ginny’s silky fur as the sedatives took her away. I only got\nthrough 59 words that afternoon.\nI wrote the day the US somehow elected a racist, abusive, corrupt demagogue, and\nevery day afterwards as I saw my country and others turn towards hate and\nauthoritarianism. I wrote while climate change and income inequality worsened.\nAnd now here I am writing at home on the same desk where I work now, quarantined\nlike most of you all, hoping to survive the worst pandemic the world has seen in\na century.\nThis is not about how disciplined I was. Because during what have been some of\nthe worst years of my life, a weird inversion happened. It’s not that I was\ngoing through that shit and still writing in addition to it. I had to keep\nwriting. Writing was one thing I could still control in the face of many things\nI could not. If I could make it through the book, maybe I could make it through\nthe other things too. If I had skipped a day it would have meant that the cancer\nor the deaths beat me that day, that they were stronger than me. I feared what\nit would mean to me to let go.\nI got through these four years and kept writing, but I paid a price. When I read\nthe earlier chapters, they have a whimsy and light-heartedness that later\nchapters lack. We’re all going through dark times, and I don’t feel light. The\npast few years left a mark on me, and that mark shows up in the book. I miss the\ngoofier person I used to be, sometimes. But I’d like to believe that maybe the\nperson I am now is a little more honest. Maybe some of those jokes were a mask.\nAnd, thankfully, Mom is in remission.\nPsychological self examination aside, I did keep up the writing. Which is good\nbecause, man did I underestimate this book. I was aiming for 60,000 words and\nhoped to get it done in about a year. Here I am four years later sitting on a\nquarter of a million words.\nPeople sometimes ask what it’s like writing something that big. I’ve been asking\nmyself that for the past couple of weeks. And the weird thing is, I don’t\nknow. I’ve had my head down for the past four years and haven’t looked past the\nnext paragraph or two the entire time. What does it feel like to write an email\nor draw a picture? Writing the book felt like that. I just happened to do it\nover and over again. I feel like a marathon runner who’s been watching his feet\nthe whole time and didn’t even notice when he stumbled over the finish line.\nAnd Now What?\n“Crafting Interpreters” is complete now. I had to stop here for a minute and\nlook at that sentence. I’ve been working on this book every day for around\n1,400 days. I can’t wait to take a break. So that’s the next step. My plan\nwas to finish the book right before spring break and enjoy a week on the beach\nwith family.\nThat beach trip went the way of so many other plans in early 2020, but I still\nintend to take a long break. I don’t know if you noticed, but we all have a lot\nof other shit to deal with right now. I’m going to relax.\nEvery morning since 2016, I’ve woken up with a task I had to do. Until I got my\nwriting done for the day, it was on my mind, weighing me down. Writing left me\ndrained. If you’ve ever had a newborn, you know the feeling of always having to\ncarry the baby around. After a while, it’s like you forget what it’s like to\nhave two free arms. I’ve been carrying this baby for four years, so I’m\nlooking forward to having both arms for a while.\nOnce I’m recharged, the real fun starts. Having the book online is important,\nbut for me, “Crafting Interpreters” was always meant to be a book with pages\nand a cover. So after a long bout of editing and bug fixing, I’m going to get\nstarted doing the page layout for the print edition. I love graphic design, and\nI can’t wait to hold it in my hands.\nIf you’d like to hold it in your hands when it comes out, I have a mailing\nlist where I’ll let you know when the book is done. In the meantime, I\nthink I’ve earned some rest.","guid":"http://journal.stuffwithstuff.com/2020/04/05/crafting-crafting-interpreters","isoDate":"2020-04-05T07:00:00.000Z","timestamp":"4/5/2020"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"40 Songs","link":"http://journal.stuffwithstuff.com/2018/05/19/40-songs/","pubDate":"Sat, 19 May 2018 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>I turned 40 today. Well, actually, as I&rsquo;m writing this, I&rsquo;m not yet 40. And,\nunless you happen to be reading this on the very day I post it, it&rsquo;s no longer\nmy birthday. Chronology in text is weird.</p>\n\n<p>I&rsquo;m not gonna lie. This number is hitting me hard. Intellectually, I get that\nthe fact that it&rsquo;s a round number is merely an artifact of our base ten numeral\nsystem, which is in turn an arbitrary quirk of the evolutionary history that led\nto us having ten fingers. I get it.</p>\n\n<p>But what it really feels like is the midpoint. As a male in the US, 40 isn&rsquo;t\nthat far from the halfway point of average life expectancy. I have more memories\naccrued than new experiences to anticipate. In the great hallway of life, there\nare more doors behind me than ahead, which makes the regret of those unopened\nones all the more acute.</p>\n\n<p>I was talking about all this with my sister-in-law a few months ago. Her\nmilestone is coming soon too. She plans to celebrate by writing a list of her\ntop forty favorite songs. I&rsquo;ll be damned if I don&rsquo;t love a good list, so here&rsquo;s\nmine.</p>\n\n<p>It&rsquo;s in chronological order <em>of my personal relationship to the song</em>. It\nappears when it appeared in my life. The luxury of this being my list is that I\nget to scramble time as it suits me.</p>\n\n<p>40 is a pretty long list of songs. Heck, some days it feels like a long list of\nyears. So we&rsquo;re going to need some speed, and what better way to get moving\nthen&hellip;</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=Vppbdf-qtGU\">La Grange</a></strong> - ZZ Top</h3>\n\n<p>As you&rsquo;ll find out, I live for a good build-up, and there is none better than\nthis. A couple of sticks on the edge of the snare and a palm-muted riff and\n<em>holy crap what just happened to my pulse</em>. ZZ Top is possibly the <em>tightest</em>\nband that ever lived. Every punchy ghost hit on the snare is so locked into the\nguitar and bass that it must have been played by a single giant six-armed demon.</p>\n\n<p>If your car is on fumes, wheezing out its last few yards, threatening to leave\nyou stranded in the desert, crank this song up and I promise you you&rsquo;ll get\nanother mile or two out of the tank.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=qeMFqkcPYcg\">Sweet Dreams (Are Made of This)</a></strong> - Eurythmics</h3>\n\n<p>This is the first song that I distinctly remember hearing for the first time.\nPicture tiny me standing in front of a TV, staring mouth agape at Annie Lennox&rsquo;s\nbright red hair and that weird-ass video, wondering what the hell was going on\nand why I liked it so much.</p>\n\n<p>I sometimes wonder if imprinting on this song at such a young age twisted my\nbrain. Lord knows I love a synth bassline and a four on the floor kick to an\nunhealthy degree. That thing I have for short hair on women must have come from\nsomewhere.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=yRYFKcMa_Ek\">Maneater</a></strong> - Daryl Hall &amp; John Oates</h3>\n\n<p>I&rsquo;m just old enough to remember roller rinks. My older brother and I would go,\nand I have vivid memories of how <em>cool</em> it felt to be in that dark, cavernous\nroom, surrounded by pulsing sound.</p>\n\n<p>&ldquo;Maneater&rdquo; is one of the songs I remember from there. (&ldquo;Mickey&rdquo; is another.) It\nticks almost every checkbox for what I still love in a song: tons of reverb,\nhigh string pads, machine-precision drums, rhythmic bassline locked to a minor\nchord progression. I know I should hear 80s cheese when I listen to it today,\nbut it still sounds just as spacious and moody today as it did then.</p>\n\n<p>What I also remember is strapping on my skates every time and never <em>once</em>\nhaving the courage to venture off the carpet onto the rink. It took me thirty\nyears and a friend&rsquo;s skating party to face that fear and finally get out there.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=0R6WIbx8ysE\">Send Me an Angel</a></strong> - Real Life</h3>\n\n<p>Alright, I gotta speed this up if we&rsquo;re going to get through all forty in a\nreasonable amount of time. There is a special place in the dark&ndash;of course it&rsquo;s\ndark&ndash;corner of my soul for sad synthpop. I don&rsquo;t know what it is, but slap some\nmaudlin lyrics on top of a dance beat and I&rsquo;m all over it. Fast + sad is my jam.</p>\n\n<p>The whole genre pushes my buttons, but &ldquo;Send Me an Angel&rdquo; stands out because:</p>\n\n<ol>\n<li><p>David Sterry really goes for it lyrically. It&rsquo;s hard to top &ldquo;if a girl walks\nup and carves her name in my heart, I&rsquo;ll turn and run away&rdquo; for abject\npathos.</p></li>\n<li><p>That little synth choir melody is six notes of absolute perfection.</p></li>\n</ol>\n\n<p>Decades later, I was at a show for a friend of a friend&rsquo;s band. The singer said\nthey were going to do a weird cover and if anyone knew the song, to shout out\nthe name of the band. He played the first three notes of that melody and it was\nlike the heavens opened above, presumably so angels could watch me yelling &ldquo;Real\nLife!&rdquo; over and over at the top of my lungs like an idiot.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=m0AKJMGxwpE\">Enjoy the Silence</a></strong> - Depeche Mode</h3>\n\n<p>Speaking of synthpop songs with aching melodies. I&rsquo;ve listened to Depeche Mode\nso much over the years that they are all over my memories. But the best, the\none I&rsquo;ve shared with literally no one until now&hellip;</p>\n\n<p>My best friend in elementary school had an older sister. My friend and were two\ntotal nerds (still are), but his sister was <em>so cool</em>&ndash;serious and artistic.\nExhibit A: giant Depeche Mode posters on her wall. Exhibit B: a complete and\nutter disinterest in interacting with us for even a second. At that age, that\nwas about all it took for a crush to blossom.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=Cv6tuzHUuuk\">Walk Like an Egyptian</a></strong> - Bangles</h3>\n\n<p>At some point in my childhood, I informed my parents that I liked music and\ndesired the ability to listen to it in my bedroom. My Dad, being the music snob\nhe is, solved that problem by buying young me an honest-to-God record player. No\ncassette tapes in this household, young man!</p>\n\n<p>One of the first records I got was &ldquo;Different Light&rdquo; by the Bangles. I spent a\nlot of time listening to the bassline in this song, gazing at the photos on the\ncover, and having thoughts about Susanna Hoffs I wasn&rsquo;t quite old enough to\nprocess yet.</p>\n\n<h3><strong><a href=\"https://youtu.be/vsQrKZcYtqg?t=6\">Istanbul (Not Constantinople)</a></strong> - They Might Be Giants</h3>\n\n<p>Look, I don&rsquo;t know what happened. I&rsquo;ll blame it on incredible middle school\nawkwardness, but I went through a phase where I, I shit you not, listened to\n<em>nothing</em> but TMBG. For like two years. I still know all of the lyrics to every\nsingle song on &ldquo;Flood&rdquo;, &ldquo;Lincoln&rdquo;, &ldquo;Apollo 18&rdquo;, and &ldquo;John Henry&rdquo;.</p>\n\n<p>They aren&rsquo;t my thing very much these days, but the lyrics are still up there in\nthe wetware should a particularly odd karaoke night have need of them.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=EbI0cMyyw_M\">Run Through the Jungle</a></strong> - CCR</h3>\n\n<p>I mentioned intros, right? This is another of the greats. I think most people\nlike the happy-dumb CCR hits, but for me I want the ones that remind me that the\nUS was goin&rsquo; through some <em>shit</em> when those songs came out. This tops that list.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=9muzyOd4Lh8\">Nights in White Satin</a></strong> - Moody Blues</h3>\n\n<p>One of the things I truly lament about my generation and the generations to\nfollow is our acute self-awareness. Ironic detachment of the 90s followed by\n<a href=\"https://en.wikipedia.org/wiki/New_Sincerity\">ironic <em>attachment</em></a> left us\nbasically unable to produce art without constantly obsessing about what the art\nsays about the artist.</p>\n\n<p>Can you imagine <em>anyone</em> today sitting down to record a rock album with an\norchestra, and then slapping a <em>poem</em> on the end? And doing it with complete,\nheartfelt, unironic sincerity? It&rsquo;s an ability that seems to be completely lost.</p>\n\n<p>Thankfully, this song embedded itself in my subconscious before that cultural\nshift happened. I love every single bit of this song, completely, totally.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=I_izvAbhExY\">Stayin&rsquo; Alive</a></strong> - The Bee-Gees</h3>\n\n<p>Speaking of things I love un-ironically. For a nerdy white dude, I have spent a\nsurprisingly large amount of time shaking my ass on various dancefloors across\nthe United States. Not with any particular <em>skill</em> mind you, but with\ngreat enthusiasm.</p>\n\n<p>I like basically any kind of dance music, and disco is certainly on that list.\nThe genre is a distillation of everything that makes a song danceworthy, with\neverything unnecessary filtered out. Picking one disco song is hard, and picking\none played by white guys is a borderline travesty, but I&rsquo;d be lying if I said I\ndidn&rsquo;t know every single cymbal crash in this song and had my arm thrust, finger\nextended, for each.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=gzoEK545j64\">Groove is in the Heart</a></strong> - Deee-Lite</h3>\n\n<p>Bootsy&rsquo;s bassline. That beat. If this don&rsquo;t get your booty movin&rsquo;, your booty\nmust be dead.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=1lWJXDG2i0A\">Free Fallin&rsquo;</a></strong> - Tom Petty</h3>\n\n<p>Thomas Earl Petty is another one like Depeche Mode where it&rsquo;s hard to know where\nto slot him in. His music is a constant companion in my life. Narrowing his\npresence on this list down to a single song was hard enough. &ldquo;You Wreck Me&rdquo;,\n&ldquo;Learning to Fly&rdquo;, &ldquo;American Girl&rdquo;, &ldquo;Breakdown&rdquo; are all strong contenders.</p>\n\n<p>I picked this one because it spans what I think of as the two sides of Petty &ndash;\nthe straightforward timeless American rock, and the bittersweet character\nstudies.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=hwZNL7QVJjE\">Stand By Me</a></strong> - Ben E. King</h3>\n\n<p>A high school friend got a cheap acoustic guitar and I eventually got my hands\non it. Tinkering around, I figured out the bassline to &ldquo;Stand By Me&rdquo;, playing\nthat guitar like a bass, upside down. (I&rsquo;m left-handed and it was strung\nright-handed.) This was the first bassline I ever learned.</p>\n\n<p>Did you know King never intended to record this? He wrote it for the Drifters\nand only reluctantly recorded it himself when he had some extra time in the\nstudio. Listen to that vocal performance. Can you imagine being so good that you\ncan just toss something like that out there?</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=CC5ca6Hsb2Q\">Children</a></strong> - Robert Miles</h3>\n\n<p>Apparently, there was a whole house and techno scene going on in the world.\nMaybe if I&rsquo;d been a kid in Chicago or Detroit, I would have noticed. But none of\nthat made its way to southern Louisiana until this instrumental, piano-driven\nelectronica song improbably came down from space and landed on commercial radio.</p>\n\n<p>The first time I heard this song was a <em>revelation</em>. I didn&rsquo;t even know music\nlike this existed. I loved everything about it, the rigid tempo, heartbeat kick,\noffset bass, heart-stirring melody. I couldn&rsquo;t get enough.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=brZ_WBEzw6E\">Dark + Long (Dark Train)</a></strong> - Underworld</h3>\n\n<p>Right around this time, I met a guy at work who wore these weird pants <a href=\"https://www.google.com/search?q=jnco&client=firefox-b-1-ab&source=lnms&tbm=isch&sa=X&ved=0ahUKEwim2dT2j4zbAhVOyWMKHfZZDaMQ_AUICigB&biw=1166&bih=803\">with\nhuge legs</a>. What was that about? He told my brother and I he was a &ldquo;raver&rdquo;\nand there was this music called &ldquo;techno&rdquo; and you could hear it at these things\ncalled &ldquo;raves&rdquo;.</p>\n\n<p>In one sitting, he gave us a rundown of artists that kept my ears full for\nseveral years. The band that I forged the strongest bond with is Underworld. I\nrushed out and got the &ldquo;Pearl&rsquo;s Girl&rdquo; EP, then later &ldquo;Dubnobasswithmyheadman&rdquo;\nand &ldquo;Second Toughest in the Infants&rdquo;. Eventually, I had almost everything they\never recorded.</p>\n\n<p>I met some of my closest college friends by bonding over Underworld. We once\ndrove 900 miles from Baton Rouge to Chicago, non-stop, because that was the\nclosest place to us that Underworld was playing during the &ldquo;Beaucoup Fish&rdquo; tour.\nStill one of the best shows I ever saw.</p>\n\n<p>Picking a single Underworld song is hard. Picking this particular song is\nfrustrating because for most, it&rsquo;s associated with Trainspotting. But that&rsquo;s not\nwhat I think when I hear this. To me, it&rsquo;s driving home from raves at the State\nPalace Theatre in New Orleans as the sun comes up in our rearview mirror.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=bV-hSgL1R74\">Halcyon + On + On</a></strong> - Orbital</h3>\n\n<p>A lot of techno at the 90s was, well, kind of dumb. Maybe a good beat to dance\nto, but it didn&rsquo;t leave you thinking or feeling much of anything. Aphex Twin\ntook care of the &ldquo;thinking&rdquo; part. Orbital took care of feeling. They showed that\nmusic made with computers could have as much heart as anything else.</p>\n\n<p>I&rsquo;m not the kind of person to fret about what song I want played at my funeral,\nbut if I had to pick, this might be it.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=WQYsGWh_vpE\">Roads</a></strong> - Portishead</h3>\n\n<p>Oh, the tremolo on the Rhodes, mirroring Beth Gibbons&rsquo; vibrato. Those ghost hits\non the snare. The strings. <em>That bassline.</em> Every ounce of this is flawless.</p>\n\n<p>Like most people at the time, I got into trip-hop. Some of it doesn&rsquo;t hold up,\nbut some of it, like this, I seem to respond to more and more the older I get.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=tSRYvYN1ayw\">Gorecki</a></strong> - Lamb</h3>\n\n<p>Around this time, I was working at an Internet start-up during the first dotcom\nbubble. Amazon had just started selling CDs and they had this new &ldquo;Customers who\nbought this also bought&rdquo; thing. Today, we are inundated with machine learning\nthat knows every single connection between ever human artifact every produced.\nIt&rsquo;s hard to remember what the world was before recommendation engines.</p>\n\n<p>But there was a time where if you liked some song, you might be totally unable\nto find other stuff like it, <em>even if that other stuff existed.</em> If you were\nlucky, the guy at the music store knew stuff. That was literally it.</p>\n\n<p>So when I typed in the one trip-hop band I knew into the search box at\nwww.amazon.com, and then saw a list of other bands I might also like, and other\nbands linked to from <em>them</em>, and so on, it was like the gates to Paradise had\nopened up.</p>\n\n<p>I ordered a stack of CDs, the largest music purchase of my life. They showed up\na week later. I took them home, put Lamb&rsquo;s debut album in, and put on my\nheadphones. The first time this song came on, I was moved nearly to tears.</p>\n\n<p>Granted, I was going through some girlfriend stuff at the time, so tears weren&rsquo;t\nas far away as usual, but it&rsquo;s still the most profoundly emotional listening\nexperience of my life.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=U4U19zwFENs\">La Femme d&#39;Argent</a></strong> - Air</h3>\n\n<p>One day, the roommate of the girl that caused the aforementioned troubles put in\na CD in her car stereo. She said, &ldquo;You like electronic stuff, you might like\nthis.&rdquo; I was totally flummoxed by what came on. It sounded like it had been\nrecorded in the 70s. Was it even &ldquo;electronic&rdquo; music? She insisted it had come\nout recently. I&rsquo;d never heard anything like it. It was, and still is,\nmagnificent. An album that stands outside of time and genre.</p>\n\n<p>Much much later, it occurred to me that I had dated the wrong roommate.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=Ci_LIavsEhQ\">Kathy&rsquo;s Song</a></strong> - Apoptygma Berzerk</h3>\n\n<p>I love this song first because it reminds me of discovering a whole new genre of\nmusic (synthpop and EBM), a circle of friends (&ldquo;the Baton Rouge goth community&rdquo;\nas my friend used to say) and a new bar (The Spanish Moon) all at the same time.</p>\n\n<p>Going to that bar led to throwing parties with the same people and music, which\nled to me DJing at our house, which eventually led to me DJing at the Spanish\nMoon, which was a huge step for me to get past some of my crippling shyness.</p>\n\n<p>I love this song second because my sister-in-law&rsquo;s name is &ldquo;Cathy&rdquo;, and I played\nthis at her wedding to my brother on the day that I got to officially call her\nfamily.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=hpji_vmCUVU\">Remember (Mood II Swing Mix)</a></strong> - BT</h3>\n\n<p>There are a number of BT songs that could be on this list, but I picked this\nremix because it&rsquo;s the track I&rsquo;ve listened to the most over the years. &ldquo;Flaming\nJune&rdquo; and &ldquo;Poseidon&rdquo; are up there too.</p>\n\n<p>But, also, because every time I hear that little fuzz effect come in at :15, I\ncan still perfectly picture the owner of The Spanish Moon sprinting across the\ndancefloor towards the DJ booth, panic in his eyes, because he thought I&rsquo;d blown\nhis sound system.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=sbnujaAbD2A\">Autumn Tactics</a></strong> - Chicane</h3>\n\n<p>That couple year span when &ldquo;progressive house&rdquo; was the thing brought a lot of\ngreat artists to my attention. Of all of them, I probably sunk more time into\nChicane&rsquo;s first two albums than anything else. This isn&rsquo;t really a house track\n&ndash; I don&rsquo;t know how to categorize it, honestly &ndash; and maybe that&rsquo;s why it&rsquo;s\nheld up so well for me. I&rsquo;ve been listening to it for close to twenty years, and\nI still haven&rsquo;t tired of it.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=B4px0qQrG5E\">Poor Leno</a></strong> - Röyksopp</h3>\n\n<p>We&rsquo;re getting closer to the modern era, witnessed by the fact that I stumbled\nonto this song from a <em>video</em> on the <em>Internet</em>. This song led to me buying\nturntables. I was going to clubs listening to house all the time, but most of\nthe DJs were playing stripped down tribal or tech house that sounded soulless\nand empty to me. I didn&rsquo;t necessarily need a full set of lyrics, but I at least\nwanted a chord progression.</p>\n\n<p>I realized that if I ever wanted to hear this track or others like it on a\ndancefloor, I was going to have to make it happen myself. I filled up my online\nshopping cart at Turntable Lab. A few weeks later some very large, very heavy\nboxes showed up at work, and I was off learning how to beatmatch.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=omJQVvKVQCk\">Tracey In My Room</a></strong> - EBTG vs Soul Vision</h3>\n\n<p>This song is a two-fer. Tracy Thorn from Everything but the Girl is one of my\nfavorite vocalists. When Ben Watt took EBTG in a decidedly electronic direction\nwith &ldquo;Walking Wounded&rdquo; and then &ldquo;Temperamental&rdquo;, I was right there with him.</p>\n\n<p>But around this time was also when I started to get fully into house music, the\nmore heartfelt the better. This record, a mash-up of a house song and the vocals\nfrom &ldquo;Wrong&rdquo; merges those two better than it has any right to.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=5ViItcZyYBw\">Unspoken</a></strong> - Four Tet</h3>\n\n<p>In my twenties, my friends and I used to hit <a href=\"http://parkavecds.com/\">Park Ave.\nCDs</a> every Tuesday when new music came out. This album\nwas at a listening station on an end cap. When the first song came on, it was as\nif the lights in the building gradually dimmed, leaving nothing but sound.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=mMh-Y2IWJZc\">Back of my Hand</a></strong> - Gemma Hayes</h3>\n\n<p>We went to this record store so often that the employees would hook us up with\nsamplers and other merch. This song was on one. It&rsquo;s not my usual genre and I\ncan&rsquo;t say I&rsquo;ve listened to much else by her. But the production on this song\npushes it out of generic singer-songwriter and into something really interesting\nto me.</p>\n\n<p>I love the contrast between the folksy guitar &ndash; twelve-string? double-tracked?\n&ndash; and that that tinny mechanical drum loop. When the fully-EQed beat and organ\ndrops, my heart goes a-flutter.</p>\n\n<p>I had this song as my alarm clock for several years. It was a gentle way to wake\nup and the end result was the lyrics embedding themselves in my subconscious.\nYears later, my kids started asking me to sing them bedtime songs. This was one\nof the few whose words I remembered and whose melody fit within my not-so-wide\nvocal range.</p>\n\n<p>Listening brings back peaceful mornings sipping coffee in Orlando, and gentle\nnights in Washington stroking my daughters&rsquo; hair as they fall asleep. It&rsquo;s hard\nto imagine a better pair of bookends.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=0wrsZog8qXg\">Such Great Heights</a></strong> - Postal Service</h3>\n\n<p>The drag about being into electronic music in Orlando back then was, well, the\nother people into it. Instead of the fun rave scene of New Orleans where kids\nwere down to Earth and just wanted a good time, Orlando was a <em>club</em> scene &ndash;\noverdressed bros and over-made-up woman desperately trying to impress each other\nwhile trying not to look desperate.</p>\n\n<p>Indie dance music and Orlando&rsquo;s Independent Bar (called &ldquo;Barbarella&rdquo; at the\ntime) saved me from that. The indie night there remains the absolute best\ndancefloor, and the most fun crowd I&rsquo;ve ever experienced. Like clockwork, every\nFriday night ended with a packed, sweaty, grinning mass of euphoric people.</p>\n\n<p>There are a number of songs I could pick to be the anthem for that time in my\nlife, but this one also happens to mark a great point in a relationship (before\nthe relationship went no-so-great).</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=SPlQpGeTbIE\">Move Your Feet</a></strong> - Junior Senior</h3>\n\n<p>One of the few things I love as much as dance music is pixel art, so this song&rsquo;s\nvideo pushes all of the buttons on the 747 control panel of my heart.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=Gs069dndIYk\">September</a></strong> - Earth, Wind, and Fire</h3>\n\n<p>I expected more soul music to make this list, but somehow it didn&rsquo;t. It would\nhave been a real shame to omit this gem. Thursdays were soul night at I-Bar and\nI can&rsquo;t hear this song without picturing my friend Amy cutting up the\ndancefloor.</p>\n\n<p>This song gets twice my love because I also used to spin the fantastic <a href=\"https://www.youtube.com/watch?v=wn5Q37qOiiA\">Phats &amp;\nSmall house remix</a>.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=g6jhpaX7fNQ\">Under the Milky Way</a></strong> - The Church</h3>\n\n<p>You know those songs that reside in a primordial part of your brain? I can&rsquo;t\nrecall ever <em>not</em> knowing this song. I&rsquo;m wired towards the low end of the\nfrequency spectrum. I play bass, and tend to focus on the bass and rhythm side\nof songs. That extends to vocals. I can&rsquo;t do histrionic screechy singers.\nNothing sets my soul at ease quite like a soft baritone.</p>\n\n<p>This is another song I used to sing to my kids as they fell asleep.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=2q9_ZEtuTR8\">Maybe Tomorrow</a></strong> - Stereophonics</h3>\n\n<p>The beginning of the video for this song is a dirty lie. This song wasn&rsquo;t\ncrafted by imperfect human hands. It was plucked, flawless, from some sonic vein\ndeep within the Earth.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=BiPLOmTp6IA\">Stop</a></strong> - Black Rebel Motorcycle Club</h3>\n\n<p>Hanging out at Independent Bar opened one of the most fulfilling chapters of my\nlife. It was there that I met my friend Mikey, which led to us starting a band.\nPlaying music with others was a transcendent experiences &ndash; to hear four people\nproduce one single harmonious sound. To give birth to something better than we\ncould have made on our own. Being on stage is a bonus. Just to play is the\nthing.</p>\n\n<p>My bandmates introduced me to a lot of great rock, including BRMC. I used to\nlisten to this track on the way to shows and by the time I got to the gig, that\nbassline had me feeling like I could walk through a brick wall.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=MYYG1lAUntM\">Baby in Two</a></strong> - Pernice Brothers</h3>\n\n<p>My drummer Shannon introduced me to Pernice Brothers. Our band days are over, we\nlive about three thousand miles apart, but he will always be my drummer and I\nwill always be his bassist. There&rsquo;s a special kind of love that forms only\nbetween two halves of a rhythm section and this album is the soundtrack to mine.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=S28tILqie1o\">Cupid</a></strong> - Sam Cooke</h3>\n\n<p>God, did they know how to record back then. Take one of the world&rsquo;s greatest\nvoices. Add beautiful, authentic reverb, and just enough tape saturation, and\nyou get a sound so rich I can practically taste it.</p>\n\n<p>But the technical merits are an aside. The real reason this is here is because\nit marks the time when I met my wife. This song is inseparable from her,\nfrom <em>us</em>.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=L5dUsZ4Djd0\">Blue Ridge Mountains</a></strong> - Fleet Foxes</h3>\n\n<p>By this time, I was burned out from eight years in the game industry. Tired\nof the heat and <em>sameness</em> Florida&ndash;every month indistinguishable from the\nprevious, the days an unending blur of sunlight.</p>\n\n<p>My wife and I discovered the Pacific Northwest on a work trip. We played this\nalbum non-stop during our honeymoon on the Olympic Peninsula, and by the end we\nwere ready to uproot and move. Back in Florida, during the months it took for me\nto find work in Seattle, this record was a constant reminder of the promise\nawaiting us out west.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=NDHY1D0tKRA\">I Will Follow You Into the Dark</a></strong> - Death Cab for Cutie</h3>\n\n<p>There is a Seattle city ordinance that you must like Ben Gibbard.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=3mUfOs-CTCw\">Shooting Stars</a></strong> - Bag Raiders</h3>\n\n<p>My love of disco and house naturally turned into a love of nu-disco. I don&rsquo;t\nknow what&rsquo;s going on in Australia, but there&rsquo;s a whole pile of bands out of\nSydney and Melbourne that sound like they took everything I love about the 70s\nand 80s, mashed it all together, and somehow made it sound fresh again.</p>\n\n<p>One of the joys of being a Dad is playing music with my kids. I get to choose\nthe songs that will form their subconscious musical memory. They love this\nalbum, perhaps largely because I used to pick them up and dance with them in the\nkitchen every time we played it. I hope when they are much older and hear this,\nthey still think of me.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=7HPMK9Uxq3I\">Elevate</a></strong> - St. Lucia</h3>\n\n<p>Like I said, the 80s is new again. I won&rsquo;t lie. Listening to music that apes a\ngenre that I still remember the first time it came around makes me feel pretty\nold. That weird cringe I get when I see fashion come full circle and the young\nfolk start wearing stuff I still have jammed in the back of my closet.</p>\n\n<p>I try to ignore that twinge because, honestly, St. Lucia is fantastic. This\nisn&rsquo;t some ironic winking aping of the past (looking at you The Darkness and\nSteel Panther). St. Lucia is a gushing love letter to everything great about\nbeachy 80s pop. It&rsquo;s mai tais, sand between your toes, coconut sunscreen.\nEndless summer and eternal youth.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=ImKY6TZEyrI\">Fade Into You</a></strong> - Mazzy Star</h3>\n\n<p>We&rsquo;re nearing the end of the list, nearly through forty years of living and\nlistening. It&rsquo;s been a long drive down a winding road, and the sun will be up\nsoon.</p>\n\n<h3><strong><a href=\"https://www.youtube.com/watch?v=xzQvGz6_fvA\">I&rsquo;m on Fire</a></strong> - Bruce Springsteen</h3>\n\n<p>Forty feels like all my younger selves are lost, receded far into the past. Yet,\nat the same time, they still burn vibrantly alive inside, refusing to be\nforgotten.</p>\n","contentSnippet":"I turned 40 today. Well, actually, as I’m writing this, I’m not yet 40. And,\nunless you happen to be reading this on the very day I post it, it’s no longer\nmy birthday. Chronology in text is weird.\nI’m not gonna lie. This number is hitting me hard. Intellectually, I get that\nthe fact that it’s a round number is merely an artifact of our base ten numeral\nsystem, which is in turn an arbitrary quirk of the evolutionary history that led\nto us having ten fingers. I get it.\nBut what it really feels like is the midpoint. As a male in the US, 40 isn’t\nthat far from the halfway point of average life expectancy. I have more memories\naccrued than new experiences to anticipate. In the great hallway of life, there\nare more doors behind me than ahead, which makes the regret of those unopened\nones all the more acute.\nI was talking about all this with my sister-in-law a few months ago. Her\nmilestone is coming soon too. She plans to celebrate by writing a list of her\ntop forty favorite songs. I’ll be damned if I don’t love a good list, so here’s\nmine.\nIt’s in chronological order of my personal relationship to the song. It\nappears when it appeared in my life. The luxury of this being my list is that I\nget to scramble time as it suits me.\n40 is a pretty long list of songs. Heck, some days it feels like a long list of\nyears. So we’re going to need some speed, and what better way to get moving\nthen…\nLa Grange - ZZ Top\nAs you’ll find out, I live for a good build-up, and there is none better than\nthis. A couple of sticks on the edge of the snare and a palm-muted riff and\nholy crap what just happened to my pulse. ZZ Top is possibly the tightest\nband that ever lived. Every punchy ghost hit on the snare is so locked into the\nguitar and bass that it must have been played by a single giant six-armed demon.\nIf your car is on fumes, wheezing out its last few yards, threatening to leave\nyou stranded in the desert, crank this song up and I promise you you’ll get\nanother mile or two out of the tank.\nSweet Dreams (Are Made of This) - Eurythmics\nThis is the first song that I distinctly remember hearing for the first time.\nPicture tiny me standing in front of a TV, staring mouth agape at Annie Lennox’s\nbright red hair and that weird-ass video, wondering what the hell was going on\nand why I liked it so much.\nI sometimes wonder if imprinting on this song at such a young age twisted my\nbrain. Lord knows I love a synth bassline and a four on the floor kick to an\nunhealthy degree. That thing I have for short hair on women must have come from\nsomewhere.\nManeater - Daryl Hall & John Oates\nI’m just old enough to remember roller rinks. My older brother and I would go,\nand I have vivid memories of how cool it felt to be in that dark, cavernous\nroom, surrounded by pulsing sound.\n“Maneater” is one of the songs I remember from there. (“Mickey” is another.) It\nticks almost every checkbox for what I still love in a song: tons of reverb,\nhigh string pads, machine-precision drums, rhythmic bassline locked to a minor\nchord progression. I know I should hear 80s cheese when I listen to it today,\nbut it still sounds just as spacious and moody today as it did then.\nWhat I also remember is strapping on my skates every time and never once\nhaving the courage to venture off the carpet onto the rink. It took me thirty\nyears and a friend’s skating party to face that fear and finally get out there.\nSend Me an Angel - Real Life\nAlright, I gotta speed this up if we’re going to get through all forty in a\nreasonable amount of time. There is a special place in the dark–of course it’s\ndark–corner of my soul for sad synthpop. I don’t know what it is, but slap some\nmaudlin lyrics on top of a dance beat and I’m all over it. Fast + sad is my jam.\nThe whole genre pushes my buttons, but “Send Me an Angel” stands out because:\nDavid Sterry really goes for it lyrically. It’s hard to top “if a girl walks\nup and carves her name in my heart, I’ll turn and run away” for abject\npathos.\n\n\nThat little synth choir melody is six notes of absolute perfection.\n\n\n\nDecades later, I was at a show for a friend of a friend’s band. The singer said\nthey were going to do a weird cover and if anyone knew the song, to shout out\nthe name of the band. He played the first three notes of that melody and it was\nlike the heavens opened above, presumably so angels could watch me yelling “Real\nLife!” over and over at the top of my lungs like an idiot.\nEnjoy the Silence - Depeche Mode\nSpeaking of synthpop songs with aching melodies. I’ve listened to Depeche Mode\nso much over the years that they are all over my memories. But the best, the\none I’ve shared with literally no one until now…\nMy best friend in elementary school had an older sister. My friend and were two\ntotal nerds (still are), but his sister was so cool–serious and artistic.\nExhibit A: giant Depeche Mode posters on her wall. Exhibit B: a complete and\nutter disinterest in interacting with us for even a second. At that age, that\nwas about all it took for a crush to blossom.\nWalk Like an Egyptian - Bangles\nAt some point in my childhood, I informed my parents that I liked music and\ndesired the ability to listen to it in my bedroom. My Dad, being the music snob\nhe is, solved that problem by buying young me an honest-to-God record player. No\ncassette tapes in this household, young man!\nOne of the first records I got was “Different Light” by the Bangles. I spent a\nlot of time listening to the bassline in this song, gazing at the photos on the\ncover, and having thoughts about Susanna Hoffs I wasn’t quite old enough to\nprocess yet.\nIstanbul (Not Constantinople) - They Might Be Giants\nLook, I don’t know what happened. I’ll blame it on incredible middle school\nawkwardness, but I went through a phase where I, I shit you not, listened to\nnothing but TMBG. For like two years. I still know all of the lyrics to every\nsingle song on “Flood”, “Lincoln”, “Apollo 18”, and “John Henry”.\nThey aren’t my thing very much these days, but the lyrics are still up there in\nthe wetware should a particularly odd karaoke night have need of them.\nRun Through the Jungle - CCR\nI mentioned intros, right? This is another of the greats. I think most people\nlike the happy-dumb CCR hits, but for me I want the ones that remind me that the\nUS was goin’ through some shit when those songs came out. This tops that list.\nNights in White Satin - Moody Blues\nOne of the things I truly lament about my generation and the generations to\nfollow is our acute self-awareness. Ironic detachment of the 90s followed by\nironic attachment left us\nbasically unable to produce art without constantly obsessing about what the art\nsays about the artist.\nCan you imagine anyone today sitting down to record a rock album with an\norchestra, and then slapping a poem on the end? And doing it with complete,\nheartfelt, unironic sincerity? It’s an ability that seems to be completely lost.\nThankfully, this song embedded itself in my subconscious before that cultural\nshift happened. I love every single bit of this song, completely, totally.\nStayin’ Alive - The Bee-Gees\nSpeaking of things I love un-ironically. For a nerdy white dude, I have spent a\nsurprisingly large amount of time shaking my ass on various dancefloors across\nthe United States. Not with any particular skill mind you, but with\ngreat enthusiasm.\nI like basically any kind of dance music, and disco is certainly on that list.\nThe genre is a distillation of everything that makes a song danceworthy, with\neverything unnecessary filtered out. Picking one disco song is hard, and picking\none played by white guys is a borderline travesty, but I’d be lying if I said I\ndidn’t know every single cymbal crash in this song and had my arm thrust, finger\nextended, for each.\nGroove is in the Heart - Deee-Lite\nBootsy’s bassline. That beat. If this don’t get your booty movin’, your booty\nmust be dead.\nFree Fallin’ - Tom Petty\nThomas Earl Petty is another one like Depeche Mode where it’s hard to know where\nto slot him in. His music is a constant companion in my life. Narrowing his\npresence on this list down to a single song was hard enough. “You Wreck Me”,\n“Learning to Fly”, “American Girl”, “Breakdown” are all strong contenders.\nI picked this one because it spans what I think of as the two sides of Petty –\nthe straightforward timeless American rock, and the bittersweet character\nstudies.\nStand By Me - Ben E. King\nA high school friend got a cheap acoustic guitar and I eventually got my hands\non it. Tinkering around, I figured out the bassline to “Stand By Me”, playing\nthat guitar like a bass, upside down. (I’m left-handed and it was strung\nright-handed.) This was the first bassline I ever learned.\nDid you know King never intended to record this? He wrote it for the Drifters\nand only reluctantly recorded it himself when he had some extra time in the\nstudio. Listen to that vocal performance. Can you imagine being so good that you\ncan just toss something like that out there?\nChildren - Robert Miles\nApparently, there was a whole house and techno scene going on in the world.\nMaybe if I’d been a kid in Chicago or Detroit, I would have noticed. But none of\nthat made its way to southern Louisiana until this instrumental, piano-driven\nelectronica song improbably came down from space and landed on commercial radio.\nThe first time I heard this song was a revelation. I didn’t even know music\nlike this existed. I loved everything about it, the rigid tempo, heartbeat kick,\noffset bass, heart-stirring melody. I couldn’t get enough.\nDark + Long (Dark Train) - Underworld\nRight around this time, I met a guy at work who wore these weird pants with\nhuge legs. What was that about? He told my brother and I he was a “raver”\nand there was this music called “techno” and you could hear it at these things\ncalled “raves”.\nIn one sitting, he gave us a rundown of artists that kept my ears full for\nseveral years. The band that I forged the strongest bond with is Underworld. I\nrushed out and got the “Pearl’s Girl” EP, then later “Dubnobasswithmyheadman”\nand “Second Toughest in the Infants”. Eventually, I had almost everything they\never recorded.\nI met some of my closest college friends by bonding over Underworld. We once\ndrove 900 miles from Baton Rouge to Chicago, non-stop, because that was the\nclosest place to us that Underworld was playing during the “Beaucoup Fish” tour.\nStill one of the best shows I ever saw.\nPicking a single Underworld song is hard. Picking this particular song is\nfrustrating because for most, it’s associated with Trainspotting. But that’s not\nwhat I think when I hear this. To me, it’s driving home from raves at the State\nPalace Theatre in New Orleans as the sun comes up in our rearview mirror.\nHalcyon + On + On - Orbital\nA lot of techno at the 90s was, well, kind of dumb. Maybe a good beat to dance\nto, but it didn’t leave you thinking or feeling much of anything. Aphex Twin\ntook care of the “thinking” part. Orbital took care of feeling. They showed that\nmusic made with computers could have as much heart as anything else.\nI’m not the kind of person to fret about what song I want played at my funeral,\nbut if I had to pick, this might be it.\nRoads - Portishead\nOh, the tremolo on the Rhodes, mirroring Beth Gibbons’ vibrato. Those ghost hits\non the snare. The strings. That bassline. Every ounce of this is flawless.\nLike most people at the time, I got into trip-hop. Some of it doesn’t hold up,\nbut some of it, like this, I seem to respond to more and more the older I get.\nGorecki - Lamb\nAround this time, I was working at an Internet start-up during the first dotcom\nbubble. Amazon had just started selling CDs and they had this new “Customers who\nbought this also bought” thing. Today, we are inundated with machine learning\nthat knows every single connection between ever human artifact every produced.\nIt’s hard to remember what the world was before recommendation engines.\nBut there was a time where if you liked some song, you might be totally unable\nto find other stuff like it, even if that other stuff existed. If you were\nlucky, the guy at the music store knew stuff. That was literally it.\nSo when I typed in the one trip-hop band I knew into the search box at\nwww.amazon.com, and then saw a list of other bands I might also like, and other\nbands linked to from them, and so on, it was like the gates to Paradise had\nopened up.\nI ordered a stack of CDs, the largest music purchase of my life. They showed up\na week later. I took them home, put Lamb’s debut album in, and put on my\nheadphones. The first time this song came on, I was moved nearly to tears.\nGranted, I was going through some girlfriend stuff at the time, so tears weren’t\nas far away as usual, but it’s still the most profoundly emotional listening\nexperience of my life.\nLa Femme d'Argent - Air\nOne day, the roommate of the girl that caused the aforementioned troubles put in\na CD in her car stereo. She said, “You like electronic stuff, you might like\nthis.” I was totally flummoxed by what came on. It sounded like it had been\nrecorded in the 70s. Was it even “electronic” music? She insisted it had come\nout recently. I’d never heard anything like it. It was, and still is,\nmagnificent. An album that stands outside of time and genre.\nMuch much later, it occurred to me that I had dated the wrong roommate.\nKathy’s Song - Apoptygma Berzerk\nI love this song first because it reminds me of discovering a whole new genre of\nmusic (synthpop and EBM), a circle of friends (“the Baton Rouge goth community”\nas my friend used to say) and a new bar (The Spanish Moon) all at the same time.\nGoing to that bar led to throwing parties with the same people and music, which\nled to me DJing at our house, which eventually led to me DJing at the Spanish\nMoon, which was a huge step for me to get past some of my crippling shyness.\nI love this song second because my sister-in-law’s name is “Cathy”, and I played\nthis at her wedding to my brother on the day that I got to officially call her\nfamily.\nRemember (Mood II Swing Mix) - BT\nThere are a number of BT songs that could be on this list, but I picked this\nremix because it’s the track I’ve listened to the most over the years. “Flaming\nJune” and “Poseidon” are up there too.\nBut, also, because every time I hear that little fuzz effect come in at :15, I\ncan still perfectly picture the owner of The Spanish Moon sprinting across the\ndancefloor towards the DJ booth, panic in his eyes, because he thought I’d blown\nhis sound system.\nAutumn Tactics - Chicane\nThat couple year span when “progressive house” was the thing brought a lot of\ngreat artists to my attention. Of all of them, I probably sunk more time into\nChicane’s first two albums than anything else. This isn’t really a house track\n– I don’t know how to categorize it, honestly – and maybe that’s why it’s\nheld up so well for me. I’ve been listening to it for close to twenty years, and\nI still haven’t tired of it.\nPoor Leno - Röyksopp\nWe’re getting closer to the modern era, witnessed by the fact that I stumbled\nonto this song from a video on the Internet. This song led to me buying\nturntables. I was going to clubs listening to house all the time, but most of\nthe DJs were playing stripped down tribal or tech house that sounded soulless\nand empty to me. I didn’t necessarily need a full set of lyrics, but I at least\nwanted a chord progression.\nI realized that if I ever wanted to hear this track or others like it on a\ndancefloor, I was going to have to make it happen myself. I filled up my online\nshopping cart at Turntable Lab. A few weeks later some very large, very heavy\nboxes showed up at work, and I was off learning how to beatmatch.\nTracey In My Room - EBTG vs Soul Vision\nThis song is a two-fer. Tracy Thorn from Everything but the Girl is one of my\nfavorite vocalists. When Ben Watt took EBTG in a decidedly electronic direction\nwith “Walking Wounded” and then “Temperamental”, I was right there with him.\nBut around this time was also when I started to get fully into house music, the\nmore heartfelt the better. This record, a mash-up of a house song and the vocals\nfrom “Wrong” merges those two better than it has any right to.\nUnspoken - Four Tet\nIn my twenties, my friends and I used to hit Park Ave.\nCDs every Tuesday when new music came out. This album\nwas at a listening station on an end cap. When the first song came on, it was as\nif the lights in the building gradually dimmed, leaving nothing but sound.\nBack of my Hand - Gemma Hayes\nWe went to this record store so often that the employees would hook us up with\nsamplers and other merch. This song was on one. It’s not my usual genre and I\ncan’t say I’ve listened to much else by her. But the production on this song\npushes it out of generic singer-songwriter and into something really interesting\nto me.\nI love the contrast between the folksy guitar – twelve-string? double-tracked?\n– and that that tinny mechanical drum loop. When the fully-EQed beat and organ\ndrops, my heart goes a-flutter.\nI had this song as my alarm clock for several years. It was a gentle way to wake\nup and the end result was the lyrics embedding themselves in my subconscious.\nYears later, my kids started asking me to sing them bedtime songs. This was one\nof the few whose words I remembered and whose melody fit within my not-so-wide\nvocal range.\nListening brings back peaceful mornings sipping coffee in Orlando, and gentle\nnights in Washington stroking my daughters’ hair as they fall asleep. It’s hard\nto imagine a better pair of bookends.\nSuch Great Heights - Postal Service\nThe drag about being into electronic music in Orlando back then was, well, the\nother people into it. Instead of the fun rave scene of New Orleans where kids\nwere down to Earth and just wanted a good time, Orlando was a club scene –\noverdressed bros and over-made-up woman desperately trying to impress each other\nwhile trying not to look desperate.\nIndie dance music and Orlando’s Independent Bar (called “Barbarella” at the\ntime) saved me from that. The indie night there remains the absolute best\ndancefloor, and the most fun crowd I’ve ever experienced. Like clockwork, every\nFriday night ended with a packed, sweaty, grinning mass of euphoric people.\nThere are a number of songs I could pick to be the anthem for that time in my\nlife, but this one also happens to mark a great point in a relationship (before\nthe relationship went no-so-great).\nMove Your Feet - Junior Senior\nOne of the few things I love as much as dance music is pixel art, so this song’s\nvideo pushes all of the buttons on the 747 control panel of my heart.\nSeptember - Earth, Wind, and Fire\nI expected more soul music to make this list, but somehow it didn’t. It would\nhave been a real shame to omit this gem. Thursdays were soul night at I-Bar and\nI can’t hear this song without picturing my friend Amy cutting up the\ndancefloor.\nThis song gets twice my love because I also used to spin the fantastic Phats &\nSmall house remix.\nUnder the Milky Way - The Church\nYou know those songs that reside in a primordial part of your brain? I can’t\nrecall ever not knowing this song. I’m wired towards the low end of the\nfrequency spectrum. I play bass, and tend to focus on the bass and rhythm side\nof songs. That extends to vocals. I can’t do histrionic screechy singers.\nNothing sets my soul at ease quite like a soft baritone.\nThis is another song I used to sing to my kids as they fell asleep.\nMaybe Tomorrow - Stereophonics\nThe beginning of the video for this song is a dirty lie. This song wasn’t\ncrafted by imperfect human hands. It was plucked, flawless, from some sonic vein\ndeep within the Earth.\nStop - Black Rebel Motorcycle Club\nHanging out at Independent Bar opened one of the most fulfilling chapters of my\nlife. It was there that I met my friend Mikey, which led to us starting a band.\nPlaying music with others was a transcendent experiences – to hear four people\nproduce one single harmonious sound. To give birth to something better than we\ncould have made on our own. Being on stage is a bonus. Just to play is the\nthing.\nMy bandmates introduced me to a lot of great rock, including BRMC. I used to\nlisten to this track on the way to shows and by the time I got to the gig, that\nbassline had me feeling like I could walk through a brick wall.\nBaby in Two - Pernice Brothers\nMy drummer Shannon introduced me to Pernice Brothers. Our band days are over, we\nlive about three thousand miles apart, but he will always be my drummer and I\nwill always be his bassist. There’s a special kind of love that forms only\nbetween two halves of a rhythm section and this album is the soundtrack to mine.\nCupid - Sam Cooke\nGod, did they know how to record back then. Take one of the world’s greatest\nvoices. Add beautiful, authentic reverb, and just enough tape saturation, and\nyou get a sound so rich I can practically taste it.\nBut the technical merits are an aside. The real reason this is here is because\nit marks the time when I met my wife. This song is inseparable from her,\nfrom us.\nBlue Ridge Mountains - Fleet Foxes\nBy this time, I was burned out from eight years in the game industry. Tired\nof the heat and sameness Florida–every month indistinguishable from the\nprevious, the days an unending blur of sunlight.\nMy wife and I discovered the Pacific Northwest on a work trip. We played this\nalbum non-stop during our honeymoon on the Olympic Peninsula, and by the end we\nwere ready to uproot and move. Back in Florida, during the months it took for me\nto find work in Seattle, this record was a constant reminder of the promise\nawaiting us out west.\nI Will Follow You Into the Dark - Death Cab for Cutie\nThere is a Seattle city ordinance that you must like Ben Gibbard.\nShooting Stars - Bag Raiders\nMy love of disco and house naturally turned into a love of nu-disco. I don’t\nknow what’s going on in Australia, but there’s a whole pile of bands out of\nSydney and Melbourne that sound like they took everything I love about the 70s\nand 80s, mashed it all together, and somehow made it sound fresh again.\nOne of the joys of being a Dad is playing music with my kids. I get to choose\nthe songs that will form their subconscious musical memory. They love this\nalbum, perhaps largely because I used to pick them up and dance with them in the\nkitchen every time we played it. I hope when they are much older and hear this,\nthey still think of me.\nElevate - St. Lucia\nLike I said, the 80s is new again. I won’t lie. Listening to music that apes a\ngenre that I still remember the first time it came around makes me feel pretty\nold. That weird cringe I get when I see fashion come full circle and the young\nfolk start wearing stuff I still have jammed in the back of my closet.\nI try to ignore that twinge because, honestly, St. Lucia is fantastic. This\nisn’t some ironic winking aping of the past (looking at you The Darkness and\nSteel Panther). St. Lucia is a gushing love letter to everything great about\nbeachy 80s pop. It’s mai tais, sand between your toes, coconut sunscreen.\nEndless summer and eternal youth.\nFade Into You - Mazzy Star\nWe’re nearing the end of the list, nearly through forty years of living and\nlistening. It’s been a long drive down a winding road, and the sun will be up\nsoon.\nI’m on Fire - Bruce Springsteen\nForty feels like all my younger selves are lost, receded far into the past. Yet,\nat the same time, they still burn vibrantly alive inside, refusing to be\nforgotten.","guid":"http://journal.stuffwithstuff.com/2018/05/19/40-songs","isoDate":"2018-05-19T07:00:00.000Z","timestamp":"5/19/2018"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"Long Names Are Long","link":"http://journal.stuffwithstuff.com/2016/06/16/long-names-are-long/","pubDate":"Thu, 16 Jun 2016 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>One smart thing Google does is rigorous code reviews. Every change, before you\ncan land it, gets reviewed in at least two way. First, someone on the team does\na normal review to make sure the code does what it&rsquo;s supposed to.</p>\n\n<p>But, then, there&rsquo;s a second layer of review called <em>readability</em>. It makes sure\nthe code is, well, readable: Is it easy to understand and maintain? Does it\nfollow the style and idioms of the language? Is it well-documented?</p>\n\n<p><a href=\"https://www.dartlang.org/\">Dart</a> usage inside Google is cranking up, so I&rsquo;ve been doing a long ton of\nthese kind of code reviews. As a language designer, it&rsquo;s fascinating. I get a\nfirst-hand view into how people use Dart, which is really useful for evolving\nit. I have a clearer picture of which mistakes are common and which features are\nheavily used. I feel like an ethnographer journaling the lives of natives.</p>\n\n<p>But, anyway, that&rsquo;s not what this is about. Heck, it&rsquo;s not even about Dart. What\nI want to talk about is something I see in a lot of code that drives me up the\nwall: <strong>identifiers that are too damn long.</strong></p>\n\n<p>Yes, names can be too short. Back when C only required external identifiers to\nbe unique up to the first six characters; auto-complete hadn&rsquo;t been invented;\nand every keypress had to be made uphill, in the snow, both ways; it was a\nproblem. I&rsquo;m glad we now live in a futuristic utopia where keyboard farts like\n<code>p</code>, <code>idxcrpm</code>, and <code>x3</code> are rare.</p>\n\n<p>But the pendulum has swung too far in the other direction. We shouldn&rsquo;t be\nHemingway, but we don&rsquo;t need to be Tennessee Williams either. Very <em>long</em> names\nalso hurt the clarity of the code where they are used. Giant identifiers dwarf\nthe operations you&rsquo;re performing on them, are hard to visually scan, and force\nextra line breaks which interrupt the flow of the code.</p>\n\n<p>Long class names discourage users from declaring variables of that type, leading\nto massive, gnarly nested expressions instead of hoisting things out to locals.\nLong method names obscure their equally important argument lists. Long variables\nare annoying to use repeatedly, leading to sprawling method chains or cascades.</p>\n\n<p>I&rsquo;ve seen identifiers over 60 characters long. You could fit a haiku or a koan\nin there (and likely enlighten the reader more than the actual chosen name did).\nFear not, I am here to help.</p>\n\n<h2>Choosing a Good Name</h2>\n\n<p>A name has two goals:</p>\n\n<ul>\n<li><p>It needs to be <em>clear</em>: you need to know what the name refers to.</p></li>\n<li><p>It needs to be <em>precise</em>: you need to know what it does <em>not</em> refer to.</p></li>\n</ul>\n\n<p>After a name has accomplished those goals, any additional characters are dead\nweight. Here&rsquo;s some guidelines I use when I names things in my code:</p>\n\n<h3>1. Omit words that are obvious given a variable&rsquo;s or parameter&rsquo;s type</h3>\n\n<p>If your language has a static type system, users usually know the type of a\nvariable. Methods tend to be short, so even when looking at local variable whose\ntype was inferred, or in a code review or some place where static analysis isn&rsquo;t\navailable, it rarely takes more than scanning a few lines to tell what type a\nvariable has.</p>\n\n<p>Given that, it&rsquo;s redundant to put the type in the variable&rsquo;s name. We have\nrightfully abandoned <a href=\"https://en.wikipedia.org/wiki/Hungarian_notation\">Hungarian notation</a>. <em>Let it go.</em></p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Bad:</span>\n<span class=\"kt\">String</span> <span class=\"n\">nameString</span><span class=\"p\">;</span>\n<span class=\"n\">DockableModelessWindow</span> <span class=\"n\">dockableModelessWindow</span><span class=\"p\">;</span>\n\n<span class=\"c1\">// Better:</span>\n<span class=\"kt\">String</span> <span class=\"n\">name</span><span class=\"p\">;</span>\n<span class=\"n\">DockableModelessWindow</span> <span class=\"n\">window</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>In particular, for collections, it&rsquo;s almost always better to just use a plural\nnoun describing the <em>contents</em> instead of a singular noun describing the\n<em>collection</em>. If the reader cares more about what&rsquo;s <em>in</em> the collection, the\nname should reflect that.</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Bad:</span>\n<span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">DateTime</span><span class=\"o\">&gt;</span> <span class=\"n\">holidayDateList</span><span class=\"p\">;</span>\n<span class=\"n\">Map</span><span class=\"o\">&lt;</span><span class=\"n\">Employee</span><span class=\"p\">,</span> <span class=\"n\">Role</span><span class=\"o\">&gt;</span> <span class=\"n\">employeeRoleHashMap</span><span class=\"p\">;</span>\n\n<span class=\"c1\">// Better:</span>\n<span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">DateTime</span><span class=\"o\">&gt;</span> <span class=\"n\">holidays</span><span class=\"p\">;</span>\n<span class=\"n\">Map</span><span class=\"o\">&lt;</span><span class=\"n\">Employee</span><span class=\"p\">,</span> <span class=\"n\">Role</span><span class=\"o\">&gt;</span> <span class=\"n\">employeeRoles</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>This also applies to method names. The method name doesn&rsquo;t need to describe its\nparameters or their types&mdash;the parameter list does that for you.</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Bad:</span>\n<span class=\"n\">mergeTableCells</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">TableCell</span><span class=\"o\">&gt;</span> <span class=\"n\">cells</span><span class=\"p\">)</span>\n<span class=\"n\">sortEventsUsingComparator</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Event</span><span class=\"o\">&gt;</span> <span class=\"n\">events</span><span class=\"p\">,</span>\n    <span class=\"n\">Comparator</span><span class=\"o\">&lt;</span><span class=\"n\">Event</span><span class=\"o\">&gt;</span> <span class=\"n\">comparator</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// Better:</span>\n<span class=\"n\">merge</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">TableCell</span><span class=\"o\">&gt;</span> <span class=\"n\">cells</span><span class=\"p\">)</span>\n<span class=\"n\">sort</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Event</span><span class=\"o\">&gt;</span> <span class=\"n\">events</span><span class=\"p\">,</span> <span class=\"n\">Comparator</span><span class=\"o\">&lt;</span><span class=\"n\">Event</span><span class=\"o\">&gt;</span> <span class=\"n\">comparator</span><span class=\"p\">)</span>\n</code></pre></div>\n<p>This tends to make callsites read better:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">mergeTableCells</span><span class=\"p\">(</span><span class=\"n\">tableCells</span><span class=\"p\">);</span>\n<span class=\"n\">sortEventsUsingComparator</span><span class=\"p\">(</span><span class=\"n\">events</span><span class=\"p\">,</span> <span class=\"n\">comparator</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>Is it just me, or is there an echo echo in here here?</p>\n\n<h3>2. Omit words that don&rsquo;t disambiguate the name</h3>\n\n<p>Some people tend to cram everything they know about something into its name.\nRemember, the name is an <em>identifier</em>: it points you to <em>where</em> it&rsquo;s defined.\nIt&rsquo;s not an exhaustive catalog of everything the reader could want to know about\nthe object. The definition does that. The name just gets them there.</p>\n\n<p>When I see an identifier like <code>recentlyUpdatedAnnualSalesBid</code>, I ask:</p>\n\n<ul>\n<li><p>Are there updated annual sales bids that aren&rsquo;t recent?</p></li>\n<li><p>Are there recent annual sales bids that were not updated?</p></li>\n<li><p>Are there recently updated sales bids that aren&rsquo;t annual?</p></li>\n<li><p>Are there recently updated annual bids not related to sales?</p></li>\n<li><p>Are there recently updated annual sales things that are not bids?</p></li>\n</ul>\n\n<p>A &ldquo;no&rdquo; for any of these usually points to an extraneous word.</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Bad:</span>\n<span class=\"n\">finalBattleMostDangerousBossMonster</span><span class=\"p\">;</span>\n<span class=\"n\">weaklingFirstEncounterMonster</span><span class=\"p\">;</span>\n\n<span class=\"c1\">// Better:</span>\n<span class=\"n\">boss</span><span class=\"p\">;</span>\n<span class=\"n\">firstMonster</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>Of course, you can go too far. Shortening that first example to <code>bid</code> might be a\nlittle <em>too</em> vague. But, when in doubt, leave it out. You can always add\nqualifiers later if the name proves to cause a collision or be imprecise but\nit&rsquo;s unlikely you&rsquo;ll come back later to trim the fat.</p>\n\n<h3>3. Omit words that are known from the surrounding context</h3>\n\n<p>I can use &ldquo;I&rdquo; in this paragraph because you can see this post is by Bob Nystrom.\nMy dumb face is right up there. I don&rsquo;t need to keep saying “Bob Nystrom”\neverywhere here (despite Bob Nystrom&rsquo;s temptation to aggrandize Bob Nystrom by\ndoing so). Code works the same way. A method or field occurs in the context of a\nclass. A variable occurs in the context of a method. Take that context for\ngranted and don&rsquo;t repeat it.</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Bad:</span>\n<span class=\"kd\">class</span> <span class=\"nc\">AnnualHolidaySale</span> <span class=\"p\">{</span>\n  <span class=\"kt\">int</span> <span class=\"n\">_annualSaleRebate</span><span class=\"p\">;</span>\n  <span class=\"kt\">void</span> <span class=\"n\">promoteHolidaySale</span><span class=\"p\">()</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\">// Better:</span>\n<span class=\"kd\">class</span> <span class=\"nc\">AnnualHolidaySale</span> <span class=\"p\">{</span>\n  <span class=\"kt\">int</span> <span class=\"n\">_rebate</span><span class=\"p\">;</span>\n  <span class=\"kt\">void</span> <span class=\"n\">promote</span><span class=\"p\">()</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>In practice, this means that the more deeply nested a name is, the more surrounding context it has. That in turn means it usually has a shorter name. The effect is that identifiers with shorter scopes have shorter names.</p>\n\n<h3>4. Omit words that don&rsquo;t mean much of anything</h3>\n\n<p>I used to see this a lot in the game industry. Some people succumb to the temptation to inflate their identifiers by adding Serious Business sounding words. I guess it makes their code feel more important and, by extension, makes <em>them</em> feel more important.</p>\n\n<p>In many cases, the words carry no meaningful information. They&rsquo;re just fluff or jargon. Usual suspects include: <code>data</code>, <code>state</code>, <code>amount</code>, <code>value</code>, <code>manager</code>, <code>engine</code>, <code>object</code>, <code>entity</code>, and <code>instance</code>.</p>\n\n<p>A good name paints a picture in the mind of the reader. Calling something a &ldquo;manager&rdquo; doesn&rsquo;t convey any image to the reader about what the thing does. Does it do performance evaluations? Give raises?</p>\n\n<p>Ask yourself &ldquo;Would this identifier mean the same thing if I removed the word?&rdquo; If so, the word doesn&rsquo;t carry its weight: vote if off the island.</p>\n\n<h2>Applying the Guidelines&hellip; to Waffles</h2>\n\n<p>To give you a feel for how these rules work in practice, here&rsquo;s an example that breaks all of these rules. This contrived example is heart-breakingly close to real code I&rsquo;ve seen in reviews:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">DeliciousBelgianWaffleObject</span> <span class=\"p\">{</span>\n  <span class=\"kt\">void</span> <span class=\"n\">garnishDeliciousBelgianWaffleWithStrawberryList</span><span class=\"p\">(</span>\n      <span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Strawberry</span><span class=\"o\">&gt;</span> <span class=\"n\">strawberryList</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>We know from the type that it takes a list of strawberries (#1), so let&rsquo;s cut that out:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">DeliciousBelgianWaffleObject</span> <span class=\"p\">{</span>\n    <span class=\"kt\">void</span> <span class=\"n\">garnishDeliciousBelgianWaffle</span><span class=\"p\">(</span>\n        <span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Strawberry</span><span class=\"o\">&gt;</span> <span class=\"n\">strawberries</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Unless our program has foul-tasting Belgian waffles, or waffles of other nationalities, we can drop those adjectives (#2):</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">WaffleObject</span> <span class=\"p\">{</span>\n  <span class=\"kt\">void</span> <span class=\"n\">garnishWaffle</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Strawberry</span><span class=\"o\">&gt;</span> <span class=\"n\">strawberries</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>The method is inside a <code>WaffleObject</code>, so we know what it&rsquo;s going to garnish (#3):</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">WaffleObject</span> <span class=\"p\">{</span>\n  <span class=\"kt\">void</span> <span class=\"n\">garnish</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Strawberry</span><span class=\"o\">&gt;</span> <span class=\"n\">strawberries</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Obviously it&rsquo;s an object. Everything is an object. That&rsquo;s kind of what &ldquo;object-oriented&rdquo; means (#4):</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">Waffle</span> <span class=\"p\">{</span>\n  <span class=\"kt\">void</span> <span class=\"n\">garnish</span><span class=\"p\">(</span><span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Strawberry</span><span class=\"o\">&gt;</span> <span class=\"n\">strawberries</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"p\">...</span> <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>There, much better.</p>\n\n<p>I think these are pretty simple guidelines. You may think it&rsquo;s pointless to worry about this stuff, but I believe that <a href=\"/2009/06/05/naming-things-in-code/\">naming things</a> is one of the most fundamental tasks we do when programming. Names are the structure we impose on the formless sea of bits that is computing.</p>\n","contentSnippet":"One smart thing Google does is rigorous code reviews. Every change, before you\ncan land it, gets reviewed in at least two way. First, someone on the team does\na normal review to make sure the code does what it’s supposed to.\nBut, then, there’s a second layer of review called readability. It makes sure\nthe code is, well, readable: Is it easy to understand and maintain? Does it\nfollow the style and idioms of the language? Is it well-documented?\nDart usage inside Google is cranking up, so I’ve been doing a long ton of\nthese kind of code reviews. As a language designer, it’s fascinating. I get a\nfirst-hand view into how people use Dart, which is really useful for evolving\nit. I have a clearer picture of which mistakes are common and which features are\nheavily used. I feel like an ethnographer journaling the lives of natives.\nBut, anyway, that’s not what this is about. Heck, it’s not even about Dart. What\nI want to talk about is something I see in a lot of code that drives me up the\nwall: identifiers that are too damn long.\nYes, names can be too short. Back when C only required external identifiers to\nbe unique up to the first six characters; auto-complete hadn’t been invented;\nand every keypress had to be made uphill, in the snow, both ways; it was a\nproblem. I’m glad we now live in a futuristic utopia where keyboard farts like\np, idxcrpm, and x3 are rare.\nBut the pendulum has swung too far in the other direction. We shouldn’t be\nHemingway, but we don’t need to be Tennessee Williams either. Very long names\nalso hurt the clarity of the code where they are used. Giant identifiers dwarf\nthe operations you’re performing on them, are hard to visually scan, and force\nextra line breaks which interrupt the flow of the code.\nLong class names discourage users from declaring variables of that type, leading\nto massive, gnarly nested expressions instead of hoisting things out to locals.\nLong method names obscure their equally important argument lists. Long variables\nare annoying to use repeatedly, leading to sprawling method chains or cascades.\nI’ve seen identifiers over 60 characters long. You could fit a haiku or a koan\nin there (and likely enlighten the reader more than the actual chosen name did).\nFear not, I am here to help.\nChoosing a Good Name\nA name has two goals:\nIt needs to be clear: you need to know what the name refers to.\n\n\nIt needs to be precise: you need to know what it does not refer to.\n\n\n\nAfter a name has accomplished those goals, any additional characters are dead\nweight. Here’s some guidelines I use when I names things in my code:\n1. Omit words that are obvious given a variable’s or parameter’s type\nIf your language has a static type system, users usually know the type of a\nvariable. Methods tend to be short, so even when looking at local variable whose\ntype was inferred, or in a code review or some place where static analysis isn’t\navailable, it rarely takes more than scanning a few lines to tell what type a\nvariable has.\nGiven that, it’s redundant to put the type in the variable’s name. We have\nrightfully abandoned Hungarian notation. Let it go.\n// Bad:\nString nameString;\nDockableModelessWindow dockableModelessWindow;\n\n// Better:\nString name;\nDockableModelessWindow window;\n\n\nIn particular, for collections, it’s almost always better to just use a plural\nnoun describing the contents instead of a singular noun describing the\ncollection. If the reader cares more about what’s in the collection, the\nname should reflect that.\n// Bad:\nList<DateTime> holidayDateList;\nMap<Employee, Role> employeeRoleHashMap;\n\n// Better:\nList<DateTime> holidays;\nMap<Employee, Role> employeeRoles;\n\n\nThis also applies to method names. The method name doesn’t need to describe its\nparameters or their types—the parameter list does that for you.\n// Bad:\nmergeTableCells(List<TableCell> cells)\nsortEventsUsingComparator(List<Event> events,\n    Comparator<Event> comparator)\n\n// Better:\nmerge(List<TableCell> cells)\nsort(List<Event> events, Comparator<Event> comparator)\n\n\nThis tends to make callsites read better:\nmergeTableCells(tableCells);\nsortEventsUsingComparator(events, comparator);\n\n\nIs it just me, or is there an echo echo in here here?\n2. Omit words that don’t disambiguate the name\nSome people tend to cram everything they know about something into its name.\nRemember, the name is an identifier: it points you to where it’s defined.\nIt’s not an exhaustive catalog of everything the reader could want to know about\nthe object. The definition does that. The name just gets them there.\nWhen I see an identifier like recentlyUpdatedAnnualSalesBid, I ask:\nAre there updated annual sales bids that aren’t recent?\n\n\nAre there recent annual sales bids that were not updated?\n\n\nAre there recently updated sales bids that aren’t annual?\n\n\nAre there recently updated annual bids not related to sales?\n\n\nAre there recently updated annual sales things that are not bids?\n\n\n\nA “no” for any of these usually points to an extraneous word.\n// Bad:\nfinalBattleMostDangerousBossMonster;\nweaklingFirstEncounterMonster;\n\n// Better:\nboss;\nfirstMonster;\n\n\nOf course, you can go too far. Shortening that first example to bid might be a\nlittle too vague. But, when in doubt, leave it out. You can always add\nqualifiers later if the name proves to cause a collision or be imprecise but\nit’s unlikely you’ll come back later to trim the fat.\n3. Omit words that are known from the surrounding context\nI can use “I” in this paragraph because you can see this post is by Bob Nystrom.\nMy dumb face is right up there. I don’t need to keep saying “Bob Nystrom”\neverywhere here (despite Bob Nystrom’s temptation to aggrandize Bob Nystrom by\ndoing so). Code works the same way. A method or field occurs in the context of a\nclass. A variable occurs in the context of a method. Take that context for\ngranted and don’t repeat it.\n// Bad:\nclass AnnualHolidaySale {\n  int _annualSaleRebate;\n  void promoteHolidaySale() { ... }\n}\n\n// Better:\nclass AnnualHolidaySale {\n  int _rebate;\n  void promote() { ... }\n}\n\n\nIn practice, this means that the more deeply nested a name is, the more surrounding context it has. That in turn means it usually has a shorter name. The effect is that identifiers with shorter scopes have shorter names.\n4. Omit words that don’t mean much of anything\nI used to see this a lot in the game industry. Some people succumb to the temptation to inflate their identifiers by adding Serious Business sounding words. I guess it makes their code feel more important and, by extension, makes them feel more important.\nIn many cases, the words carry no meaningful information. They’re just fluff or jargon. Usual suspects include: data, state, amount, value, manager, engine, object, entity, and instance.\nA good name paints a picture in the mind of the reader. Calling something a “manager” doesn’t convey any image to the reader about what the thing does. Does it do performance evaluations? Give raises?\nAsk yourself “Would this identifier mean the same thing if I removed the word?” If so, the word doesn’t carry its weight: vote if off the island.\nApplying the Guidelines… to Waffles\nTo give you a feel for how these rules work in practice, here’s an example that breaks all of these rules. This contrived example is heart-breakingly close to real code I’ve seen in reviews:\nclass DeliciousBelgianWaffleObject {\n  void garnishDeliciousBelgianWaffleWithStrawberryList(\n      List<Strawberry> strawberryList) { ... }\n}\n\n\nWe know from the type that it takes a list of strawberries (#1), so let’s cut that out:\nclass DeliciousBelgianWaffleObject {\n    void garnishDeliciousBelgianWaffle(\n        List<Strawberry> strawberries) { ... }\n}\n\n\nUnless our program has foul-tasting Belgian waffles, or waffles of other nationalities, we can drop those adjectives (#2):\nclass WaffleObject {\n  void garnishWaffle(List<Strawberry> strawberries) { ... }\n}\n\n\nThe method is inside a WaffleObject, so we know what it’s going to garnish (#3):\nclass WaffleObject {\n  void garnish(List<Strawberry> strawberries) { ... }\n}\n\n\nObviously it’s an object. Everything is an object. That’s kind of what “object-oriented” means (#4):\nclass Waffle {\n  void garnish(List<Strawberry> strawberries) { ... }\n}\n\n\nThere, much better.\nI think these are pretty simple guidelines. You may think it’s pointless to worry about this stuff, but I believe that naming things is one of the most fundamental tasks we do when programming. Names are the structure we impose on the formless sea of bits that is computing.","guid":"http://journal.stuffwithstuff.com/2016/06/16/long-names-are-long","isoDate":"2016-06-16T07:00:00.000Z","timestamp":"6/16/2016"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"The Hardest Program I've Ever Written","link":"http://journal.stuffwithstuff.com/2015/09/08/the-hardest-program-ive-ever-written/","pubDate":"Tue, 08 Sep 2015 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<style>\n.skull, .skull-note {\n  border-radius: 4px;\n  -moz-border-radius: 4px;\n  -webkit-border-radius: 4px;\n\n  background: hsl(35, 100%, 96%);\n  color: hsl(35, 40%, 50%);\n\n  padding: 1px;\n}\n\n.skull::before, .skull-note::before {\n  content: \"\\01f480\";\n  margin-right: -2px;\n}\n\na.skull {\n  position: relative;\n  top: -0.4em;\n  font-size: 80%;\n}\n\na.skull:hover, a.skull-note:hover {\n  color: hsl(35, 100%, 30%);\n}\n</style>\n\n<p>The hardest program I&rsquo;ve ever written, once you strip out the whitespace, is\n3,835 lines long. That handful of code took me almost a year to write. Granted,\nthat doesn&rsquo;t take into account the code that didn&rsquo;t make it. The <a href=\"https://github.com/dart-lang/dart_style/commits/master\">commit\nhistory</a> shows that I deleted 20,704 lines of code over that time. Every\nsurviving line has about three fallen comrades.</p>\n\n<p>If it took that much thrashing to get it right, you&rsquo;d expect it to do something\npretty deep right? Maybe a low-level hardware interface or some wicked graphics\ndemo with tons of math and pumping early-90s-style techno? A likely-to-turn-evil\nmachine learning AI Skynet thing?</p>\n\n<p>Nope. It reads in a string and writes out a string. The only difference between\nthe input and output strings is that it modifies some of the whitespace\ncharacters. I&rsquo;m talking, of course, about <a href=\"https://github.com/dart-lang/dart_style\">an automated code\nformatter</a>.</p>\n\n<h2>Introducing dartfmt</h2>\n\n<p>I work on the <a href=\"https://www.dartlang.org/\">Dart</a> programming language. Part of my job is helping make more\nDart code readable, idiomatic, and consistent, which is why I ended up writing\nour <a href=\"https://www.dartlang.org/articles/style-guide/\">style guide</a>. That was a good first step, but any style guide written in\nEnglish is either so brief that it&rsquo;s ambiguous, or so long that no one reads it.</p>\n\n<p>Go&rsquo;s <a href=\"https://golang.org/cmd/gofmt/\">&ldquo;gofmt&rdquo;</a> tool showed a better solution: automatically format\neverything. Code is easier to read and contribute to because it&rsquo;s already in the\nstyle you&rsquo;re used to. Even if the output of the formatter isn&rsquo;t great, it ends\nthose interminable soul-crushing arguments on code reviews about formatting.</p>\n\n<p>Of course, I still have to sell users on running the formatter in the first\nplace. For <em>that</em>, having great output really does matter. Also, I&rsquo;m pretty\npicky with the formatting in my own code, and I didn&rsquo;t want to tell users to use\na tool that I didn&rsquo;t use myself.</p>\n\n<p>Getting that kind of quality means applying pretty sophisticated formatting\nrules. That in turn makes <em>performance</em> difficult. I knew balancing quality and\nspeed would be hard, but I didn&rsquo;t realize just how deep the rabbit hole went.</p>\n\n<p>I have finally emerged back into the sun, and I&rsquo;m pleased with what I brought\nback. I like the output, and the performance is solid. On my laptop, it can blow\nthrough over two million lines of code in about 45 seconds, using a single core.</p>\n\n<h2>Why is formatting hard?</h2>\n\n<p>At this point, you&rsquo;re probably thinking, &ldquo;Wait. What&rsquo;s so hard about\nformatting?&rdquo; After you&rsquo;ve parsed, can&rsquo;t you just walk the <a href=\"https://en.wikipedia.org/wiki/Abstract_syntax_tree\">AST</a> and\n<a href=\"https://en.wikipedia.org/wiki/Prettyprint\">pretty-print</a> it with some whitespace?</p>\n\n<p>If every statement fit within the column limit of the page, yup. It&rsquo;s a piece of\ncake. (I think that&rsquo;s what gofmt does.) But our formatter also keeps your code\nwithin the line length limit. That means adding line breaks (or &ldquo;splits&rdquo; as the\nformatter calls them), and determining the best place to add those is <a href=\"https://en.wikipedia.org/wiki/Line_wrap_and_word_wrap#Knuth.27s_algorithm\">famously\nhard</a>.</p>\n\n<p>Check out this guy:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">experimentalBootstrap</span> <span class=\"o\">=</span> <span class=\"n\">document</span><span class=\"p\">.</span><span class=\"n\">querySelectorAll</span><span class=\"p\">(</span><span class=\"s1\">&#39;link&#39;</span><span class=\"p\">).</span><span class=\"n\">any</span><span class=\"p\">((</span><span class=\"n\">link</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span>\n    <span class=\"n\">link</span><span class=\"p\">.</span><span class=\"n\">attributes</span><span class=\"p\">[</span><span class=\"s1\">&#39;rel&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;import&#39;</span> <span class=\"o\">&amp;&amp;</span>\n        <span class=\"n\">link</span><span class=\"p\">.</span><span class=\"n\">attributes</span><span class=\"p\">[</span><span class=\"s1\">&#39;href&#39;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"n\">POLYMER_EXPERIMENTAL_HTML</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>There are thirteen places where a line break is possible here according to our\nstyle rules. That&rsquo;s 8,192 different combinations if we brute force them all <a\nid=\"1\" href=\"#1-note\" class=\"skull\">1</a>. The search space we have to cover is\n<em>exponentially</em> large, and even ranking different solutions is a subtle problem.\nIs it better to split before the <code>.any()</code>? Why or why not?</p>\n\n<div class=\"update\">\n\n<p><strong>What is up with the skulls?</strong></p>\n\n<p>I had two goals with this article: to explain how dartfmt works, and to show a realistic picture of how a real programmer solves a difficult problem with all of the messiness that entails. Alas, the first is more than long enough to try your patience, so I shunted all of the dead ends and failed attempts to footnotes. Click the skulls to laugh at my misfortune.</p>\n\n</div>\n\n<p>In Dart, we made things harder on ourselves. We have anonymous functions, lots\nof <a href=\"https://api.dartlang.org/133511/dart-core/Iterable-class.html\">higher-order functions</a>, and&mdash;until we added <a href=\"https://www.dartlang.org/articles/await-async/\"><code>async</code> and\n<code>await</code></a>&mdash;used <a href=\"https://api.dartlang.org/1.12.1/dart-async/Future-class.html\">futures</a> for concurrency. That means lots of\ncallbacks and lots of long method chains. Some Dart users really dig a\nfunctional style and appear to be playing a game where whoever crams the most\nwork before a single semicolon wins.</p>\n\n<p>Here&rsquo;s real code from an amateur player:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">_bindAssignablePropsOn</span><span class=\"p\">.</span><span class=\"n\">forEach</span><span class=\"p\">((</span><span class=\"kt\">String</span> <span class=\"n\">eventName</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">node</span>\n    <span class=\"p\">.</span><span class=\"n\">addEventListener</span><span class=\"p\">(</span><span class=\"n\">eventName</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">zone</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">(()</span> <span class=\"o\">=&gt;</span> <span class=\"n\">bindAssignableProps</span>\n        <span class=\"p\">.</span><span class=\"n\">forEach</span><span class=\"p\">((</span><span class=\"n\">propAndExp</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">propAndExp</span><span class=\"p\">[</span><span class=\"m\">1</span><span class=\"p\">].</span><span class=\"n\">assign</span><span class=\"p\">(</span>\n            <span class=\"n\">scope</span><span class=\"p\">.</span><span class=\"n\">context</span><span class=\"p\">,</span> <span class=\"n\">jsNode</span><span class=\"p\">[</span><span class=\"n\">propAndExp</span><span class=\"p\">[</span><span class=\"m\">0</span><span class=\"p\">]])))));</span>\n</code></pre></div>\n<p>Yeah, that&rsquo;s four nested functions. 1,048,576 ways to split that one. Here&rsquo;s one\nof the best that I&rsquo;ve found. This is what a pro player brings to the game:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"k\">return</span> <span class=\"n\">doughnutFryer</span>\n    <span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n    <span class=\"p\">.</span><span class=\"n\">then</span><span class=\"p\">((</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">_frostingGlazer</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">())</span>\n    <span class=\"p\">.</span><span class=\"n\">then</span><span class=\"p\">((</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">Future</span><span class=\"p\">.</span><span class=\"n\">wait</span><span class=\"p\">([</span>\n          <span class=\"n\">_conveyorBelts</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">(),</span>\n          <span class=\"n\">sprinkleSprinkler</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">(),</span>\n          <span class=\"n\">sauceDripper</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n        <span class=\"p\">]))</span>\n    <span class=\"p\">.</span><span class=\"n\">catchError</span><span class=\"p\">(</span><span class=\"n\">cannotGetConveyorBeltRunning</span><span class=\"p\">)</span>\n    <span class=\"p\">.</span><span class=\"n\">then</span><span class=\"p\">((</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">tellEveryoneDonutsAreJustAboutDone</span><span class=\"p\">())</span>\n    <span class=\"p\">.</span><span class=\"n\">then</span><span class=\"p\">((</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"n\">Future</span><span class=\"p\">.</span><span class=\"n\">wait</span><span class=\"p\">([</span>\n          <span class=\"n\">croissantFactory</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">(),</span>\n          <span class=\"n\">_giantBakingOvens</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">(),</span>\n          <span class=\"n\">butterbutterer</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n        <span class=\"p\">])</span>\n            <span class=\"p\">.</span><span class=\"n\">catchError</span><span class=\"p\">(</span><span class=\"n\">_handleBakingFailures</span><span class=\"p\">)</span>\n            <span class=\"p\">.</span><span class=\"n\">timeout</span><span class=\"p\">(</span><span class=\"n\">scriptLoadingTimeout</span><span class=\"p\">,</span> <span class=\"nl\">onTimeout:</span> <span class=\"n\">_handleBakingFailures</span><span class=\"p\">)</span>\n            <span class=\"p\">.</span><span class=\"n\">catchError</span><span class=\"p\">(</span><span class=\"n\">cannotGetConveyorBeltRunning</span><span class=\"p\">))</span>\n    <span class=\"p\">.</span><span class=\"n\">catchError</span><span class=\"p\">(</span><span class=\"n\">cannotGetConveyorBeltRunning</span><span class=\"p\">)</span>\n    <span class=\"p\">.</span><span class=\"n\">then</span><span class=\"p\">((</span><span class=\"n\">_</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"n\">_logger</span><span class=\"p\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s2\">&quot;Let&#39;s eat!&quot;</span><span class=\"p\">);</span>\n<span class=\"p\">});</span>\n</code></pre></div>\n<p>(The funny names are because this was sanitized from internal code.) That&rsquo;s a\n<em>single</em> statement, all 565 characters of it. There are about 549 <em>billion</em> ways\nwe could line break it.</p>\n\n<p>Ultimately, this is what the formatter does. It applies some fairly\nsophisticated ranking rules to find the best set of line breaks from an\nexponential solution space. Note that &ldquo;best&rdquo; is a property of the <em>entire\nstatement</em> being formatted. A line break changes the indentation of the\nremainder of the statement, which in turn affects which other line breaks are\nneeded. Sorry, Knuth. No <a href=\"https://en.wikipedia.org/wiki/Dynamic_programming\">dynamic programming</a> this time <a id=\"2\"\nhref=\"#2-note\" class=\"skull\">2</a>.</p>\n\n<p>I think the formatter does a good job, but <em>how</em> it does it is a mystery to\nusers. People get spooked when robots surprise them, so I thought I would trace\nthe inner workings of its metal mind. And maybe try to justify to myself why it\ntook me a year to write a program whose behavior in many ways is\nindistinguishable from <code>cat</code>.</p>\n\n<h2>How the formatter sees your code</h2>\n\n<p>As you&rsquo;d expect from a program that works on source code, the formatter is\nstructured much like a compiler. It has a <a href=\"https://en.wikipedia.org/wiki/Compiler#Structure_of_a_compiler\">front end</a> that parses your code\nand converts that to an <a href=\"https://en.wikipedia.org/wiki/Intermediate_language#Intermediate_representation\">intermediate representation</a> <a id=\"3\"\nhref=\"#3-note\" class=\"skull\">3</a>. It does some optimization and clean up on\nthat <a id=\"4\" href=\"#4-note\" class=\"skull\">4</a>, and then the IR goes to a\nback end <a id=\"5\" href=\"#5-note\" class=\"skull\">5</a> that produces the final\noutput. The main objects here are <strong>chunks</strong>, <strong>rules</strong>, and <strong>spans</strong>.</p>\n\n<h3>Chunks</h3>\n\n<p>A <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk.dart\">chunk</a> is an atomic unit of formatting. It&rsquo;s a contiguous region of\ncharacters that we know will not contain any line breaks. Given this code:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">format</span> <span class=\"cm\">/* comment */</span> <span class=\"k\">this</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>We break it into these chunks: <code>format</code> <code>/* comment */</code> <code>this;</code>.</p>\n\n<p>Chunks are similar to a <a href=\"https://en.wikipedia.org/wiki/Lexical_analysis#Token\">token</a> in a conventional compiler, but they tend to\nbe, well, <em>chunkier</em>. Often, the text for several tokens ends up in the same\nchunk, like <code>this</code> and <code>;</code> here. If a line break can never occur between two\ntokens, they end up in the same chunk <a id=\"6\" href=\"#6-note\"\nclass=\"skull\">6</a>.</p>\n\n<p>Chunks are mostly linear. For example, given an expression like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">some</span><span class=\"p\">(</span><span class=\"n\">nested</span><span class=\"p\">,</span> <span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">ca</span> <span class=\"o\">+</span> <span class=\"n\">ll</span><span class=\"p\">))</span>\n</code></pre></div>\n<p>We chunk it to the flat list: <code>some(</code> <code>nested,</code> <code>function(</code> <code>ca +</code> <code>ll))</code>.</p>\n\n<p>We could treat an entire source file like a single flat sequence of chunks, but\nit would take forever and a day to line break the whole thing <a id=\"7\"\nhref=\"#7-note\" class=\"skull\">7</a>. With things like long chains of asynchronous\ncode, a single &ldquo;statement&rdquo; may be hundreds of lines of code containing several\nnested functions or collections that each contain their own piles of code.</p>\n\n<p>We can&rsquo;t treat those nested functions or collection literals entirely\nindependently because the surrounding expression affects how they are indented.\nThat in turn affects how long their lines are. Indent a function body two more\nspaces and now its statements have two fewer spaces before they hit the end of\nthe line.</p>\n\n<p>Instead, we treat nested block bodies as a separate little list of chunks to be\nformatted mostly on their own but subordinate to where they appear. The chunk\nthat begins one of these literals, like the <code>{</code> preceding a function or map,\ncontains a list of child <em>block chunks</em> for the contained block. In other words,\nchunks do form a tree, but one that only reflects block nesting, not\nexpressions.</p>\n\n<p>The end of a chunk marks the point where a split may occur in the final output,\nand the chunk has some data describing it <a id=\"8\" href=\"#8-note\"\nclass=\"skull\">8</a>. It keeps track of whether a blank line should be added\nbetween the chunks (like\nbetween two class definitions), how much the next line should be indented, and\nthe expression nesting depth at that point in the code.</p>\n\n<p>The most important bit of data about the split is the <em>rule</em> that controls it <a\nid=\"9\" href=\"#9-note\" class=\"skull\">9</a>.</p>\n\n<h3>Rules</h3>\n\n<p>Each potential split in the program is owned by a <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/rule/rule.dart\">rule</a>. A single rule may\nown the splits of several chunks. For example, a series of binary operators of\nthe same kind like <code>a + b + c + d</code> uses a single rule for the splits after each\n<code>+</code> operator.</p>\n\n<p>A rule controls which of its splits break and which don&rsquo;t. It determines this\nbased on the state that the rule is in, which it calls its <em>value</em>. You can\nthink of a rule like a dial and the value is what you&rsquo;ve turned it to. Given a\nvalue, the rule will tell you which of its chunks get split.</p>\n\n<p>The simplest rule is a <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/rule/rule.dart#L85\">&ldquo;hard split&rdquo; rule</a>. It says that its chunk\n<em>always</em> splits, so it only has one value: <code>0</code>. This is useful for things like\nline comments where you always need to split after it, even in the middle of an\nexpression <a id=\"10\" href=\"#10-note\" class=\"skull\">10</a>.</p>\n\n<p>Then there is a <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/rule/rule.dart#L104\">&ldquo;simple&rdquo; split rule</a>. It allows two values: <code>0</code> means\nnone of its chunks split and <code>1</code> means they all do. Since most splits are\nindependent of the others, this gets used for most of the splits in the program.</p>\n\n<p>Beyond that, there are <a href=\"https://github.com/dart-lang/dart_style/tree/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/rule\">a handful of special-case rules</a>. These are used\nin places where we want to more precisely control the configuration of a set of\nsplits. For example, the positional argument list in a function list is\ncontrolled by <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/rule/argument.dart\">a single rule</a>. A function call like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span><span class=\"p\">,</span> <span class=\"n\">third</span><span class=\"p\">)</span>\n</code></pre></div>\n<p>Will have splits after <code>function(</code>, <code>first,</code>, <code>second,</code>, and <code>third)</code>. They are\nall owned by a single rule that only allows the following configurations:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// 0: Don&#39;t split at all.</span>\n<span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span><span class=\"p\">,</span> <span class=\"n\">third</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 1: Split before the first.</span>\n<span class=\"n\">function</span><span class=\"p\">(</span>\n    <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span><span class=\"p\">,</span> <span class=\"n\">third</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 2: Split before only the last argument.</span>\n<span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span><span class=\"p\">,</span>\n    <span class=\"n\">third</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 3: Split before only the middle argument.</span>\n<span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"p\">,</span>\n    <span class=\"n\">second</span><span class=\"p\">,</span> <span class=\"n\">third</span><span class=\"p\">)</span>\n\n<span class=\"c1\">// 4: Split before all of them.</span>\n<span class=\"n\">function</span><span class=\"p\">(</span>\n    <span class=\"n\">first</span><span class=\"p\">,</span>\n    <span class=\"n\">second</span><span class=\"p\">,</span>\n    <span class=\"n\">third</span><span class=\"p\">)</span>\n</code></pre></div>\n<p>Having a single rule for this instead of individual rules for each argument lets\nus prohibit things like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">function</span><span class=\"p\">(</span>\n    <span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span><span class=\"p\">,</span>\n    <span class=\"n\">third</span><span class=\"p\">)</span>\n</code></pre></div>\n<h3>Constraints</h3>\n\n<p>Grouping a range of splits under a single rule helps us prevent split\nconfigurations we want to avoid like this, but it&rsquo;s not enough. There are more\ncomplex constraints we want to enforce like: &ldquo;if a split occurs inside a list\nelement, the list should split too&rdquo;. That avoids output like this:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"p\">[</span><span class=\"n\">first</span><span class=\"p\">,</span> <span class=\"n\">second</span> <span class=\"o\">+</span>\n    <span class=\"n\">third</span><span class=\"p\">,</span> <span class=\"n\">fourth</span><span class=\"p\">]</span>\n</code></pre></div>\n<p>Here, the list and the <code>+</code> expression have their own rules, but those rules need\nto interact. If the <code>+</code> takes value <code>1</code>, the list rule needs to as well. To\nsupport this, rules can <em>constrain</em> each other. Any rule can limit the values\nanother rule is allowed to take based on its own value. Typically, this is used\nto make a rule inside a nested expression force the rules surrounding itself to\nsplit when it does <a id=\"11\" href=\"#11-note\" class=\"skull\">11</a>.</p>\n\n<p>Finally, each rule has a <em>cost</em>. This is a numeric penalty that applies when any\nof that rule&rsquo;s chunks are split. This helps us determine which sets of splits\nare better or worse than others <a id=\"12\" href=\"#12-note\"\nclass=\"skull\">12</a>.</p>\n\n<p>Rule costs are only part of how overall fitness is calculated. Most of the cost\ncalculation comes from <em>spans</em>.</p>\n\n<h3>Spans</h3>\n\n<p>A <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk.dart#L331\">span</a> marks a series of contiguous chunks that we want to avoid splitting.\nI picture it like a rubber band stretching around them. If a split happens in\nany of those chunks, the span is broken. When that happens, the solution is\npenalized based on the cost of the span.</p>\n\n<p>Spans can nest arbitrarily deeply. In an expression like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">first</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">),</span> <span class=\"n\">second</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">))</span>\n</code></pre></div>\n<p>There will be spans around <code>a, b</code> and <code>c, d</code> to try to keep those argument lists\nfrom splitting, but also another span around <code>first(a, b), second(c, d)</code> to keep\nthe outer argument list from splitting.</p>\n\n<p>If a split occurs between <code>a,</code> and <code>b</code>, the <code>a, b</code> span splits, but so does the\n<code>first(a, b), second(c, d)</code> one. However, if a split occurs after <code>first(a, b),</code>\nthen the <code>a, b</code> span is still fine. In this way, spans teach the formatter to\nprefer splitting at a higher level of nesting when possible since it breaks\nfewer nested spans.</p>\n\n<h2>Parsing source to chunks</h2>\n\n<p>Converting your raw source code to this representation is fairly\nstraightforward. The formatter uses the wonderful <a href=\"https://pub.dartlang.org/packages/analyzer\">analyzer</a> package to parse\nyour code to an <a href=\"https://en.wikipedia.org/wiki/Abstract_syntax_tree\">AST</a>. This gives us a tree structure that represents every\nsingle byte of your program. Unlike many ASTs, it even includes comments.</p>\n\n<p>Once we have that, the formatter does a <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/source_visitor.dart\">top-down traversal of the\ntree</a>. As it walks, it <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_writer.dart\">writes out chunks, rules, and spans</a>\nfor the various grammar productions. This is where the formatting &ldquo;style&rdquo; is\ndetermined.</p>\n\n<p>There&rsquo;s no rocket science here, but there are a <em>lot</em> of <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk_builder.dart#L184\">hairy</a>\n<a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk_builder.dart#L210\">corner</a> <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk_builder.dart#L283\">cases</a>. Comments can appear in weird places. We have\nto handle weird things like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">function</span><span class=\"p\">(</span><span class=\"n\">argument</span><span class=\"p\">,</span> <span class=\"c1\">// comment</span>\n    <span class=\"n\">argument</span><span class=\"p\">)</span>\n</code></pre></div>\n<p>Here, we normally would have a split after the first argument owned by an\nargument list rule. But the line comment adheres to the <code>,</code> and has a hard split\nafter it, so we need to make sure the argument list rule handles that.</p>\n\n<p>Whitespace is only implicitly tracked by the AST so we have to <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/source_visitor.dart#L1979\">reconstitute\nit</a> in the few places where your original whitespace affects the output.\nHaving a detailed test suite really helps here.</p>\n\n<p>Once we&rsquo;ve visited the entire tree, the AST has been converted to a tree of\nchunks and a bunch of spans wrapped around pieces of it.</p>\n\n<h2>Formatting chunks</h2>\n\n<p>We&rsquo;ve got ourselves a big tree of chunks owned by a slew of rules. Earlier, I\nsaid a rule is like a knob. Now we get to dial them in.</p>\n\n<p>Doing this naïvely is infeasible. Even a small source file contains hundreds of\nindividual rules and the set of possible solutions is exponential in the number\nof rules.</p>\n\n<p>The first thing we do is <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/chunk_builder.dart#L736\">divide the chunk list</a> into regions we <em>know</em>\ncan&rsquo;t interfere with each other. These are roughly &ldquo;lines&rdquo; of code. So with:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">first</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">);</span>\n<span class=\"n\">second</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>We know that how we split the first statement has no effect on the second one.\nSo we run through the list of chunks and break them into shorter lists whenever\nwe hit a hard split that isn&rsquo;t nested inside an expression.</p>\n\n<p>Each of these shorter chunk lists is fed to the <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/line_splitter.dart\">line splitter</a>. Its job is to\npick the best set of values for all the rules used by the chunks in the line. In\nmost cases, this is trivial: if the whole line fits on the page, every rule gets\nset to zero&mdash;no splits&mdash;and we&rsquo;re done.</p>\n\n<p>When a line doesn&rsquo;t fit, the splitter has to figure out which combination of\nrule values produces the best result. That is:</p>\n\n<ol>\n<li><p>The one with the fewest characters that go over the column limit.</p></li>\n<li><p>The one with the lowest cost, based on which rules and spans were split.</p></li>\n</ol>\n\n<p>Calculating the cost for a set of rule values is pretty easy, but there are\nstill way too many permutations to brute force it. If we can&rsquo;t brute force it,\nhow do we do it?</p>\n\n<h2>How line splitting works</h2>\n\n<p>I&rsquo;m a college dropout so my knowledge of algorithms was fairly, um, rudimentary.\nSo before I interviewed at Google, I spent two days in a hotel room cramming as\nmany of them&mdash;mostly graph traversal&mdash;in my head as I could. At the\ntime, I thought graphs would never come up in the interviews&hellip;</p>\n\n<p>Then I had multiple interview questions that reduced down to doing the right\nkind of traversal over a graph. At the time, I thought this stuff would never be\nrelevant to my actual job&hellip;</p>\n\n<p>Then I spent the past few years at Google discovering that damn near every\nprogram I have to write can be reduced down to some kind of graph search. I\nwrote a <a href=\"https://pub.dartlang.org/\">package manager</a> where dependencies are a transitive closure and\nversion constraint solving is graph based. My <a href=\"https://github.com/munificent/hauberk\">hobby roguelike</a> uses\ngraphs for pathfinding. Graphs out the wazoo. I can do BFS in my sleep now.</p>\n\n<p>Naturally, after several other failed approaches, I found that line splitting\ncan be handled like a graph search problem <a id=\"13\" href=\"#13-note\"\nclass=\"skull\">13</a>. Each node in the graph represents a\n<a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/solve_state.dart\"><em>solution</em></a>&mdash;a set of values for each rule. Solutions can be\n<em>partial</em>: some rules may be left with their values unbound.</p>\n\n<p>From a given partial solution (including the initial &ldquo;no rules bound&rdquo; one),\nthere are edge to new partial solutions. Each binds one additional rule to a\nvalue. By starting from an empty solution and walking this graph, we eventually\nreach complete solutions where all of the rules have been bound to values.</p>\n\n<p>Graph search is great if you know where your destination is and you&rsquo;re trying to\nfind the best path. But we don&rsquo;t actually know that. We don&rsquo;t know what the best\ncomplete solution <em>is</em>. (If we did, we&rsquo;ve be done already!)</p>\n\n<p>Given this, no textbook graph search algorithm is sufficient. We need to apply\nsome domain knowledge&mdash;we need to take advantage of rules and conditions\nimplicit in the <em>specific</em> problem we&rsquo;re solving.</p>\n\n<p>After a dozen dead ends, I found three (sort of four) that are enough to get it\nfinding the right solution quickly:</p>\n\n<h3>Bailing early</h3>\n\n<p>We are trying to minimize two soft constraints at the same time:</p>\n\n<ol>\n<li><p>We want to minimize the number of characters that overflow the line length\nlimit. We can&rsquo;t make this a hard constraint that there is <em>no</em> overflow\nbecause it&rsquo;s possible for a long identifier or string literal to overflow in\n<em>every</em> solution. In that case, we still need to find the one that&rsquo;s closest\nto fitting.</p></li>\n<li><p>We want to find the lowest cost&mdash;the fewest split rules and broken\nspans.</p></li>\n</ol>\n\n<p>The first constraint dominates the second: we&rsquo;ll prefer a solution with any cost\nif it fits one more character in. In practice, there is almost always a solution\nthat does fit, so it usually comes down to picking the lowest cost solution <a\nid=\"14\" href=\"#14-note\" class=\"skull\">14</a>.</p>\n\n<p>We don&rsquo;t know <em>a priori</em> what the cost of the winning solution will be, but we\ndo know one useful piece of information: <em>forcing a rule to split always\nincreases the cost</em>.</p>\n\n<p>If we treat any unbound rule as being implicitly unsplit <a id=\"15\"\nhref=\"#15-note\" class=\"skull\">15</a>, that means the starting solution with\neverything unbound always has the lowest cost (zero). We can then explore\noutward from there in order of increasing cost by adding one rule at a time.</p>\n\n<p>This is a basic <a href=\"https://en.wikipedia.org/wiki/Best-first_search\">best-first search</a>: we keep a <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/solve_state_queue.dart\">running queue</a> of all of\nthe partial solutions we&rsquo;ve haven&rsquo;t explored yet, sorted from lowest cost to\nhighest. Each iteration, we pop a solution off.</p>\n\n<p>If the solution completely fits in the page width, then we know we&rsquo;ve won the\noverflow constraint. Since we&rsquo;re exploring in order of increasing cost, we also\nknow it&rsquo;s the lowest cost. So, ta-da!, <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/line_splitter.dart#L171\">we found the winner and can stop\nexploring</a>. Otherwise, if it has any unbound rules, we enqueue new\nsolutions, each of which binds one of those to a value.</p>\n\n<p>We basically explore the entire solution space in order of increasing cost. As\nsoon as we find a solution that fits in the page, we stop.</p>\n\n<h3>Avoiding dead ends</h3>\n\n<p>The above sounds pretty promising, but it turns out that there can be an\nimperial ton of &ldquo;low-cost but overflowing&rdquo; solutions. When you&rsquo;re trying to\nformat a really long line, there are plenty of ways it can <em>not</em> fit, and this\nalgorithm will try basically all of them. After all, they&rsquo;re low cost since they\ndon&rsquo;t have many splits.</p>\n\n<p>We need to avoid wasting time tweaking rules that aren&rsquo;t part of the problem.\nFor example, say we&rsquo;re looking at a partial solution like this:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Blog-friendly 40-char line limit:    |</span>\n<span class=\"n\">function</span><span class=\"p\">(</span>\n    <span class=\"n\">firstCall</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">c</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"p\">,</span> <span class=\"n\">g</span><span class=\"p\">,</span> <span class=\"n\">h</span><span class=\"p\">),</span>\n    <span class=\"n\">secondCall</span><span class=\"p\">(</span><span class=\"s2\">&quot;very long argument string here&quot;</span><span class=\"p\">));</span>\n</code></pre></div>\n<p>There are a bunch of ways we can split the arguments to <code>firstCall()</code>, but <em>we\ndon&rsquo;t need to</em>. Its line already fits. The only line we need to worry about is\nthe <code>secondCall()</code> one.</p>\n\n<p>So, when we are expanding a partial solution, we only bind <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/solve_state.dart#L28\">rules that have\nchunks <em>on overflowing lines</em></a>. If all of a rule&rsquo;s chunks are on lines\nthat already fit, we don&rsquo;t mess with it. In fact, we don&rsquo;t even worry about\nrules on any overflowing line but the first. Since tweaking the first line will\naffect the others, there&rsquo;s no reason to worry about them yet <a id=\"16\"\nhref=\"#16-note\" class=\"skull\">16</a>.</p>\n\n<p>This <em>dramatically</em> cuts down &ldquo;branchiness&rdquo; of the graph. Even though a partial\nsolution may have dozens of unbound rules, usually only a couple are on long\nlines and only those get explored.</p>\n\n<h3>Pruning redundant branches</h3>\n\n<p>This gets us pretty far, but the splitter can still go off the deep end in some\ncases. The problem is that within large statements, you still run into cases\nwhere how you format part of the statement is <em>mostly</em> independent of later\nparts.</p>\n\n<p>Take something like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">// Blog-friendly 40-char line limit:    |</span>\n<span class=\"k\">new</span> <span class=\"n\">Compiler</span><span class=\"p\">(</span>\n    <span class=\"nl\">assertions:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;checked-mode&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">annotations:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;annotations&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">primitives:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;primitives&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">minify:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;minify&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">preserve:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;preserve&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">liveAnalysis:</span> <span class=\"n\">check</span><span class=\"p\">(</span><span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;live&#39;</span><span class=\"p\">),</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;analysis&#39;</span><span class=\"p\">)),</span>\n    <span class=\"nl\">multi:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;multi&#39;</span><span class=\"p\">),</span>\n    <span class=\"nl\">sourceMap:</span> <span class=\"n\">options</span><span class=\"p\">.</span><span class=\"n\">has</span><span class=\"p\">(</span><span class=\"s1\">&#39;source-map&#39;</span><span class=\"p\">));</span>\n</code></pre></div>\n<p>Each of those named arguments can be split in a few different ways. And, since\nthose are less nested&mdash;which means fewer split spans&mdash;than that nasty\n<code>liveAnalysis:</code> line, <em>it will try every combination of all of them</em> before it\nfinally gets down to the business of splitting that <code>check()</code> call.</p>\n\n<p>The best way to split the <code>liveAnalysis:</code> line is the best way to split it\nregardless of how we split <code>assertions:</code> or <code>annotations:</code>. In other words,\nthere are big branches of the solution space that initially differ in irrelevant\nways, but eventually reconvene to roughly the same solution. We traverse every\nsingle one of them.</p>\n\n<p>What we need is a way to prune entire branches of the solution space. Given two\npartial solutions A and B, if we could say not just &ldquo;A is better than B&rdquo; but\n&ldquo;every solution we can get to from A will be better than every solution we can\nget to from B&rdquo; then we can discard B <em>and the entire branch of solutions\nstemming from it</em>.</p>\n\n<p>It took some work, but I finally figured out that you <em>can</em> do this in many\ncases. Given two partial solutions, if one has a lower cost than the other and:</p>\n\n<ul>\n<li><p>They have the same set of unbound rules (but their bound rules have different\nvalues, obviously).</p></li>\n<li><p>None of their bound rules are on the same line as an unbound rule.</p></li>\n<li><p>None of their bound rules place constraints on an unbound rule.</p></li>\n</ul>\n\n<p>If all of those are true, then the one with a lower cost will always lead to\nsolutions that also have a lower cost. Its entire branch wins. We can <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/solve_state_queue.dart#L124\">discard\nthe other solution</a> and everything that it leads to. Once I got <em>this</em>\nworking, the formatter could line split damn near anything in record time <a\nid=\"17\" href=\"#17-note\" class=\"skull\">17</a>.</p>\n\n<h3>An escape hatch</h3>\n\n<p>Alas, that &ldquo;damn near&rdquo; is significant. There are still a <em>few</em> cases where the\nformatter takes a long time. I&rsquo;ve only ever seen this on machine generated code.\nStuff like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">ResolutionCopier</span> <span class=\"p\">{</span>\n  <span class=\"err\">@</span><span class=\"n\">override</span>\n  <span class=\"kt\">bool</span> <span class=\"n\">visitClassDeclaration</span><span class=\"p\">(</span><span class=\"n\">ClassDeclaration</span> <span class=\"n\">node</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">ClassDeclaration</span> <span class=\"n\">toNode</span> <span class=\"o\">=</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"n\">_toNode</span> <span class=\"o\">as</span> <span class=\"n\">ClassDeclaration</span><span class=\"p\">;</span>\n    <span class=\"k\">return</span> <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n        <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n            <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n                <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span><span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span><span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n                        <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span><span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n                            <span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span><span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span><span class=\"n\">javaBooleanAnd</span><span class=\"p\">(</span>\n                                    <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">documentationComment</span><span class=\"p\">,</span>\n                                        <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">documentationComment</span><span class=\"p\">),</span>\n                                    <span class=\"n\">_isEqualNodeLists</span><span class=\"p\">(</span>\n                                        <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">metadata</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">metadata</span><span class=\"p\">)),</span>\n                                <span class=\"n\">_isEqualTokens</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">abstractKeyword</span><span class=\"p\">,</span>\n                                    <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">abstractKeyword</span><span class=\"p\">)),</span> <span class=\"n\">_isEqualTokens</span><span class=\"p\">(</span>\n                                <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">classKeyword</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">classKeyword</span><span class=\"p\">)),</span>\n                            <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span>\n                                <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">name</span><span class=\"p\">)),</span> <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span>\n                            <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">typeParameters</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">typeParameters</span><span class=\"p\">)),</span>\n                        <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span>\n                            <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">extendsClause</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">extendsClause</span><span class=\"p\">)),</span>\n                    <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span>\n                        <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">withClause</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">withClause</span><span class=\"p\">)),</span> <span class=\"n\">_isEqualNodes</span><span class=\"p\">(</span>\n                    <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">implementsClause</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">implementsClause</span><span class=\"p\">)),</span>\n                <span class=\"n\">_isEqualTokens</span><span class=\"p\">(</span><span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">leftBracket</span><span class=\"p\">,</span> <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">leftBracket</span><span class=\"p\">)),</span>\n            <span class=\"n\">_isEqualNodeLists</span><span class=\"p\">(</span>\n                <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">members</span><span class=\"p\">,</span>\n                <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">members</span><span class=\"p\">)),</span>\n        <span class=\"n\">_isEqualTokens</span><span class=\"p\">(</span>\n            <span class=\"n\">node</span><span class=\"p\">.</span><span class=\"n\">rightBracket</span><span class=\"p\">,</span>\n            <span class=\"n\">toNode</span><span class=\"p\">.</span><span class=\"n\">rightBracket</span><span class=\"p\">));</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Yeah, welcome to my waking nightmare. Unsurprisingly, code like this bogs down\nthe formatter. I want dartfmt to be usable in things like presubmit scripts\nwhere it will have a ton of weird code thrown at it and it <em>must</em> complete in a\nreliable amount of time.</p>\n\n<p>So there is one final escape hatch. If the line splitter tries, like, 5,000\nsolutions and still hasn&rsquo;t found a winner yet, it just picks the best it found\nso far and <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_splitting/line_splitter.dart#L181\">bails</a>.</p>\n\n<p>In practice, I only see it hit this case on generated code. Thank God.</p>\n\n<h2>Finally, output</h2>\n\n<p>Once the line splitter has picked values for all of the rules, the rest is easy.\nThe formatter <a href=\"https://github.com/dart-lang/dart_style/blob/3b3277668b2ff0cb7be954c3217c73264454bd7c/lib/src/line_writer.dart\">walks the tree of chunks</a>, printing their text. When a\nrule forces a chunk to split, it outputs a newline (or two), updates the\nindentation appropriately and keeps trucking.</p>\n\n<p>The end result is a string of (I hope!) beautifully formatted Dart code. So much\nwork just to add or remove a few spaces!</p>\n\n<h3>Footnotes</h3>\n\n<p><a id=\"1-note\" href=\"#1\" class=\"skull-note\">1</a> Yes, I really did brute force\nall of the combinations at first. It let me focus on getting the output correct\nbefore I worried about performance. Speed was fine for most statements. The\nother few wouldn&rsquo;t finish until after the heat death of the universe.</p>\n\n<p><a id=\"2-note\" href=\"#2\" class=\"skull-note\">2</a> For most of the time, the\nformatter <em>did</em> use dynamic programming and memoization. I felt like a wizard\nwhen I first figured out how to do it. It worked fairly well, but was a\nnightmare to debug.</p>\n\n<p>It was <em>highly</em> recursive, and ensuring that the keys to the memoization table\nwere precise enough to not cause bugs but not <em>so</em> precise that the cache\nlookups always fail was a very delicate balancing act. Over time, the amount of\ndata needed to uniquely identify the state of a subproblem grew, including\nthings like the entire expression nesting stack at a point in the line, and the\nmemoization table performed worse and worse.</p>\n\n<p><a id=\"3-note\" href=\"#3\" class=\"skull-note\">3</a> The IR evolved constantly.\nSpans and rules were later additions. Even the way chunks tracked indentation\nchanged frequently. Indentation used to be stored in levels, where each level\nwas two spaces. Then directly in spaces. Expression nesting went through a\nnumber of representations.</p>\n\n<p>In all of this, the IR&rsquo;s job is to balance being easy for the front-end to\n<em>produce</em> while being efficient for the back end to <em>consume</em>. The back end\nreally drives this. The IR is structured to be the right data structure for the\nalgorithm the back end wants to use.</p>\n\n<p><a id=\"4-note\" href=\"#4\" class=\"skull-note\">4</a> Comments were the one of the\nbiggest challenges. The formatter initially assumed there would be no newlines\nin some places. Who would expect a newline, say, between the keywords in\n<code>abstract class</code>? Alas, there&rsquo;s nothing preventing a user from doing:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">abstract</span> <span class=\"c1\">// Oh, crap. A line comment.</span>\n<span class=\"kd\">class</span> <span class=\"nc\">Foo</span> <span class=\"p\">{}</span>\n</code></pre></div>\n<p>So I had to do a ton of work to make it resilient in the face of comments and\nnewlines appearing in all sorts of weird places. There&rsquo;s no single clean\nsolution for this, just lots of edge cases and special handling.</p>\n\n<p><a id=\"5-note\" href=\"#5\" class=\"skull-note\">5</a> The back end is where all of\nthe performance challenges come from, and it went through two almost complete\nrewrites before it ended up where it is today.</p>\n\n<p><a id=\"6-note\" href=\"#6\" class=\"skull-note\">6</a> I started from a simpler\nformatter written by a teammate that treated text, whitespace, and splits all as\nseparate chunks. I unified those so that each chunk included non-whitespace\ntext, line split information, and whitespace information if it didn&rsquo;t split.\nThat simplified a lot.</p>\n\n<p><a id=\"7-note\" href=\"#7\" class=\"skull-note\">7</a> When I added support for\nbetter indentation of nested functions, that broke the code that split source\ninto separately splittable regions. For a while, a single top-level statement\nwould be split as a single unit, even if it contained nested functions with\nhundreds of lines of code. It was&hellip; not fast.</p>\n\n<p><a id=\"8-note\" href=\"#8\" class=\"skull-note\">8</a> Ideally, the split information\nin a chunk would describe the split <em>before</em> the chunk&rsquo;s text. This would avoid\nthe pointless split information on the last chunk, and also solve annoying\nspecial-case handling of the indentation before the very first chunk.</p>\n\n<p>I&rsquo;ve tried to correct this mistake a number of times, but it causes a\nnear-infinite number of off-by-one bugs and I just haven&rsquo;t had the time to push\nit all the way through and fix everything.</p>\n\n<p><a id=\"9-note\" href=\"#9\" class=\"skull-note\">9</a> Rules are a relatively recent\naddition. Originally each chunk&rsquo;s split was handled independently. You could\nspecify some relations between them like &ldquo;if this chunk splits then this other\none has to as well&rdquo;, but you could not express things like &ldquo;only one of these\nthree chunks may split&rdquo;</p>\n\n<p>Eventually, I realized the latter is what I really needed to get argument lists\nformatting well, so I conceived of rules as a separate concept and rewrote the\nfront and line splitter to work using those.</p>\n\n<p><a id=\"10-note\" href=\"#10\" class=\"skull-note\">10</a> At first, I thought hard\nsplits weren&rsquo;t needed. Any place a mandatory newline appears (like between two\nstatements) is a place where you could just break the list of chunks in two and\nline split each half independently. From the line splitter&rsquo;s perspective, there\nwould be no hard splits.</p>\n\n<p>Which would work&hellip; except for line comments:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">some</span><span class=\"p\">(</span><span class=\"n\">expression</span><span class=\"p\">,</span>\n   <span class=\"c1\">// with a line comment</span>\n   <span class=\"n\">rightInTheMiddleOfIt</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>This has to be split as a single unit to get the expression nesting and\nindentation correct, but it also contains a mandatory newline after the line\ncomment.</p>\n\n<p><a id=\"11-note\" href=\"#11\" class=\"skull-note\">11</a> There used to be a separate\nclass for a &ldquo;multisplit&rdquo; to directly handle forcing outer expressions to split\nwhen inner ones did. Once rules came along, they also needed to express\nconstraints between them, and eventually those constraints were expressive\nenough to be able to handle the multisplit behavior directly and multisplits\nwere removed.</p>\n\n<p><a id=\"12-note\" href=\"#12\" class=\"skull-note\">12</a> I spent a <em>lot</em> of time\ntuning costs for different grammar productions to control how tightly bound\ndifferent expressions were. The goal was to allow splits at the places where the\nreader thought code was &ldquo;loosest&rdquo;, so stuff like higher precedence expressions\nwould have higher costs.</p>\n\n<p>Tuning these costs was a nightmare. It was like a hanging mobile where tweaking\none cost would unbalance all of the others. On more than one occasion, I found\nmyself considering making them floating point instead of integers, a sure sign\nof madness.</p>\n\n<p>It turns out spans are what you really want in order to express looseness.\nNested infix operators then fall out naturally because you have more spans\naround the deeper nested operands. The parse tree gives it to you for free.</p>\n\n<p>These days, almost every chunk and span has a cost of 1, and it&rsquo;s the <em>quantity</em>\nof nested spans and contained chunks that determine where it splits.</p>\n\n<p><a id=\"13-note\" href=\"#13\" class=\"skull-note\">13</a> I had known that\n<a href=\"http://clang.llvm.org/docs/ClangFormat.html\">clang-format</a> worked this way for a long time, but I could never wrap my head\naround how to apply it to dartfmt&rsquo;s richer chunk/rule/span system.</p>\n\n<p>I took a lot of walks along the bike trail next to work trying to think through\na way to get graph search working when the two numbers being optimized (overflow\ncharacters and cost) are in direct opposition, and we don&rsquo;t even know what the\ngoal state looks like. It took a long time before it clicked. Even then, it\ndidn&rsquo;t work at all until I figured out the right heuristics to use to optimize\nit.</p>\n\n<p><a id=\"14-note\" href=\"#14\" class=\"skull-note\">14</a> For a long time, overflow\nand cost were treated as a single fitness function. Every overflow character\njust added a very high value to the cost to make the splitter strongly want to\navoid them.</p>\n\n<p>Splitting overflow out as a separate metric turned out to be key to getting the\ngraph search to work because it let us order the solutions by cost independently\nof overflow characters.</p>\n\n<p><a id=\"15-note\" href=\"#15\" class=\"skull-note\">15</a> I went back and forth on\nhow an unbound rule should implicitly behave. Treating it as implicitly split\ngives you solutions with fewer overflow characters sooner. Treating it as\nunsplit gives you lower costs.</p>\n\n<p><a id=\"16-note\" href=\"#16\" class=\"skull-note\">16</a> Oh, God. I tried a million\ndifferent ways to reduce the branchiness before I hit on only looking at rules\nin the first long line. I&rsquo;m still amazed that it works.</p>\n\n<p>I could also talk about how controlling branchiness lets us avoid reaching the\nsame state from multiple different paths. After all, it&rsquo;s a <em>graph</em>, but\neverything I&rsquo;ve described talks about it like it&rsquo;s a tree. By carefully\ncontrolling how we extend partial solutions, we ensure we only take a single\npath to any given complete solution.</p>\n\n<p>Before I got that working, I had to keep a &ldquo;visited&rdquo; set to make sure we didn&rsquo;t\nexplore the same regions twice, but just maintaining that set was a big\nperformance sink.</p>\n\n<p><a id=\"17-note\" href=\"#17\" class=\"skull-note\">17</a> Discarding overlapping\nbranches is the last macro-optimization I did and its behavior is very subtle.\nCorrectly detecting when two partial solutions overlap took a <em>lot</em> of\niteration. Every time I thought I had it, one random weird test would fail where\nit accidentally collapsed two branches that <em>would</em> eventually diverge.</p>\n\n<p>That bullet list was paid for in blood, sweat, and tears. I honestly don&rsquo;t think\nI could have figured them out at all until late in the project when I had a\n<a href=\"https://github.com/dart-lang/dart_style/tree/3b3277668b2ff0cb7be954c3217c73264454bd7c/test\">comprehensive test suite</a>.</p>\n","contentSnippet":".skull, .skull-note {\n  border-radius: 4px;\n  -moz-border-radius: 4px;\n  -webkit-border-radius: 4px;\n\n  background: hsl(35, 100%, 96%);\n  color: hsl(35, 40%, 50%);\n\n  padding: 1px;\n}\n\n.skull::before, .skull-note::before {\n  content: \"\\01f480\";\n  margin-right: -2px;\n}\n\na.skull {\n  position: relative;\n  top: -0.4em;\n  font-size: 80%;\n}\n\na.skull:hover, a.skull-note:hover {\n  color: hsl(35, 100%, 30%);\n}\n\n\nThe hardest program I’ve ever written, once you strip out the whitespace, is\n3,835 lines long. That handful of code took me almost a year to write. Granted,\nthat doesn’t take into account the code that didn’t make it. The commit\nhistory shows that I deleted 20,704 lines of code over that time. Every\nsurviving line has about three fallen comrades.\nIf it took that much thrashing to get it right, you’d expect it to do something\npretty deep right? Maybe a low-level hardware interface or some wicked graphics\ndemo with tons of math and pumping early-90s-style techno? A likely-to-turn-evil\nmachine learning AI Skynet thing?\nNope. It reads in a string and writes out a string. The only difference between\nthe input and output strings is that it modifies some of the whitespace\ncharacters. I’m talking, of course, about an automated code\nformatter.\nIntroducing dartfmt\nI work on the Dart programming language. Part of my job is helping make more\nDart code readable, idiomatic, and consistent, which is why I ended up writing\nour style guide. That was a good first step, but any style guide written in\nEnglish is either so brief that it’s ambiguous, or so long that no one reads it.\nGo’s “gofmt” tool showed a better solution: automatically format\neverything. Code is easier to read and contribute to because it’s already in the\nstyle you’re used to. Even if the output of the formatter isn’t great, it ends\nthose interminable soul-crushing arguments on code reviews about formatting.\nOf course, I still have to sell users on running the formatter in the first\nplace. For that, having great output really does matter. Also, I’m pretty\npicky with the formatting in my own code, and I didn’t want to tell users to use\na tool that I didn’t use myself.\nGetting that kind of quality means applying pretty sophisticated formatting\nrules. That in turn makes performance difficult. I knew balancing quality and\nspeed would be hard, but I didn’t realize just how deep the rabbit hole went.\nI have finally emerged back into the sun, and I’m pleased with what I brought\nback. I like the output, and the performance is solid. On my laptop, it can blow\nthrough over two million lines of code in about 45 seconds, using a single core.\nWhy is formatting hard?\nAt this point, you’re probably thinking, “Wait. What’s so hard about\nformatting?” After you’ve parsed, can’t you just walk the AST and\npretty-print it with some whitespace?\nIf every statement fit within the column limit of the page, yup. It’s a piece of\ncake. (I think that’s what gofmt does.) But our formatter also keeps your code\nwithin the line length limit. That means adding line breaks (or “splits” as the\nformatter calls them), and determining the best place to add those is famously\nhard.\nCheck out this guy:\nexperimentalBootstrap = document.querySelectorAll('link').any((link) =>\n    link.attributes['rel'] == 'import' &&\n        link.attributes['href'] == POLYMER_EXPERIMENTAL_HTML);\n\n\nThere are thirteen places where a line break is possible here according to our\nstyle rules. That’s 8,192 different combinations if we brute force them all 1. The search space we have to cover is\nexponentially large, and even ranking different solutions is a subtle problem.\nIs it better to split before the .any()? Why or why not?\nWhat is up with the skulls?\nI had two goals with this article: to explain how dartfmt works, and to show a realistic picture of how a real programmer solves a difficult problem with all of the messiness that entails. Alas, the first is more than long enough to try your patience, so I shunted all of the dead ends and failed attempts to footnotes. Click the skulls to laugh at my misfortune.\nIn Dart, we made things harder on ourselves. We have anonymous functions, lots\nof higher-order functions, and—until we added async and\nawait—used futures for concurrency. That means lots of\ncallbacks and lots of long method chains. Some Dart users really dig a\nfunctional style and appear to be playing a game where whoever crams the most\nwork before a single semicolon wins.\nHere’s real code from an amateur player:\n_bindAssignablePropsOn.forEach((String eventName) => node\n    .addEventListener(eventName, (_) => zone.run(() => bindAssignableProps\n        .forEach((propAndExp) => propAndExp[1].assign(\n            scope.context, jsNode[propAndExp[0]])))));\n\n\nYeah, that’s four nested functions. 1,048,576 ways to split that one. Here’s one\nof the best that I’ve found. This is what a pro player brings to the game:\nreturn doughnutFryer\n    .start()\n    .then((_) => _frostingGlazer.start())\n    .then((_) => Future.wait([\n          _conveyorBelts.start(),\n          sprinkleSprinkler.start(),\n          sauceDripper.start()\n        ]))\n    .catchError(cannotGetConveyorBeltRunning)\n    .then((_) => tellEveryoneDonutsAreJustAboutDone())\n    .then((_) => Future.wait([\n          croissantFactory.start(),\n          _giantBakingOvens.start(),\n          butterbutterer.start()\n        ])\n            .catchError(_handleBakingFailures)\n            .timeout(scriptLoadingTimeout, onTimeout: _handleBakingFailures)\n            .catchError(cannotGetConveyorBeltRunning))\n    .catchError(cannotGetConveyorBeltRunning)\n    .then((_) {\n  _logger.info(\"Let's eat!\");\n});\n\n\n(The funny names are because this was sanitized from internal code.) That’s a\nsingle statement, all 565 characters of it. There are about 549 billion ways\nwe could line break it.\nUltimately, this is what the formatter does. It applies some fairly\nsophisticated ranking rules to find the best set of line breaks from an\nexponential solution space. Note that “best” is a property of the entire\nstatement being formatted. A line break changes the indentation of the\nremainder of the statement, which in turn affects which other line breaks are\nneeded. Sorry, Knuth. No dynamic programming this time 2.\nI think the formatter does a good job, but how it does it is a mystery to\nusers. People get spooked when robots surprise them, so I thought I would trace\nthe inner workings of its metal mind. And maybe try to justify to myself why it\ntook me a year to write a program whose behavior in many ways is\nindistinguishable from cat.\nHow the formatter sees your code\nAs you’d expect from a program that works on source code, the formatter is\nstructured much like a compiler. It has a front end that parses your code\nand converts that to an intermediate representation 3. It does some optimization and clean up on\nthat 4, and then the IR goes to a\nback end 5 that produces the final\noutput. The main objects here are chunks, rules, and spans.\nChunks\nA chunk is an atomic unit of formatting. It’s a contiguous region of\ncharacters that we know will not contain any line breaks. Given this code:\nformat /* comment */ this;\n\n\nWe break it into these chunks: format /* comment */ this;.\nChunks are similar to a token in a conventional compiler, but they tend to\nbe, well, chunkier. Often, the text for several tokens ends up in the same\nchunk, like this and ; here. If a line break can never occur between two\ntokens, they end up in the same chunk 6.\nChunks are mostly linear. For example, given an expression like:\nsome(nested, function(ca + ll))\n\n\nWe chunk it to the flat list: some( nested, function( ca + ll)).\nWe could treat an entire source file like a single flat sequence of chunks, but\nit would take forever and a day to line break the whole thing 7. With things like long chains of asynchronous\ncode, a single “statement” may be hundreds of lines of code containing several\nnested functions or collections that each contain their own piles of code.\nWe can’t treat those nested functions or collection literals entirely\nindependently because the surrounding expression affects how they are indented.\nThat in turn affects how long their lines are. Indent a function body two more\nspaces and now its statements have two fewer spaces before they hit the end of\nthe line.\nInstead, we treat nested block bodies as a separate little list of chunks to be\nformatted mostly on their own but subordinate to where they appear. The chunk\nthat begins one of these literals, like the { preceding a function or map,\ncontains a list of child block chunks for the contained block. In other words,\nchunks do form a tree, but one that only reflects block nesting, not\nexpressions.\nThe end of a chunk marks the point where a split may occur in the final output,\nand the chunk has some data describing it 8. It keeps track of whether a blank line should be added\nbetween the chunks (like\nbetween two class definitions), how much the next line should be indented, and\nthe expression nesting depth at that point in the code.\nThe most important bit of data about the split is the rule that controls it 9.\nRules\nEach potential split in the program is owned by a rule. A single rule may\nown the splits of several chunks. For example, a series of binary operators of\nthe same kind like a + b + c + d uses a single rule for the splits after each\n+ operator.\nA rule controls which of its splits break and which don’t. It determines this\nbased on the state that the rule is in, which it calls its value. You can\nthink of a rule like a dial and the value is what you’ve turned it to. Given a\nvalue, the rule will tell you which of its chunks get split.\nThe simplest rule is a “hard split” rule. It says that its chunk\nalways splits, so it only has one value: 0. This is useful for things like\nline comments where you always need to split after it, even in the middle of an\nexpression 10.\nThen there is a “simple” split rule. It allows two values: 0 means\nnone of its chunks split and 1 means they all do. Since most splits are\nindependent of the others, this gets used for most of the splits in the program.\nBeyond that, there are a handful of special-case rules. These are used\nin places where we want to more precisely control the configuration of a set of\nsplits. For example, the positional argument list in a function list is\ncontrolled by a single rule. A function call like:\nfunction(first, second, third)\n\n\nWill have splits after function(, first,, second,, and third). They are\nall owned by a single rule that only allows the following configurations:\n// 0: Don't split at all.\nfunction(first, second, third)\n\n// 1: Split before the first.\nfunction(\n    first, second, third)\n\n// 2: Split before only the last argument.\nfunction(first, second,\n    third)\n\n// 3: Split before only the middle argument.\nfunction(first,\n    second, third)\n\n// 4: Split before all of them.\nfunction(\n    first,\n    second,\n    third)\n\n\nHaving a single rule for this instead of individual rules for each argument lets\nus prohibit things like:\nfunction(\n    first, second,\n    third)\n\n\nConstraints\nGrouping a range of splits under a single rule helps us prevent split\nconfigurations we want to avoid like this, but it’s not enough. There are more\ncomplex constraints we want to enforce like: “if a split occurs inside a list\nelement, the list should split too”. That avoids output like this:\n[first, second +\n    third, fourth]\n\n\nHere, the list and the + expression have their own rules, but those rules need\nto interact. If the + takes value 1, the list rule needs to as well. To\nsupport this, rules can constrain each other. Any rule can limit the values\nanother rule is allowed to take based on its own value. Typically, this is used\nto make a rule inside a nested expression force the rules surrounding itself to\nsplit when it does 11.\nFinally, each rule has a cost. This is a numeric penalty that applies when any\nof that rule’s chunks are split. This helps us determine which sets of splits\nare better or worse than others 12.\nRule costs are only part of how overall fitness is calculated. Most of the cost\ncalculation comes from spans.\nSpans\nA span marks a series of contiguous chunks that we want to avoid splitting.\nI picture it like a rubber band stretching around them. If a split happens in\nany of those chunks, the span is broken. When that happens, the solution is\npenalized based on the cost of the span.\nSpans can nest arbitrarily deeply. In an expression like:\nfunction(first(a, b), second(c, d))\n\n\nThere will be spans around a, b and c, d to try to keep those argument lists\nfrom splitting, but also another span around first(a, b), second(c, d) to keep\nthe outer argument list from splitting.\nIf a split occurs between a, and b, the a, b span splits, but so does the\nfirst(a, b), second(c, d) one. However, if a split occurs after first(a, b),\nthen the a, b span is still fine. In this way, spans teach the formatter to\nprefer splitting at a higher level of nesting when possible since it breaks\nfewer nested spans.\nParsing source to chunks\nConverting your raw source code to this representation is fairly\nstraightforward. The formatter uses the wonderful analyzer package to parse\nyour code to an AST. This gives us a tree structure that represents every\nsingle byte of your program. Unlike many ASTs, it even includes comments.\nOnce we have that, the formatter does a top-down traversal of the\ntree. As it walks, it writes out chunks, rules, and spans\nfor the various grammar productions. This is where the formatting “style” is\ndetermined.\nThere’s no rocket science here, but there are a lot of hairy\ncorner cases. Comments can appear in weird places. We have\nto handle weird things like:\nfunction(argument, // comment\n    argument)\n\n\nHere, we normally would have a split after the first argument owned by an\nargument list rule. But the line comment adheres to the , and has a hard split\nafter it, so we need to make sure the argument list rule handles that.\nWhitespace is only implicitly tracked by the AST so we have to reconstitute\nit in the few places where your original whitespace affects the output.\nHaving a detailed test suite really helps here.\nOnce we’ve visited the entire tree, the AST has been converted to a tree of\nchunks and a bunch of spans wrapped around pieces of it.\nFormatting chunks\nWe’ve got ourselves a big tree of chunks owned by a slew of rules. Earlier, I\nsaid a rule is like a knob. Now we get to dial them in.\nDoing this naïvely is infeasible. Even a small source file contains hundreds of\nindividual rules and the set of possible solutions is exponential in the number\nof rules.\nThe first thing we do is divide the chunk list into regions we know\ncan’t interfere with each other. These are roughly “lines” of code. So with:\nfirst(line);\nsecond(line);\n\n\nWe know that how we split the first statement has no effect on the second one.\nSo we run through the list of chunks and break them into shorter lists whenever\nwe hit a hard split that isn’t nested inside an expression.\nEach of these shorter chunk lists is fed to the line splitter. Its job is to\npick the best set of values for all the rules used by the chunks in the line. In\nmost cases, this is trivial: if the whole line fits on the page, every rule gets\nset to zero—no splits—and we’re done.\nWhen a line doesn’t fit, the splitter has to figure out which combination of\nrule values produces the best result. That is:\nThe one with the fewest characters that go over the column limit.\n\n\nThe one with the lowest cost, based on which rules and spans were split.\n\n\n\nCalculating the cost for a set of rule values is pretty easy, but there are\nstill way too many permutations to brute force it. If we can’t brute force it,\nhow do we do it?\nHow line splitting works\nI’m a college dropout so my knowledge of algorithms was fairly, um, rudimentary.\nSo before I interviewed at Google, I spent two days in a hotel room cramming as\nmany of them—mostly graph traversal—in my head as I could. At the\ntime, I thought graphs would never come up in the interviews…\nThen I had multiple interview questions that reduced down to doing the right\nkind of traversal over a graph. At the time, I thought this stuff would never be\nrelevant to my actual job…\nThen I spent the past few years at Google discovering that damn near every\nprogram I have to write can be reduced down to some kind of graph search. I\nwrote a package manager where dependencies are a transitive closure and\nversion constraint solving is graph based. My hobby roguelike uses\ngraphs for pathfinding. Graphs out the wazoo. I can do BFS in my sleep now.\nNaturally, after several other failed approaches, I found that line splitting\ncan be handled like a graph search problem 13. Each node in the graph represents a\nsolution—a set of values for each rule. Solutions can be\npartial: some rules may be left with their values unbound.\nFrom a given partial solution (including the initial “no rules bound” one),\nthere are edge to new partial solutions. Each binds one additional rule to a\nvalue. By starting from an empty solution and walking this graph, we eventually\nreach complete solutions where all of the rules have been bound to values.\nGraph search is great if you know where your destination is and you’re trying to\nfind the best path. But we don’t actually know that. We don’t know what the best\ncomplete solution is. (If we did, we’ve be done already!)\nGiven this, no textbook graph search algorithm is sufficient. We need to apply\nsome domain knowledge—we need to take advantage of rules and conditions\nimplicit in the specific problem we’re solving.\nAfter a dozen dead ends, I found three (sort of four) that are enough to get it\nfinding the right solution quickly:\nBailing early\nWe are trying to minimize two soft constraints at the same time:\nWe want to minimize the number of characters that overflow the line length\nlimit. We can’t make this a hard constraint that there is no overflow\nbecause it’s possible for a long identifier or string literal to overflow in\nevery solution. In that case, we still need to find the one that’s closest\nto fitting.\n\n\nWe want to find the lowest cost—the fewest split rules and broken\nspans.\n\n\n\nThe first constraint dominates the second: we’ll prefer a solution with any cost\nif it fits one more character in. In practice, there is almost always a solution\nthat does fit, so it usually comes down to picking the lowest cost solution 14.\nWe don’t know a priori what the cost of the winning solution will be, but we\ndo know one useful piece of information: forcing a rule to split always\nincreases the cost.\nIf we treat any unbound rule as being implicitly unsplit 15, that means the starting solution with\neverything unbound always has the lowest cost (zero). We can then explore\noutward from there in order of increasing cost by adding one rule at a time.\nThis is a basic best-first search: we keep a running queue of all of\nthe partial solutions we’ve haven’t explored yet, sorted from lowest cost to\nhighest. Each iteration, we pop a solution off.\nIf the solution completely fits in the page width, then we know we’ve won the\noverflow constraint. Since we’re exploring in order of increasing cost, we also\nknow it’s the lowest cost. So, ta-da!, we found the winner and can stop\nexploring. Otherwise, if it has any unbound rules, we enqueue new\nsolutions, each of which binds one of those to a value.\nWe basically explore the entire solution space in order of increasing cost. As\nsoon as we find a solution that fits in the page, we stop.\nAvoiding dead ends\nThe above sounds pretty promising, but it turns out that there can be an\nimperial ton of “low-cost but overflowing” solutions. When you’re trying to\nformat a really long line, there are plenty of ways it can not fit, and this\nalgorithm will try basically all of them. After all, they’re low cost since they\ndon’t have many splits.\nWe need to avoid wasting time tweaking rules that aren’t part of the problem.\nFor example, say we’re looking at a partial solution like this:\n// Blog-friendly 40-char line limit:    |\nfunction(\n    firstCall(a, b, c, d, e, f, g, h),\n    secondCall(\"very long argument string here\"));\n\n\nThere are a bunch of ways we can split the arguments to firstCall(), but we\ndon’t need to. Its line already fits. The only line we need to worry about is\nthe secondCall() one.\nSo, when we are expanding a partial solution, we only bind rules that have\nchunks on overflowing lines. If all of a rule’s chunks are on lines\nthat already fit, we don’t mess with it. In fact, we don’t even worry about\nrules on any overflowing line but the first. Since tweaking the first line will\naffect the others, there’s no reason to worry about them yet 16.\nThis dramatically cuts down “branchiness” of the graph. Even though a partial\nsolution may have dozens of unbound rules, usually only a couple are on long\nlines and only those get explored.\nPruning redundant branches\nThis gets us pretty far, but the splitter can still go off the deep end in some\ncases. The problem is that within large statements, you still run into cases\nwhere how you format part of the statement is mostly independent of later\nparts.\nTake something like:\n// Blog-friendly 40-char line limit:    |\nnew Compiler(\n    assertions: options.has('checked-mode'),\n    annotations: options.has('annotations'),\n    primitives: options.has('primitives'),\n    minify: options.has('minify'),\n    preserve: options.has('preserve'),\n    liveAnalysis: check(options.has('live'), options.has('analysis')),\n    multi: options.has('multi'),\n    sourceMap: options.has('source-map'));\n\n\nEach of those named arguments can be split in a few different ways. And, since\nthose are less nested—which means fewer split spans—than that nasty\nliveAnalysis: line, it will try every combination of all of them before it\nfinally gets down to the business of splitting that check() call.\nThe best way to split the liveAnalysis: line is the best way to split it\nregardless of how we split assertions: or annotations:. In other words,\nthere are big branches of the solution space that initially differ in irrelevant\nways, but eventually reconvene to roughly the same solution. We traverse every\nsingle one of them.\nWhat we need is a way to prune entire branches of the solution space. Given two\npartial solutions A and B, if we could say not just “A is better than B” but\n“every solution we can get to from A will be better than every solution we can\nget to from B” then we can discard B and the entire branch of solutions\nstemming from it.\nIt took some work, but I finally figured out that you can do this in many\ncases. Given two partial solutions, if one has a lower cost than the other and:\nThey have the same set of unbound rules (but their bound rules have different\nvalues, obviously).\n\n\nNone of their bound rules are on the same line as an unbound rule.\n\n\nNone of their bound rules place constraints on an unbound rule.\n\n\n\nIf all of those are true, then the one with a lower cost will always lead to\nsolutions that also have a lower cost. Its entire branch wins. We can discard\nthe other solution and everything that it leads to. Once I got this\nworking, the formatter could line split damn near anything in record time 17.\nAn escape hatch\nAlas, that “damn near” is significant. There are still a few cases where the\nformatter takes a long time. I’ve only ever seen this on machine generated code.\nStuff like:\nclass ResolutionCopier {\n  @override\n  bool visitClassDeclaration(ClassDeclaration node) {\n    ClassDeclaration toNode = this._toNode as ClassDeclaration;\n    return javaBooleanAnd(\n        javaBooleanAnd(\n            javaBooleanAnd(\n                javaBooleanAnd(javaBooleanAnd(javaBooleanAnd(\n                        javaBooleanAnd(javaBooleanAnd(\n                            javaBooleanAnd(javaBooleanAnd(javaBooleanAnd(\n                                    _isEqualNodes(node.documentationComment,\n                                        toNode.documentationComment),\n                                    _isEqualNodeLists(\n                                        node.metadata, toNode.metadata)),\n                                _isEqualTokens(node.abstractKeyword,\n                                    toNode.abstractKeyword)), _isEqualTokens(\n                                node.classKeyword, toNode.classKeyword)),\n                            _isEqualNodes(\n                                node.name, toNode.name)), _isEqualNodes(\n                            node.typeParameters, toNode.typeParameters)),\n                        _isEqualNodes(\n                            node.extendsClause, toNode.extendsClause)),\n                    _isEqualNodes(\n                        node.withClause, toNode.withClause)), _isEqualNodes(\n                    node.implementsClause, toNode.implementsClause)),\n                _isEqualTokens(node.leftBracket, toNode.leftBracket)),\n            _isEqualNodeLists(\n                node.members,\n                toNode.members)),\n        _isEqualTokens(\n            node.rightBracket,\n            toNode.rightBracket));\n  }\n}\n\n\nYeah, welcome to my waking nightmare. Unsurprisingly, code like this bogs down\nthe formatter. I want dartfmt to be usable in things like presubmit scripts\nwhere it will have a ton of weird code thrown at it and it must complete in a\nreliable amount of time.\nSo there is one final escape hatch. If the line splitter tries, like, 5,000\nsolutions and still hasn’t found a winner yet, it just picks the best it found\nso far and bails.\nIn practice, I only see it hit this case on generated code. Thank God.\nFinally, output\nOnce the line splitter has picked values for all of the rules, the rest is easy.\nThe formatter walks the tree of chunks, printing their text. When a\nrule forces a chunk to split, it outputs a newline (or two), updates the\nindentation appropriately and keeps trucking.\nThe end result is a string of (I hope!) beautifully formatted Dart code. So much\nwork just to add or remove a few spaces!\nFootnotes\n1 Yes, I really did brute force\nall of the combinations at first. It let me focus on getting the output correct\nbefore I worried about performance. Speed was fine for most statements. The\nother few wouldn’t finish until after the heat death of the universe.\n2 For most of the time, the\nformatter did use dynamic programming and memoization. I felt like a wizard\nwhen I first figured out how to do it. It worked fairly well, but was a\nnightmare to debug.\nIt was highly recursive, and ensuring that the keys to the memoization table\nwere precise enough to not cause bugs but not so precise that the cache\nlookups always fail was a very delicate balancing act. Over time, the amount of\ndata needed to uniquely identify the state of a subproblem grew, including\nthings like the entire expression nesting stack at a point in the line, and the\nmemoization table performed worse and worse.\n3 The IR evolved constantly.\nSpans and rules were later additions. Even the way chunks tracked indentation\nchanged frequently. Indentation used to be stored in levels, where each level\nwas two spaces. Then directly in spaces. Expression nesting went through a\nnumber of representations.\nIn all of this, the IR’s job is to balance being easy for the front-end to\nproduce while being efficient for the back end to consume. The back end\nreally drives this. The IR is structured to be the right data structure for the\nalgorithm the back end wants to use.\n4 Comments were the one of the\nbiggest challenges. The formatter initially assumed there would be no newlines\nin some places. Who would expect a newline, say, between the keywords in\nabstract class? Alas, there’s nothing preventing a user from doing:\nabstract // Oh, crap. A line comment.\nclass Foo {}\n\n\nSo I had to do a ton of work to make it resilient in the face of comments and\nnewlines appearing in all sorts of weird places. There’s no single clean\nsolution for this, just lots of edge cases and special handling.\n5 The back end is where all of\nthe performance challenges come from, and it went through two almost complete\nrewrites before it ended up where it is today.\n6 I started from a simpler\nformatter written by a teammate that treated text, whitespace, and splits all as\nseparate chunks. I unified those so that each chunk included non-whitespace\ntext, line split information, and whitespace information if it didn’t split.\nThat simplified a lot.\n7 When I added support for\nbetter indentation of nested functions, that broke the code that split source\ninto separately splittable regions. For a while, a single top-level statement\nwould be split as a single unit, even if it contained nested functions with\nhundreds of lines of code. It was… not fast.\n8 Ideally, the split information\nin a chunk would describe the split before the chunk’s text. This would avoid\nthe pointless split information on the last chunk, and also solve annoying\nspecial-case handling of the indentation before the very first chunk.\nI’ve tried to correct this mistake a number of times, but it causes a\nnear-infinite number of off-by-one bugs and I just haven’t had the time to push\nit all the way through and fix everything.\n9 Rules are a relatively recent\naddition. Originally each chunk’s split was handled independently. You could\nspecify some relations between them like “if this chunk splits then this other\none has to as well”, but you could not express things like “only one of these\nthree chunks may split”\nEventually, I realized the latter is what I really needed to get argument lists\nformatting well, so I conceived of rules as a separate concept and rewrote the\nfront and line splitter to work using those.\n10 At first, I thought hard\nsplits weren’t needed. Any place a mandatory newline appears (like between two\nstatements) is a place where you could just break the list of chunks in two and\nline split each half independently. From the line splitter’s perspective, there\nwould be no hard splits.\nWhich would work… except for line comments:\nsome(expression,\n   // with a line comment\n   rightInTheMiddleOfIt);\n\n\nThis has to be split as a single unit to get the expression nesting and\nindentation correct, but it also contains a mandatory newline after the line\ncomment.\n11 There used to be a separate\nclass for a “multisplit” to directly handle forcing outer expressions to split\nwhen inner ones did. Once rules came along, they also needed to express\nconstraints between them, and eventually those constraints were expressive\nenough to be able to handle the multisplit behavior directly and multisplits\nwere removed.\n12 I spent a lot of time\ntuning costs for different grammar productions to control how tightly bound\ndifferent expressions were. The goal was to allow splits at the places where the\nreader thought code was “loosest”, so stuff like higher precedence expressions\nwould have higher costs.\nTuning these costs was a nightmare. It was like a hanging mobile where tweaking\none cost would unbalance all of the others. On more than one occasion, I found\nmyself considering making them floating point instead of integers, a sure sign\nof madness.\nIt turns out spans are what you really want in order to express looseness.\nNested infix operators then fall out naturally because you have more spans\naround the deeper nested operands. The parse tree gives it to you for free.\nThese days, almost every chunk and span has a cost of 1, and it’s the quantity\nof nested spans and contained chunks that determine where it splits.\n13 I had known that\nclang-format worked this way for a long time, but I could never wrap my head\naround how to apply it to dartfmt’s richer chunk/rule/span system.\nI took a lot of walks along the bike trail next to work trying to think through\na way to get graph search working when the two numbers being optimized (overflow\ncharacters and cost) are in direct opposition, and we don’t even know what the\ngoal state looks like. It took a long time before it clicked. Even then, it\ndidn’t work at all until I figured out the right heuristics to use to optimize\nit.\n14 For a long time, overflow\nand cost were treated as a single fitness function. Every overflow character\njust added a very high value to the cost to make the splitter strongly want to\navoid them.\nSplitting overflow out as a separate metric turned out to be key to getting the\ngraph search to work because it let us order the solutions by cost independently\nof overflow characters.\n15 I went back and forth on\nhow an unbound rule should implicitly behave. Treating it as implicitly split\ngives you solutions with fewer overflow characters sooner. Treating it as\nunsplit gives you lower costs.\n16 Oh, God. I tried a million\ndifferent ways to reduce the branchiness before I hit on only looking at rules\nin the first long line. I’m still amazed that it works.\nI could also talk about how controlling branchiness lets us avoid reaching the\nsame state from multiple different paths. After all, it’s a graph, but\neverything I’ve described talks about it like it’s a tree. By carefully\ncontrolling how we extend partial solutions, we ensure we only take a single\npath to any given complete solution.\nBefore I got that working, I had to keep a “visited” set to make sure we didn’t\nexplore the same regions twice, but just maintaining that set was a big\nperformance sink.\n17 Discarding overlapping\nbranches is the last macro-optimization I did and its behavior is very subtle.\nCorrectly detecting when two partial solutions overlap took a lot of\niteration. Every time I thought I had it, one random weird test would fail where\nit accidentally collapsed two branches that would eventually diverge.\nThat bullet list was paid for in blood, sweat, and tears. I honestly don’t think\nI could have figured them out at all until late in the project when I had a\ncomprehensive test suite.","guid":"http://journal.stuffwithstuff.com/2015/09/08/the-hardest-program-ive-ever-written","isoDate":"2015-09-08T07:00:00.000Z","timestamp":"9/8/2015"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"What the Hero Sees: Field-of-View for Roguelikes","link":"http://journal.stuffwithstuff.com/2015/09/07/what-the-hero-sees/","pubDate":"Mon, 07 Sep 2015 00:00:00 -0700","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<style>\ncanvas {\n  display: inline-block;\n  max-width: 100%;\n  cursor: crosshair;\n}\n</style>\n\n<p>This is a record for me. I&rsquo;ve been procrastinating this post for eight years. I\nmoved four times, got married, had two kids, and ported my roguelike to <a href=\"https://www.dartlang.org/\">a\nlanguage</a> that didn&rsquo;t exist when I first wrote the code this post is\nabout. You can thank Simon Andersson for prodding me to finally write it down.</p>\n\n<p>Every good game, or genre of games, has a pyramid of rewards. From simple\npleasures that mete out a droplet of endorphins when you click the next button\nup to the deep, abiding feeling of accomplishment you get from slaying the final\nboss on nightmare mode.</p>\n\n<p>The roguelike genre standardizes many of these, and one of my favorites is the\njoy of <em>exploring the dungeon</em>. You start out on a black screen, only one tiny\nroom visible. As you walk around, the map incrementally fills in&mdash;a perfect\ngraphical representation of your own knowledge and mastery increasing.</p>\n\n<figure>\n  <canvas id=\"explore\">Sorry, you need canvas support for this demo.</canvas>\n  <figcaption>Click and drag the hero to explore. Click walls and floors to\n  alter the dungeon.</figcaption>\n</figure>\n\n<p>There wouldn&rsquo;t be much to explore if your hero could see through walls. The\nsecond they entered the dungeon, the entire map would be filled in, all of the\ncrypt&rsquo;s hidden secrets laid bare to warrior and player alike. To prevent that,\nwe need to simulate something that seems trivial: <em>walls blocking the hero&rsquo;s\nview</em>.</p>\n\n<p>In the roguelike scene, this is referred to as <em>field of view</em>, and there are <a href=\"http://www.roguebasin.com/index.php?title=Field_of_Vision\">a\nnumber of ways to do it</a>. Many of the posts linked there talk about &ldquo;light&rdquo;\nand &ldquo;shadow&rdquo; as well, but they calculate the same thing as visilibity. In both\ncases, we&rsquo;re trying to find the set of tiles that can be reached by rays\nemanating from some point source. I&rsquo;ll use both terms interchangeably.</p>\n\n<h2>Brute force line-of-sight?</h2>\n\n<p>The simplest solution is to repurpose your line-of-sight code. You already need\ncode to determine if there is an open line from one point to another on the map.\nYou use that to tell if things like arrows and fireballs reach their target or\nbounce harmlessly off the dungeon wall.</p>\n\n<p>This is invariably done using <a href=\"https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm\">Bresenham&rsquo;s line algorithm</a>. It&rsquo;s one\nof the true classics of graphics programming&mdash;an elegant, simple algorithm\nfrom 1962 that&rsquo;s still useful today. (This kind of living connection to CS&rsquo;s\npast is one of the things I love about hacking on a roguelike. How often do you\nhave a good reason to recode a procedure originally devised for a 1950s-era drum\nplotter?)</p>\n\n<p>As you&rsquo;d imagine for an algorithm designed to run on a machine that took punch\ncards, it&rsquo;s very efficient&hellip; for tracing a line between <em>two points</em>. But field\nof view is different: we need to scan the entire dungeon&mdash;or at least the\npart that fits on the player&rsquo;s screen&mdash;and calculate the visibility of\n<em>every</em> tile.</p>\n\n<p>You actually <em>can</em> run Bresenham a few thousand times whenever the hero moves on\na modern machine, but doing that feels, well, like cheating somehow. Can we come\nup with something more efficient?</p>\n\n<p>The answer is, of course, &ldquo;yes&rdquo;. (It would be a short post if it wasn&rsquo;t.) And,\nin fact, a lot of others have already done so. But, one lazy sunny Saturday\nmorning in 2006, I didn&rsquo;t see any I liked and wanted to come up with one that\nmade more sense to me.</p>\n\n<h2>Pieces of eight</h2>\n\n<p>If you have the mind of a programmer, the first thing you do when presented with\na problem is to break it into multiple (hopefully) smaller problems. Our goal is\nto calculate the entire field of view surrounding the hero, but we can slice\nthat 360&deg; problem into 45&deg; pie pieces. One looks like this:</p>\n\n<figure>\n  <canvas id=\"octant\">Sorry, you need canvas support for this demo.</canvas>\n  <figcaption>Click to paint a wedge.</figcaption>\n</figure>\n\n<p>This wedge is called an <a href=\"https://en.wikipedia.org/wiki/Octant_(plane_geometry)\"><em>octant</em></a>, and it&rsquo;s common in 2D algorithms. We\ncan paint every tile in that triangle like so:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"m\">1</span><span class=\"p\">;</span> <span class=\"n\">row</span> <span class=\"o\">&lt;</span> <span class=\"n\">maxDistance</span><span class=\"p\">;</span> <span class=\"n\">row</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"m\">0</span><span class=\"p\">;</span> <span class=\"n\">col</span> <span class=\"o\">&lt;=</span> <span class=\"n\">row</span><span class=\"p\">;</span> <span class=\"n\">col</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"kd\">var</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">hero</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">col</span><span class=\"p\">;</span>\n    <span class=\"kd\">var</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">hero</span><span class=\"p\">.</span><span class=\"n\">y</span> <span class=\"o\">-</span> <span class=\"n\">row</span><span class=\"p\">;</span>\n\n    <span class=\"n\">paint</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>If we take that wedge and apply some transformations, we can cover the entire\nfield around the hero. The above code is most of the way there. If you squint,\nyou can see there are two coordinate systems. The <code>row</code> and <code>col</code> variables are\nin the octant&rsquo;s coordinate space. Meanwhile, <code>x</code> and <code>y</code> are in real tile\nspace&mdash;what you see on screen.</p>\n\n<p>The first two lines inside the loops map octant space to tile space. Using just\n<code>+</code> and <code>-</code> and <code>row</code> and <code>col</code>, there are eight ways to calculate <code>x</code> and <code>y</code>.\nEach represents a reflection or 90&deg; rotation of the original octant. If we\nenumerate them all, we get:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"n\">Vec</span> <span class=\"n\">transformOctant</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">octant</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"k\">switch</span> <span class=\"p\">(</span><span class=\"n\">octant</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">case</span> <span class=\"m\">0</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">row</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">1</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">col</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">2</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span> <span class=\"n\">row</span><span class=\"p\">,</span>  <span class=\"n\">col</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">3</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span> <span class=\"n\">col</span><span class=\"p\">,</span>  <span class=\"n\">row</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">4</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">col</span><span class=\"p\">,</span>  <span class=\"n\">row</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">5</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">row</span><span class=\"p\">,</span>  <span class=\"n\">col</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">6</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">col</span><span class=\"p\">);</span>\n    <span class=\"k\">case</span> <span class=\"m\">7</span><span class=\"o\">:</span> <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Vec</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">row</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Each case represents a different octant, starting at the top and going clockwise\naround the circle. Painting them all covers the whole view (with a bit of\ninnocuous overlap):</p>\n\n<figure>\n  <canvas id=\"octants\">Sorry, you need canvas support for this demo.</canvas>\n  <figcaption>Click to paint the whole view.</figcaption>\n</figure>\n\n<p>From here on out, we only have deal with a single triangle&rsquo;s worth of <code>row</code> and\n<code>col</code>, and we can cover the entire field of view just by running the same code\neight times, once for each octant.</p>\n\n<h2>A Line of Shadows</h2>\n\n<p>Another way to approach a problem is to negate it, and that&rsquo;s what this\nalgorithm does. Instead of calculating which tiles are visible, it figures out\nwhich are hidden, which put it in a family of algorithms that do &ldquo;shadow\ncasting&rdquo;. Before I explain it, try it out yourself:</p>\n\n<figure>\n  <canvas id=\"shadow-cast\">Sorry, you need canvas support for this demo.</canvas>\n  <figcaption>Drag the slider up to advance the shadow line. Click anywhere\n  else to change the dungeon.</figcaption>\n</figure>\n\n<p>We start at the hero and work upwards one row at a time. As we sweep through the\noctant, we incrementally update a data structure called the <em>shadow line</em>. It&rsquo;s\nthe white line you see next to the slider. It tracks which parts of the row are\nin the shade of opaque tiles on previous rows and which aren&rsquo;t.</p>\n\n<p>The line is a series of segments, each representing one obscured region of the\nline. We can define this like so:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">ShadowLine</span> <span class=\"p\">{</span>\n  <span class=\"kd\">final</span> <span class=\"n\">List</span><span class=\"o\">&lt;</span><span class=\"n\">Shadow</span><span class=\"o\">&gt;</span> <span class=\"n\">_shadows</span> <span class=\"o\">=</span> <span class=\"p\">[];</span>\n<span class=\"p\">}</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">Shadow</span> <span class=\"p\">{</span>\n  <span class=\"kt\">num</span> <span class=\"n\">start</span><span class=\"p\">;</span>\n  <span class=\"kt\">num</span> <span class=\"n\">end</span><span class=\"p\">;</span>\n\n  <span class=\"n\">Shadow</span><span class=\"p\">(</span><span class=\"k\">this</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"k\">this</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>The interesting question is, &ldquo;What is the <em>range</em> of <code>start</code> and <code>end</code>?&rdquo; The\nnaïve answer is to use tile coordinates. If we&rsquo;re five rows in and the shadow\nline is five tiles long, the segment coordinates would range from 0 to 5.</p>\n\n<p>The problem is that since light expands outwards from a point, the shadows\nstretch out as they get farther away. We don&rsquo;t want to have to recalculate the\nsegment positions each time we advance a row and the rays spread out.</p>\n\n<p>Instead, we store their <em>slopes</em>. Regardless of what row we&rsquo;re on, they always\nrange from 0 (the short edge of the octant) to 1 (the diagonal edge). They are\ndistance-independent. This is what the black line in the demo above shows. As\nyou click to add and remove wall, you can see new shadows appear, but they don&rsquo;t\nmove or grow as you sweep the row up and down.</p>\n\n<h2>Projecting a tile</h2>\n\n<p>The tricky part is calculating those slopes given some tile in the octant. There\nare a couple of corner cases to consider. Literally. A tile is a square, and the\nshadow it projects goes from one corner of the square to another.</p>\n\n<p>Given our canonical octant, we know the tile will be above and to the right of\nthe hero. That means the projected shadow&rsquo;s extent will always be from the\ntop-left corner of a tile to the bottom-right corner. The other two corners lie\nin the middle of the shadow. (This isn&rsquo;t strictly true if the tile is straight\nup from the hero, but we can safely ignore that.)</p>\n\n<p>What we need, then, is to calculate the slopes of those two corners of a tile.\nThe math is a kind of fussy, but it&rsquo;s:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"c1\">/// Creates a [Shadow] that corresponds to the projected</span>\n<span class=\"c1\">/// silhouette of the tile at [row], [col].</span>\n<span class=\"n\">Shadow</span> <span class=\"n\">projectTile</span><span class=\"p\">(</span><span class=\"kt\">int</span> <span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">col</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"n\">topLeft</span> <span class=\"o\">=</span> <span class=\"n\">col</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">row</span> <span class=\"o\">+</span> <span class=\"m\">2</span><span class=\"p\">);</span>\n  <span class=\"kd\">var</span> <span class=\"n\">bottomRight</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">col</span> <span class=\"o\">+</span> <span class=\"m\">1</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">row</span> <span class=\"o\">+</span> <span class=\"m\">1</span><span class=\"p\">);</span>\n  <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"n\">Shadow</span><span class=\"p\">(</span><span class=\"n\">topLeft</span><span class=\"p\">,</span> <span class=\"n\">bottomRight</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>This function has two uses. The obvious one is that we call this for each opaque\ntile and add its result to the shadow line. But the projection comes into play\nbefore that too.</p>\n\n<p>You can think of the result of this function as the shadow that the tile casts\n<em>past</em> itself, but it also describes the projection from the hero <em>to</em> this\ntile. In other words, it describes which angles need to be unblocked for this\ntile to be visible.</p>\n\n<p>When we scan a row, we call <code>projectTile()</code> on every tile&mdash;transparent or\nopaque&mdash; and compare it to the existing shadow line. If the tile&rsquo;s\nprojection is covered by the shadow line, we know it can&rsquo;t be seen. If it isn&rsquo;t,\nit can.</p>\n\n<p>An interesting edge case is tiles whose projection is <em>partially</em> covered by the\nshadow line. Different games take different approaches here. Mine is considered\n<em>permissive</em>: if you can see any part of a tile, it&rsquo;s visible. A tile&rsquo;s\nprojection has to be totally covered by the shadow to be hidden. If you want\nsomething less permissive, this algorithm is easy to tweak.</p>\n\n<p>Let&rsquo;s code! First, we&rsquo;ll add a method to see if one shadow totally covers\nanother:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">Shadow</span> <span class=\"p\">{</span>\n  <span class=\"c1\">/// Returns `true` if [other] is completely covered by this shadow.</span>\n  <span class=\"kt\">bool</span> <span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">Shadow</span> <span class=\"n\">other</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">start</span> <span class=\"o\">&lt;=</span> <span class=\"n\">other</span><span class=\"p\">.</span><span class=\"n\">start</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">end</span> <span class=\"o\">&gt;=</span> <span class=\"n\">other</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">;</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Then we use that to see if any shadow in the line covers the tile:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">ShadowLine</span> <span class=\"p\">{</span>\n  <span class=\"kt\">bool</span> <span class=\"n\">isInShadow</span><span class=\"p\">(</span><span class=\"n\">Shadow</span> <span class=\"n\">projection</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">shadow</span> <span class=\"k\">in</span> <span class=\"n\">_shadows</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">projection</span><span class=\"p\">))</span> <span class=\"k\">return</span> <span class=\"kc\">true</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">return</span> <span class=\"kc\">false</span><span class=\"p\">;</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Using that, we can determine the visibility of every tile in a row. Given a\nShadowLine in <code>line</code>, and a set of tiles in <code>tiles</code>, it&rsquo;s:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"m\">0</span><span class=\"p\">;</span> <span class=\"n\">col</span> <span class=\"o\">&lt;=</span> <span class=\"n\">row</span><span class=\"p\">;</span> <span class=\"n\">col</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"n\">projection</span> <span class=\"o\">=</span> <span class=\"n\">_projectTile</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">);</span>\n  <span class=\"kd\">var</span> <span class=\"n\">pos</span> <span class=\"o\">=</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">transformOctant</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"n\">octant</span><span class=\"p\">);</span>\n  <span class=\"n\">tiles</span><span class=\"p\">[</span><span class=\"n\">pos</span><span class=\"p\">].</span><span class=\"n\">isVisible</span> <span class=\"o\">=</span> <span class=\"o\">!</span><span class=\"n\">line</span><span class=\"p\">.</span><span class=\"n\">isInShadow</span><span class=\"p\">(</span><span class=\"n\">projection</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<h2>Inky pools of shadows</h2>\n\n<p>We can calculate which tiles are obscured by the shadow line, but that isn&rsquo;t\nvery useful since our shadow line is always empty right now. Let&rsquo;s fix that.</p>\n\n<p>As we trace the row, each time we hit an opaque tile, we add it to the shadow\nline. If the shadow line was a simple list of these little shadow segments, the\nlist would get longer and longer. In a dense dungeon, the hero may be near\nhundreds of solid tiles. Having to walk through an increasingly long list of\nshadow segments to see if a tile is obscured would get slower and slower.</p>\n\n<p>Fortunately, I have a simple fix that makes the algorithm get <em>faster</em> as tiles\nocclude more of the view. <em>This</em> is the part where I think my algorithm is\npretty cool, and it&rsquo;s why I&rsquo;m excited to share it with you.</p>\n\n<p>Often, when a new segment is added to the shadow line, it overlaps other\nshadows. When that happens, we <em>merge</em> it with the existing shadows. The end\nresult is that the shadow line will have a single <code>Shadow</code> object for each\n<em>contiguous</em> range of obscured area.</p>\n\n<p>This does mean adding a new shadow to the line is more complex. There are a\nhandful of cases:</p>\n\n<ol>\n<li><p><strong>The shadow is contained within an existing one.</strong> That means the new shadow\ndoesn&rsquo;t cover any new territory, so we can discard it.</p></li>\n<li><p><strong>The shadow doesn&rsquo;t overlap any other ones.</strong> In this case, we insert it in\nsorted order between the segments that come before and after it.</p></li>\n<li><p><strong>The shadow overlaps another shadow on its starting edge.</strong> We take the\nprevious shadow and grow it to encompass the new shadow&rsquo;s endpoint and\ndiscard the new one.</p></li>\n<li><p><strong>The shadow overlaps another shadow on its ending edge.</strong> Do the same thing,\nbut in reverse: grow the following shadow to cover the new one.</p></li>\n<li><p><strong>The shadow overlaps shadows on <em>both</em> ends.</strong> This is the fun one. We take\nthe previous shadow and extend it to cover the <em>next</em> shadow&rsquo;s endpoint. Then\nwe discard both the new shadow and that next one.</p></li>\n</ol>\n\n<p>The first case doesn&rsquo;t change the list of shadows at all. In the second case,\nthe list of shadows gets longer. In the next two, adding a new shadow doesn&rsquo;t\ngrow the list, it just shifts an endpoint. The last case is the fun one: there,\nthe list gets <em>shorter</em>.</p>\n\n<p>(Pop quiz! Why don&rsquo;t we have to worry about cases where a shadow overlaps more\nthan two existing ones?)</p>\n\n<p>Here&rsquo;s the entire method to add a shadow to the line:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">ShadowLine</span> <span class=\"p\">{</span>\n  <span class=\"kt\">void</span> <span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Shadow</span> <span class=\"n\">shadow</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Figure out where to slot the new shadow in the list.</span>\n    <span class=\"kd\">var</span> <span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"m\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">for</span> <span class=\"p\">(;</span> <span class=\"n\">index</span> <span class=\"o\">&lt;</span> <span class=\"n\">_shadows</span><span class=\"p\">.</span><span class=\"n\">length</span><span class=\"p\">;</span> <span class=\"n\">index</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"c1\">// Stop when we hit the insertion point.</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">].</span><span class=\"n\">start</span> <span class=\"o\">&gt;=</span> <span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">)</span> <span class=\"k\">break</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// The new shadow is going here. See if it overlaps the</span>\n    <span class=\"c1\">// previous or next.</span>\n    <span class=\"kd\">var</span> <span class=\"n\">overlappingPrevious</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">index</span> <span class=\"o\">&gt;</span> <span class=\"m\">0</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"n\">index</span> <span class=\"o\">-</span> <span class=\"m\">1</span><span class=\"p\">].</span><span class=\"n\">end</span> <span class=\"o\">&gt;</span> <span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"n\">overlappingPrevious</span> <span class=\"o\">=</span> <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"n\">index</span> <span class=\"o\">-</span> <span class=\"m\">1</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"kd\">var</span> <span class=\"n\">overlappingNext</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">index</span> <span class=\"o\">&lt;</span> <span class=\"n\">_shadows</span><span class=\"p\">.</span><span class=\"n\">length</span> <span class=\"o\">&amp;&amp;</span>\n        <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">].</span><span class=\"n\">start</span> <span class=\"o\">&lt;</span> <span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"n\">overlappingNext</span> <span class=\"o\">=</span> <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">];</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c1\">// Insert and unify with overlapping shadows.</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">overlappingNext</span> <span class=\"o\">!=</span> <span class=\"kc\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">overlappingPrevious</span> <span class=\"o\">!=</span> <span class=\"kc\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Overlaps both, so unify one and delete the other.</span>\n        <span class=\"n\">overlappingPrevious</span><span class=\"p\">.</span><span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">overlappingNext</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">;</span>\n        <span class=\"n\">_shadows</span><span class=\"p\">.</span><span class=\"n\">removeAt</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">);</span>\n      <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Overlaps the next one, so unify it with that.</span>\n        <span class=\"n\">overlappingNext</span><span class=\"p\">.</span><span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">start</span><span class=\"p\">;</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">overlappingPrevious</span> <span class=\"o\">!=</span> <span class=\"kc\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Overlaps the previous one, so unify it with that.</span>\n        <span class=\"n\">overlappingPrevious</span><span class=\"p\">.</span><span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">shadow</span><span class=\"p\">.</span><span class=\"n\">end</span><span class=\"p\">;</span>\n      <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// Does not overlap anything, so insert.</span>\n        <span class=\"n\">_shadows</span><span class=\"p\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">shadow</span><span class=\"p\">);</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>OK, so that&rsquo;s kind of hairy, but it&rsquo;s not deep magic, just a bunch of different\ncases to handle. Clever readers are probably wondering why we don&rsquo;t do a binary\nsearch to find the insertion point. The list is sorted after all. If you want to\nbe super smart, go for it. In practice, I don&rsquo;t think it makes much of a\ndifference. The maximum size of the list is small enough that a linear search\nmay actually be faster.</p>\n\n<p>(Pop quiz two! What <em>is</em> the maximum size of the list? Show your work.)</p>\n\n<p>Very clever readers may have noticed we don&rsquo;t check for the first case, a\ncompletely contained shadow here. That&rsquo;s because we&rsquo;ve already done that check.\nEarlier, when we detect if this tile is visible, that also tells us if it&rsquo;s\nshadow is contained. If it is, we don&rsquo;t bother calling <code>add()</code>.</p>\n\n<p>There&rsquo;s another simple optimization we can do. If we get to the point where the\nshadow line is a single segment from 0 to 1&mdash;in other words, the whole line\nis in shadow&mdash;then we can skip all of the projection calculation, updating,\netc. Every tile will be hidden after that. Here&rsquo;s how we detect that:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kd\">class</span> <span class=\"nc\">ShadowLine</span> <span class=\"p\">{</span>\n  <span class=\"kt\">bool</span> <span class=\"kd\">get</span> <span class=\"n\">isFullShadow</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">_shadows</span><span class=\"p\">.</span><span class=\"n\">length</span> <span class=\"o\">==</span> <span class=\"m\">1</span> <span class=\"o\">&amp;&amp;</span>\n        <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"m\">0</span><span class=\"p\">].</span><span class=\"n\">start</span> <span class=\"o\">==</span> <span class=\"m\">0</span> <span class=\"o\">&amp;&amp;</span>\n        <span class=\"n\">_shadows</span><span class=\"p\">[</span><span class=\"m\">0</span><span class=\"p\">].</span><span class=\"n\">end</span> <span class=\"o\">==</span> <span class=\"m\">1</span><span class=\"p\">;</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"p\">...</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<h2>Putting it all together</h2>\n\n<p>OK, so we have code to:</p>\n\n<ol>\n<li><p>Walk over every octant.</p></li>\n<li><p>Walk every tile in an octant.</p></li>\n<li><p>Update the tile&rsquo;s visibility.</p></li>\n<li><p>Update the shadow line if the tile is opaque.</p></li>\n</ol>\n\n<p>Let&rsquo;s stitch the last few pieces together along with a dash of bounds checking.\nBuilding on top of what we have above, here&rsquo;s the top-level code to update the\nvisibility of the whole dungeon:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"kt\">void</span> <span class=\"n\">refreshVisibility</span><span class=\"p\">(</span><span class=\"n\">Vec</span> <span class=\"n\">hero</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">octant</span> <span class=\"o\">=</span> <span class=\"m\">0</span><span class=\"p\">;</span> <span class=\"n\">octant</span> <span class=\"o\">&lt;</span> <span class=\"m\">8</span><span class=\"p\">;</span> <span class=\"n\">octant</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">refreshOctant</span><span class=\"p\">(</span><span class=\"n\">hero</span><span class=\"p\">,</span> <span class=\"n\">octant</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"kt\">void</span> <span class=\"n\">refreshOctant</span><span class=\"p\">(</span><span class=\"n\">Vec</span> <span class=\"n\">hero</span><span class=\"p\">,</span> <span class=\"kt\">int</span> <span class=\"n\">octant</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"n\">line</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ShadowLine</span><span class=\"p\">();</span>\n  <span class=\"kd\">var</span> <span class=\"n\">fullShadow</span> <span class=\"o\">=</span> <span class=\"kc\">false</span><span class=\"p\">;</span>\n\n  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">row</span> <span class=\"o\">=</span> <span class=\"m\">1</span><span class=\"p\">;;</span> <span class=\"n\">row</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Stop once we go out of bounds.</span>\n    <span class=\"kd\">var</span> <span class=\"n\">pos</span> <span class=\"o\">=</span> <span class=\"n\">hero</span> <span class=\"o\">+</span> <span class=\"n\">transformOctant</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"m\">0</span><span class=\"p\">,</span> <span class=\"n\">octant</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">tiles</span><span class=\"p\">.</span><span class=\"n\">bounds</span><span class=\"p\">.</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">pos</span><span class=\"p\">))</span> <span class=\"k\">break</span><span class=\"p\">;</span>\n\n    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"n\">col</span> <span class=\"o\">=</span> <span class=\"m\">0</span><span class=\"p\">;</span> <span class=\"n\">col</span> <span class=\"o\">&lt;=</span> <span class=\"n\">row</span><span class=\"p\">;</span> <span class=\"n\">col</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"kd\">var</span> <span class=\"n\">pos</span> <span class=\"o\">=</span> <span class=\"n\">hero</span> <span class=\"o\">+</span> <span class=\"n\">transformOctant</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"n\">octant</span><span class=\"p\">);</span>\n\n      <span class=\"c1\">// If we&#39;ve traversed out of bounds, bail on this row.</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"n\">tiles</span><span class=\"p\">.</span><span class=\"n\">bounds</span><span class=\"p\">.</span><span class=\"n\">contains</span><span class=\"p\">(</span><span class=\"n\">pos</span><span class=\"p\">))</span> <span class=\"k\">break</span><span class=\"p\">;</span>\n\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">fullShadow</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"n\">tiles</span><span class=\"p\">[</span><span class=\"n\">pos</span><span class=\"p\">].</span><span class=\"n\">isVisible</span> <span class=\"o\">=</span> <span class=\"kc\">false</span><span class=\"p\">;</span>\n      <span class=\"p\">}</span> <span class=\"k\">else</span> <span class=\"p\">{</span>\n        <span class=\"kd\">var</span> <span class=\"n\">projection</span> <span class=\"o\">=</span> <span class=\"n\">projectTile</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">,</span> <span class=\"n\">col</span><span class=\"p\">);</span>\n\n        <span class=\"c1\">// Set the visibility of this tile.</span>\n        <span class=\"kd\">var</span> <span class=\"n\">visible</span> <span class=\"o\">=</span> <span class=\"o\">!</span><span class=\"n\">line</span><span class=\"p\">.</span><span class=\"n\">isInShadow</span><span class=\"p\">(</span><span class=\"n\">projection</span><span class=\"p\">);</span>\n        <span class=\"n\">tiles</span><span class=\"p\">[</span><span class=\"n\">pos</span><span class=\"p\">].</span><span class=\"n\">isVisible</span> <span class=\"o\">=</span> <span class=\"n\">visible</span><span class=\"p\">;</span>\n\n        <span class=\"c1\">// Add any opaque tiles to the shadow map.</span>\n        <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">visible</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">tiles</span><span class=\"p\">[</span><span class=\"n\">pos</span><span class=\"p\">].</span><span class=\"n\">isWall</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n          <span class=\"n\">line</span><span class=\"p\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">projection</span><span class=\"p\">);</span>\n          <span class=\"n\">fullShadow</span> <span class=\"o\">=</span> <span class=\"n\">line</span><span class=\"p\">.</span><span class=\"n\">isFullShadow</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>And there we have it. It runs very fast in wide open areas since there will be\nfew shadow segments and the list is short. Likewise, it runs fast in closed\nareas since the shadow list will also be short&mdash;it will contain a small\nnumber of long segments. It performs the worst in &ldquo;spotty&rdquo; areas with lots of\nsmall trees or pillars, but even there, the performance is pretty solid.</p>\n\n<p>I&rsquo;d love to say I implemented a bunch of other algorithms and this one came out\nthe winner, but honestly I was too lazy to that. I will say that this has never\nshowed up as a hot spot when I&rsquo;ve profiled the game. That&rsquo;s good enough for me,\nand I hope this will be helpful for you too.</p>\n\n<p>If you want to see all of the code for these demos, it&rsquo;s <a href=\"https://github.com/munificent/fov\">here</a>. Or, in\nthe context of <a href=\"https://github.com/munificent/hauberk\">my game</a> <a href=\"https://github.com/munificent/hauberk/blob/master/lib/src/engine/fov.dart\">here</a>.</p>\n\n<script type=\"application/dart\" src=\"/code/2015-09-07-what-the-hero-sees/main.dart\"></script>\n\n<script src=\"/code/2015-09-07-what-the-hero-sees/packages/browser/dart.js\"></script>\n","contentSnippet":"canvas {\n  display: inline-block;\n  max-width: 100%;\n  cursor: crosshair;\n}\n\n\nThis is a record for me. I’ve been procrastinating this post for eight years. I\nmoved four times, got married, had two kids, and ported my roguelike to a\nlanguage that didn’t exist when I first wrote the code this post is\nabout. You can thank Simon Andersson for prodding me to finally write it down.\nEvery good game, or genre of games, has a pyramid of rewards. From simple\npleasures that mete out a droplet of endorphins when you click the next button\nup to the deep, abiding feeling of accomplishment you get from slaying the final\nboss on nightmare mode.\nThe roguelike genre standardizes many of these, and one of my favorites is the\njoy of exploring the dungeon. You start out on a black screen, only one tiny\nroom visible. As you walk around, the map incrementally fills in—a perfect\ngraphical representation of your own knowledge and mastery increasing.\nSorry, you need canvas support for this demo.\n  Click and drag the hero to explore. Click walls and floors to\n  alter the dungeon.\n\n\nThere wouldn’t be much to explore if your hero could see through walls. The\nsecond they entered the dungeon, the entire map would be filled in, all of the\ncrypt’s hidden secrets laid bare to warrior and player alike. To prevent that,\nwe need to simulate something that seems trivial: walls blocking the hero’s\nview.\nIn the roguelike scene, this is referred to as field of view, and there are a\nnumber of ways to do it. Many of the posts linked there talk about “light”\nand “shadow” as well, but they calculate the same thing as visilibity. In both\ncases, we’re trying to find the set of tiles that can be reached by rays\nemanating from some point source. I’ll use both terms interchangeably.\nBrute force line-of-sight?\nThe simplest solution is to repurpose your line-of-sight code. You already need\ncode to determine if there is an open line from one point to another on the map.\nYou use that to tell if things like arrows and fireballs reach their target or\nbounce harmlessly off the dungeon wall.\nThis is invariably done using Bresenham’s line algorithm. It’s one\nof the true classics of graphics programming—an elegant, simple algorithm\nfrom 1962 that’s still useful today. (This kind of living connection to CS’s\npast is one of the things I love about hacking on a roguelike. How often do you\nhave a good reason to recode a procedure originally devised for a 1950s-era drum\nplotter?)\nAs you’d imagine for an algorithm designed to run on a machine that took punch\ncards, it’s very efficient… for tracing a line between two points. But field\nof view is different: we need to scan the entire dungeon—or at least the\npart that fits on the player’s screen—and calculate the visibility of\nevery tile.\nYou actually can run Bresenham a few thousand times whenever the hero moves on\na modern machine, but doing that feels, well, like cheating somehow. Can we come\nup with something more efficient?\nThe answer is, of course, “yes”. (It would be a short post if it wasn’t.) And,\nin fact, a lot of others have already done so. But, one lazy sunny Saturday\nmorning in 2006, I didn’t see any I liked and wanted to come up with one that\nmade more sense to me.\nPieces of eight\nIf you have the mind of a programmer, the first thing you do when presented with\na problem is to break it into multiple (hopefully) smaller problems. Our goal is\nto calculate the entire field of view surrounding the hero, but we can slice\nthat 360° problem into 45° pie pieces. One looks like this:\nSorry, you need canvas support for this demo.\n  Click to paint a wedge.\n\n\nThis wedge is called an octant, and it’s common in 2D algorithms. We\ncan paint every tile in that triangle like so:\nfor (var row = 1; row < maxDistance; row++) {\n  for (var col = 0; col <= row; col++) {\n    var x = hero.x + col;\n    var y = hero.y - row;\n\n    paint(x, y);\n  }\n}\n\n\nIf we take that wedge and apply some transformations, we can cover the entire\nfield around the hero. The above code is most of the way there. If you squint,\nyou can see there are two coordinate systems. The row and col variables are\nin the octant’s coordinate space. Meanwhile, x and y are in real tile\nspace—what you see on screen.\nThe first two lines inside the loops map octant space to tile space. Using just\n+ and - and row and col, there are eight ways to calculate x and y.\nEach represents a reflection or 90° rotation of the original octant. If we\nenumerate them all, we get:\nVec transformOctant(int row, int col, int octant) {\n  switch (octant) {\n    case 0: return new Vec( col, -row);\n    case 1: return new Vec( row, -col);\n    case 2: return new Vec( row,  col);\n    case 3: return new Vec( col,  row);\n    case 4: return new Vec(-col,  row);\n    case 5: return new Vec(-row,  col);\n    case 6: return new Vec(-row, -col);\n    case 7: return new Vec(-col, -row);\n  }\n}\n\n\nEach case represents a different octant, starting at the top and going clockwise\naround the circle. Painting them all covers the whole view (with a bit of\ninnocuous overlap):\nSorry, you need canvas support for this demo.\n  Click to paint the whole view.\n\n\nFrom here on out, we only have deal with a single triangle’s worth of row and\ncol, and we can cover the entire field of view just by running the same code\neight times, once for each octant.\nA Line of Shadows\nAnother way to approach a problem is to negate it, and that’s what this\nalgorithm does. Instead of calculating which tiles are visible, it figures out\nwhich are hidden, which put it in a family of algorithms that do “shadow\ncasting”. Before I explain it, try it out yourself:\nSorry, you need canvas support for this demo.\n  Drag the slider up to advance the shadow line. Click anywhere\n  else to change the dungeon.\n\n\nWe start at the hero and work upwards one row at a time. As we sweep through the\noctant, we incrementally update a data structure called the shadow line. It’s\nthe white line you see next to the slider. It tracks which parts of the row are\nin the shade of opaque tiles on previous rows and which aren’t.\nThe line is a series of segments, each representing one obscured region of the\nline. We can define this like so:\nclass ShadowLine {\n  final List<Shadow> _shadows = [];\n}\n\nclass Shadow {\n  num start;\n  num end;\n\n  Shadow(this.start, this.end);\n}\n\n\nThe interesting question is, “What is the range of start and end?” The\nnaïve answer is to use tile coordinates. If we’re five rows in and the shadow\nline is five tiles long, the segment coordinates would range from 0 to 5.\nThe problem is that since light expands outwards from a point, the shadows\nstretch out as they get farther away. We don’t want to have to recalculate the\nsegment positions each time we advance a row and the rays spread out.\nInstead, we store their slopes. Regardless of what row we’re on, they always\nrange from 0 (the short edge of the octant) to 1 (the diagonal edge). They are\ndistance-independent. This is what the black line in the demo above shows. As\nyou click to add and remove wall, you can see new shadows appear, but they don’t\nmove or grow as you sweep the row up and down.\nProjecting a tile\nThe tricky part is calculating those slopes given some tile in the octant. There\nare a couple of corner cases to consider. Literally. A tile is a square, and the\nshadow it projects goes from one corner of the square to another.\nGiven our canonical octant, we know the tile will be above and to the right of\nthe hero. That means the projected shadow’s extent will always be from the\ntop-left corner of a tile to the bottom-right corner. The other two corners lie\nin the middle of the shadow. (This isn’t strictly true if the tile is straight\nup from the hero, but we can safely ignore that.)\nWhat we need, then, is to calculate the slopes of those two corners of a tile.\nThe math is a kind of fussy, but it’s:\n/// Creates a [Shadow] that corresponds to the projected\n/// silhouette of the tile at [row], [col].\nShadow projectTile(int row, int col) {\n  var topLeft = col / (row + 2);\n  var bottomRight = (col + 1) / (row + 1);\n  return new Shadow(topLeft, bottomRight);\n}\n\n\nThis function has two uses. The obvious one is that we call this for each opaque\ntile and add its result to the shadow line. But the projection comes into play\nbefore that too.\nYou can think of the result of this function as the shadow that the tile casts\npast itself, but it also describes the projection from the hero to this\ntile. In other words, it describes which angles need to be unblocked for this\ntile to be visible.\nWhen we scan a row, we call projectTile() on every tile—transparent or\nopaque— and compare it to the existing shadow line. If the tile’s\nprojection is covered by the shadow line, we know it can’t be seen. If it isn’t,\nit can.\nAn interesting edge case is tiles whose projection is partially covered by the\nshadow line. Different games take different approaches here. Mine is considered\npermissive: if you can see any part of a tile, it’s visible. A tile’s\nprojection has to be totally covered by the shadow to be hidden. If you want\nsomething less permissive, this algorithm is easy to tweak.\nLet’s code! First, we’ll add a method to see if one shadow totally covers\nanother:\nclass Shadow {\n  /// Returns `true` if [other] is completely covered by this shadow.\n  bool contains(Shadow other) {\n    return start <= other.start && end >= other.end;\n  }\n\n  ...\n}\n\n\nThen we use that to see if any shadow in the line covers the tile:\nclass ShadowLine {\n  bool isInShadow(Shadow projection) {\n    for (var shadow in _shadows) {\n      if (shadow.contains(projection)) return true;\n    }\n\n    return false;\n  }\n\n  ...\n}\n\n\nUsing that, we can determine the visibility of every tile in a row. Given a\nShadowLine in line, and a set of tiles in tiles, it’s:\nfor (var col = 0; col <= row; col++) {\n  var projection = _projectTile(row, col);\n  var pos = start + transformOctant(row, col, octant);\n  tiles[pos].isVisible = !line.isInShadow(projection);\n}\n\n\nInky pools of shadows\nWe can calculate which tiles are obscured by the shadow line, but that isn’t\nvery useful since our shadow line is always empty right now. Let’s fix that.\nAs we trace the row, each time we hit an opaque tile, we add it to the shadow\nline. If the shadow line was a simple list of these little shadow segments, the\nlist would get longer and longer. In a dense dungeon, the hero may be near\nhundreds of solid tiles. Having to walk through an increasingly long list of\nshadow segments to see if a tile is obscured would get slower and slower.\nFortunately, I have a simple fix that makes the algorithm get faster as tiles\nocclude more of the view. This is the part where I think my algorithm is\npretty cool, and it’s why I’m excited to share it with you.\nOften, when a new segment is added to the shadow line, it overlaps other\nshadows. When that happens, we merge it with the existing shadows. The end\nresult is that the shadow line will have a single Shadow object for each\ncontiguous range of obscured area.\nThis does mean adding a new shadow to the line is more complex. There are a\nhandful of cases:\nThe shadow is contained within an existing one. That means the new shadow\ndoesn’t cover any new territory, so we can discard it.\n\n\nThe shadow doesn’t overlap any other ones. In this case, we insert it in\nsorted order between the segments that come before and after it.\n\n\nThe shadow overlaps another shadow on its starting edge. We take the\nprevious shadow and grow it to encompass the new shadow’s endpoint and\ndiscard the new one.\n\n\nThe shadow overlaps another shadow on its ending edge. Do the same thing,\nbut in reverse: grow the following shadow to cover the new one.\n\n\nThe shadow overlaps shadows on both ends. This is the fun one. We take\nthe previous shadow and extend it to cover the next shadow’s endpoint. Then\nwe discard both the new shadow and that next one.\n\n\n\nThe first case doesn’t change the list of shadows at all. In the second case,\nthe list of shadows gets longer. In the next two, adding a new shadow doesn’t\ngrow the list, it just shifts an endpoint. The last case is the fun one: there,\nthe list gets shorter.\n(Pop quiz! Why don’t we have to worry about cases where a shadow overlaps more\nthan two existing ones?)\nHere’s the entire method to add a shadow to the line:\nclass ShadowLine {\n  void add(Shadow shadow) {\n    // Figure out where to slot the new shadow in the list.\n    var index = 0;\n    for (; index < _shadows.length; index++) {\n      // Stop when we hit the insertion point.\n      if (_shadows[index].start >= shadow.start) break;\n    }\n\n    // The new shadow is going here. See if it overlaps the\n    // previous or next.\n    var overlappingPrevious;\n    if (index > 0 && _shadows[index - 1].end > shadow.start) {\n      overlappingPrevious = _shadows[index - 1];\n    }\n\n    var overlappingNext;\n    if (index < _shadows.length &&\n        _shadows[index].start < shadow.end) {\n      overlappingNext = _shadows[index];\n    }\n\n    // Insert and unify with overlapping shadows.\n    if (overlappingNext != null) {\n      if (overlappingPrevious != null) {\n        // Overlaps both, so unify one and delete the other.\n        overlappingPrevious.end = overlappingNext.end;\n        _shadows.removeAt(index);\n      } else {\n        // Overlaps the next one, so unify it with that.\n        overlappingNext.start = shadow.start;\n      }\n    } else {\n      if (overlappingPrevious != null) {\n        // Overlaps the previous one, so unify it with that.\n        overlappingPrevious.end = shadow.end;\n      } else {\n        // Does not overlap anything, so insert.\n        _shadows.insert(index, shadow);\n      }\n    }\n  }\n\n  ...\n}\n\n\nOK, so that’s kind of hairy, but it’s not deep magic, just a bunch of different\ncases to handle. Clever readers are probably wondering why we don’t do a binary\nsearch to find the insertion point. The list is sorted after all. If you want to\nbe super smart, go for it. In practice, I don’t think it makes much of a\ndifference. The maximum size of the list is small enough that a linear search\nmay actually be faster.\n(Pop quiz two! What is the maximum size of the list? Show your work.)\nVery clever readers may have noticed we don’t check for the first case, a\ncompletely contained shadow here. That’s because we’ve already done that check.\nEarlier, when we detect if this tile is visible, that also tells us if it’s\nshadow is contained. If it is, we don’t bother calling add().\nThere’s another simple optimization we can do. If we get to the point where the\nshadow line is a single segment from 0 to 1—in other words, the whole line\nis in shadow—then we can skip all of the projection calculation, updating,\netc. Every tile will be hidden after that. Here’s how we detect that:\nclass ShadowLine {\n  bool get isFullShadow {\n    return _shadows.length == 1 &&\n        _shadows[0].start == 0 &&\n        _shadows[0].end == 1;\n  }\n\n  ...\n}\n\n\nPutting it all together\nOK, so we have code to:\nWalk over every octant.\n\n\nWalk every tile in an octant.\n\n\nUpdate the tile’s visibility.\n\n\nUpdate the shadow line if the tile is opaque.\n\n\n\nLet’s stitch the last few pieces together along with a dash of bounds checking.\nBuilding on top of what we have above, here’s the top-level code to update the\nvisibility of the whole dungeon:\nvoid refreshVisibility(Vec hero) {\n  for (var octant = 0; octant < 8; octant++) {\n    refreshOctant(hero, octant);\n  }\n}\n\nvoid refreshOctant(Vec hero, int octant) {\n  var line = new ShadowLine();\n  var fullShadow = false;\n\n  for (var row = 1;; row++) {\n    // Stop once we go out of bounds.\n    var pos = hero + transformOctant(row, 0, octant);\n    if (!tiles.bounds.contains(pos)) break;\n\n    for (var col = 0; col <= row; col++) {\n      var pos = hero + transformOctant(row, col, octant);\n\n      // If we've traversed out of bounds, bail on this row.\n      if (!tiles.bounds.contains(pos)) break;\n\n      if (fullShadow) {\n        tiles[pos].isVisible = false;\n      } else {\n        var projection = projectTile(row, col);\n\n        // Set the visibility of this tile.\n        var visible = !line.isInShadow(projection);\n        tiles[pos].isVisible = visible;\n\n        // Add any opaque tiles to the shadow map.\n        if (visible && tiles[pos].isWall) {\n          line.add(projection);\n          fullShadow = line.isFullShadow;\n        }\n      }\n    }\n  }\n}\n\n\nAnd there we have it. It runs very fast in wide open areas since there will be\nfew shadow segments and the list is short. Likewise, it runs fast in closed\nareas since the shadow list will also be short—it will contain a small\nnumber of long segments. It performs the worst in “spotty” areas with lots of\nsmall trees or pillars, but even there, the performance is pretty solid.\nI’d love to say I implemented a bunch of other algorithms and this one came out\nthe winner, but honestly I was too lazy to that. I will say that this has never\nshowed up as a hot spot when I’ve profiled the game. That’s good enough for me,\nand I hope this will be helpful for you too.\nIf you want to see all of the code for these demos, it’s here. Or, in\nthe context of my game here.","guid":"http://journal.stuffwithstuff.com/2015/09/07/what-the-hero-sees","isoDate":"2015-09-07T07:00:00.000Z","timestamp":"9/7/2015"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"What Color is Your Function?","link":"http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/","pubDate":"Sun, 01 Feb 2015 00:00:00 -0800","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>I don&rsquo;t know about you, but nothing gets me going in the morning quite like a\ngood old fashioned programming language rant. It stirs the blood to see someone\nskewer one of those <a href=\"http://www.paulgraham.com/avg.html\">&ldquo;blub&rdquo;</a> languages the plebians use, muddling through\ntheir day with it between furtive visits to StackOverflow.</p>\n\n<p>(Meanwhile, you and I, only use the most enlightened of languages. Chisel-sharp\ntools designed for the manicured hands of expert craftspersons such as\nourselves.)</p>\n\n<p>Of course, as the <em>author</em> of said screed, I run a risk. The language I mock\ncould be one you like! Without realizing it, I could have let the rabble into\nmy blog, pitchforks and torches at the ready, and my fool-hardy pamphlet could\ndraw their ire!</p>\n\n<p>To protect myself from the heat of those flames, and to avoid offending your\npossibly delicate sensibilities, instead, I&rsquo;ll rant about a language I just\nmade up. A strawman whose sole purpose is to be set aflame.</p>\n\n<p>I know, this seems pointless right? Trust me, by the end, we&rsquo;ll see whose face\n(or faces!) have been painted on his straw noggin.</p>\n\n<h2>A new language</h2>\n\n<p>Learning an entire new (crappy) language just for a blog post is a tall order,\nso let&rsquo;s say it&rsquo;s mostly similar to one you and I already know. We&rsquo;ll say it\nhas syntax sorta like JS. Curly braces and semicolons. <code>if</code>, <code>while</code>, etc. The\n<em>lingua franca</em> of the programming grotto.</p>\n\n<p>I&rsquo;m picking JS <em>not</em> because that&rsquo;s what this post is about. It&rsquo;s just that\nit&rsquo;s the language you, statistical representation of the average reader, are\nmost likely to be able grok. Voilà:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"kd\">function</span> <span class=\"nx\">thisIsAFunction</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"k\">return</span> <span class=\"s2\">&quot;It&#39;s awesome&quot;</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Because our strawman is a <em>modern</em> (shitty) language, we also have first-class\nfunctions. So you can make something like like:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"c1\">// Return a list containing all of the elements in collection</span>\n<span class=\"c1\">// that match predicate.</span>\n<span class=\"kd\">function</span> <span class=\"nx\">filter</span><span class=\"p\">(</span><span class=\"nx\">collection</span><span class=\"p\">,</span> <span class=\"nx\">predicate</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"kd\">var</span> <span class=\"nx\">result</span> <span class=\"o\">=</span> <span class=\"p\">[];</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">var</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"nx\">collection</span><span class=\"p\">.</span><span class=\"nx\">length</span><span class=\"p\">;</span> <span class=\"nx\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"nx\">predicate</span><span class=\"p\">(</span><span class=\"nx\">collection</span><span class=\"p\">[</span><span class=\"nx\">i</span><span class=\"p\">]))</span> <span class=\"nx\">result</span><span class=\"p\">.</span><span class=\"nx\">push</span><span class=\"p\">(</span><span class=\"nx\">collection</span><span class=\"p\">[</span><span class=\"nx\">i</span><span class=\"p\">]);</span>\n  <span class=\"p\">}</span>\n  <span class=\"k\">return</span> <span class=\"nx\">result</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>This is one of those <em>higher-order</em> functions, and, like the name implies, they\nare classy as all get out and super useful. You&rsquo;re probably used to them for\nmucking around with collections, but once you internalize the concept, you\nstart using them damn near everywhere.</p>\n\n<p>Maybe in your testing framework:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">describe</span><span class=\"p\">(</span><span class=\"s2\">&quot;An apple&quot;</span><span class=\"p\">,</span> <span class=\"kd\">function</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"nx\">it</span><span class=\"p\">(</span><span class=\"s2\">&quot;ain&#39;t no orange&quot;</span><span class=\"p\">,</span> <span class=\"kd\">function</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nx\">expect</span><span class=\"p\">(</span><span class=\"s2\">&quot;Apple&quot;</span><span class=\"p\">).</span><span class=\"nx\">not</span><span class=\"p\">.</span><span class=\"nx\">toBe</span><span class=\"p\">(</span><span class=\"s2\">&quot;Orange&quot;</span><span class=\"p\">);</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">});</span>\n</code></pre></div>\n<p>Or when you need to parse some data:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">tokens</span><span class=\"p\">.</span><span class=\"nx\">match</span><span class=\"p\">(</span><span class=\"nx\">Token</span><span class=\"p\">.</span><span class=\"nx\">LEFT_BRACKET</span><span class=\"p\">,</span> <span class=\"kd\">function</span><span class=\"p\">(</span><span class=\"nx\">token</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// Parse a list literal...</span>\n  <span class=\"nx\">tokens</span><span class=\"p\">.</span><span class=\"nx\">consume</span><span class=\"p\">(</span><span class=\"nx\">Token</span><span class=\"p\">.</span><span class=\"nx\">RIGHT_BRACKET</span><span class=\"p\">);</span>\n<span class=\"p\">});</span>\n</code></pre></div>\n<p>So you go to town and write all sorts of awesome reusable libraries and\napplications passing around functions, calling functions, returning functions.\nFunctapalooza.</p>\n\n<h2>What color is your function?</h2>\n\n<p>Except wait. Here&rsquo;s where our language gets screwy. It has this one peculiar\nfeature:</p>\n\n<p><strong>1. Every function has a color.</strong></p>\n\n<p>Each function&mdash;anonymous callback or regular named one&mdash;is either red\nor blue. Since my blog&rsquo;s code highlighter can&rsquo;t handle actual color, we&rsquo;ll say\nthe syntax is like:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">blue</span><span class=\"err\">•</span><span class=\"kd\">function</span> <span class=\"nx\">doSomethingAzure</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// This is a blue function...</span>\n<span class=\"p\">}</span>\n\n<span class=\"nx\">red</span><span class=\"err\">•</span><span class=\"kd\">function</span> <span class=\"nx\">doSomethingCarnelian</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"c1\">// This is a red function...</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>There are <em>no</em> colorless functions in the language. Want to make a function?\nGotta pick a color. Them&rsquo;s the rules. And, actually, there are a couple more\nrules you have to follow too:</p>\n\n<p><strong>2. The way you call a function depends on its color.</strong></p>\n\n<p>Imagine a &ldquo;blue call&rdquo; syntax and a &ldquo;red call&rdquo; syntax. Something like:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">doSomethingAzure</span><span class=\"p\">(...)</span><span class=\"err\">•</span><span class=\"nx\">blue</span><span class=\"p\">;</span>\n<span class=\"nx\">doSomethingCarnelian</span><span class=\"p\">()</span><span class=\"err\">•</span><span class=\"nx\">red</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>When calling a function, you need to use the call that corresponds to its color.\nIf you get it wrong&mdash;call a red function with <code>•blue</code> after the parentheses\nor vice versa&mdash;it does something bad. Dredge up some long-forgotten\nnightmare from your childhood like a clown with snakes for arms hiding under\nyour bed. That jumps out of your monitor and sucks out your vitreous humour.</p>\n\n<p>Annoying rule, right? Oh, and one more:</p>\n\n<p><strong>3. You can only call a red function from within another red function.</strong></p>\n\n<p>You <em>can</em> call a blue function from with a red one. This is kosher:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">red</span><span class=\"err\">•</span><span class=\"kd\">function</span> <span class=\"nx\">doSomethingCarnelian</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"nx\">doSomethingAzure</span><span class=\"p\">()</span><span class=\"err\">•</span><span class=\"nx\">blue</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>But you can&rsquo;t go the other way. If you try to do this:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"nx\">blue</span><span class=\"err\">•</span><span class=\"kd\">function</span> <span class=\"nx\">doSomethingAzure</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n  <span class=\"nx\">doSomethingCarnelian</span><span class=\"p\">()</span><span class=\"err\">•</span><span class=\"nx\">red</span><span class=\"p\">;</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Well, you&rsquo;re gonna get a visit from old Spidermouth the Night Clown.</p>\n\n<p>This makes writing higher-order functions like our <code>filter()</code> example trickier.\nWe have to pick a color for <em>it</em> and that affects the colors of the functions\nwe&rsquo;re allowed to pass to it. The obvious solution is to make <code>filter()</code> red.\nThat way, it can take either red or blue functions and call them. But then we\nrun into the next itchy spot in the hairshirt that is this language:</p>\n\n<p><strong>4. Red functions are more painful to call.</strong></p>\n\n<p>For now, I won&rsquo;t precisely define &ldquo;painful&rdquo;, but just imagine that the\nprogrammer has to jump through some kind of annoying hoops every time they call\na red function. Maybe it&rsquo;s really verbose, or maybe you can&rsquo;t do it inside\ncertain kinds of statements. Maybe you can only call them on line numbers that\nare prime.</p>\n\n<p>What matters is that, if you decide to make a function red, everyone using your\nAPI will want to spit in your coffee and/or deposit some even less savory\nfluids in it.</p>\n\n<p>The obvious solution then is to <em>never</em> use red functions. Just make everything\nblue and you&rsquo;re back to the sane world where all functions have the same color,\nwhich is equivalent to them all having no color, which is equivalent to our\nlanguage not being entirely stupid.</p>\n\n<p>Alas, the sadistic language designers&mdash;and we all know all programming\nlanguage designers are sadists, don&rsquo;t we?&mdash;jabbed one final thorn in our\nside:</p>\n\n<p><strong>5. Some core library functions are red.</strong></p>\n\n<p>There are some functions built in to the platform, functions that we <em>need</em> to\nuse, that we are unable to write ourselves, that only come in red. At this\npoint, a reasonable person might think the language hates us.</p>\n\n<h2>It&rsquo;s functional programming&rsquo;s fault!</h2>\n\n<p>You might be thinking that the problem here is we&rsquo;re trying to use higher-order\nfunctions. If we just stop flouncing around in all of that functional frippery\nand write normal blue collar first-order functions like God intended, we&rsquo;d\nspare ourselves all the heartache.</p>\n\n<p>If we only call blue functions, make our function blue. Otherwise, make it red.\nAs long as we never make functions that accept functions, we don&rsquo;t have to\nworry about trying to be &ldquo;polymorphic over function color&rdquo; (polychromatic?) or\nany nonsense like that.</p>\n\n<p>But, alas, higher order functions are just one example. This problem is\npervasive any time we want to break our program down into separate functions\nthat get reused.</p>\n\n<p>For example, let&rsquo;s say we have a nice little blob of code that, I don&rsquo;t know,\nimplements Dijkstra&rsquo;s algorithm over a graph representing how much your social\nnetwork are crushing on each other. (I spent way too long trying to decide what\nsuch a result would even represent. Transitive undesirability?)</p>\n\n<p>Later, you end up needing to use this same blob of code somewhere else. You do\nthe natural thing and hoist it out into a separate function. You call it from\nthe old place and your new code that uses it. But what color should it be?\nObviously, you&rsquo;ll make it blue if you can, but what if it uses one of those\nnasty red-only core library functions?</p>\n\n<p>What if the new place you want to call it is blue? You&rsquo;ll have to turn it red.\nThen you&rsquo;ll have to turn the function that calls <em>it</em> red. Ugh. No matter what,\nyou&rsquo;ll have to think about color constantly. It will be the sand in your\nswimsuit on the beach vacation of development.</p>\n\n<h2>A colorful allegory</h2>\n\n<p>Of course, I&rsquo;m not really talking about color here, am I? It&rsquo;s an allegory, a\nliterary trick. The Sneetches isn&rsquo;t about stars on bellies, it&rsquo;s about race. By\nnow, you may have an inkling of what color actually represents. If not, here&rsquo;s\nthe big reveal:</p>\n\n<p><strong>Red functions are asynchronous ones.</strong></p>\n\n<p>If you&rsquo;re programming in JavaScript on Node.js, everytime you define a function\nthat &ldquo;returns&rdquo; a value by invoking a callback, you just made a red function.\nLook back at that list of rules and see how my metaphor stacks up:</p>\n\n<ol>\n<li><p>Synchronous functions return values, async ones do not and instead invoke\ncallbacks.</p></li>\n<li><p>Synchronous functions give their result as a return value, async functions\ngive it by invoking a callback you pass to it.</p></li>\n<li><p>You can&rsquo;t call an async function from a synchronous one because you won&rsquo;t be\nable to determine the result until the async one completes later.</p></li>\n<li><p>Async functions don&rsquo;t compose in expressions because of the callbacks, have\ndifferent error-handling, and can&rsquo;t be used with <code>try/catch</code> or inside a lot\nof other control flow statements.</p></li>\n<li><p>Node&rsquo;s whole shtick is that the core libs are all asynchronous. (Though they\ndid dial that back and start adding <code>___Sync()</code> versions of a lot of\nthings.)</p></li>\n</ol>\n\n<p>When people talk about &ldquo;callback hell&rdquo; they&rsquo;re talking about how annoying it is\nto have red functions in their language. When they create <a href=\"https://www.npmjs.com/search?q=async\">4089 libraries for\ndoing asynchronous programming</a>, they&rsquo;re trying to cope at the library\nlevel with a problem that the language foisted onto them.</p>\n\n<h2>I promise the future is better</h2>\n\n<p>People in the Node community have realized that callbacks are a pain for a long\ntime, and have looked around for solutions. One technique that gets a bunch of\npeople excited is <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\"><em>promises</em></a>, which you may also know by their\nrapper name &ldquo;futures&rdquo;.</p>\n\n<p>These are sort of a jacked up wrapper around a callback and an error handler.\nIf you think of passing a callback and errorback to a function as a <em>concept</em>,\na promise is basically a <em>reification</em> of that idea. It&rsquo;s a first-class object\nthat represents an asynchronous operation.</p>\n\n<p>I just jammed a bunch of fancy PL language in that paragraph so it probably\nsounds like a sweet deal, but it&rsquo;s basically snake oil. Promises <em>do</em> make\nasync code a little easier to write. They compose a bit better, so rule #4\nisn&rsquo;t <em>quite</em> so onerous.</p>\n\n<p>But, honestly, it&rsquo;s like the difference between being punched in the gut versus\npunched in the privates. Less painful, yes, but I don&rsquo;t think anyone should\nreally get thrilled about the value proposition.</p>\n\n<p>You still can&rsquo;t use them with exception handling or other control flow\nstatements. You still can&rsquo;t call a function that returns a future from\nsynchronous code. (Well, you <em>can</em>, but if you do, the person who later\nmaintains your code will invent a time machine, travel back in time to the\nmoment that you did this and stab you in the face with a #2 pencil.)</p>\n\n<p>You&rsquo;ve still divided your entire world into asynchronous and synchronous halves\nand all of the misery that entails. So, even if your language features promises\nor futures, its face looks an awful lot like the one on my strawman.</p>\n\n<p>(Yes, that means even <a href=\"http://dartlang.org\">Dart</a>, the language I work on. That&rsquo;s why I&rsquo;m so\nexcited some of the team are <a href=\"https://github.com/dart-lang/fletch\">experimenting with other concurrency\nmodels</a>.)</p>\n\n<h2>I&rsquo;m awaiting a solution</h2>\n\n<p>C# programmers are probably feeling pretty smug right now (a condition they&rsquo;ve\nincreasingly fallen prey to as Hejlsberg and company have piled sweet feature\nafter sweet feature into the language). In C#, you can use <a href=\"https://msdn.microsoft.com/en-us/library/hh191443.aspx\">the <code>await</code>\nkeyword</a> to invoke an\nasynchronous function.</p>\n\n<p>This lets you make asynchronous calls just as easily as you can synchronous\nones, with the tiny addition of a cute little keyword. You can nest <code>await</code>\ncalls in expressions, use them in exception handling code, stuff them inside\ncontrol flow. Go nuts. Make it rain <code>await</code> calls like a they&rsquo;re dollars in the\nadvance you got for your new rap album.</p>\n\n<p>Async-await <em>is</em> nice, which is why we&rsquo;re adding it to Dart. It makes it a lot\neasier to <em>write</em> asynchronous code. You know a &ldquo;but&rdquo; is coming. It is.\n<em>But&hellip;</em> you still have divided the world in two. Those async functions are\neasier to write, but <em>they&rsquo;re still async functions</em>.</p>\n\n<p>You&rsquo;ve still got two colors. Async-await solves annoying rule #4: they make red\nfunctions not much worse to call than blue ones. But all of the other rules are\nstill there:</p>\n\n<ol>\n<li><p>Synchronous functions return values, async ones return <code>Task&lt;T&gt;</code> (or\n<code>Future&lt;T&gt;</code> in Dart) wrappers around the value.</p></li>\n<li><p>Sync functions are just called, async ones need an <code>await</code>.</p></li>\n<li><p>If you call an async function you&rsquo;ve got this wrapper object when you\nactually want the <code>T</code>. You can&rsquo;t unwrap it unless you make <em>your</em> function\nasync and await it. (But see below.)</p></li>\n<li><p>Aside from a liberal garnish of <code>await</code>, we did at least fix this.</p></li>\n<li><p>C#&lsquo;s core library is actually older than async so I guess they never had\nthis problem.</p></li>\n</ol>\n\n<p>It <em>is</em> better. I will take async-await over bare callbacks or futures any day\nof the week. But we&rsquo;re lying to ourselves if we think all of our troubles are\ngone. As soon as you start trying to write higher-order functions, or reuse\ncode, you&rsquo;re right back to realizing color is still there, bleeding all over\nyour codebase.</p>\n\n<h2>What language <em>isn&rsquo;t</em> colored?</h2>\n\n<p>So JS, Dart, C#, and Python have this problem. CoffeeScript and most other\nlanguages that compile to JS do too (which is why Dart inherited it). I <em>think</em>\neven ClojureScript has this issue even though they&rsquo;ve tried really hard to push\nagainst it with their <a href=\"https://github.com/clojure/core.async\">core.async</a> stuff.</p>\n\n<p>Wanna know one that doesn&rsquo;t? <em>Java.</em> I know right? How often do you get to say,\n&ldquo;Yeah, Java is the one that really does this right.&rdquo;? But there you go. In\ntheir defense, they are actively trying to correct this oversight by moving to\nfutures and async IO. It&rsquo;s like a race to the bottom.</p>\n\n<p>C# also actually <em>can</em> avoid this problem too. They opted <em>in</em> to having color.\nBefore they added async-await and all of the <code>Task&lt;T&gt;</code> stuff, you just used\nregular sync API calls. Three more languages that don&rsquo;t have this problem: Go,\nLua, and Ruby.</p>\n\n<p>Any guess what they have in common?</p>\n\n<p><em>Threads.</em> Or, more precisely: <em>multiple independent callstacks that <a href=\"/2013/01/13/iteration-inside-and-out/\">can be\nswitched between</a></em>. It isn&rsquo;t strictly necessary for them to be operating\nsystem threads. Goroutines in Go, coroutines in Lua, and fibers in Ruby are\nperfectly adequate.</p>\n\n<p>(That&rsquo;s why C# has that little caveat. You can avoid the pain of async in C# by\nusing threads.)</p>\n\n<h2>Remembrance of operations past</h2>\n\n<p>The fundamental problem is &ldquo;How do you pick up where you left off when an\noperation completes&rdquo;? You&rsquo;ve built up some big callstack and then you call some\nIO operation. For performance, that operation uses the operating system&rsquo;s\nunderlying asynchronous API. You <em>cannot</em> wait for it to complete because it\nwon&rsquo;t. You have to return all the way back to your language&rsquo;s event loop and\ngive the OS some time to spin before it will be done.</p>\n\n<p>Once it is, you need to resume what you were doing. The usual way a language\n&ldquo;remembers where it is&rdquo; is the <em>callstack</em>. That tracks all of the functions\nthat are currently being invoked and where the instruction pointer is in each\none.</p>\n\n<p>But to do async IO, you have to unwind discard the entire C callstack. Kind of\na Catch-22. You can do super fast IO, you just can&rsquo;t do anything with the\nresult! Every language that has async IO in its bowels&mdash;or in the case of\nJS, the browser&rsquo;s event loop&mdash;copes with this in some way.</p>\n\n<p>Node with its ever-marching-to-the-right callbacks stuffs all of those\ncallframes in closures. When you do:</p>\n<div class=\"highlight\"><pre><code class=\"language-js\" data-lang=\"js\"><span></span><span class=\"kd\">function</span> <span class=\"nx\">makeSundae</span><span class=\"p\">(</span><span class=\"nx\">callback</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"nx\">scoopIceCream</span><span class=\"p\">(</span><span class=\"kd\">function</span> <span class=\"p\">(</span><span class=\"nx\">iceCream</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nx\">warmUpCaramel</span><span class=\"p\">(</span><span class=\"kd\">function</span> <span class=\"p\">(</span><span class=\"nx\">caramel</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n      <span class=\"nx\">callback</span><span class=\"p\">(</span><span class=\"nx\">pourOnIceCream</span><span class=\"p\">(</span><span class=\"nx\">iceCream</span><span class=\"p\">,</span> <span class=\"nx\">caramel</span><span class=\"p\">));</span>\n    <span class=\"p\">});</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>Each of those function expressions <em>closes</em> over all of its surrounding\ncontext. That moves parameters like <code>iceCream</code> and <code>caramel</code> off the callstack\nand onto the heap. When the outer function returns and the callstack is\ntrashed, it&rsquo;s cool. That data is still floating around the heap.</p>\n\n<p>The problem is you have to <em>manually</em> reify every damn one of these steps.\nThere&rsquo;s actually a name for this transformation: <a href=\"http://en.wikipedia.org/wiki/Continuation-passing_style\"><em>continuation-passing\nstyle</em></a>. It was invented by language hackers in the 70s as an intermediate\nrepresentation to use in the guts of their compilers. It&rsquo;s a really bizarro way\nto represent code that happens to make some compiler optimizations easier to\ndo.</p>\n\n<p>No one ever for a second thought that a programmer would <em>write actual code\nlike that</em>. And then Node came along and all of the sudden here we are\npretending to be compiler back-ends. Where did we go wrong?</p>\n\n<p>Note that promises and futures don&rsquo;t actually buy you anything, either. If\nyou&rsquo;ve used them, you know you&rsquo;re still hand-creating giant piles of function\nliterals. You&rsquo;re just passing them to <code>.then()</code> instead of to the asynchronous\nfunction itself.</p>\n\n<h2>Awaiting a generated solution</h2>\n\n<p>Async-await <em>does</em> help. If you peel back your compiler&rsquo;s skull and see what\nit&rsquo;s doing when it hits an <code>await</code> call you&rsquo;d see it actually doing the\nCPS-transform. That&rsquo;s <em>why</em> you need to use <code>await</code> in C#: it&rsquo;s a clue to the\ncompiler to say, &ldquo;break the function in half here&rdquo;. Everything after the\n<code>await</code> gets hoisted into a new function that it synthesizes on your behalf.</p>\n\n<p>This is why async-await didn&rsquo;t need any <em>runtime</em> support in the .NET\nframework. The compiler compiles it away to a series of chained closures that\nit can already handle. (Interestingly, closures themselves also don&rsquo;t need\nruntime support. <em>They</em> get compiled to anonymous classes. In C#, closures\nreally <em>are</em> a <a href=\"http://c2.com/cgi/wiki?ClosuresAndObjectsAreEquivalent\">poor man&rsquo;s objects</a>.)</p>\n\n<p>You might be wondering when I&rsquo;m going to bring up generators. Does your\nlanguage have a <code>yield</code> keyword? Then it can do something very similar.</p>\n\n<p>(In fact, I <em>believe</em> generators and async-await are isomorphic. I&rsquo;ve got a bit\nof code floating around in some dark corner of my hard disc that implements a\ngenerator-style game loop using only async-await.)</p>\n\n<p>Where was I? Oh, right. So with callbacks, promises, async-await, and\ngenerators, you ultimately end up taking your asynchronous function and\nsmearing it out into a bunch of closures that live over in the heap.</p>\n\n<p>Your function passes the outermost one into the runtime. When the event loop or\nIO operation is done, it invokes that function and you pick up where you left\noff. But that means everything above you <em>also</em> has to return. You still have\nto unwind the <em>whole</em> stack.</p>\n\n<p>This is where the &ldquo;red functions can only be called by red functions&rdquo; rule\ncomes from. You have to closurify the entire callstack all the way back to\n<code>main()</code> or the event handler.</p>\n\n<h2>Reified callstacks</h2>\n\n<p>But if you have threads (green- or OS-level), you don&rsquo;t need to do that. You\ncan just suspend the entire thread and hop straight back to the OS or event\nloop <em>without having to return from all of those functions</em>.</p>\n\n<p>Go is the language that does this most beautifully in my opinion. As soon as\nyou do any IO operation, it just parks that goroutine and resumes any other\nones that aren&rsquo;t blocked on IO.</p>\n\n<p>If you look at the IO operations in the standard library, they seem\nsynchronous. In other words, they just do work and then return a result when\nthey are done. But it&rsquo;s not that they&rsquo;re synchronous in the sense that it would\nmean in JavaScript. Other Go code can run while one of these operations is\npending. It&rsquo;s that Go has <em>eliminated the distinction between synchronous and\nasynchronous code</em>.</p>\n\n<p>Concurrency in Go is a facet of how <em>you</em> choose to model your program, and not\na color seared into each function in the standard library. This means all of\nthe pain of the five rules I mentioned above is completely and totally\neliminated.</p>\n\n<p>So, the next time you start telling me about some new hot language and how\nawesome its concurrency story is because it has asynchronous APIs, now you&rsquo;ll\nknow why I start grinding my teeth. Because it means you&rsquo;re right back to red\nfunctions and blue ones.</p>\n","contentSnippet":"I don’t know about you, but nothing gets me going in the morning quite like a\ngood old fashioned programming language rant. It stirs the blood to see someone\nskewer one of those “blub” languages the plebians use, muddling through\ntheir day with it between furtive visits to StackOverflow.\n(Meanwhile, you and I, only use the most enlightened of languages. Chisel-sharp\ntools designed for the manicured hands of expert craftspersons such as\nourselves.)\nOf course, as the author of said screed, I run a risk. The language I mock\ncould be one you like! Without realizing it, I could have let the rabble into\nmy blog, pitchforks and torches at the ready, and my fool-hardy pamphlet could\ndraw their ire!\nTo protect myself from the heat of those flames, and to avoid offending your\npossibly delicate sensibilities, instead, I’ll rant about a language I just\nmade up. A strawman whose sole purpose is to be set aflame.\nI know, this seems pointless right? Trust me, by the end, we’ll see whose face\n(or faces!) have been painted on his straw noggin.\nA new language\nLearning an entire new (crappy) language just for a blog post is a tall order,\nso let’s say it’s mostly similar to one you and I already know. We’ll say it\nhas syntax sorta like JS. Curly braces and semicolons. if, while, etc. The\nlingua franca of the programming grotto.\nI’m picking JS not because that’s what this post is about. It’s just that\nit’s the language you, statistical representation of the average reader, are\nmost likely to be able grok. Voilà:\nfunction thisIsAFunction() {\n  return \"It's awesome\";\n}\n\n\nBecause our strawman is a modern (shitty) language, we also have first-class\nfunctions. So you can make something like like:\n// Return a list containing all of the elements in collection\n// that match predicate.\nfunction filter(collection, predicate) {\n  var result = [];\n  for (var i = 0; i < collection.length; i++) {\n    if (predicate(collection[i])) result.push(collection[i]);\n  }\n  return result;\n}\n\n\nThis is one of those higher-order functions, and, like the name implies, they\nare classy as all get out and super useful. You’re probably used to them for\nmucking around with collections, but once you internalize the concept, you\nstart using them damn near everywhere.\nMaybe in your testing framework:\ndescribe(\"An apple\", function() {\n  it(\"ain't no orange\", function() {\n    expect(\"Apple\").not.toBe(\"Orange\");\n  });\n});\n\n\nOr when you need to parse some data:\ntokens.match(Token.LEFT_BRACKET, function(token) {\n  // Parse a list literal...\n  tokens.consume(Token.RIGHT_BRACKET);\n});\n\n\nSo you go to town and write all sorts of awesome reusable libraries and\napplications passing around functions, calling functions, returning functions.\nFunctapalooza.\nWhat color is your function?\nExcept wait. Here’s where our language gets screwy. It has this one peculiar\nfeature:\n1. Every function has a color.\nEach function—anonymous callback or regular named one—is either red\nor blue. Since my blog’s code highlighter can’t handle actual color, we’ll say\nthe syntax is like:\nblue•function doSomethingAzure() {\n  // This is a blue function...\n}\n\nred•function doSomethingCarnelian() {\n  // This is a red function...\n}\n\n\nThere are no colorless functions in the language. Want to make a function?\nGotta pick a color. Them’s the rules. And, actually, there are a couple more\nrules you have to follow too:\n2. The way you call a function depends on its color.\nImagine a “blue call” syntax and a “red call” syntax. Something like:\ndoSomethingAzure(...)•blue;\ndoSomethingCarnelian()•red;\n\n\nWhen calling a function, you need to use the call that corresponds to its color.\nIf you get it wrong—call a red function with •blue after the parentheses\nor vice versa—it does something bad. Dredge up some long-forgotten\nnightmare from your childhood like a clown with snakes for arms hiding under\nyour bed. That jumps out of your monitor and sucks out your vitreous humour.\nAnnoying rule, right? Oh, and one more:\n3. You can only call a red function from within another red function.\nYou can call a blue function from with a red one. This is kosher:\nred•function doSomethingCarnelian() {\n  doSomethingAzure()•blue;\n}\n\n\nBut you can’t go the other way. If you try to do this:\nblue•function doSomethingAzure() {\n  doSomethingCarnelian()•red;\n}\n\n\nWell, you’re gonna get a visit from old Spidermouth the Night Clown.\nThis makes writing higher-order functions like our filter() example trickier.\nWe have to pick a color for it and that affects the colors of the functions\nwe’re allowed to pass to it. The obvious solution is to make filter() red.\nThat way, it can take either red or blue functions and call them. But then we\nrun into the next itchy spot in the hairshirt that is this language:\n4. Red functions are more painful to call.\nFor now, I won’t precisely define “painful”, but just imagine that the\nprogrammer has to jump through some kind of annoying hoops every time they call\na red function. Maybe it’s really verbose, or maybe you can’t do it inside\ncertain kinds of statements. Maybe you can only call them on line numbers that\nare prime.\nWhat matters is that, if you decide to make a function red, everyone using your\nAPI will want to spit in your coffee and/or deposit some even less savory\nfluids in it.\nThe obvious solution then is to never use red functions. Just make everything\nblue and you’re back to the sane world where all functions have the same color,\nwhich is equivalent to them all having no color, which is equivalent to our\nlanguage not being entirely stupid.\nAlas, the sadistic language designers—and we all know all programming\nlanguage designers are sadists, don’t we?—jabbed one final thorn in our\nside:\n5. Some core library functions are red.\nThere are some functions built in to the platform, functions that we need to\nuse, that we are unable to write ourselves, that only come in red. At this\npoint, a reasonable person might think the language hates us.\nIt’s functional programming’s fault!\nYou might be thinking that the problem here is we’re trying to use higher-order\nfunctions. If we just stop flouncing around in all of that functional frippery\nand write normal blue collar first-order functions like God intended, we’d\nspare ourselves all the heartache.\nIf we only call blue functions, make our function blue. Otherwise, make it red.\nAs long as we never make functions that accept functions, we don’t have to\nworry about trying to be “polymorphic over function color” (polychromatic?) or\nany nonsense like that.\nBut, alas, higher order functions are just one example. This problem is\npervasive any time we want to break our program down into separate functions\nthat get reused.\nFor example, let’s say we have a nice little blob of code that, I don’t know,\nimplements Dijkstra’s algorithm over a graph representing how much your social\nnetwork are crushing on each other. (I spent way too long trying to decide what\nsuch a result would even represent. Transitive undesirability?)\nLater, you end up needing to use this same blob of code somewhere else. You do\nthe natural thing and hoist it out into a separate function. You call it from\nthe old place and your new code that uses it. But what color should it be?\nObviously, you’ll make it blue if you can, but what if it uses one of those\nnasty red-only core library functions?\nWhat if the new place you want to call it is blue? You’ll have to turn it red.\nThen you’ll have to turn the function that calls it red. Ugh. No matter what,\nyou’ll have to think about color constantly. It will be the sand in your\nswimsuit on the beach vacation of development.\nA colorful allegory\nOf course, I’m not really talking about color here, am I? It’s an allegory, a\nliterary trick. The Sneetches isn’t about stars on bellies, it’s about race. By\nnow, you may have an inkling of what color actually represents. If not, here’s\nthe big reveal:\nRed functions are asynchronous ones.\nIf you’re programming in JavaScript on Node.js, everytime you define a function\nthat “returns” a value by invoking a callback, you just made a red function.\nLook back at that list of rules and see how my metaphor stacks up:\nSynchronous functions return values, async ones do not and instead invoke\ncallbacks.\n\n\nSynchronous functions give their result as a return value, async functions\ngive it by invoking a callback you pass to it.\n\n\nYou can’t call an async function from a synchronous one because you won’t be\nable to determine the result until the async one completes later.\n\n\nAsync functions don’t compose in expressions because of the callbacks, have\ndifferent error-handling, and can’t be used with try/catch or inside a lot\nof other control flow statements.\n\n\nNode’s whole shtick is that the core libs are all asynchronous. (Though they\ndid dial that back and start adding ___Sync() versions of a lot of\nthings.)\n\n\n\nWhen people talk about “callback hell” they’re talking about how annoying it is\nto have red functions in their language. When they create 4089 libraries for\ndoing asynchronous programming, they’re trying to cope at the library\nlevel with a problem that the language foisted onto them.\nI promise the future is better\nPeople in the Node community have realized that callbacks are a pain for a long\ntime, and have looked around for solutions. One technique that gets a bunch of\npeople excited is promises, which you may also know by their\nrapper name “futures”.\nThese are sort of a jacked up wrapper around a callback and an error handler.\nIf you think of passing a callback and errorback to a function as a concept,\na promise is basically a reification of that idea. It’s a first-class object\nthat represents an asynchronous operation.\nI just jammed a bunch of fancy PL language in that paragraph so it probably\nsounds like a sweet deal, but it’s basically snake oil. Promises do make\nasync code a little easier to write. They compose a bit better, so rule #4\nisn’t quite so onerous.\nBut, honestly, it’s like the difference between being punched in the gut versus\npunched in the privates. Less painful, yes, but I don’t think anyone should\nreally get thrilled about the value proposition.\nYou still can’t use them with exception handling or other control flow\nstatements. You still can’t call a function that returns a future from\nsynchronous code. (Well, you can, but if you do, the person who later\nmaintains your code will invent a time machine, travel back in time to the\nmoment that you did this and stab you in the face with a #2 pencil.)\nYou’ve still divided your entire world into asynchronous and synchronous halves\nand all of the misery that entails. So, even if your language features promises\nor futures, its face looks an awful lot like the one on my strawman.\n(Yes, that means even Dart, the language I work on. That’s why I’m so\nexcited some of the team are experimenting with other concurrency\nmodels.)\nI’m awaiting a solution\nC# programmers are probably feeling pretty smug right now (a condition they’ve\nincreasingly fallen prey to as Hejlsberg and company have piled sweet feature\nafter sweet feature into the language). In C#, you can use the await\nkeyword to invoke an\nasynchronous function.\nThis lets you make asynchronous calls just as easily as you can synchronous\nones, with the tiny addition of a cute little keyword. You can nest await\ncalls in expressions, use them in exception handling code, stuff them inside\ncontrol flow. Go nuts. Make it rain await calls like a they’re dollars in the\nadvance you got for your new rap album.\nAsync-await is nice, which is why we’re adding it to Dart. It makes it a lot\neasier to write asynchronous code. You know a “but” is coming. It is.\nBut… you still have divided the world in two. Those async functions are\neasier to write, but they’re still async functions.\nYou’ve still got two colors. Async-await solves annoying rule #4: they make red\nfunctions not much worse to call than blue ones. But all of the other rules are\nstill there:\nSynchronous functions return values, async ones return Task<T> (or\nFuture<T> in Dart) wrappers around the value.\n\n\nSync functions are just called, async ones need an await.\n\n\nIf you call an async function you’ve got this wrapper object when you\nactually want the T. You can’t unwrap it unless you make your function\nasync and await it. (But see below.)\n\n\nAside from a liberal garnish of await, we did at least fix this.\n\n\nC#‘s core library is actually older than async so I guess they never had\nthis problem.\n\n\n\nIt is better. I will take async-await over bare callbacks or futures any day\nof the week. But we’re lying to ourselves if we think all of our troubles are\ngone. As soon as you start trying to write higher-order functions, or reuse\ncode, you’re right back to realizing color is still there, bleeding all over\nyour codebase.\nWhat language isn’t colored?\nSo JS, Dart, C#, and Python have this problem. CoffeeScript and most other\nlanguages that compile to JS do too (which is why Dart inherited it). I think\neven ClojureScript has this issue even though they’ve tried really hard to push\nagainst it with their core.async stuff.\nWanna know one that doesn’t? Java. I know right? How often do you get to say,\n“Yeah, Java is the one that really does this right.”? But there you go. In\ntheir defense, they are actively trying to correct this oversight by moving to\nfutures and async IO. It’s like a race to the bottom.\nC# also actually can avoid this problem too. They opted in to having color.\nBefore they added async-await and all of the Task<T> stuff, you just used\nregular sync API calls. Three more languages that don’t have this problem: Go,\nLua, and Ruby.\nAny guess what they have in common?\nThreads. Or, more precisely: multiple independent callstacks that can be\nswitched between. It isn’t strictly necessary for them to be operating\nsystem threads. Goroutines in Go, coroutines in Lua, and fibers in Ruby are\nperfectly adequate.\n(That’s why C# has that little caveat. You can avoid the pain of async in C# by\nusing threads.)\nRemembrance of operations past\nThe fundamental problem is “How do you pick up where you left off when an\noperation completes”? You’ve built up some big callstack and then you call some\nIO operation. For performance, that operation uses the operating system’s\nunderlying asynchronous API. You cannot wait for it to complete because it\nwon’t. You have to return all the way back to your language’s event loop and\ngive the OS some time to spin before it will be done.\nOnce it is, you need to resume what you were doing. The usual way a language\n“remembers where it is” is the callstack. That tracks all of the functions\nthat are currently being invoked and where the instruction pointer is in each\none.\nBut to do async IO, you have to unwind discard the entire C callstack. Kind of\na Catch-22. You can do super fast IO, you just can’t do anything with the\nresult! Every language that has async IO in its bowels—or in the case of\nJS, the browser’s event loop—copes with this in some way.\nNode with its ever-marching-to-the-right callbacks stuffs all of those\ncallframes in closures. When you do:\nfunction makeSundae(callback) {\n  scoopIceCream(function (iceCream) {\n    warmUpCaramel(function (caramel) {\n      callback(pourOnIceCream(iceCream, caramel));\n    });\n  });\n}\n\n\nEach of those function expressions closes over all of its surrounding\ncontext. That moves parameters like iceCream and caramel off the callstack\nand onto the heap. When the outer function returns and the callstack is\ntrashed, it’s cool. That data is still floating around the heap.\nThe problem is you have to manually reify every damn one of these steps.\nThere’s actually a name for this transformation: continuation-passing\nstyle. It was invented by language hackers in the 70s as an intermediate\nrepresentation to use in the guts of their compilers. It’s a really bizarro way\nto represent code that happens to make some compiler optimizations easier to\ndo.\nNo one ever for a second thought that a programmer would write actual code\nlike that. And then Node came along and all of the sudden here we are\npretending to be compiler back-ends. Where did we go wrong?\nNote that promises and futures don’t actually buy you anything, either. If\nyou’ve used them, you know you’re still hand-creating giant piles of function\nliterals. You’re just passing them to .then() instead of to the asynchronous\nfunction itself.\nAwaiting a generated solution\nAsync-await does help. If you peel back your compiler’s skull and see what\nit’s doing when it hits an await call you’d see it actually doing the\nCPS-transform. That’s why you need to use await in C#: it’s a clue to the\ncompiler to say, “break the function in half here”. Everything after the\nawait gets hoisted into a new function that it synthesizes on your behalf.\nThis is why async-await didn’t need any runtime support in the .NET\nframework. The compiler compiles it away to a series of chained closures that\nit can already handle. (Interestingly, closures themselves also don’t need\nruntime support. They get compiled to anonymous classes. In C#, closures\nreally are a poor man’s objects.)\nYou might be wondering when I’m going to bring up generators. Does your\nlanguage have a yield keyword? Then it can do something very similar.\n(In fact, I believe generators and async-await are isomorphic. I’ve got a bit\nof code floating around in some dark corner of my hard disc that implements a\ngenerator-style game loop using only async-await.)\nWhere was I? Oh, right. So with callbacks, promises, async-await, and\ngenerators, you ultimately end up taking your asynchronous function and\nsmearing it out into a bunch of closures that live over in the heap.\nYour function passes the outermost one into the runtime. When the event loop or\nIO operation is done, it invokes that function and you pick up where you left\noff. But that means everything above you also has to return. You still have\nto unwind the whole stack.\nThis is where the “red functions can only be called by red functions” rule\ncomes from. You have to closurify the entire callstack all the way back to\nmain() or the event handler.\nReified callstacks\nBut if you have threads (green- or OS-level), you don’t need to do that. You\ncan just suspend the entire thread and hop straight back to the OS or event\nloop without having to return from all of those functions.\nGo is the language that does this most beautifully in my opinion. As soon as\nyou do any IO operation, it just parks that goroutine and resumes any other\nones that aren’t blocked on IO.\nIf you look at the IO operations in the standard library, they seem\nsynchronous. In other words, they just do work and then return a result when\nthey are done. But it’s not that they’re synchronous in the sense that it would\nmean in JavaScript. Other Go code can run while one of these operations is\npending. It’s that Go has eliminated the distinction between synchronous and\nasynchronous code.\nConcurrency in Go is a facet of how you choose to model your program, and not\na color seared into each function in the standard library. This means all of\nthe pain of the five rules I mentioned above is completely and totally\neliminated.\nSo, the next time you start telling me about some new hot language and how\nawesome its concurrency story is because it has asynchronous APIs, now you’ll\nknow why I start grinding my teeth. Because it means you’re right back to red\nfunctions and blue ones.","guid":"http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function","isoDate":"2015-02-01T08:00:00.000Z","timestamp":"2/1/2015"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"Rooms and Mazes: A Procedural Dungeon Generator","link":"http://journal.stuffwithstuff.com/2014/12/21/rooms-and-mazes/","pubDate":"Sun, 21 Dec 2014 00:00:00 -0800","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<style>\ncanvas {\n  background: #222;\n  display: inline-block;\n  max-width: 100%;\n}\n</style>\n\n<p>Several months ago I promised a follow-up to my previous blog post about <a href=\"/2014/07/15/a-turn-based-game-loop/\">turn-based game loops</a> in <a href=\"https://github.com/munificent/hauberk\">my roguelike</a>. Then I got completely sidetracked by <a href=\"/2014/11/03/bringing-my-web-book-to-print-and-ebook/\">self-publishing</a> <a href=\"/2014/11/20/how-my-book-launch-went/\">my book</a>, <a href=\"http://gameprogrammingpatterns.com/\"><em>Game Programming Patterns</em></a>, and forgot all about it. I totally left you hanging.</p>\n\n<p>Well, I finally got some time to think about my roguelike again and today, I&rsquo;m here to&hellip; keep you hanging. Alas, you are at the mercy of my wandering attention span! Instead of game loops, today we&rsquo;re going to talk about possibly the most fun and challenging part of making a roguelike: generating dungeons!</p>\n\n<p>Go ahead and click the little box below to see what we end up with:</p>\n\n<figure>\n  <canvas id=\"enchilada\" width=\"570\" height=\"390\">Sorry, you need canvas support for this demo.</canvas>\n  <figcaption>Click it again to restart it.</figcaption>\n</figure>\n\n<p>Pretty neat, huh? If you want to skip the prose, the code is <a href=\"https://github.com/munificent/hauberk/blob/db360d9efa714efb6d937c31953ef849c7394a39/lib/src/content/dungeon.dart\">here</a>.</p>\n\n<p>One of my earliest memories of computing is a maze generator running on my family&rsquo;s Apple IIe. It filled the screen with a grid of green squares, then incrementally cut holes in the walls. Eventually, every square of the grid was connected and the screen was filled with a complete, perfect maze.</p>\n\n<p>My little home computer could create something that had deep structure&mdash;every square of the maze could be reached from any other&mdash;and yet it seemed to be chaotic&mdash;it carved at random and every maze was different. This was enough to blow my ten-year-old mind. It still kind of does today.</p>\n\n<h2>What&rsquo;s in a dungeon?</h2>\n\n<p>Procedural generation&mdash;having the game build stuff randomly instead of using hand-authored content&mdash;is amazing when it works well. You get a ton of replayability because the game is different every time. As the person implementing the game, you also get the critical feature of not knowing what you&rsquo;re going to get even though you wrote the code. The game can surprise <em>you</em> too.</p>\n\n<p>People get into procedural generation because it seems easier. Hand-authoring content is obviously a lot of work. If you want your game to have a hundred levels, you have to make a hundred things. But make one little random level generator and you can have a hundred levels, a thousand, or a million, for free!</p>\n\n<p>Alas, it doesn&rsquo;t <em>quite</em> work out that way. You see, <em>defining the procedure</em> is a hell of a lot harder than just sitting down and banging out some content. You have to take some very nebulous, artistic chunk of your brain, figure out precisely what it&rsquo;s doing, and translate that to code. You&rsquo;re coding a simulation of yourself.</p>\n\n<p>It must balance a number of technical and aesthetic constraints. For mine, I focused on:</p>\n\n<ul>\n<li><p>It needs to be <strong>fairly efficient.</strong> The generator only runs when the player enters a new level, so it doesn&rsquo;t have to be as <em>super</em> fast, but I still don&rsquo;t want a several second pause giving the player time to question whether they should be playing a game or doing something more productive with their life.</p></li>\n<li><p>The dungeon needs to be <strong>connected.</strong> Like the mazes on my old green-screen Apple, that means from any point in the dungeon, there is a way&mdash;possibly circuitous&mdash;to any other point.</p>\n\n<p>This is vital because if player has to complete a quest like &ldquo;find the magic chalice&rdquo; or &ldquo;kill the cockatrice&rdquo;, it&rsquo;s pretty cruel if the dungeon drops that in some walled-off room the player can&rsquo;t get to. It also avoids wasting time generating and populating areas the player can never see.</p></li>\n<li><p>Moreso, I want dungeons to <strong>not be perfect.</strong> &ldquo;Perfect&rdquo; in the context of mazes and graphs (which are synonymous) means there is <em>only one</em> path between any two points. If you flatten out all of the windy passages, you&rsquo;ll discover your twisty maze is really just a tree all crumpled up. Passageways branch but never merge. <em>Im</em>-perfect mazes have loops and cycles&mdash;multiple paths from A to B.</p>\n\n<p>This is a gameplay constraint, not a technical one. You could make a roguelike with perfect dungeons, and many simple roguelikes do that because generators for those are easier to design and implement.</p>\n\n<p>But I find them less fun to play. When you hit a dead end (which is often), you have to do a lot of backtracking to get to a new area to explore. You can&rsquo;t circle around to avoid certain enemies, or sneak out a back passage. Neither can the bad guys, for that matter.</p>\n\n<p>Fundamentally, games are about making decisions from a set of alternatives. At a literal level, perfect dungeons only give you one path to choose from.</p></li>\n<li><p>I want <strong>open rooms.</strong> I could make dungeons just be nothing but mazes of narrow passages, but then you could never get surrounded by a horde of monsters. It would feel claustrophic and kill a bunch of interesting combat tactics.</p>\n\n<p>Wide open areas are critical for area effect spells, and big dramatic battles. They also provide space for interesting decorations and themed areas. Vaults, pits, traps, treasure rooms, etc. Rooms are the high points of the hero&rsquo;s journey.</p></li>\n<li><p>I want <strong>passageways.</strong> At the same time, I don&rsquo;t want the dungeon to <em>just</em> be rooms. There are some games that create levels this way where doors directly join room to room. It works OK, but I find it a bit monotonous. I like the player feeling confined part of the time, and having narrow corridors that the player can draw monsters into is a key tactic in the game.</p></li>\n<li><p>All of this needs to be <strong>tunable.</strong> Many roguelikes have one huge multi-floor dungeon where depths vary in difficulty but not much else. My game is different. It has a number of different <em>areas</em>. Each has its own look and feel. Some may be small and cramped, others spacious and orderly.</p>\n\n<p>I solve this partially by having multiple distinct dungeon generation algorithms. Outdoor areas use an entirely different process. (I should probably write about that too sometime. Look, another unfulfilled promise!)\nBut coding a new dungeon generator from scratch for <em>every</em> area is a huge time sink. Instead, I want the generator to have a bunch of knobs and levers I can tweak so I can make a number of areas that share the same code but have their own feel.</p></li>\n</ul>\n\n<h2>A room with a view</h2>\n\n<p>I&rsquo;ve been working on this game pretty much forever (it&rsquo;s gone through four different implementation languages!) and I&rsquo;ve tried a number of different dungeon generators. My main source of inspiration is a game called <a href=\"http://rephial.org/\">Angband</a>. The only thing I&rsquo;ve sunk more of my life into than working on my game is playing that one.</p>\n\n<p>Angband is fantastically old. When it forked off of Moria, Nancy Kerrigan had just taken a round of melee damage from a club-wielding troll. On machines of that time, it was much harder to make a fast dungeon generator, and Angband&rsquo;s is pretty simple:</p>\n\n<ol>\n<li><p>Sprinkle a bunch of randomly located, non-overlapping rooms.</p></li>\n<li><p>Draw random corridors to connect them.</p></li>\n</ol>\n\n<p>To ensure rooms don&rsquo;t overlap, I just discard a room if it collides with any previously placed one. To avoid a possible infinite loop, instead of trying until a certain number of rooms are successfully <em>placed</em>, I do a fixed number of <em>attempts</em> to place rooms. Failure becomes more common as the dungeon gets fuller&mdash;after all, you can only fit so many rooms in a given area&mdash;but tuning this gives you some control over room density, like so:</p>\n\n<figure>\n  <canvas id=\"rooms\" width=\"570\" height=\"390\">Sorry, you need canvas support for this demo.</canvas>\n  <label for=\"attempts\">Attempts:</label>\n  <input type=\"range\" id=\"attempts\" min=\"10\" value=\"200\" max=\"1000\">\n  <output for=\"attempts\" id=\"attempts-output\">200</output>\n</figure>\n\n<h2>A dark and twisty passageway</h2>\n\n<p>Most of the dungeon generators I&rsquo;ve written start with this. The hard part, by far, is making good passageways to connect them. That&rsquo;s really what this post is about&mdash;a neat way to solve that problem.</p>\n\n<p>Angband&rsquo;s solution is brute force but surprisingly effective. It picks a pair of rooms&mdash;completely ignoring how far apart they are&mdash;and starts a passageway that wanders randomly from one (hopefully) to the other. It&rsquo;s got a few clever checks to keep things from overlapping too much but passageways can and do cut through other rooms, cross other passages or dead end.</p>\n\n<p>I tried implementing that a number of times but (likely failures on my part) never got to something I really liked. The corridors I ended up with always looked too straight, or overlapped other stuff in unattractive ways.</p>\n\n<p>Then, a few months ago, I stumbled onto a <a href=\"http://www.reddit.com/r/roguelikedev/comments/2brhl8/screenshot_saturday_08/cj87umz\">description of a dungeon generator</a> by <a href=\"http://www.reddit.com/user/FastAsUcan\">u/FastAsUcan</a> on the <a href=\"http://www.reddit.com/r/roguelikedev/\">/r/roguelikedev</a> subreddit. His generator, <a href=\"http://www.odedwelgreen.com/karcero/\">Karcero</a>, is based on <a href=\"http://weblog.jamisbuck.org/\">Jamis Buck&rsquo;s</a> dungeon generator. If you&rsquo;ve ever done any procedural dungeon generation, you know&mdash;or should know&mdash;who Buck is. He&rsquo;s got a ton of great articles on random mazes.</p>\n\n<p>Years ago, I remember seeing an actual <a href=\"http://www.myth-weavers.com/generate_dungeon.php\">dungeon generator</a> he wrote for use with pen-and-paper Dungeons &amp; Dragons. Unlike most of his maze stuff, this had actual rooms, and the results looked great.</p>\n\n<p>But, at the time, I didn&rsquo;t know how it <em>worked</em>. How do you go from mazes to open winding corridors and rooms? I tucked this open question away in the corner of my mind and immediately forgot about it.</p>\n\n<p>The post by FastAsUcan provides the answer. It works like so:</p>\n\n<ol>\n<li><p>Make a perfect maze. There are a number of different algorithms for this, but they&rsquo;re all fairly straightforward.</p></li>\n<li><p>Make the maze <em>sparse</em>. Find dead end passages and fill them back in with solid rock.</p></li>\n<li><p>Pick some of the remaining dead ends and cut holes in them to adjacent walls. This makes the maze imperfect. (Remember, this is a good thing!)</p></li>\n<li><p>Create rooms and find good locations to place them. &ldquo;Good&rdquo; here means not overlapping the maze but <em>near</em> it so you can add a door and connect it.</p></li>\n</ol>\n\n<p>The magic step, and the piece I was missing, is <em>sparseness</em>. A normal maze fills every single square of the world, leaving no areas where you can fit a room. The trick that Jamis and FastAsUcan do here is to carve the whole maze and then <em>uncarve</em> the dead ends.</p>\n\n<p>Doing that is actually pretty easy. A dead end is just a tile that has walls on three sides. When you find one of those, you fill that tile back in. That may in turn make the tile it connects to a dead end. Keep doing this until you run out of dead ends and you&rsquo;ll end up with lots of solid area where rooms can be placed.</p>\n\n<p>Of course, if you do that starting with a perfect maze and run to completion, you&rsquo;ll erase the whole maze! A perfect maze has no loops so <em>everything</em> is a dead end if you follow passages long enough. Jamis&rsquo; solution is to not erase <em>all</em> of the dead ends, just some. It stops after a while. Something like this:</p>\n\n<figure>\n  <canvas id=\"dead-ends\" width=\"570\" height=\"390\">Sorry, you need canvas support for this demo.</canvas>\n  <label for=\"dead-end-open\">Corridors to leave:</label>\n  <input type=\"range\" id=\"dead-end-open\" min=\"1\" value=\"1000\" max=\"3000\">\n  <output for=\"dead-end-open\" id=\"dead-end-open-output\">1000</output>\n</figure>\n\n<p>Once you do that, you can start placing rooms. The process Jamis uses for this is interesting. He picks a room size and then tries to place it on every single location in the dungeon. Any location that overlaps a room or passageway is discarded. The remaining positions are &ldquo;ranked&rdquo; where rooms that are near passageways are better. It then picks the best position and places the room there, and puts some doors between the room and the passage.</p>\n\n<p>Rinse, lather, repeat and you&rsquo;ve got yourself a dungeon.</p>\n\n<h2>Rooms <em>then</em> mazes</h2>\n\n<p>I went ahead and coded this up exactly as described. It went OK, but I found that the process of placing rooms was pretty slow. It works well for dungeons of the small size you do for a tabletop role-playing game, but not so much at the scale of a computer roguelike.</p>\n\n<p>So, I did some tinkering and came up with a slight variation. My contribution is pretty minor, but I thought it would be worth writing down. (Honestly, I just think it&rsquo;s fun to watch animated dungeon generators, and the prose is pure fluff.)</p>\n\n<p>Where Buck and Karcero start with the maze and then add the rooms, mine does things in the opposite order. First, it places a bunch of random rooms. Then, it iterates over every tile in the dungeon. When it finds a solid one where an open area <em>could</em> be, it starts running a maze generator at that point.</p>\n\n<p>Maze generators work by incrementally carving passages while avoiding cutting into an already open area. That&rsquo;s how you ensure the maze only has one solution. If you let it carve into existing passages, you&rsquo;d get loops.</p>\n\n<p>This is conveniently exactly what you need to let the maze grow and fill the odd shaped areas that surround the rooms. In other words, a maze generator is a randomized <a href=\"http://en.wikipedia.org/wiki/Flood_fill\">flood fill</a> algorithm. Run this on every solid region between the rooms and we&rsquo;re left with the entire dungeon packed full of disconnected rooms and mazes.</p>\n\n<figure>\n  <canvas id=\"maze-fill\" width=\"570\" height=\"390\">\n      Sorry, you need canvas support for this demo.\n  </canvas>\n  <figcaption>\n    Each color here represents a different region of connected tiles.\n  </figcaption>\n</figure>\n\n<h2>Looking for a connection</h2>\n\n<p>All that remains is to stitch those back together into a single continuous dungeon. Fortunately, that&rsquo;s pretty easy to do. The room generator chooses odd sizes and positions for rooms so they are aligned with the mazes. Those in turn fill in all of the unused area, so we&rsquo;re assured that each unconnected region is only a single tile away from its neighbors.</p>\n\n<p>After filling in the rooms and mazes, we find all of those possible <em>connectors</em>. These are tiles that are:</p>\n\n<ol>\n<li><p>Solid rock.</p></li>\n<li><p>Adjacent to two regions of different colors.</p></li>\n</ol>\n\n<p>Here they are highlighted:</p>\n\n<figure>\n  <canvas id=\"connectors\" width=\"570\" height=\"390\">\n      Sorry, you need canvas support for this demo.\n  </canvas>\n</figure>\n\n<p>We use these to tie the regions together. Normally we think of the entire dungeon as a graph with each tile a vertex, but we&rsquo;re going to go up a level of abstraction. Now, we treat each <em>region</em> of tiles as a single vertex and each connector as an edge between them.</p>\n\n<p>If we use <em>all</em> of the connectors, our dungeon would be way too densely connected. Instead, we carve through just the connectors we need to get each region connected to the whole <em>once</em>. In fancy terms, we&rsquo;re finding a <a href=\"http://en.wikipedia.org/wiki/Spanning_tree\"><em>spanning tree</em></a>.</p>\n\n<p>The process is pretty straightforward:</p>\n\n<ol>\n<li><p><strong>Pick a random room to be the main region.</strong></p></li>\n<li><p><strong>Pick a random connector that touches the main region and open it up.</strong> In the demo, it does that by placing a door, but you can do an open passageway, locked door, or magical wardrobe. Be creative.</p>\n\n<p>Note that this process is agnostic about rooms and mazes. It just deals in\n&ldquo;regions&rdquo;. That means it can connect rooms directly to other rooms sometimes. You can avoid that if you want, but I find the resulting dungeons more fun to play.</p></li>\n<li><p><strong>The connected region is now part of the main one. Unify it.</strong> In the demo, I use a little flood fill algorithm to color in the newly merged region because it looks pretty. In a real implementation, you don&rsquo;t need to mess with tiles. Just make a little data structure that tracks &ldquo;region X is now merged&rdquo;.</p></li>\n<li><p><strong>Remove any extraneous connectors.</strong> There are likely other existing connectors that connect the two regions that just merged. Since they no longer connect two separate regions and we want a spanning tree, discard them.</p></li>\n<li><p><strong>If there are still connectors left, go to #2.</strong> Any remaining connectors imply that there is still at least one disconnected region. Keep looping until all of the unconnected regions are merged into the main one.</p></li>\n</ol>\n\n<p>Earlier, I said that I don&rsquo;t want a perfect dungeon because they make for crappy gameplay. But, since this creates a spanning tree, that&rsquo;s exactly what we&rsquo;ve got. We only allow a single connector between any two regions so our dungeon <em>is</em> a tree and there&rsquo;s only a single path between any two points.</p>\n\n<p>Fixing that is pretty simple. In step 3, when we cull the unneeded connectors, we give them a <em>slight</em> chance of being opened up. Something like:</p>\n<div class=\"highlight\"><pre><code class=\"language-dart\" data-lang=\"dart\"><span></span><span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">rng</span><span class=\"p\">.</span><span class=\"n\">oneIn</span><span class=\"p\">(</span><span class=\"m\">50</span><span class=\"p\">))</span> <span class=\"n\">_carve</span><span class=\"p\">(</span><span class=\"n\">pos</span><span class=\"p\">,</span> <span class=\"n\">CELL_DOOR</span><span class=\"p\">);</span>\n</code></pre></div>\n<p>This occasionally carves an extra opening between regions. That gives us the imperfect loops we want to make the dungeon more fun to play in. Note that this is also easily tunable. If we make the chance more likely, we get more densely connected dungeons.</p>\n\n<h2>Uncarving</h2>\n\n<p>If we stop here, we&rsquo;ll get dungeons that are packed chock full of maze corridors, most of which are dead ends. That has a certain sadistic appeal, but isn&rsquo;t exactly what I&rsquo;m going for. The last remaining step is the &ldquo;sparseness&rdquo; pass described earlier.</p>\n\n<p>Now that we&rsquo;ve got all of our rooms connected to each other, we can remove all of the dead ends in the maze. When we do that, the mazes are reduced to just the winding set of passageways needed to connect the rooms to each other. Every corridor is guaranteed to go somewhere interesting.</p>\n\n<h2>What we ended up with</h2>\n\n<p>In summary:</p>\n\n<ol>\n<li><p>Place a bunch of random non-overlapping rooms.</p></li>\n<li><p>Fill in the remaining solid regions with mazes.</p></li>\n<li><p>Connect each of the mazes and rooms to their neighbors, with a chance to add some extra connections.</p></li>\n<li><p>Remove all of the dead ends.</p></li>\n</ol>\n\n<p>I&rsquo;m pretty happy with it so far. It&rsquo;s not perfect, though. It tends to produce annoyingly windy passages between rooms. You can tune that by tweaking your maze generation algorithm, but making the passageways less windy tends to make them wander to the edge of the dungeon, which has its own strange look.</p>\n\n<p>The fact that rooms and mazes are aligned to odd boundaries makes things simpler and helps fill it in nicely, but it does give the dungeon a bit of an artificially aligned look. But, overall, it&rsquo;s an improvement over what I had before, and the dungeons it makes seem to be pretty fun to play.</p>\n\n<p>If you want to see for yourself, you can play the game <a href=\"http://munificent.github.io/hauberk/\">right in your browser</a>. The code for these demos is <a href=\"https://github.com/munificent/rooms-and-mazes\">here</a>, but it&rsquo;s pretty gnarly. Making them animated adds a lot of complexity. Instead, <a href=\"https://github.com/munificent/hauberk/blob/db360d9efa714efb6d937c31953ef849c7394a39/lib/src/content/dungeon.dart\">here</a> is the much cleaner implementation my game uses.</p>\n\n<p>As a bonus for making it this far, here&rsquo;s a super dense giant dungeon. I find it hypnotic:</p>\n\n<figure>\n  <canvas id=\"giant\" width=\"570\" height=\"390\">\n      Sorry, you need canvas support for this demo.\n  </canvas>\n</figure>\n\n<script type=\"application/dart\" src=\"/code/2014-12-21-rooms-and-mazes/main.dart\"></script>\n\n<script src=\"/code/2014-12-21-rooms-and-mazes/packages/browser/dart.js\"></script>\n","contentSnippet":"canvas {\n  background: #222;\n  display: inline-block;\n  max-width: 100%;\n}\n\n\nSeveral months ago I promised a follow-up to my previous blog post about turn-based game loops in my roguelike. Then I got completely sidetracked by self-publishing my book, Game Programming Patterns, and forgot all about it. I totally left you hanging.\nWell, I finally got some time to think about my roguelike again and today, I’m here to… keep you hanging. Alas, you are at the mercy of my wandering attention span! Instead of game loops, today we’re going to talk about possibly the most fun and challenging part of making a roguelike: generating dungeons!\nGo ahead and click the little box below to see what we end up with:\nSorry, you need canvas support for this demo.\n  Click it again to restart it.\n\n\nPretty neat, huh? If you want to skip the prose, the code is here.\nOne of my earliest memories of computing is a maze generator running on my family’s Apple IIe. It filled the screen with a grid of green squares, then incrementally cut holes in the walls. Eventually, every square of the grid was connected and the screen was filled with a complete, perfect maze.\nMy little home computer could create something that had deep structure—every square of the maze could be reached from any other—and yet it seemed to be chaotic—it carved at random and every maze was different. This was enough to blow my ten-year-old mind. It still kind of does today.\nWhat’s in a dungeon?\nProcedural generation—having the game build stuff randomly instead of using hand-authored content—is amazing when it works well. You get a ton of replayability because the game is different every time. As the person implementing the game, you also get the critical feature of not knowing what you’re going to get even though you wrote the code. The game can surprise you too.\nPeople get into procedural generation because it seems easier. Hand-authoring content is obviously a lot of work. If you want your game to have a hundred levels, you have to make a hundred things. But make one little random level generator and you can have a hundred levels, a thousand, or a million, for free!\nAlas, it doesn’t quite work out that way. You see, defining the procedure is a hell of a lot harder than just sitting down and banging out some content. You have to take some very nebulous, artistic chunk of your brain, figure out precisely what it’s doing, and translate that to code. You’re coding a simulation of yourself.\nIt must balance a number of technical and aesthetic constraints. For mine, I focused on:\nIt needs to be fairly efficient. The generator only runs when the player enters a new level, so it doesn’t have to be as super fast, but I still don’t want a several second pause giving the player time to question whether they should be playing a game or doing something more productive with their life.\n\n\nThe dungeon needs to be connected. Like the mazes on my old green-screen Apple, that means from any point in the dungeon, there is a way—possibly circuitous—to any other point.\nThis is vital because if player has to complete a quest like “find the magic chalice” or “kill the cockatrice”, it’s pretty cruel if the dungeon drops that in some walled-off room the player can’t get to. It also avoids wasting time generating and populating areas the player can never see.\n\n\nMoreso, I want dungeons to not be perfect. “Perfect” in the context of mazes and graphs (which are synonymous) means there is only one path between any two points. If you flatten out all of the windy passages, you’ll discover your twisty maze is really just a tree all crumpled up. Passageways branch but never merge. Im-perfect mazes have loops and cycles—multiple paths from A to B.\nThis is a gameplay constraint, not a technical one. You could make a roguelike with perfect dungeons, and many simple roguelikes do that because generators for those are easier to design and implement.\nBut I find them less fun to play. When you hit a dead end (which is often), you have to do a lot of backtracking to get to a new area to explore. You can’t circle around to avoid certain enemies, or sneak out a back passage. Neither can the bad guys, for that matter.\nFundamentally, games are about making decisions from a set of alternatives. At a literal level, perfect dungeons only give you one path to choose from.\n\n\nI want open rooms. I could make dungeons just be nothing but mazes of narrow passages, but then you could never get surrounded by a horde of monsters. It would feel claustrophic and kill a bunch of interesting combat tactics.\nWide open areas are critical for area effect spells, and big dramatic battles. They also provide space for interesting decorations and themed areas. Vaults, pits, traps, treasure rooms, etc. Rooms are the high points of the hero’s journey.\n\n\nI want passageways. At the same time, I don’t want the dungeon to just be rooms. There are some games that create levels this way where doors directly join room to room. It works OK, but I find it a bit monotonous. I like the player feeling confined part of the time, and having narrow corridors that the player can draw monsters into is a key tactic in the game.\n\n\nAll of this needs to be tunable. Many roguelikes have one huge multi-floor dungeon where depths vary in difficulty but not much else. My game is different. It has a number of different areas. Each has its own look and feel. Some may be small and cramped, others spacious and orderly.\nI solve this partially by having multiple distinct dungeon generation algorithms. Outdoor areas use an entirely different process. (I should probably write about that too sometime. Look, another unfulfilled promise!)\nBut coding a new dungeon generator from scratch for every area is a huge time sink. Instead, I want the generator to have a bunch of knobs and levers I can tweak so I can make a number of areas that share the same code but have their own feel.\n\n\n\nA room with a view\nI’ve been working on this game pretty much forever (it’s gone through four different implementation languages!) and I’ve tried a number of different dungeon generators. My main source of inspiration is a game called Angband. The only thing I’ve sunk more of my life into than working on my game is playing that one.\nAngband is fantastically old. When it forked off of Moria, Nancy Kerrigan had just taken a round of melee damage from a club-wielding troll. On machines of that time, it was much harder to make a fast dungeon generator, and Angband’s is pretty simple:\nSprinkle a bunch of randomly located, non-overlapping rooms.\n\n\nDraw random corridors to connect them.\n\n\n\nTo ensure rooms don’t overlap, I just discard a room if it collides with any previously placed one. To avoid a possible infinite loop, instead of trying until a certain number of rooms are successfully placed, I do a fixed number of attempts to place rooms. Failure becomes more common as the dungeon gets fuller—after all, you can only fit so many rooms in a given area—but tuning this gives you some control over room density, like so:\nSorry, you need canvas support for this demo.\n  Attempts:\n  \n  200\n\n\nA dark and twisty passageway\nMost of the dungeon generators I’ve written start with this. The hard part, by far, is making good passageways to connect them. That’s really what this post is about—a neat way to solve that problem.\nAngband’s solution is brute force but surprisingly effective. It picks a pair of rooms—completely ignoring how far apart they are—and starts a passageway that wanders randomly from one (hopefully) to the other. It’s got a few clever checks to keep things from overlapping too much but passageways can and do cut through other rooms, cross other passages or dead end.\nI tried implementing that a number of times but (likely failures on my part) never got to something I really liked. The corridors I ended up with always looked too straight, or overlapped other stuff in unattractive ways.\nThen, a few months ago, I stumbled onto a description of a dungeon generator by u/FastAsUcan on the /r/roguelikedev subreddit. His generator, Karcero, is based on Jamis Buck’s dungeon generator. If you’ve ever done any procedural dungeon generation, you know—or should know—who Buck is. He’s got a ton of great articles on random mazes.\nYears ago, I remember seeing an actual dungeon generator he wrote for use with pen-and-paper Dungeons & Dragons. Unlike most of his maze stuff, this had actual rooms, and the results looked great.\nBut, at the time, I didn’t know how it worked. How do you go from mazes to open winding corridors and rooms? I tucked this open question away in the corner of my mind and immediately forgot about it.\nThe post by FastAsUcan provides the answer. It works like so:\nMake a perfect maze. There are a number of different algorithms for this, but they’re all fairly straightforward.\n\n\nMake the maze sparse. Find dead end passages and fill them back in with solid rock.\n\n\nPick some of the remaining dead ends and cut holes in them to adjacent walls. This makes the maze imperfect. (Remember, this is a good thing!)\n\n\nCreate rooms and find good locations to place them. “Good” here means not overlapping the maze but near it so you can add a door and connect it.\n\n\n\nThe magic step, and the piece I was missing, is sparseness. A normal maze fills every single square of the world, leaving no areas where you can fit a room. The trick that Jamis and FastAsUcan do here is to carve the whole maze and then uncarve the dead ends.\nDoing that is actually pretty easy. A dead end is just a tile that has walls on three sides. When you find one of those, you fill that tile back in. That may in turn make the tile it connects to a dead end. Keep doing this until you run out of dead ends and you’ll end up with lots of solid area where rooms can be placed.\nOf course, if you do that starting with a perfect maze and run to completion, you’ll erase the whole maze! A perfect maze has no loops so everything is a dead end if you follow passages long enough. Jamis’ solution is to not erase all of the dead ends, just some. It stops after a while. Something like this:\nSorry, you need canvas support for this demo.\n  Corridors to leave:\n  \n  1000\n\n\nOnce you do that, you can start placing rooms. The process Jamis uses for this is interesting. He picks a room size and then tries to place it on every single location in the dungeon. Any location that overlaps a room or passageway is discarded. The remaining positions are “ranked” where rooms that are near passageways are better. It then picks the best position and places the room there, and puts some doors between the room and the passage.\nRinse, lather, repeat and you’ve got yourself a dungeon.\nRooms then mazes\nI went ahead and coded this up exactly as described. It went OK, but I found that the process of placing rooms was pretty slow. It works well for dungeons of the small size you do for a tabletop role-playing game, but not so much at the scale of a computer roguelike.\nSo, I did some tinkering and came up with a slight variation. My contribution is pretty minor, but I thought it would be worth writing down. (Honestly, I just think it’s fun to watch animated dungeon generators, and the prose is pure fluff.)\nWhere Buck and Karcero start with the maze and then add the rooms, mine does things in the opposite order. First, it places a bunch of random rooms. Then, it iterates over every tile in the dungeon. When it finds a solid one where an open area could be, it starts running a maze generator at that point.\nMaze generators work by incrementally carving passages while avoiding cutting into an already open area. That’s how you ensure the maze only has one solution. If you let it carve into existing passages, you’d get loops.\nThis is conveniently exactly what you need to let the maze grow and fill the odd shaped areas that surround the rooms. In other words, a maze generator is a randomized flood fill algorithm. Run this on every solid region between the rooms and we’re left with the entire dungeon packed full of disconnected rooms and mazes.\nLooking for a connection\nAll that remains is to stitch those back together into a single continuous dungeon. Fortunately, that’s pretty easy to do. The room generator chooses odd sizes and positions for rooms so they are aligned with the mazes. Those in turn fill in all of the unused area, so we’re assured that each unconnected region is only a single tile away from its neighbors.\nAfter filling in the rooms and mazes, we find all of those possible connectors. These are tiles that are:\nSolid rock.\n\n\nAdjacent to two regions of different colors.\n\n\n\nHere they are highlighted:\nWe use these to tie the regions together. Normally we think of the entire dungeon as a graph with each tile a vertex, but we’re going to go up a level of abstraction. Now, we treat each region of tiles as a single vertex and each connector as an edge between them.\nIf we use all of the connectors, our dungeon would be way too densely connected. Instead, we carve through just the connectors we need to get each region connected to the whole once. In fancy terms, we’re finding a spanning tree.\nThe process is pretty straightforward:\nPick a random room to be the main region.\n\n\nPick a random connector that touches the main region and open it up. In the demo, it does that by placing a door, but you can do an open passageway, locked door, or magical wardrobe. Be creative.\nNote that this process is agnostic about rooms and mazes. It just deals in\n“regions”. That means it can connect rooms directly to other rooms sometimes. You can avoid that if you want, but I find the resulting dungeons more fun to play.\n\n\nThe connected region is now part of the main one. Unify it. In the demo, I use a little flood fill algorithm to color in the newly merged region because it looks pretty. In a real implementation, you don’t need to mess with tiles. Just make a little data structure that tracks “region X is now merged”.\n\n\nRemove any extraneous connectors. There are likely other existing connectors that connect the two regions that just merged. Since they no longer connect two separate regions and we want a spanning tree, discard them.\n\n\nIf there are still connectors left, go to #2. Any remaining connectors imply that there is still at least one disconnected region. Keep looping until all of the unconnected regions are merged into the main one.\n\n\n\nEarlier, I said that I don’t want a perfect dungeon because they make for crappy gameplay. But, since this creates a spanning tree, that’s exactly what we’ve got. We only allow a single connector between any two regions so our dungeon is a tree and there’s only a single path between any two points.\nFixing that is pretty simple. In step 3, when we cull the unneeded connectors, we give them a slight chance of being opened up. Something like:\nif (rng.oneIn(50)) _carve(pos, CELL_DOOR);\n\n\nThis occasionally carves an extra opening between regions. That gives us the imperfect loops we want to make the dungeon more fun to play in. Note that this is also easily tunable. If we make the chance more likely, we get more densely connected dungeons.\nUncarving\nIf we stop here, we’ll get dungeons that are packed chock full of maze corridors, most of which are dead ends. That has a certain sadistic appeal, but isn’t exactly what I’m going for. The last remaining step is the “sparseness” pass described earlier.\nNow that we’ve got all of our rooms connected to each other, we can remove all of the dead ends in the maze. When we do that, the mazes are reduced to just the winding set of passageways needed to connect the rooms to each other. Every corridor is guaranteed to go somewhere interesting.\nWhat we ended up with\nIn summary:\nPlace a bunch of random non-overlapping rooms.\n\n\nFill in the remaining solid regions with mazes.\n\n\nConnect each of the mazes and rooms to their neighbors, with a chance to add some extra connections.\n\n\nRemove all of the dead ends.\n\n\n\nI’m pretty happy with it so far. It’s not perfect, though. It tends to produce annoyingly windy passages between rooms. You can tune that by tweaking your maze generation algorithm, but making the passageways less windy tends to make them wander to the edge of the dungeon, which has its own strange look.\nThe fact that rooms and mazes are aligned to odd boundaries makes things simpler and helps fill it in nicely, but it does give the dungeon a bit of an artificially aligned look. But, overall, it’s an improvement over what I had before, and the dungeons it makes seem to be pretty fun to play.\nIf you want to see for yourself, you can play the game right in your browser. The code for these demos is here, but it’s pretty gnarly. Making them animated adds a lot of complexity. Instead, here is the much cleaner implementation my game uses.\nAs a bonus for making it this far, here’s a super dense giant dungeon. I find it hypnotic:","guid":"http://journal.stuffwithstuff.com/2014/12/21/rooms-and-mazes","isoDate":"2014-12-21T08:00:00.000Z","timestamp":"12/21/2014"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"How My Book Launch Went","link":"http://journal.stuffwithstuff.com/2014/11/20/how-my-book-launch-went/","pubDate":"Thu, 20 Nov 2014 00:00:00 -0800","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<p>Greetings, superfans! When we <a href=\"/2014/11/03/bringing-my-web-book-to-print-and-ebook/\">last tuned in</a>, I was just about to &ldquo;launch&rdquo; <a href=\"http://gameprogrammingpatterns.com/\">my self-published book</a>. I put that in quotes because it&rsquo;s an awfully serious-sounding word for what was really just doing some clicking on my laptop. If my last post was the climax of my book writing adventure, consider this the denouement. You&rsquo;ve been with me this long, it&rsquo;s the least I can do.</p>\n\n<p>I do hold back one detail, though: while I talk about sales here, I won&rsquo;t be putting cash numbers on it. If you try hard enough, you can calculate them yourself, but I feel weird sharing financial details. Strangely, it&rsquo;s not because I&rsquo;m shy about <em>strangers</em> knowing it as much as I am friends and family. So much room for awkwardness there.</p>\n\n<h2>I am a Marketer and I do Marketer-y Things</h2>\n\n<p>As I mentioned before, I decided to self-publish about halfway through writing the manuscript. That meant I had to wear all of the hats that a publisher has dedicated noggins for: editor, designer, proofreader, and&hellip; marketer. This last one is the least fun for me, but I know it&rsquo;s important.</p>\n\n<p>I read a bit online and what a lot of people said was that email lists are gold. <em>I</em> like that they are pull-based instead of push-based. Instead of jamming myself and my book down strangers&rsquo; throats, they sign up of their own volition. I only get in touch with the people who actually want to hear from me.</p>\n\n<p>So I created a <a href=\"http://mailchimp.com/\">MailChimp</a> account&mdash;chosen over other mailing list providers mainly because of their cute logo&mdash;and slapped a little &ldquo;sign up!&rdquo; form on every page of the site. Whenever I put a new chapter online, I got a traffic bump and some fraction of those people were kind or foolhardy enough to grant me their email address.</p>\n\n<p>I did this pretty early in the writing process so that I could give it time to grow before the book was complete. By putting the whole book online and releasing it chapterly (like a Dickens serial for the Internet age) I had amassed a surprisingly large list by the time I was ready to <strike>try to squeeze money out of them</strike> tell them my book was complete. Around 8,000 people, which still seems like a crazy large number to me.</p>\n\n<p>I also, despite <a href=\"https://twitter.com/munificentbob\">the content of my tweets</a>, managed to acquire a fair number of twitter friends. (I don&rsquo;t like thinking of them &ldquo;followers&rdquo;. Celebutants and TEDx thought/cult leaders have &ldquo;followers&rdquo;. I just have Internet pals.)</p>\n\n<h2>A New Front Page</h2>\n\n<p>Now that the book is a <em>product</em> as much as it is a <em>web site</em>, I redid the front page to highlight both of those. It still, of course, links to the web version. And, <em>of course</em>, the entire contents of the book are still readable on the web. But I also added links to the various sites where you could get the print version, Kindle, and EPUB.</p>\n\n<p>I wanted to emphasize the &ldquo;bookyness&rdquo; of it, the physicality, so I got out my camera and my macro lens and took a bunch of honest-to-God photos of it:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/cover-shoot.jpg\">\n  <figcaption>Wait&hellip; if the camera is in the photo, how did I take <em>this</em> shot?</figcaption>\n</figure>\n\n<p>There&rsquo;s something weird and meta about taking a picture of myself taking photos of a book whose cover I designed using a photo I took of an illustration I drew. I should take a picture of myself writing this blog post just to go full Inception.</p>\n\n<p>Next, I spent way too long coming up with a design and text for the front page. Seriously, it took me as long to make what is effectively a glorified list of hyperlinks as it did to write, illustrate, and edit a full chapter of the book. I think it&rsquo;s worth it, though. The front page is the reader&rsquo;s first impression of the book. If I make you feel that page is beautiful and high quality, it&rsquo;s a short hop to having faith that the inside of the book is too.</p>\n\n<p>I ended up with this:</p>\n\n<figure>\n  <a href=\"http://gameprogrammingpatterns.com\" target=\"_blank\"><img class=\"framed\" src=\"/image/2014/11/new-site.jpg\"></a>\n  <figcaption>Click to zoom!</figcaption>\n</figure>\n\n<h2>This Part of the Blog Post is About Writing a Blog Post</h2>\n\n<p>I feel a little squirmy writing this. Like I said, I&rsquo;m uncomfortable with self-promotion. I hoped, wanted, to get a decent amount of&hellip; attention? traffic? validation of my worth as a human? when I announced the for-sale versions of the book. Readers had been asking for them for a while, so I knew there would be some excitement just by saying, &ldquo;Here they are.&rdquo;</p>\n\n<p>But that didn&rsquo;t feel really newsworthy to me. There wasn&rsquo;t much to discuss, just &ldquo;here they are. moneys plz.&rdquo; People like a story, and I like telling them, especially when the protagonist is yours truly. I&rsquo;ve been really lucky to have a lot of encouragement on this project from readers, and I thought one way to say thanks would be to give a window into what the production process was like. It&rsquo;s a side of book-making that I don&rsquo;t see very much online.</p>\n\n<p>Also, it let me blather about fonts for six thousand words. Seriously, the <a href=\"/2014/11/03/bringing-my-web-book-to-print-and-ebook/\">blog post</a> I wrote about turning the manuscript into a physical book is longer than almost every chapter in the book. Clearly, I need an editor.</p>\n\n<p>This also took a lot of time&mdash;about a week&mdash;but I really enjoyed writing it all down. I did my best to make it an entertaining read. While I hoped it would drive traffic to the book, I did honestly want it to be a worthwhile read in and of itself. I believe that, when played well, life is a non-zero-sum game.</p>\n\n<h2>I &lt;3 Filling Out Web Forms</h2>\n\n<p>I was ready to upload the new site, and the new blog post. All that was left was to actually make the book available. This involved uploading various files&mdash;inside PDF for the print version, cover, EPUB file, MOBI file&mdash;to various sites whose forms cover the full gamut of usability. Clicking the final &ldquo;OK&rdquo; on CreateSpace, Kindle Direct Publishing, and Smashwords was both nerve-wracking and anti-climactic.</p>\n\n<p>Then the waiting game. Most of these sites do various amounts of automated and manual validation that take time to process. I noticed a typo that forced me to re-upload to CreateSpace. Kindle found a couple of spelling errors (surprising given how many rounds of editing I&rsquo;d done by now). Smashwords asked me to have an explicit cover page.</p>\n\n<p>Once those were all happy, the listings appeared. If you knew to look for them, you could have bought the book.</p>\n\n<p>CreateSpace and Smashwords also distribute to other sales channels (things like Lightning Source and book stores for the former; iBooks, Nook, Kobo, etc. for the latter). I wanted to wait for those sales channels to populate before I pulled the switch but&hellip; well, I got impatient.</p>\n\n<p>As soon as I saw <a href=\"http://www.amazon.com/gp/product/0990582906\">the Amazon page for my book</a>, I just couldn&rsquo;t wait any more. I pushed the new version of the site and the blog post. I wrote an email and blasted the mailing list. I tweeted. I mentioned it on G+.</p>\n\n<p>What I <em>didn&rsquo;t</em> do this time was post it to reddit. It felt a little too self-serving for how reddit rolls. I did post a link to the blog <a href=\"https://news.ycombinator.com/item?id=8555285\">on Hacker News</a> since that crowd is more accepting of self-promotion.</p>\n\n<p>I had tabs open for the Smashwords sales dashboard, CreateSpace royalties, Kindle Direct Publishing sales report, twitter, and Hacker News. I refreshed those suckers like my life depended on it.</p>\n\n<h2>Command, We Are Ready for Launch</h2>\n\n<p>This moment, as dumb as it sounds, was actually pretty stressful. A surprisingly large number of self-published books just sink to the depths leaving nary a ripple on the surface. You hear horror stories of writers whose novels sell <em>zero</em> copies. Nonfiction is a lot easier, but I still had no idea if people really liked the book enough to drop real cash on it.</p>\n\n<p><em>Refresh refresh refresh refresh.</em> A nervous sweat trickled down my neck.</p>\n\n<p>A few minutes later, Smashwords reported two sales. Holy shit! Someone bought the book! I was a professional writer!</p>\n\n<p>Then people started retweeting me. Someone posted a blurb about it <a href=\"http://www.reddit.com/r/gamedev/comments/2l9hr0/game_programming_patterns_is_now_in_print/\">on the gamedev subreddit</a> and someone else did <a href=\"http://www.reddit.com/r/programming/comments/2l8v11/today_is_the_day_game_programming_patterns_now_in/\">on the programming subreddit</a>.</p>\n\n<p>People started saying super nice things! About me! It was awesome! Also, I was drinking in celebration at the same time so that multiplied all the good feelings.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/cat.gif\">\n  <figcaption>How I felt.</figcaption>\n</figure>\n\n<p>I feverishly replied to as many comments, tweets, and emails as I could. (All the while still refreshing the other tabs.) Eventually, I maxed out my serotonin levels and had to crash. Like some candy raver in an E puddle in the back of the chill-out room, I passed out, totally spent.</p>\n\n<h2>The Next Day</h2>\n\n<p>I woke up the next morning feeling like a kid on Christmas. A kid who wasn&rsquo;t <em>entirely</em> certain he&rsquo;d been good enough for Santa to bring him presents. Morning coffee in hand, I opened up my laptop and checked all the dashboards.</p>\n\n<p>While I slept, I&rsquo;d sold enough copies to pay off all of the expenses of the book. That isn&rsquo;t actually <em>that</em> much: all I&rsquo;d paid for was ISBN numbers, a couple of fonts, freelance copy-editing, and a business license. But, still, I was in the black now.</p>\n\n<p>I replied to as many people as I could and then headed into the office to <strike>get some work done</strike> spend the rest of the day refreshing my browser. Aggregate sales stats started showing up in the various dashboards:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/kindle-hockey.png\">\n  <figcaption>Kindle sales on the first day.</figcaption>\n</figure>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/smash-hockey.png\">\n  <figcaption>Smashwords (EPUB) sales on the first day.</figcaption>\n</figure>\n\n<p>CreateSpace doesn&rsquo;t draw a pretty picture for you, but the raw numbers were doing the same thing. I told my coworkers and they got all excited for me.</p>\n\n<p>The rest of the day was basically a blur of responding to people and telling my wife and team how high the numbers were going. At some point, when I refreshed the Amazon page, I noticed a little banner had appeared next to my book:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/banner.png\">\n  <figcaption>No way.</figcaption>\n</figure>\n\n<p>It turns out Amazon tracks book sales <em>very quickly.</em> For the brief period of time where I had saturated social media, enough sales were coming in to actually make it the best-selling game programming book for a little while.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/best-game.png\">\n  <figcaption>Sorry &ldquo;Learning Python&rdquo;.</figcaption>\n</figure>\n\n<p>Wait, did I say &ldquo;game programming&rdquo;? I meant #1 out of <em>all programming books</em>:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/best-programming.png\">\n  <figcaption>I did a victory lap at this point.</figcaption>\n</figure>\n\n<p>At it&rsquo;s peak, my book was the #7 best-selling book in the entire computer category:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/best-computer.png\">\n  <figcaption>Up there with Minecraft!</figcaption>\n</figure>\n\n<p>Around this time, I started referring to myself in the third person as &ldquo;best-selling author Robert Nystrom&rdquo;. Of course, most of the other books in those lists had been there for weeks or months, but I had my moment in the sun and I was committed to making the most of it.</p>\n\n<h2>Return to Normalcy</h2>\n\n<p>The peak, naturally, only lasted about a day. I was most curious to see what the right side of the graph would look like. Would it fall to zero? A slow trickle? A steady passive income?</p>\n\n<p>When I sent out the email for the book, one thing I asked was for people to write honest, detailed reviews. I figured a book page with a good set of reviews would give it the air of legimitacy for future customers who stumbled onto the book on their own. That in turn would help the book have a longer sales tail.</p>\n\n<p>Because people are awesome and I love every one of them, people did indeed do this. It took a while, but reviews started trickling in.</p>\n\n<p>Other pleasant surprises started happening too. The book finally made its way through the other channels. I put it up on <a href=\"https://play.google.com/store/books/details/Robert_Nystrom_Game_Programming_Patterns?id=9fIwBQAAQBAJ\">Google Play</a>, and Smashwords got it onto <a href=\"http://itunes.apple.com/us/book/isbn9780990582915\">iBooks</a>, <a href=\"http://www.barnesandnoble.com/w/game-programming-patterns-robert-nystrom/1102794265?ean=2940046391428\">Nook</a>, and some other places. I finally figured out a place to <a href=\"https://payhip.com/b/iZRI\">sell the PDF</a>. (If you go to <a href=\"http://gameprogrammingpatterns.com/\">the book&rsquo;s site</a> now, these are all listed there.)</p>\n\n<p>In a mistake that I don&rsquo;t understand but can&rsquo;t bear to correct, Apple even decided to spice up my name a bit:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/umlaut.png\">\n  <figcaption>Robert Nyström, now 15% more metal.</figcaption>\n</figure>\n\n<p>Then, a few days later, the most magical part of this whole thing started happening (though, honestly, the umlaut is a close second). That&rsquo;s about how long it took for print copies to get shipped to people.</p>\n\n<p>Soon, friends and family&mdash;some who I haven&rsquo;t seen in years&mdash;started sending me pictures of their copies of the book. Kind strangers in countries I couldn&rsquo;t find on a map tweeted pictures of themselves opening the shipping box with excitement to see my dumb face staring out at them.</p>\n\n<p>It&rsquo;s hard to articulate how profoundly gratifying that is. Through almost the entire six years I&rsquo;ve been working on this book, it&rsquo;s been a purely digital thing. While I spend an astonishing amount of my life on the Internet, it still never quite feels &ldquo;real&rdquo; to me.</p>\n\n<p>Is rearranging some polarization on an SSD really <em>making</em> something? Is a few words glowing on an LCD actually communicating with a <em>person</em>, or just some pixelated avatar?</p>\n\n<p>But seeing photos of real live people holding an actual <em>physical thing</em> filled with words and illustrations I put together, and seeing them <em>happy</em> to have it in their hands finally made it click for me that I made something real that actually affected people.</p>\n\n<h2>How We&rsquo;re Looking Now</h2>\n\n<p>Things have mostly settled down since then, though I do still have lots of email to catch up on (sorry!). Now that the book is in pretty much every sales channel, eBook walled garden, and international site for Amazon, I&rsquo;m <em>finally</em> getting to the point where I can think of the book as <em>done</em> and put it into the background of my life.</p>\n\n<p>So far, buyers have been trickling in at a decent rate. Here&rsquo;s what my Kindle sales look like as of writing this post:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/kindle-now.png\">\n  <figcaption>EPUB is similar, and I think print is too.</figcaption>\n</figure>\n\n<p>The book has been out about two weeks, and I&rsquo;ve sold:</p>\n\n<ul>\n<li><p><strong>796 print copies.</strong> 555 in the US, 145 in Great Britain, 95 in Europe, and 1 directly from createspace.com</p></li>\n<li><p><strong>274 Kindle copies.</strong> I&rsquo;ll spare you the per country break-down, but it is really cool to see that I&rsquo;ve sold it in India, Japan, Brazil, and other places.</p></li>\n<li><p><strong>70 copies from smashwords.</strong> This is people who wany to buy the EPUB file directly.</p></li>\n<li><p><strong>7 copies from iBooks.</strong> The book only appeared a few days ago, so I expect this to catch up with the other channels over time.</p></li>\n</ul>\n\n<p>That&rsquo;s a grand total of <strong>1,147 copies sold in the first two weeks.</strong> I won&rsquo;t be retiring off of this, but I&rsquo;m really really happy with that number, and unbelievably grateful to everyone who bought a copy.</p>\n\n<p>While I&rsquo;m planning to take a good long break from serious projects first, this level of success has certainly gotten me pumped about writing another book. If I do, I&rsquo;m 100% confident now in my approach of putting the entire book online for free. I&rsquo;m certain I wouldn&rsquo;t have sold anywhere near this many copies if the book&rsquo;s web site hadn&rsquo;t built an audience who were ready and eager to get their hands on a copy.</p>\n\n<p>It turns out giving something away is a great way to get something back.</p>\n","contentSnippet":"Greetings, superfans! When we last tuned in, I was just about to “launch” my self-published book. I put that in quotes because it’s an awfully serious-sounding word for what was really just doing some clicking on my laptop. If my last post was the climax of my book writing adventure, consider this the denouement. You’ve been with me this long, it’s the least I can do.\nI do hold back one detail, though: while I talk about sales here, I won’t be putting cash numbers on it. If you try hard enough, you can calculate them yourself, but I feel weird sharing financial details. Strangely, it’s not because I’m shy about strangers knowing it as much as I am friends and family. So much room for awkwardness there.\nI am a Marketer and I do Marketer-y Things\nAs I mentioned before, I decided to self-publish about halfway through writing the manuscript. That meant I had to wear all of the hats that a publisher has dedicated noggins for: editor, designer, proofreader, and… marketer. This last one is the least fun for me, but I know it’s important.\nI read a bit online and what a lot of people said was that email lists are gold. I like that they are pull-based instead of push-based. Instead of jamming myself and my book down strangers’ throats, they sign up of their own volition. I only get in touch with the people who actually want to hear from me.\nSo I created a MailChimp account—chosen over other mailing list providers mainly because of their cute logo—and slapped a little “sign up!” form on every page of the site. Whenever I put a new chapter online, I got a traffic bump and some fraction of those people were kind or foolhardy enough to grant me their email address.\nI did this pretty early in the writing process so that I could give it time to grow before the book was complete. By putting the whole book online and releasing it chapterly (like a Dickens serial for the Internet age) I had amassed a surprisingly large list by the time I was ready to try to squeeze money out of them tell them my book was complete. Around 8,000 people, which still seems like a crazy large number to me.\nI also, despite the content of my tweets, managed to acquire a fair number of twitter friends. (I don’t like thinking of them “followers”. Celebutants and TEDx thought/cult leaders have “followers”. I just have Internet pals.)\nA New Front Page\nNow that the book is a product as much as it is a web site, I redid the front page to highlight both of those. It still, of course, links to the web version. And, of course, the entire contents of the book are still readable on the web. But I also added links to the various sites where you could get the print version, Kindle, and EPUB.\nI wanted to emphasize the “bookyness” of it, the physicality, so I got out my camera and my macro lens and took a bunch of honest-to-God photos of it:\nWait… if the camera is in the photo, how did I take this shot?\n\n\nThere’s something weird and meta about taking a picture of myself taking photos of a book whose cover I designed using a photo I took of an illustration I drew. I should take a picture of myself writing this blog post just to go full Inception.\nNext, I spent way too long coming up with a design and text for the front page. Seriously, it took me as long to make what is effectively a glorified list of hyperlinks as it did to write, illustrate, and edit a full chapter of the book. I think it’s worth it, though. The front page is the reader’s first impression of the book. If I make you feel that page is beautiful and high quality, it’s a short hop to having faith that the inside of the book is too.\nI ended up with this:\n\n  Click to zoom!\n\n\nThis Part of the Blog Post is About Writing a Blog Post\nI feel a little squirmy writing this. Like I said, I’m uncomfortable with self-promotion. I hoped, wanted, to get a decent amount of… attention? traffic? validation of my worth as a human? when I announced the for-sale versions of the book. Readers had been asking for them for a while, so I knew there would be some excitement just by saying, “Here they are.”\nBut that didn’t feel really newsworthy to me. There wasn’t much to discuss, just “here they are. moneys plz.” People like a story, and I like telling them, especially when the protagonist is yours truly. I’ve been really lucky to have a lot of encouragement on this project from readers, and I thought one way to say thanks would be to give a window into what the production process was like. It’s a side of book-making that I don’t see very much online.\nAlso, it let me blather about fonts for six thousand words. Seriously, the blog post I wrote about turning the manuscript into a physical book is longer than almost every chapter in the book. Clearly, I need an editor.\nThis also took a lot of time—about a week—but I really enjoyed writing it all down. I did my best to make it an entertaining read. While I hoped it would drive traffic to the book, I did honestly want it to be a worthwhile read in and of itself. I believe that, when played well, life is a non-zero-sum game.\nI <3 Filling Out Web Forms\nI was ready to upload the new site, and the new blog post. All that was left was to actually make the book available. This involved uploading various files—inside PDF for the print version, cover, EPUB file, MOBI file—to various sites whose forms cover the full gamut of usability. Clicking the final “OK” on CreateSpace, Kindle Direct Publishing, and Smashwords was both nerve-wracking and anti-climactic.\nThen the waiting game. Most of these sites do various amounts of automated and manual validation that take time to process. I noticed a typo that forced me to re-upload to CreateSpace. Kindle found a couple of spelling errors (surprising given how many rounds of editing I’d done by now). Smashwords asked me to have an explicit cover page.\nOnce those were all happy, the listings appeared. If you knew to look for them, you could have bought the book.\nCreateSpace and Smashwords also distribute to other sales channels (things like Lightning Source and book stores for the former; iBooks, Nook, Kobo, etc. for the latter). I wanted to wait for those sales channels to populate before I pulled the switch but… well, I got impatient.\nAs soon as I saw the Amazon page for my book, I just couldn’t wait any more. I pushed the new version of the site and the blog post. I wrote an email and blasted the mailing list. I tweeted. I mentioned it on G+.\nWhat I didn’t do this time was post it to reddit. It felt a little too self-serving for how reddit rolls. I did post a link to the blog on Hacker News since that crowd is more accepting of self-promotion.\nI had tabs open for the Smashwords sales dashboard, CreateSpace royalties, Kindle Direct Publishing sales report, twitter, and Hacker News. I refreshed those suckers like my life depended on it.\nCommand, We Are Ready for Launch\nThis moment, as dumb as it sounds, was actually pretty stressful. A surprisingly large number of self-published books just sink to the depths leaving nary a ripple on the surface. You hear horror stories of writers whose novels sell zero copies. Nonfiction is a lot easier, but I still had no idea if people really liked the book enough to drop real cash on it.\nRefresh refresh refresh refresh. A nervous sweat trickled down my neck.\nA few minutes later, Smashwords reported two sales. Holy shit! Someone bought the book! I was a professional writer!\nThen people started retweeting me. Someone posted a blurb about it on the gamedev subreddit and someone else did on the programming subreddit.\nPeople started saying super nice things! About me! It was awesome! Also, I was drinking in celebration at the same time so that multiplied all the good feelings.\nHow I felt.\n\n\nI feverishly replied to as many comments, tweets, and emails as I could. (All the while still refreshing the other tabs.) Eventually, I maxed out my serotonin levels and had to crash. Like some candy raver in an E puddle in the back of the chill-out room, I passed out, totally spent.\nThe Next Day\nI woke up the next morning feeling like a kid on Christmas. A kid who wasn’t entirely certain he’d been good enough for Santa to bring him presents. Morning coffee in hand, I opened up my laptop and checked all the dashboards.\nWhile I slept, I’d sold enough copies to pay off all of the expenses of the book. That isn’t actually that much: all I’d paid for was ISBN numbers, a couple of fonts, freelance copy-editing, and a business license. But, still, I was in the black now.\nI replied to as many people as I could and then headed into the office to get some work done spend the rest of the day refreshing my browser. Aggregate sales stats started showing up in the various dashboards:\nKindle sales on the first day.\n\n\n\n  \n  Smashwords (EPUB) sales on the first day.\n\n\nCreateSpace doesn’t draw a pretty picture for you, but the raw numbers were doing the same thing. I told my coworkers and they got all excited for me.\nThe rest of the day was basically a blur of responding to people and telling my wife and team how high the numbers were going. At some point, when I refreshed the Amazon page, I noticed a little banner had appeared next to my book:\nNo way.\n\n\nIt turns out Amazon tracks book sales very quickly. For the brief period of time where I had saturated social media, enough sales were coming in to actually make it the best-selling game programming book for a little while.\nSorry “Learning Python”.\n\n\nWait, did I say “game programming”? I meant #1 out of all programming books:\nI did a victory lap at this point.\n\n\nAt it’s peak, my book was the #7 best-selling book in the entire computer category:\nUp there with Minecraft!\n\n\nAround this time, I started referring to myself in the third person as “best-selling author Robert Nystrom”. Of course, most of the other books in those lists had been there for weeks or months, but I had my moment in the sun and I was committed to making the most of it.\nReturn to Normalcy\nThe peak, naturally, only lasted about a day. I was most curious to see what the right side of the graph would look like. Would it fall to zero? A slow trickle? A steady passive income?\nWhen I sent out the email for the book, one thing I asked was for people to write honest, detailed reviews. I figured a book page with a good set of reviews would give it the air of legimitacy for future customers who stumbled onto the book on their own. That in turn would help the book have a longer sales tail.\nBecause people are awesome and I love every one of them, people did indeed do this. It took a while, but reviews started trickling in.\nOther pleasant surprises started happening too. The book finally made its way through the other channels. I put it up on Google Play, and Smashwords got it onto iBooks, Nook, and some other places. I finally figured out a place to sell the PDF. (If you go to the book’s site now, these are all listed there.)\nIn a mistake that I don’t understand but can’t bear to correct, Apple even decided to spice up my name a bit:\nRobert Nyström, now 15% more metal.\n\n\nThen, a few days later, the most magical part of this whole thing started happening (though, honestly, the umlaut is a close second). That’s about how long it took for print copies to get shipped to people.\nSoon, friends and family—some who I haven’t seen in years—started sending me pictures of their copies of the book. Kind strangers in countries I couldn’t find on a map tweeted pictures of themselves opening the shipping box with excitement to see my dumb face staring out at them.\nIt’s hard to articulate how profoundly gratifying that is. Through almost the entire six years I’ve been working on this book, it’s been a purely digital thing. While I spend an astonishing amount of my life on the Internet, it still never quite feels “real” to me.\nIs rearranging some polarization on an SSD really making something? Is a few words glowing on an LCD actually communicating with a person, or just some pixelated avatar?\nBut seeing photos of real live people holding an actual physical thing filled with words and illustrations I put together, and seeing them happy to have it in their hands finally made it click for me that I made something real that actually affected people.\nHow We’re Looking Now\nThings have mostly settled down since then, though I do still have lots of email to catch up on (sorry!). Now that the book is in pretty much every sales channel, eBook walled garden, and international site for Amazon, I’m finally getting to the point where I can think of the book as done and put it into the background of my life.\nSo far, buyers have been trickling in at a decent rate. Here’s what my Kindle sales look like as of writing this post:\nEPUB is similar, and I think print is too.\n\n\nThe book has been out about two weeks, and I’ve sold:\n796 print copies. 555 in the US, 145 in Great Britain, 95 in Europe, and 1 directly from createspace.com\n\n\n274 Kindle copies. I’ll spare you the per country break-down, but it is really cool to see that I’ve sold it in India, Japan, Brazil, and other places.\n\n\n70 copies from smashwords. This is people who wany to buy the EPUB file directly.\n\n\n7 copies from iBooks. The book only appeared a few days ago, so I expect this to catch up with the other channels over time.\n\n\n\nThat’s a grand total of 1,147 copies sold in the first two weeks. I won’t be retiring off of this, but I’m really really happy with that number, and unbelievably grateful to everyone who bought a copy.\nWhile I’m planning to take a good long break from serious projects first, this level of success has certainly gotten me pumped about writing another book. If I do, I’m 100% confident now in my approach of putting the entire book online for free. I’m certain I wouldn’t have sold anywhere near this many copies if the book’s web site hadn’t built an audience who were ready and eager to get their hands on a copy.\nIt turns out giving something away is a great way to get something back.","guid":"http://journal.stuffwithstuff.com/2014/11/20/how-my-book-launch-went","isoDate":"2014-11-20T08:00:00.000Z","timestamp":"11/20/2014"},{"creator":"robert@stuffwithstuff.com (Robert Nystrom)","title":"Zero to 353 Pages: Bringing My Web Book to Print and eBook","link":"http://journal.stuffwithstuff.com/2014/11/03/bringing-my-web-book-to-print-and-ebook/","pubDate":"Mon, 03 Nov 2014 00:00:00 -0800","author":"robert@stuffwithstuff.com (Robert Nystrom)","content":"<figure>\n  <a href=\"http://gameprogrammingpatterns.com/\"><img class=\"framed\" src=\"/image/2014/11/book.jpg\"></a>\n  <figcaption>Look what I made!</figcaption>\n</figure>\n\n<p>It&rsquo;s a funny feeling to spend nearly six years making something and then finally hold it in your hand. It&rsquo;s simultaneously, &ldquo;This is <em>it!</em>&rdquo; and &ldquo;Is <em>this</em> it?&rdquo; How can it be so small when it feels like such a big piece of my life?</p>\n\n<p>Most of that time, <a href=\"http://gameprogrammingpatterns.com/\">the book</a> existed entirely on the web. It was less &ldquo;book&rdquo; and more &ldquo;book-length manuscript that you can read with your browser&rdquo;. The web site is still the book&rsquo;s real home in some ways. If you want to know more about game programming and software architecture, <a href=\"http://gameprogrammingpatterns.com/contents.html\">take a look</a>. You can read the whole thing online, for free, because I love you.</p>\n\n<p>I already wrote <a href=\"/2014/04/22/zero-to-95688-how-i-wrote-game-programming-patterns/\">a post</a> about the <em>writing</em> part of the process. That was the real mountain to climb. But, once I reached the summit and decided (1) I wanted to also have print and eBook editions and (2) I wanted to do it all myself, I learned that one does not simply walk <em>out</em> of Mordor either.</p>\n\n<p>This gratuitously, vaingloriously long post is about climbing back <em>down</em> the mountain&mdash;all of the <em>stuff</em> required to turn a web site into a book. Remember on Mr. Rogers Neighborhood where they would take a trip to a factory to see how cute little piglets are turned into hotdogs or something charming like that? This is like that, but marginally less incarnadine.</p>\n\n<h2>Where it Starts</h2>\n\n<p>On April 22nd, I finished the third draft of the last chapter of the book. The next day, I uploaded it and modestly told a few friends. And by that, I mean I <a href=\"https://twitter.com/munificentbob/status/458811197966409728\">milked it</a> for <a href=\"https://plus.google.com/100798142896685420545/posts/HJ3J368V6Mp\">all it was worth</a> on all <a href=\"http://www.reddit.com/r/programming/comments/23qnnc/i_finished_writing_my_free_book_on_game/\">the social networks</a>.</p>\n\n<p>As soon as I shook out <a href=\"https://github.com/munificent/game-programming-patterns/issues?q=is%3Aissue+is%3Aclosed\">all of the bugs readers reported</a>, I went straight into working on the print and eBook versions. Like I mentioned in the last post, I work on the book every single day. Not breaking the chain has somehow been just enough of a mindtrick to get me to overcome my usual inability to finish anything bigger than breakfast.</p>\n\n<p>By this point, I was actually superstitious about breaking it. I really wanted to hold the physical book in my hands, so until that was done, I was afraid to take even single day&rsquo;s break.</p>\n\n<figure>\n  <iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/sb7uzrKnAGA\" frameborder=\"0\" allowfullscreen></iframe>\n  <figcaption>I did break the chain on <em>one</em> day. It was my birthday in Kauai. I spent the morning playing on the beach with my kids, the afternoon snorkeling with sea turtles, the evening grilling burgers for my friends, and the night boozing it up. The book kinda slipped my mind.</figcaption>\n</figure>\n\n<p>The first step was doing yet another editing pass over the manuscript. At this point, I&rsquo;d done three drafts of each chapter, but ink on paper is a lot harder to fix than a web site, so I wanted to give it one more round of scrutiny.</p>\n\n<p>This was also, strangely, the first time I&rsquo;d read the book <em>front to back</em>. The chapters are relatively unconnected, sort of like recipes in a cookbook, and I wrote them out of order. Everytime I finished a chapter, the next one I started was the one that seemed like the most fun right then.</p>\n\n<p>I found a bunch of places where I said the same thing twice near each other in the book, but years apart in my life when I wrote them. I fixed those, and tons of other style and tone issues. Then I found a freelance copy editor and got her to do a pass over it.</p>\n\n<p>Despite having done four drafts at this point, she still found dozens of mistakes that I managed to miss. If you ever write book, I <em>highly</em> recommend this step. You&rsquo;ll be astonished at how much you miss that a good editor will find.</p>\n\n<h2>eBooks, Ugh</h2>\n\n<p>I&rsquo;m going to mix up the chronology here and talk about the eBook version first. In reality, I interleaved working on this and the print version and going back and forth over chapters with my copy editor, Lauren. The eBook stuff is less exciting than the print design, so let&rsquo;s just get it out of the way.</p>\n\n<p>I was actually in pretty good shape going in to this. I wrote the book <a href=\"https://github.com/munificent/game-programming-patterns/tree/master/book\">in markdown</a>, and had <a href=\"https://github.com/munificent/game-programming-patterns/blob/master/script/format.py\">a little Python script</a> that takes those files, some CSS, and an HTML template, and burps out the web site.</p>\n\n<p>If you&rsquo;ve never done an eBook before (you lucky devil, you), they come in two predominant flavors: EPUB and MOBI. Most of the world uses EPUB, but Kindle demands MOBI in some sort of gigantic distributed prank on the entire writing community.</p>\n\n<p>An EPUB file is basically a zip file containing a web site. Seriously. Take your static site and run this on it:</p>\n<div class=\"highlight\"><pre><code class=\"language-bash\" data-lang=\"bash\"><span></span><span class=\"nb\">cd</span> my_awesome_site\nzip -X0 my_awesome_site.epub mimetype\nzip -Xur9D my_awesome_site.epub *\n</code></pre></div>\n<p>Now you&rsquo;re 90% of the way to having an eBook. It&rsquo;s the other 10% that makes you want to claw your eyes out. See, eBooks are a lot like web sites&hellip; circa 2004. Instead of this fancy HTML5 stuff which is clearly, like, living in the future with all of its new tags that don&rsquo;t need to be closed, EPUB requires XHTML, the evil mutant offspring of HTML and XML. The turducken of the markup world.</p>\n\n<p>Worse, eBook readers handle CSS about as well as Netscape Navigator and IE4 did. If you lived through the horror show that was web design in the &lsquo;90s where you had three browsers open all day, you know what I&rsquo;m talking about. Except that now each of those &ldquo;browsers&rdquo; is a separate physical device that you have to jump through hoops to get your &ldquo;site&rdquo; on.</p>\n\n<p>Getting an updated <code>.mobi</code> file into the Kindle app on my tablet involved some combination of Dropbox, an Android file manager, going to the Amazon website to delete the previous version, sending an email to a mysterious dead drop address granted me by Amazon, waiting for the Kindle app to crash a few times, and, on occasion, blood sacrifice.</p>\n\n<p>The things I do for love.</p>\n\n<p>Oh, and did I mention the XML? SO MUCH XML. The <a href=\"http://idpf.org/epub\">EPUB format</a> was clearly written by uptight pencil-pushers whose OCD was permanently triggered by the chaos of the web. You need a <code>content.opf</code> XML manifest that lists <em>every single file</em> in your eBook. You also need a <code>container.xml</code> manifest that points to that <code>.opf</code> file. You need a manifest for your manifest.</p>\n\n<p>The <code>.opf</code> file needs a <code>&lt;spine&gt;</code> tag containing the ordered list of stuff in the book. And a <code>&lt;guide&gt;</code> containing&hellip; an ordered list of the stuff in the book. Also, there&rsquo;s a separate&mdash;mandatory, of course!&mdash;<code>toc.nxc</code> file containing, you guessed it, an ordered list of the stuff in the book. Not only that, each item in the TOC is not just in order but <em>explicitly manually numbered</em>:</p>\n<div class=\"highlight\"><pre><code class=\"language-xml\" data-lang=\"xml\"><span></span><span class=\"nt\">&lt;navPoint</span> <span class=\"na\">id=</span><span class=\"s\">&quot;copyright&quot;</span> <span class=\"na\">playOrder=</span><span class=\"s\">&quot;1&quot;</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;navLabel&gt;&lt;text&gt;</span>Copyright<span class=\"nt\">&lt;/text&gt;&lt;/navLabel&gt;</span>\n  <span class=\"nt\">&lt;content</span> <span class=\"na\">src=</span><span class=\"s\">&quot;copyright.html&quot;</span> <span class=\"nt\">/&gt;</span>\n<span class=\"nt\">&lt;/navPoint&gt;</span>\n\n<span class=\"nt\">&lt;navPoint</span> <span class=\"na\">id=</span><span class=\"s\">&quot;acknowledgements&quot;</span> <span class=\"na\">playOrder=</span><span class=\"s\">&quot;2&quot;</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;navLabel&gt;&lt;text&gt;</span>Acknowledgements<span class=\"nt\">&lt;/text&gt;&lt;/navLabel&gt;</span>\n  <span class=\"nt\">&lt;content</span> <span class=\"na\">src=</span><span class=\"s\">&quot;acknowledgements.html&quot;</span> <span class=\"nt\">/&gt;</span>\n<span class=\"nt\">&lt;/navPoint&gt;</span>\n\n<span class=\"nt\">&lt;navPoint</span> <span class=\"na\">id=</span><span class=\"s\">&quot;dedication&quot;</span> <span class=\"na\">playOrder=</span><span class=\"s\">&quot;3&quot;</span><span class=\"nt\">&gt;</span>\n  <span class=\"nt\">&lt;navLabel&gt;&lt;text&gt;</span>Dedication<span class=\"nt\">&lt;/text&gt;&lt;/navLabel&gt;</span>\n  <span class=\"nt\">&lt;content</span> <span class=\"na\">src=</span><span class=\"s\">&quot;dedication.html&quot;</span> <span class=\"nt\">/&gt;</span>\n<span class=\"nt\">&lt;/navPoint&gt;</span>\n</code></pre></div>\n<p>See those little <code>playOrder</code> attributes? It&rsquo;s like double-entry bookkeeping, minus the fun and excitement of double-entry bookkeeping.</p>\n\n<p>But, despite my ranting here, it&rsquo;s not really <em>hard</em>. It&rsquo;s sort of like counting to a thousand by hitting <code>+</code> and <code>1</code> over and over on your calculator. (I had a fun childhood.) Once you&rsquo;ve got a happy little EPUB file, you throw it at KindleGen, a rancorous old app from Amazon, and it begrudgingly converts it to a MOBI for you. Behold:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/ebooks.png\">\n  <figcaption>It took me almost six years to make these two files.</figcaption>\n</figure>\n\n<p>If you ignore the fact that it took about a hundred iterations to please the <a href=\"http://validator.idpf.org/\">EPUB validator</a> Gods, this was straightforward. Now, let&rsquo;s talk about the fun stuff!</p>\n\n<h2>My Dirty Little Secret</h2>\n\n<p>Warning: Seriously ardent exposition on design lies ahead. The rest of this post will be like watching two of your best friends who after years of awkward sexual tension finally hook up and now aren&rsquo;t so much showering you with public displays of affection as they are public displays of not-always-entirely-dry humping. I really <em>really</em> like fonts.</p>\n\n<p>When I first started the book, I wrote a little promise to myself in my pink locked diary that I never show anyone. (Except now you, I guess, Dearest Reader.) That promise was, &ldquo;If I can finish writing this whole damn manuscript, I will let myself typeset it.&rdquo;</p>\n\n<p>I know that probably sounds strange but if you haven&rsquo;t figured out I&rsquo;m a bit off center by now, you must be skimming this post for the pictures.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/pumpkin.jpg\">\n  <figcaption>Here&rsquo;s one of a tiny pumpkin pie I baked!</figcaption>\n</figure>\n\n<p>Most of my life, I had one cranial hemisphere in the artist bucket and one in the logical bin. I grew up drawing and painting, but usually on graph paper.</p>\n\n<p>A quick trip down my résumé makes stops at computer animator, web designer, UI designer, part-time UI programmer, <em>full</em>-time UI programmer, and tools programmer, before finally landing on regular full-on programmer. My left brain metastasized and took over pretty much the whole light show upstairs.</p>\n\n<p>I love programming, and I&rsquo;m happy to spend almost all day doing stuff that&rsquo;s not that visual, but, man, sometimes I really miss design. Thus the vow: if I could complete this giant ball of logical thought, I would reward myself by fully giving into my artistic side.</p>\n\n<h2>You Mean I Get To Pick a Page Size?</h2>\n\n<p>Of the design stuff I <em>have</em> done in the past, almost all of it has been for the web. There&rsquo;s a lot to like about web design, but it&rsquo;s sort of like body painting. No matter how steady you are with your airbrush, there&rsquo;s an inherit squishiness and unreliability to the underlying medium.</p>\n\n<p>When you can&rsquo;t trust the user not to futz with the size of their browser window or even control what fonts they have access to, it&rsquo;s hard to design something that looks exactly the way you want. But, <em>print</em>, now that&rsquo;s a different story.</p>\n\n<p>The first thing I did was decide how big the pages would be. Let me repeat that for you web folks: <strong>I, the designer, got to <em>choose</em> the page size.</strong> Because Amazon is the giant gorilla of the publishing industry and <a href=\"https://www.createspace.com/\">CreateSpace</a> is its cuddly orangutan buddy, I decided to go with that for handling the print-on-demand production of the book. They have a <a href=\"https://www.createspace.com/Special/Pop/book_trimsizes-pagecount.html\">few different trim sizes</a> you can pick from.</p>\n\n<p>I grabbed a bunch of programming books I had nearby, took my ruler out, and measured those suckers. I wanted my book to be like a real programming book, so I measured their dimensions, margins, line height, font size, the works. I took some averages, settled on 7.5&quot; &times; 9.25&quot; and that was that.</p>\n\n<h2>Fonts, Fonts, Fonts</h2>\n\n<p>Now that I knew how big my canvas was, it was time to start painting it. And, for a book, that means fonts. Sweet, delicious, heavenly fonts.</p>\n\n<p>As a web designer, I was used to&mdash;paraphrasing Henry Ford here&mdash;having any serif I wanted, as long as it was Georgia. (And I remember the days <em>before</em> Georgia, a ghastly fever dream thankfully cured by heroic doctor <a href=\"http://en.wikipedia.org/wiki/Matthew_Carter\">Matthew Carter</a>.)</p>\n\n<p><a href=\"https://www.google.com/fonts\">Google Web Fonts</a> turned things up a notch, but once you filter out all of the fonts on there that <a href=\"https://www.google.com/fonts/specimen/Domine\">don&rsquo;t have italics</a>, or <a href=\"https://www.google.com/fonts/specimen/Vollkorn\">have shitty metrics</a>, or incomplete character sets, or <a href=\"https://www.google.com/fonts/specimen/EB+Garamond\">only one weight</a>, what you&rsquo;re left with is&hellip; well, Georgia starts looking pretty good again.</p>\n\n<p>But, now. Now! I could just <em>go out and buy a fucking font and then use it</em>. Any font I wanted! It was intoxicating. Incredible. Overwhelming. Paralyzing.</p>\n\n<p>I spent nights in a hallucinogenic daze going through dozens of serif (for body copy), sans serif (asides and headers), and monospace (code, naturally) fonts. For all I know, it could have been weeks. Time had lost all meaning. When my fugue dissipated, I had a beard, a Grateful Dead tattoo, and three fonts.</p>\n\n<p>Ironically, the first two, Source Sans Pro and Source Code Pro, <em>are</em> Google Web Fonts, and are what <a href=\"http://gameprogrammingpatterns.com/\">the site</a> uses:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/source.png\">\n  <figcaption>Not pictured: beard and tattoo.</figcaption>\n</figure>\n\n<p>I don&rsquo;t know if this is astute branding on my part or just a failure of imagination, but do I think Adobe really nailed it with Source Code Pro&mdash;even when in print&mdash;and it pairs just as perfectly with Source Sans as theirs names would lead you to believe.</p>\n\n<p>That just left a body font, the most important font in the book. Like I do, I over-constrained the hell out of the problem:</p>\n\n<ul>\n<li><p><strong>I wanted a relatively small <a href=\"http://www.typographydeconstructed.com/x-height/\">x-height</a>.</strong> I don&rsquo;t dig the current trend of really big x-heights, especially not in print. They look like a schoolgirl&rsquo;s loopy handwriting to me, minus hearts over the &ldquo;i&quot;s. If I&rsquo;m going to print this bad boy at 2400 DPI, it can handle some nice small <a href=\"http://www.typographydeconstructed.com/bowl/\">bowls</a>.</p></li>\n<li><p><strong>But not <em>too</em> small.</strong> The prose is heavily seasoned with <code>inline code</code>, so the body and code fonts need to have similar vertical metrics or it will look like Danny DeVito and Arnold Schwarzenegger in <em>Twins</em>.</p></li>\n<li><p><strong>I love <a href=\"http://www.fonts.com/content/learning/fontology/level-1/type-families/oldstyle\">Old Style</a> typefaces.</strong> Garamond, Jenson, and Bembo are my homeboys. Low contrast in line thickness, angled stress and a bit of humanist irregularity, <em>aww yiss.</em> I can&rsquo;t stand the wimpy horizontal strokes of Didone fonts. I seriously get irrationally angered by them.</p></li>\n<li><p><strong>But a font that&rsquo;s <em>too</em> calligraphic would clash with the other fonts.</strong> A page should look like a cohesive whole. That won&rsquo;t happen if the body text looks enscribed by a medieval monk&rsquo;s quill pen while the code and headers are machined out by a robot.</p></li>\n</ul>\n\n<p>If you distill that down, what I really wanted was a font with the <em>metrics</em> of an Old Style, but the <em>letterforms</em> of a cleaner modern typeface. Also, it needed a heavier weight and a spritely italic. I swear, italics trigger some kind of delectable synaesthetic response in me like the electric tingle of a battery on my bathing suit area.</p>\n\n<p>After days of poring over typography blogs and font sites, lo and behold, I found a match. My Manic Pixie Dreamgirl in OpenType Format. <em>Sina Nova.</em></p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/sina.png\">\n  <figcaption>Sorry for the linguistic liberties, Vlad. I&rsquo;m sure you understand.</figcaption>\n</figure>\n\n<p>God, just look at it there. And wait until you see the <em>ligatures</em>. It&rsquo;s enough to make a girl swoon.</p>\n\n<p>I had assembled my army, now it was time to draw battlelines.</p>\n\n<h2>So Many Grids</h2>\n\n<p>Some people fantasize about building <a href=\"https://www.youtube.com/watch?v=PGRgXWsL-_Y\">roller coasters in their backyards</a> or <a href=\"https://www.youtube.com/watch?v=OmX1V6_gukY\">being smothered in pugs</a>. I&rsquo;ve always dreamt of designing using an honest-to-God <a href=\"http://www.amazon.com/Systems-Graphic-Systeme-Visuele-Gestaltung/dp/3721201450\">grid system</a>.</p>\n\n<p>I&rsquo;ve tried to approximate them for the web but it always ends up leaving me disappointed and slightly ashamed like trying to use role-play to reinvigorate a relationship you both know is dead. Not this time, though. I had a brand new copy of InDesign, and I wasn&rsquo;t afraid to use it!</p>\n\n<p>For those who don&rsquo;t know, a grid system organizes the content on a page. You come up with the dimensions of an invisible grid that overlays the page and everything slots within those. When done well, the text hangs together in placid harmony like a zen garden.</p>\n\n<p>Coming up with a good grid, especially for this book, was quite hard. Again, I had a bunch of constraints:</p>\n\n<ul>\n<li><p>Of course, it has to take into account the page size, and the margins. Wider margins on the inside so you don&rsquo;t get to close to the spine. We&rsquo;re an actual book now!</p></li>\n<li><p>If you&rsquo;ve <a href=\"http://gameprogrammingpatterns.com/\">read any of the book</a>, you know it&rsquo;s full of asides that provide commentary and additional info. The <a href=\"http://gameprogrammingpatterns.com/singleton.html#to-limit-a-class-to-a-single-instance\">longest one</a> is a few paragraphs and they often need to appear right next to certain passages of text.</p></li>\n<li><p>Of course, being a programming book, we&rsquo;ve got lots of code samples. Those need to be fairly wide so you don&rsquo;t have to wrap the lines very much.</p></li>\n</ul>\n\n<p>The code is particularly tricky. I like a pretty large line height (think single- versus double-spaced) for prose, but code looks wrong if you spread it out that much. Most grids use a single line height for the vertical rhythm of the page, but that wouldn&rsquo;t work for both prose and code (or for the asides for that matter).</p>\n\n<p>After days of tinkering&mdash;wonderful, relaxing, theraputic, tinkering&mdash;I had something I liked. To get there, I picked a random chapter and mocked it up. You can&rsquo;t design a layout without something to lay out, and I believe the design should take into account the actual content, so no <em>lorem ipsum</em> for me. I ended up with this:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/grid.png\">\n  <figcaption>Mmm.</figcaption>\n</figure>\n\n<p>Three 2&rdquo; columns with a &frac14;&ldquo; gutter, two for the main text and one for the asides. I used the same spacing vertically for large elements like headers on chapter title pages.</p>\n\n<p>For the main vertical rhythm, I came up with a fractional line height. The core baseline was 4.5&thinsp;pt. Prose fell on every third line, and code and aside every second. That let the latter snuggle in a little tighter while still having some semblance of a vertical cadence across the entire page:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/lines.png\">\n  <figcaption>9&thinsp;pt for code and asides, 13.5&thinsp;pt for prose.</figcaption>\n</figure>\n\n<p>I set up a running footer, and designed the section and chapter headers. Not gonna lie: I was pretty pleased with myself. There may have been some celebratory drinking.</p>\n\n<h2>Oh no, XML Again?</h2>\n\n<p>Once I had my grid and fonts, all that was left to do was typeset the whole book. That meant bringing in all of the text. I couldn&rsquo;t just copy and paste the web pages into InDesign. I&rsquo;d already carefully authored (in markdown) emphasis, bold, lists, headers, subheaders, etc. I did <em>not</em> want to start from plaintext and do that all over again.</p>\n\n<p>Fortunately, InDesign has a feature called &quot;XML import&rdquo;. You can take an arbitrary XML document, import it to InDesign, and automatically map XML tags to paragraphic and character styles you&rsquo;ve created in InDesign. Unfortunately, this feature seems to have been implemented by a narcoleptic intern who sidestepped any code review process.</p>\n\n<p>It&rsquo;s one of the buggiest pieces of nominally commercial-grade software I&rsquo;ve ever used. I, on more than one occasion, managed to get it to completely corrupt an InDesign file beyond repair. (Fortunately, help was just a <code>git reset</code> away.)</p>\n\n<p>I cracked open my little Python script and hacked it up to convert the markdown to HTML and then, through an unholy series of regexes, mash that into something approximating XML. Stuff like:</p>\n<div class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span></span><span class=\"k\">def</span> <span class=\"nf\">clean_up_code_xml</span><span class=\"p\">(</span><span class=\"n\">code</span><span class=\"p\">):</span>\n  <span class=\"c1\"># Ditch most code formatting tags.</span>\n  <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">&#39;&lt;span class=&quot;(k|kt|mi|n|nb|nc|nf)&quot;&gt;([^&lt;]+)&lt;/span&gt;&#39;</span><span class=\"p\">,</span>\n                <span class=\"sa\">r</span><span class=\"s2\">&quot;\\2&quot;</span><span class=\"p\">,</span> <span class=\"n\">code</span><span class=\"p\">)</span>\n\n  <span class=\"c1\"># Turn comments into something InDesign can map to a style.</span>\n  <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">&#39;&lt;span class=&quot;(c1|cn)&quot;&gt;([^&lt;]+)&lt;/span&gt;&#39;</span><span class=\"p\">,</span>\n                <span class=\"sa\">r</span><span class=\"s2\">&quot;&lt;comment&gt;\\2&lt;/comment&gt;&quot;</span><span class=\"p\">,</span> <span class=\"n\">code</span><span class=\"p\">)</span>\n</code></pre></div>\n<p>And:</p>\n<div class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span></span><span class=\"k\">def</span> <span class=\"nf\">clean_up_xhtml</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">):</span>\n  <span class=\"c1\"># Ditch newlines in the middle of blocks of text. Out of sheer malice,</span>\n  <span class=\"c1\"># even though they are meaningless in actual XML, InDesign treats them</span>\n  <span class=\"c1\"># as significant.</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s2\">&quot;\\n(?&lt;!&lt;)&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot; &quot;</span><span class=\"p\">,</span> <span class=\"n\">html</span><span class=\"p\">)</span>\n\n  <span class=\"c1\"># Also collapse redundant whitespace.</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">sub</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s2\">&quot; +&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot; &quot;</span><span class=\"p\">,</span> <span class=\"n\">html</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&gt; &lt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&gt;&lt;&quot;</span><span class=\"p\">)</span>\n\n  <span class=\"c1\"># Re-add newlines after closing paragraph-level tags.</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/p&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/p&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/h2&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/h2&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/h3&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/h3&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/li&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/li&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/ol&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/ol&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/ul&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/ul&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/pre&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/pre&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/aside&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/aside&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n  <span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">html</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s2\">&quot;&lt;/blockquote&gt;&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&lt;/blockquote&gt;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n  <span class=\"k\">return</span> <span class=\"n\">html</span>\n</code></pre></div>\n<p>Forgive me Father, for I have sinned. In my defense, I wasn&rsquo;t writing a program to convert <em>any</em> HTML to XML. As long as it worked on the 90k words of <em>my</em> book, it was Correct&trade; as far as I&rsquo;m concerned. This gave me a folder full of more-or-less XML files, one for each chapter. All that was left was to typeset them.</p>\n\n<h2>I&rsquo;m a Designer!</h2>\n\n<p>Starting at chapter one, <a href=\"http://gameprogrammingpatterns.com/introduction.html\">the introduction</a>, I imported its XML into InDesign. Then the work started. Each aside had to be pulled out of the main body text, restyled, and put into the sidebar. I only wanted leading indentation on paragraphs that followed previous ones, so every &ldquo;first&rdquo; paragraph that followed a header or code sample needed to be styled. I could never get lists to work in the XML, so I restyled all of those manually.</p>\n\n<p>Then the real work started. I redid every illustration to look sharp in a black-and-white, high resolution medium. I brought all sixty-something of them into Photoshop, removed the graph lines, upscaled the hell out of them, did some shenanigans to smooth the edges (but not <em>too</em> smooth since that&rsquo;s part of their charm) and then saved them as 2400 DPI TIFFs:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/illustration.png\">\n  <figcaption>Original web version on the left, upscaled and monochrome print version the right.</figcaption>\n</figure>\n\n<p>Then the real, hard work started. You see, all of that is just grunt work. You could probably get it done on Mechanical Turk if you wanted to, or just <a href=\"https://www.tug.org/TUGboat/tb21-3/tb68fine.pdf\">let Knuth solve it</a> with some clever dynamic programming. Where the <em>art</em> comes into play is dealing with this one little problem: <em>where do you put the page breaks?</em></p>\n\n<p>First off, you want to minimize <a href=\"http://en.wikipedia.org/wiki/Widows_and_orphans\">widows and orphans</a>&mdash;things like when the last line of a paragraph is at the top of the next page. InDesign can automate this, and even handle more complex rules like:</p>\n\n<ul>\n<li><p>Keep headers with at least a line or two of the paragraph that follows them.</p></li>\n<li><p>Don&rsquo;t let a block of code be split across pages at all.</p></li>\n<li><p>If a code block follows a paragraph of body copy, keep at least the last line of the body text with the code.</p></li>\n</ul>\n\n<p>This stuff is why people get all excited about InDesign. It rocks.</p>\n\n<p>But, once I set up all of those rules, I discovered I&rsquo;d basically turned InDesign into HAL 9000. Except, instead of refusing to open the pod bay doors, what it was forced to do was break a lot of things really <em>early</em>.</p>\n\n<p>You see, once I set up all of these rules, the result was that big chunks of text&mdash;headers, body text, and code&mdash;were all inseparably glued to each other. Since I told InDesign not to split in the middle, the only thing it could do was move the whole kit and caboodle to the next page, leaving a huge blank area at the bottom of the previous page, like:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/space.png\">\n  <figcaption>Most of the left (verso) page is wasted space.</figcaption>\n</figure>\n\n<p>There&rsquo;s no magic bullet to fix this. I just took it a page at a time and tried to organize and distribute the whitespace as nicely as I could. Usually, I could fill in a gap in one page by pushing a bit of stuff from earlier pages down. Other times, I&rsquo;d tweak the code to shave off a line or two, just enough to get it to fit. On occasion, I&rsquo;d break code samples into separate pieces so it could span pages.</p>\n\n<p>See for yourself:</p>\n\n<figure>\n  <iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/4_4Uw_9ZMIs\" frameborder=\"0\" allowfullscreen></iframe>\n  <figcaption>Now imagine this playing back 24 times slower.</figcaption>\n</figure>\n\n<p>It was tedious, challenging work. I started on June 19th. Working every single day, I reached the end of the last chapter <a href=\"https://github.com/munificent/game-programming-patterns/blob/60a4f3ebf49d7c24aa8ffc3100d48d0e2486039f/note/log.txt#L39-L92\">exactly two months later</a>. There was more drinking.</p>\n\n<h2>Baby Got Back (Matter)</h2>\n\n<p>So, the print edition was done, right? Nope! Real books aren&rsquo;t just a pile of chapters. They&rsquo;ve got a copyright page, title page, table of contents, and all sorts of stuff like that. The bits of those that come before the meat of the book are called <em>front matter</em> and the rest are, obviously, <em>back matter</em>.</p>\n\n<p>I spent a few more days designing a table of contents. (I just had to make it pretty. InDesign handled actually filling it in.) I wrote a copyright page, and <a href=\"http://gameprogrammingpatterns.com/acknowledgements.html\">acknowledgements</a>, even a dedication:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/dedication.jpg\">\n  <figcaption>Showing this page to my wife was one of the highlights of this whole adventure.</figcaption>\n</figure>\n\n<p>Then I moved onto the back matter. I guess a non-fiction book should have an index, right? Where&rsquo;s the &ldquo;automatically index my whole book button?&rdquo; What&rsquo;s that? There isn&rsquo;t one? Well&hellip; <em>shit</em>.</p>\n\n<p>InDesign <em>can</em> create an index for you, bless its little heart, but it doesn&rsquo;t actually know English. You have to sprinkle the index references throughout your book. What it does is figure out what pages those references are on and builds the list of index entries at the end.</p>\n\n<p>I spent two weeks going over the entire book <em>again</em>, adding index entries for anything I could imagine someone wanting to look up. I don&rsquo;t promise that it&rsquo;s a great index, but it <em>is</em> an index, God dammit.</p>\n\n<p>While I was at it, I cross-referenced the whole book. See, the web version has these magical things called &ldquo;hyperlinks&rdquo;. When one chapter mentions a concept on another one, you can &ldquo;click&rdquo; them with your &ldquo;mouse&rdquo; and the computer takes you straight to the referenced chapter! It&rsquo;s like living in the future but with less Stallone and Wesley Snipes homo-erotically punching each other.</p>\n\n<p>Paper, alas, does not support web standards. Instead you just put &ldquo;(see page 123)&rdquo; and the reader, poor plebian, has to manually turn to that page theirself. You can create cross references in InDesign and it will automatically track the referenced section and keep the page number up to date. I found every place where there was a link in the web version and manually created a cross-reference.</p>\n\n<h2>Getting My Grubby Paws On It</h2>\n\n<p>Phew! Book production is a lot of work! But this was finally nearing the end! I printed the whole book, all three-hundred-plus pages of it on my laser printer. It was heavy! I made a big heavy thing all by myself. Full of words!</p>\n\n<p>I went to the store and bought a red pen. I proofread every single page. I read my book, on paper. It, finally, after all these years, started to feel like a real thing.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/pages.jpg\">\n  <figcaption>This took a while to print.</figcaption>\n</figure>\n\n<p>I went back and fixed everything that got the red pen treatment, mainly just minor formatting bugs, then I exported a PDF. (Brief interlude where I zoom into 1000% and drool over Sina Nova again.) I uploaded it to CreateSpace. Oh boy oh boy oh boy.</p>\n\n<p>Oh, crap. I&rsquo;m not done yet. I forgot the cover!</p>\n\n<h2>Cover Me, I&rsquo;m Going In!</h2>\n\n<p>If you go by self-publishing blogs, designing a cover is the hardest, most important, most agonized over, most terribly done part of book writing. For every blog post telling you how important it is to not screw it up, there are a hundred self-published books whose cover is some amalgamation of still-watermarked screen-res stock photography, fonts that come pre-installed on Windows 95, and a design aesthetic clearly based on the belief that if one drop shadow is good, ten must be better.</p>\n\n<p>I didn&rsquo;t want to be that guy.</p>\n\n<p>To check myself, I spent some time looking at other game programming book covers. I even made a little page of thumbnails so I could put my cover mockups in there to see how they compared:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/thumbnails.jpg\">\n  <figcaption>Where&rsquo;s my book hiding in there?</figcaption>\n</figure>\n\n<p>There&rsquo;s a delicate art to crafting a design that gets the readers attention, but not in that &ldquo;what the hell was he thinking?&rdquo; way.</p>\n\n<p>The cover I&rsquo;d had in the back of my head for a long time was something hand-drawn. The book is full of little flow-charty illustrations, and I like how their informality contrasts with the technical content of the book.</p>\n\n<p>After trying a bunch of different mocks for other ideas, I spent an afternoon drawing one big illustration that combined a bunch my favorites from the book.\nI took a ton of photos of it at different angles with a macro lens and then tried to find a composition for the text that I liked. You can see the evolution here:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/covers.jpg\">\n  <figcaption>In chronological order.</figcaption>\n</figure>\n\n<p>Hopefully, you don&rsquo;t hate the final one too much.</p>\n\n<h2>My Esteemed Publisher</h2>\n\n<p>Oh, I left out one piece of the puzzle! Look on the bottom right corner of those mocks. See that? Here, look closer:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/gb.jpg\">\n  <figcaption>A little logo.</figcaption>\n</figure>\n\n<p>To publish a book, you need an <em>ISBN number</em>. CreateSpace can give you a free one, but then you can&rsquo;t use that anywhere else, and it associates the &ldquo;publisher&rdquo; of that number with CreateSpace, which felt weird to me. I&rsquo;d also need separate ISBN numbers for the two eBook versions.</p>\n\n<p>ISBNs work a bit like domain names. Each country has an appointed registrar&mdash;the company who is allowed to distribute ISBNs to publishers in one country. In the US, that&rsquo;s <a href=\"https://www.myidentifiers.com/\">Bowker</a>.</p>\n\n<p>It&rsquo;s a pretty smart racket. They basically just hand out IDs, a process that could be automated with five lines of Perl code and a copy of Apache running on an Arduino. In return for that, they get to charge you $125 for a single ISBN number. Or you can get 10 for $275. Since everyone publishes both print and eBook versions, you basically always get the 10-pack. They know what they&rsquo;re doing.</p>\n\n<p>It&rsquo;s certainly the most money I&rsquo;ve ever paid for 130 digits, but whatever. I sent them my credit card deets and started filling out the form. Whereupon I reached a <em>mandatory</em> field for &ldquo;publisher&rdquo;. Apparently, &ldquo;Yours Truly&rdquo;, &ldquo;I Just Did It Myself&rdquo;, &ldquo;Fake Vanity Press&rdquo;, and &ldquo;Can&rsquo;t I Just Skip This?&rdquo; are not valid values for that field.</p>\n\n<p>There was only one thing to do: <em>It&rsquo;s business time.</em> I got myself a business license. I am a real deal publisher. Look, it says so right here:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/license.jpg\">\n  <figcaption>I guess this blog means I&rsquo;ve now posted this conspicuously?</figcaption>\n</figure>\n\n<p>Now, when I was looking at other game programming books, I saw a bunch of others that were clearly self-published. The dead giveaways were &ldquo;publishers&rdquo; that were either (a) the author&rsquo;s name or an anagram of such, (b) obviously the name of a pet, or &copy; one of the &ldquo;we&rsquo;ll give you an ISBN for free&rdquo; companies.</p>\n\n<p>I don&rsquo;t think there&rsquo;s anything wrong with self-publishing, obviously, but it does carry a stigma to some readers. I don&rsquo;t want them to see a jokey &ldquo;publisher&rdquo; and think the book is some amateur hour affair. While my writing style is light-hearted, I actually do take the content really seriously.</p>\n\n<p>Older, established publishers tend to agglomerate over time yielding titles like &ldquo;Harcourt, Brace &amp; Howe&rdquo;, &ldquo;Harcourt Brace Jovanovich&rdquo;, &ldquo;Reed Elsevier&rdquo;, and &ldquo;Houghton Mifflin Riverdeep&rdquo;. So I picked two stuffy-sounding names and stuck them together. Then I debated how to join them&mdash;&ldquo;+&rdquo; (too mathy), &ldquo;|&rdquo; (too &#39;90s), &ldquo;-&rdquo; (hyphen, en-dash, or em-?), and &ldquo;/&rdquo; (too much like a boxing match)&mdash;before finally settling on just a plain space.</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/genever-benning.png\">\n  <figcaption>I even drew a logotype, just for kicks.</figcaption>\n</figure>\n\n<p>Although, for the record, I <em>did</em> still name it after my pets. I just took their names&mdash;Ginny and Benny&mdash;and classed them up. As the CEO and CFO of the Genever Benning empire, they are skilled executives, though a bit prone to farting in board meetings.</p>\n\n<h2>Upload it, Already!</h2>\n\n<p>OK, so we&rsquo;ve got typeset chapters, front matter, back matter, a cover, ISBN numbers, a camera-ready PDF. All systems are go go go! I uploaded everything to CreateSpace, waited for their &ldquo;manual&rdquo; review process to complete and ordered a couple of proof copies.</p>\n\n<p>The next few days were like waiting for Santa and then&hellip; in his traditional brown UPS suit, Santa arrived! The cover looked great! The back cover was even better than I&rsquo;d hoped! (Sorry, you&rsquo;ll have to get your hands on a copy to see it.) The binding looked solid! It looked like a professional quality book! I was super pumped!</p>\n\n<p>Imagine you muster up the courage to crawl out of your nerd hole and ask the captain of the cheerleading team to go to prom with you. Wonder of wonders, she says &ldquo;yes&rdquo;! That&rsquo;s how I felt.</p>\n\n<p>With my wife looking over my shoulder, I cracked it open.</p>\n\n<p>Then imagine you look that cheerleader in the eye and the realization crawls down your spine that her &ldquo;yes&rdquo; was laden with sarcasm you missed the first time around. She would never in a million years go to prom with you.</p>\n\n<p>Somehow, despite my meticulous measuring and scrupulous adherence to CreateSpace&rsquo;s guidelines, my layout was bad. The text was too small. The top margin too short. Worst of all, the inner margin was too narrow, making it hard to read text near the spine.</p>\n\n<p><em>Merde.</em></p>\n\n<h2>OK, Let&rsquo;s Do it All Again</h2>\n\n<p>As you surely realize by now, changing any of the metrics of the book is a huge undertaking. Sure, you can just edit the master and all of the pages update. But that in turn affects how the text wraps, which then totally undoes all of my careful fitting of blocks of stuff onto different pages. That grueling two-month period where I laid out each page? Out the window now.</p>\n\n<p>I went back to the drawing board. I cracked open the master. I started re-measuring things. Part of the problem was that (unsurprisingly) I&rsquo;d over-constrained myself. In addition to needing decent margins, a good-sized sidebar, and the right line height, I also wanted measurements that were relatively round numbers. A column width of 1.35728261&quot; is no fun to work with.</p>\n\n<p>In the process of rounding some of those measurements to the nearest nice round number, I&rsquo;d strayed away from actual good metrics. After bumping up the text size a bit, I spent days trying to come up with a column width, gutter size, and line height that would fit within the page margins and be easy to read.</p>\n\n<p>Eventually, I found a way out: decimal inches. Most of my print work has used&hellip; shall we say&hellip; imperial measurements? Things like 16pt or 3/16&quot;. In other words, usually some power of two fraction of an inch. But that&rsquo;s not the only option. You can go French revolution and actually do things like 1.3&quot;. InDesign won&rsquo;t bat an eye at it.</p>\n\n<p>After a bunch of monkeying around, I found a new grid. Instead of a vertical grid where prose is every three grid lines and code is every two, I bumped the fraction to &frac34;. This opened up the code and asides a bit relative to the text. I brought down the top margin and gave myself more than enough breathing room near the spine.</p>\n\n<p>All that was left to do was update all of the pages. By this point, I was angry and fired up. I was <em>so close</em> to thinking the book was done and I just wanted it to be over. I <em>burned</em> through those pages, working on them practically every waking moment. This time, I got the whole three-hundred-something pages done in a week:</p>\n\n<figure>\n  <iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/ikirNuS7jrI\" frameborder=\"0\" allowfullscreen></iframe>\n  <figcaption>Fortunately, years playing Pokemon have given me fantastic grinding skills.</figcaption>\n</figure>\n\n<p>I uploaded a new PDF, crossed my fingers and waited for the new proof to arrive. When it did&hellip; God what a sigh of relief. It looked fine. Totally readable. Hallelujah.</p>\n\n<p>That readability was great because it made it much easier for me to notice all the dumb mistakes I&rsquo;d made in my hurried re-layout. Somehow, I&rsquo;d managed to break all of the cross references, and sprinkle typos through much of the code. I did <em>another</em> proof-reading pass on the actual proof:</p>\n\n<figure>\n  <img class=\"framed\" src=\"/image/2014/11/postits.jpg\">\n  <figcaption>Every note is a mistake.</figcaption>\n</figure>\n\n<p>I fixed those, and uploaded it again. And&hellip; that&rsquo;s it. I know there are still mistakes lurking in there, and thinking about them <em>kills</em> me. But, at some point, the value of getting the damn thing in people&rsquo;s hands outweighs the value of trying to keep making it better.</p>\n\n<h2>Kicking it Out the Door</h2>\n\n<p>The print edition was done, and I made a slew of final changes to the eBook versions&mdash;mainly getting the cover in and working. Finally, only three things were left to do:</p>\n\n<ol>\n<li><p>Redo the front page of the site to mention the new formats.</p></li>\n<li><p>Upload everything to the various market places and put them on sale.</p></li>\n<li><p>Write this blog post.</p></li>\n</ol>\n\n<p>If you&rsquo;re reading this, it looks like I got those done too! You can see for youself:</p>\n\n<ul>\n<li><p><strong>The <a href=\"http://gameprogrammingpatterns.com/\">new site</a>.</strong></p></li>\n<li><p><strong>The <a href=\"http://www.amazon.com/dp/0990582906\">print version on Amazon</a>.</strong></p></li>\n<li><p><strong>The <a href=\"http://www.amazon.com/dp/B00P5URD96\">Kindle version</a>.</strong></p></li>\n<li><p><strong>The <a href=\"https://www.smashwords.com/books/view/489921\">eBook at Smashwords</a>.</strong></p></li>\n</ul>\n\n<p>iBooks should be coming soon but Apple is busy manually reviewing erotica submissions so it may be a few weeks and I was too impatient to wait for that.</p>\n\n<p>This whole production ended up taking six months. It was a ton of work, but I don&rsquo;t regret doing it. For better or worse, I can now hold this book and know that it&rsquo;s <em>mine</em>. From cover to cover, every word, picture, and bit of ink was up to me. I had a ton of help from my copy editor and from every kind reader who sent a bug report or pull request, and the book is immensely better thanks to their input. But, ultimately, the <em>decisions</em> were all mine.</p>\n\n<p>What I&rsquo;m feeling now is a curious mixture of relief, gratitude, and trepidation. Relief that it&rsquo;s done and I actually pulled off completing a large project. Immense gratitude to everyone who encouraged me to keep going. I know I wouldn&rsquo;t have finished without that.</p>\n\n<p>But, finally, trepidation. People&mdash;you&mdash;have been really supportive of the book, which is truly the best feeling in the world. But there&rsquo;s a big difference between <em>saying</em> you like the book and <em>spending cold hard cash on it</em>. I&rsquo;ve never written this for the money, but the number of copies it sells will, in some ways, legitimize it in my mind. And that&rsquo;s entirely outside of my control now.</p>\n\n<p>I feel like I&rsquo;m walking on stage, alone, squinting through the footlights to see if there&rsquo;s anyone in the audience.</p>\n","contentSnippet":"Look what I made!\n\n\nIt’s a funny feeling to spend nearly six years making something and then finally hold it in your hand. It’s simultaneously, “This is it!” and “Is this it?” How can it be so small when it feels like such a big piece of my life?\nMost of that time, the book existed entirely on the web. It was less “book” and more “book-length manuscript that you can read with your browser”. The web site is still the book’s real home in some ways. If you want to know more about game programming and software architecture, take a look. You can read the whole thing online, for free, because I love you.\nI already wrote a post about the writing part of the process. That was the real mountain to climb. But, once I reached the summit and decided (1) I wanted to also have print and eBook editions and (2) I wanted to do it all myself, I learned that one does not simply walk out of Mordor either.\nThis gratuitously, vaingloriously long post is about climbing back down the mountain—all of the stuff required to turn a web site into a book. Remember on Mr. Rogers Neighborhood where they would take a trip to a factory to see how cute little piglets are turned into hotdogs or something charming like that? This is like that, but marginally less incarnadine.\nWhere it Starts\nOn April 22nd, I finished the third draft of the last chapter of the book. The next day, I uploaded it and modestly told a few friends. And by that, I mean I milked it for all it was worth on all the social networks.\nAs soon as I shook out all of the bugs readers reported, I went straight into working on the print and eBook versions. Like I mentioned in the last post, I work on the book every single day. Not breaking the chain has somehow been just enough of a mindtrick to get me to overcome my usual inability to finish anything bigger than breakfast.\nBy this point, I was actually superstitious about breaking it. I really wanted to hold the physical book in my hands, so until that was done, I was afraid to take even single day’s break.\n\n  I did break the chain on one day. It was my birthday in Kauai. I spent the morning playing on the beach with my kids, the afternoon snorkeling with sea turtles, the evening grilling burgers for my friends, and the night boozing it up. The book kinda slipped my mind.\n\n\nThe first step was doing yet another editing pass over the manuscript. At this point, I’d done three drafts of each chapter, but ink on paper is a lot harder to fix than a web site, so I wanted to give it one more round of scrutiny.\nThis was also, strangely, the first time I’d read the book front to back. The chapters are relatively unconnected, sort of like recipes in a cookbook, and I wrote them out of order. Everytime I finished a chapter, the next one I started was the one that seemed like the most fun right then.\nI found a bunch of places where I said the same thing twice near each other in the book, but years apart in my life when I wrote them. I fixed those, and tons of other style and tone issues. Then I found a freelance copy editor and got her to do a pass over it.\nDespite having done four drafts at this point, she still found dozens of mistakes that I managed to miss. If you ever write book, I highly recommend this step. You’ll be astonished at how much you miss that a good editor will find.\neBooks, Ugh\nI’m going to mix up the chronology here and talk about the eBook version first. In reality, I interleaved working on this and the print version and going back and forth over chapters with my copy editor, Lauren. The eBook stuff is less exciting than the print design, so let’s just get it out of the way.\nI was actually in pretty good shape going in to this. I wrote the book in markdown, and had a little Python script that takes those files, some CSS, and an HTML template, and burps out the web site.\nIf you’ve never done an eBook before (you lucky devil, you), they come in two predominant flavors: EPUB and MOBI. Most of the world uses EPUB, but Kindle demands MOBI in some sort of gigantic distributed prank on the entire writing community.\nAn EPUB file is basically a zip file containing a web site. Seriously. Take your static site and run this on it:\ncd my_awesome_site\nzip -X0 my_awesome_site.epub mimetype\nzip -Xur9D my_awesome_site.epub *\n\n\nNow you’re 90% of the way to having an eBook. It’s the other 10% that makes you want to claw your eyes out. See, eBooks are a lot like web sites… circa 2004. Instead of this fancy HTML5 stuff which is clearly, like, living in the future with all of its new tags that don’t need to be closed, EPUB requires XHTML, the evil mutant offspring of HTML and XML. The turducken of the markup world.\nWorse, eBook readers handle CSS about as well as Netscape Navigator and IE4 did. If you lived through the horror show that was web design in the ‘90s where you had three browsers open all day, you know what I’m talking about. Except that now each of those “browsers” is a separate physical device that you have to jump through hoops to get your “site” on.\nGetting an updated .mobi file into the Kindle app on my tablet involved some combination of Dropbox, an Android file manager, going to the Amazon website to delete the previous version, sending an email to a mysterious dead drop address granted me by Amazon, waiting for the Kindle app to crash a few times, and, on occasion, blood sacrifice.\nThe things I do for love.\nOh, and did I mention the XML? SO MUCH XML. The EPUB format was clearly written by uptight pencil-pushers whose OCD was permanently triggered by the chaos of the web. You need a content.opf XML manifest that lists every single file in your eBook. You also need a container.xml manifest that points to that .opf file. You need a manifest for your manifest.\nThe .opf file needs a <spine> tag containing the ordered list of stuff in the book. And a <guide> containing… an ordered list of the stuff in the book. Also, there’s a separate—mandatory, of course!—toc.nxc file containing, you guessed it, an ordered list of the stuff in the book. Not only that, each item in the TOC is not just in order but explicitly manually numbered:\n<navPoint id=\"copyright\" playOrder=\"1\">\n  <navLabel><text>Copyright</text></navLabel>\n  <content src=\"copyright.html\" />\n</navPoint>\n\n<navPoint id=\"acknowledgements\" playOrder=\"2\">\n  <navLabel><text>Acknowledgements</text></navLabel>\n  <content src=\"acknowledgements.html\" />\n</navPoint>\n\n<navPoint id=\"dedication\" playOrder=\"3\">\n  <navLabel><text>Dedication</text></navLabel>\n  <content src=\"dedication.html\" />\n</navPoint>\n\n\nSee those little playOrder attributes? It’s like double-entry bookkeeping, minus the fun and excitement of double-entry bookkeeping.\nBut, despite my ranting here, it’s not really hard. It’s sort of like counting to a thousand by hitting + and 1 over and over on your calculator. (I had a fun childhood.) Once you’ve got a happy little EPUB file, you throw it at KindleGen, a rancorous old app from Amazon, and it begrudgingly converts it to a MOBI for you. Behold:\nIt took me almost six years to make these two files.\n\n\nIf you ignore the fact that it took about a hundred iterations to please the EPUB validator Gods, this was straightforward. Now, let’s talk about the fun stuff!\nMy Dirty Little Secret\nWarning: Seriously ardent exposition on design lies ahead. The rest of this post will be like watching two of your best friends who after years of awkward sexual tension finally hook up and now aren’t so much showering you with public displays of affection as they are public displays of not-always-entirely-dry humping. I really really like fonts.\nWhen I first started the book, I wrote a little promise to myself in my pink locked diary that I never show anyone. (Except now you, I guess, Dearest Reader.) That promise was, “If I can finish writing this whole damn manuscript, I will let myself typeset it.”\nI know that probably sounds strange but if you haven’t figured out I’m a bit off center by now, you must be skimming this post for the pictures.\nHere’s one of a tiny pumpkin pie I baked!\n\n\nMost of my life, I had one cranial hemisphere in the artist bucket and one in the logical bin. I grew up drawing and painting, but usually on graph paper.\nA quick trip down my résumé makes stops at computer animator, web designer, UI designer, part-time UI programmer, full-time UI programmer, and tools programmer, before finally landing on regular full-on programmer. My left brain metastasized and took over pretty much the whole light show upstairs.\nI love programming, and I’m happy to spend almost all day doing stuff that’s not that visual, but, man, sometimes I really miss design. Thus the vow: if I could complete this giant ball of logical thought, I would reward myself by fully giving into my artistic side.\nYou Mean I Get To Pick a Page Size?\nOf the design stuff I have done in the past, almost all of it has been for the web. There’s a lot to like about web design, but it’s sort of like body painting. No matter how steady you are with your airbrush, there’s an inherit squishiness and unreliability to the underlying medium.\nWhen you can’t trust the user not to futz with the size of their browser window or even control what fonts they have access to, it’s hard to design something that looks exactly the way you want. But, print, now that’s a different story.\nThe first thing I did was decide how big the pages would be. Let me repeat that for you web folks: I, the designer, got to choose the page size. Because Amazon is the giant gorilla of the publishing industry and CreateSpace is its cuddly orangutan buddy, I decided to go with that for handling the print-on-demand production of the book. They have a few different trim sizes you can pick from.\nI grabbed a bunch of programming books I had nearby, took my ruler out, and measured those suckers. I wanted my book to be like a real programming book, so I measured their dimensions, margins, line height, font size, the works. I took some averages, settled on 7.5\" × 9.25\" and that was that.\nFonts, Fonts, Fonts\nNow that I knew how big my canvas was, it was time to start painting it. And, for a book, that means fonts. Sweet, delicious, heavenly fonts.\nAs a web designer, I was used to—paraphrasing Henry Ford here—having any serif I wanted, as long as it was Georgia. (And I remember the days before Georgia, a ghastly fever dream thankfully cured by heroic doctor Matthew Carter.)\nGoogle Web Fonts turned things up a notch, but once you filter out all of the fonts on there that don’t have italics, or have shitty metrics, or incomplete character sets, or only one weight, what you’re left with is… well, Georgia starts looking pretty good again.\nBut, now. Now! I could just go out and buy a fucking font and then use it. Any font I wanted! It was intoxicating. Incredible. Overwhelming. Paralyzing.\nI spent nights in a hallucinogenic daze going through dozens of serif (for body copy), sans serif (asides and headers), and monospace (code, naturally) fonts. For all I know, it could have been weeks. Time had lost all meaning. When my fugue dissipated, I had a beard, a Grateful Dead tattoo, and three fonts.\nIronically, the first two, Source Sans Pro and Source Code Pro, are Google Web Fonts, and are what the site uses:\nNot pictured: beard and tattoo.\n\n\nI don’t know if this is astute branding on my part or just a failure of imagination, but do I think Adobe really nailed it with Source Code Pro—even when in print—and it pairs just as perfectly with Source Sans as theirs names would lead you to believe.\nThat just left a body font, the most important font in the book. Like I do, I over-constrained the hell out of the problem:\nI wanted a relatively small x-height. I don’t dig the current trend of really big x-heights, especially not in print. They look like a schoolgirl’s loopy handwriting to me, minus hearts over the “i\"s. If I’m going to print this bad boy at 2400 DPI, it can handle some nice small bowls.\n\n\nBut not too small. The prose is heavily seasoned with inline code, so the body and code fonts need to have similar vertical metrics or it will look like Danny DeVito and Arnold Schwarzenegger in Twins.\n\n\nI love Old Style typefaces. Garamond, Jenson, and Bembo are my homeboys. Low contrast in line thickness, angled stress and a bit of humanist irregularity, aww yiss. I can’t stand the wimpy horizontal strokes of Didone fonts. I seriously get irrationally angered by them.\n\n\nBut a font that’s too calligraphic would clash with the other fonts. A page should look like a cohesive whole. That won’t happen if the body text looks enscribed by a medieval monk’s quill pen while the code and headers are machined out by a robot.\n\n\n\nIf you distill that down, what I really wanted was a font with the metrics of an Old Style, but the letterforms of a cleaner modern typeface. Also, it needed a heavier weight and a spritely italic. I swear, italics trigger some kind of delectable synaesthetic response in me like the electric tingle of a battery on my bathing suit area.\nAfter days of poring over typography blogs and font sites, lo and behold, I found a match. My Manic Pixie Dreamgirl in OpenType Format. Sina Nova.\nSorry for the linguistic liberties, Vlad. I’m sure you understand.\n\n\nGod, just look at it there. And wait until you see the ligatures. It’s enough to make a girl swoon.\nI had assembled my army, now it was time to draw battlelines.\nSo Many Grids\nSome people fantasize about building roller coasters in their backyards or being smothered in pugs. I’ve always dreamt of designing using an honest-to-God grid system.\nI’ve tried to approximate them for the web but it always ends up leaving me disappointed and slightly ashamed like trying to use role-play to reinvigorate a relationship you both know is dead. Not this time, though. I had a brand new copy of InDesign, and I wasn’t afraid to use it!\nFor those who don’t know, a grid system organizes the content on a page. You come up with the dimensions of an invisible grid that overlays the page and everything slots within those. When done well, the text hangs together in placid harmony like a zen garden.\nComing up with a good grid, especially for this book, was quite hard. Again, I had a bunch of constraints:\nOf course, it has to take into account the page size, and the margins. Wider margins on the inside so you don’t get to close to the spine. We’re an actual book now!\n\n\nIf you’ve read any of the book, you know it’s full of asides that provide commentary and additional info. The longest one is a few paragraphs and they often need to appear right next to certain passages of text.\n\n\nOf course, being a programming book, we’ve got lots of code samples. Those need to be fairly wide so you don’t have to wrap the lines very much.\n\n\n\nThe code is particularly tricky. I like a pretty large line height (think single- versus double-spaced) for prose, but code looks wrong if you spread it out that much. Most grids use a single line height for the vertical rhythm of the page, but that wouldn’t work for both prose and code (or for the asides for that matter).\nAfter days of tinkering—wonderful, relaxing, theraputic, tinkering—I had something I liked. To get there, I picked a random chapter and mocked it up. You can’t design a layout without something to lay out, and I believe the design should take into account the actual content, so no lorem ipsum for me. I ended up with this:\nMmm.\n\n\nThree 2” columns with a ¼“ gutter, two for the main text and one for the asides. I used the same spacing vertically for large elements like headers on chapter title pages.\nFor the main vertical rhythm, I came up with a fractional line height. The core baseline was 4.5 pt. Prose fell on every third line, and code and aside every second. That let the latter snuggle in a little tighter while still having some semblance of a vertical cadence across the entire page:\n9 pt for code and asides, 13.5 pt for prose.\n\n\nI set up a running footer, and designed the section and chapter headers. Not gonna lie: I was pretty pleased with myself. There may have been some celebratory drinking.\nOh no, XML Again?\nOnce I had my grid and fonts, all that was left to do was typeset the whole book. That meant bringing in all of the text. I couldn’t just copy and paste the web pages into InDesign. I’d already carefully authored (in markdown) emphasis, bold, lists, headers, subheaders, etc. I did not want to start from plaintext and do that all over again.\nFortunately, InDesign has a feature called \"XML import”. You can take an arbitrary XML document, import it to InDesign, and automatically map XML tags to paragraphic and character styles you’ve created in InDesign. Unfortunately, this feature seems to have been implemented by a narcoleptic intern who sidestepped any code review process.\nIt’s one of the buggiest pieces of nominally commercial-grade software I’ve ever used. I, on more than one occasion, managed to get it to completely corrupt an InDesign file beyond repair. (Fortunately, help was just a git reset away.)\nI cracked open my little Python script and hacked it up to convert the markdown to HTML and then, through an unholy series of regexes, mash that into something approximating XML. Stuff like:\ndef clean_up_code_xml(code):\n  # Ditch most code formatting tags.\n  code = re.sub(r'<span class=\"(k|kt|mi|n|nb|nc|nf)\">([^<]+)</span>',\n                r\"\\2\", code)\n\n  # Turn comments into something InDesign can map to a style.\n  code = re.sub(r'<span class=\"(c1|cn)\">([^<]+)</span>',\n                r\"<comment>\\2</comment>\", code)\n\n\nAnd:\ndef clean_up_xhtml(html):\n  # Ditch newlines in the middle of blocks of text. Out of sheer malice,\n  # even though they are meaningless in actual XML, InDesign treats them\n  # as significant.\n  html = re.sub(r\"\\n(?<!<)\", \" \", html)\n\n  # Also collapse redundant whitespace.\n  html = re.sub(r\" +\", \" \", html)\n  html = html.replace(\"> <\", \"><\")\n\n  # Re-add newlines after closing paragraph-level tags.\n  html = html.replace(\"</p>\", \"</p>\\n\")\n  html = html.replace(\"</h2>\", \"</h2>\\n\")\n  html = html.replace(\"</h3>\", \"</h3>\\n\")\n  html = html.replace(\"</li>\", \"</li>\\n\")\n  html = html.replace(\"</ol>\", \"</ol>\\n\")\n  html = html.replace(\"</ul>\", \"</ul>\\n\")\n  html = html.replace(\"</pre>\", \"</pre>\\n\")\n  html = html.replace(\"</aside>\", \"</aside>\\n\")\n  html = html.replace(\"</blockquote>\", \"</blockquote>\\n\")\n\n  return html\n\n\nForgive me Father, for I have sinned. In my defense, I wasn’t writing a program to convert any HTML to XML. As long as it worked on the 90k words of my book, it was Correct™ as far as I’m concerned. This gave me a folder full of more-or-less XML files, one for each chapter. All that was left was to typeset them.\nI’m a Designer!\nStarting at chapter one, the introduction, I imported its XML into InDesign. Then the work started. Each aside had to be pulled out of the main body text, restyled, and put into the sidebar. I only wanted leading indentation on paragraphs that followed previous ones, so every “first” paragraph that followed a header or code sample needed to be styled. I could never get lists to work in the XML, so I restyled all of those manually.\nThen the real work started. I redid every illustration to look sharp in a black-and-white, high resolution medium. I brought all sixty-something of them into Photoshop, removed the graph lines, upscaled the hell out of them, did some shenanigans to smooth the edges (but not too smooth since that’s part of their charm) and then saved them as 2400 DPI TIFFs:\nOriginal web version on the left, upscaled and monochrome print version the right.\n\n\nThen the real, hard work started. You see, all of that is just grunt work. You could probably get it done on Mechanical Turk if you wanted to, or just let Knuth solve it with some clever dynamic programming. Where the art comes into play is dealing with this one little problem: where do you put the page breaks?\nFirst off, you want to minimize widows and orphans—things like when the last line of a paragraph is at the top of the next page. InDesign can automate this, and even handle more complex rules like:\nKeep headers with at least a line or two of the paragraph that follows them.\n\n\nDon’t let a block of code be split across pages at all.\n\n\nIf a code block follows a paragraph of body copy, keep at least the last line of the body text with the code.\n\n\n\nThis stuff is why people get all excited about InDesign. It rocks.\nBut, once I set up all of those rules, I discovered I’d basically turned InDesign into HAL 9000. Except, instead of refusing to open the pod bay doors, what it was forced to do was break a lot of things really early.\nYou see, once I set up all of these rules, the result was that big chunks of text—headers, body text, and code—were all inseparably glued to each other. Since I told InDesign not to split in the middle, the only thing it could do was move the whole kit and caboodle to the next page, leaving a huge blank area at the bottom of the previous page, like:\nMost of the left (verso) page is wasted space.\n\n\nThere’s no magic bullet to fix this. I just took it a page at a time and tried to organize and distribute the whitespace as nicely as I could. Usually, I could fill in a gap in one page by pushing a bit of stuff from earlier pages down. Other times, I’d tweak the code to shave off a line or two, just enough to get it to fit. On occasion, I’d break code samples into separate pieces so it could span pages.\nSee for yourself:\n\n  Now imagine this playing back 24 times slower.\n\n\nIt was tedious, challenging work. I started on June 19th. Working every single day, I reached the end of the last chapter exactly two months later. There was more drinking.\nBaby Got Back (Matter)\nSo, the print edition was done, right? Nope! Real books aren’t just a pile of chapters. They’ve got a copyright page, title page, table of contents, and all sorts of stuff like that. The bits of those that come before the meat of the book are called front matter and the rest are, obviously, back matter.\nI spent a few more days designing a table of contents. (I just had to make it pretty. InDesign handled actually filling it in.) I wrote a copyright page, and acknowledgements, even a dedication:\nShowing this page to my wife was one of the highlights of this whole adventure.\n\n\nThen I moved onto the back matter. I guess a non-fiction book should have an index, right? Where’s the “automatically index my whole book button?” What’s that? There isn’t one? Well… shit.\nInDesign can create an index for you, bless its little heart, but it doesn’t actually know English. You have to sprinkle the index references throughout your book. What it does is figure out what pages those references are on and builds the list of index entries at the end.\nI spent two weeks going over the entire book again, adding index entries for anything I could imagine someone wanting to look up. I don’t promise that it’s a great index, but it is an index, God dammit.\nWhile I was at it, I cross-referenced the whole book. See, the web version has these magical things called “hyperlinks”. When one chapter mentions a concept on another one, you can “click” them with your “mouse” and the computer takes you straight to the referenced chapter! It’s like living in the future but with less Stallone and Wesley Snipes homo-erotically punching each other.\nPaper, alas, does not support web standards. Instead you just put “(see page 123)” and the reader, poor plebian, has to manually turn to that page theirself. You can create cross references in InDesign and it will automatically track the referenced section and keep the page number up to date. I found every place where there was a link in the web version and manually created a cross-reference.\nGetting My Grubby Paws On It\nPhew! Book production is a lot of work! But this was finally nearing the end! I printed the whole book, all three-hundred-plus pages of it on my laser printer. It was heavy! I made a big heavy thing all by myself. Full of words!\nI went to the store and bought a red pen. I proofread every single page. I read my book, on paper. It, finally, after all these years, started to feel like a real thing.\nThis took a while to print.\n\n\nI went back and fixed everything that got the red pen treatment, mainly just minor formatting bugs, then I exported a PDF. (Brief interlude where I zoom into 1000% and drool over Sina Nova again.) I uploaded it to CreateSpace. Oh boy oh boy oh boy.\nOh, crap. I’m not done yet. I forgot the cover!\nCover Me, I’m Going In!\nIf you go by self-publishing blogs, designing a cover is the hardest, most important, most agonized over, most terribly done part of book writing. For every blog post telling you how important it is to not screw it up, there are a hundred self-published books whose cover is some amalgamation of still-watermarked screen-res stock photography, fonts that come pre-installed on Windows 95, and a design aesthetic clearly based on the belief that if one drop shadow is good, ten must be better.\nI didn’t want to be that guy.\nTo check myself, I spent some time looking at other game programming book covers. I even made a little page of thumbnails so I could put my cover mockups in there to see how they compared:\nWhere’s my book hiding in there?\n\n\nThere’s a delicate art to crafting a design that gets the readers attention, but not in that “what the hell was he thinking?” way.\nThe cover I’d had in the back of my head for a long time was something hand-drawn. The book is full of little flow-charty illustrations, and I like how their informality contrasts with the technical content of the book.\nAfter trying a bunch of different mocks for other ideas, I spent an afternoon drawing one big illustration that combined a bunch my favorites from the book.\nI took a ton of photos of it at different angles with a macro lens and then tried to find a composition for the text that I liked. You can see the evolution here:\nIn chronological order.\n\n\nHopefully, you don’t hate the final one too much.\nMy Esteemed Publisher\nOh, I left out one piece of the puzzle! Look on the bottom right corner of those mocks. See that? Here, look closer:\nA little logo.\n\n\nTo publish a book, you need an ISBN number. CreateSpace can give you a free one, but then you can’t use that anywhere else, and it associates the “publisher” of that number with CreateSpace, which felt weird to me. I’d also need separate ISBN numbers for the two eBook versions.\nISBNs work a bit like domain names. Each country has an appointed registrar—the company who is allowed to distribute ISBNs to publishers in one country. In the US, that’s Bowker.\nIt’s a pretty smart racket. They basically just hand out IDs, a process that could be automated with five lines of Perl code and a copy of Apache running on an Arduino. In return for that, they get to charge you $125 for a single ISBN number. Or you can get 10 for $275. Since everyone publishes both print and eBook versions, you basically always get the 10-pack. They know what they’re doing.\nIt’s certainly the most money I’ve ever paid for 130 digits, but whatever. I sent them my credit card deets and started filling out the form. Whereupon I reached a mandatory field for “publisher”. Apparently, “Yours Truly”, “I Just Did It Myself”, “Fake Vanity Press”, and “Can’t I Just Skip This?” are not valid values for that field.\nThere was only one thing to do: It’s business time. I got myself a business license. I am a real deal publisher. Look, it says so right here:\nI guess this blog means I’ve now posted this conspicuously?\n\n\nNow, when I was looking at other game programming books, I saw a bunch of others that were clearly self-published. The dead giveaways were “publishers” that were either (a) the author’s name or an anagram of such, (b) obviously the name of a pet, or © one of the “we’ll give you an ISBN for free” companies.\nI don’t think there’s anything wrong with self-publishing, obviously, but it does carry a stigma to some readers. I don’t want them to see a jokey “publisher” and think the book is some amateur hour affair. While my writing style is light-hearted, I actually do take the content really seriously.\nOlder, established publishers tend to agglomerate over time yielding titles like “Harcourt, Brace & Howe”, “Harcourt Brace Jovanovich”, “Reed Elsevier”, and “Houghton Mifflin Riverdeep”. So I picked two stuffy-sounding names and stuck them together. Then I debated how to join them—“+” (too mathy), “|” (too '90s), “-” (hyphen, en-dash, or em-?), and “/” (too much like a boxing match)—before finally settling on just a plain space.\nI even drew a logotype, just for kicks.\n\n\nAlthough, for the record, I did still name it after my pets. I just took their names—Ginny and Benny—and classed them up. As the CEO and CFO of the Genever Benning empire, they are skilled executives, though a bit prone to farting in board meetings.\nUpload it, Already!\nOK, so we’ve got typeset chapters, front matter, back matter, a cover, ISBN numbers, a camera-ready PDF. All systems are go go go! I uploaded everything to CreateSpace, waited for their “manual” review process to complete and ordered a couple of proof copies.\nThe next few days were like waiting for Santa and then… in his traditional brown UPS suit, Santa arrived! The cover looked great! The back cover was even better than I’d hoped! (Sorry, you’ll have to get your hands on a copy to see it.) The binding looked solid! It looked like a professional quality book! I was super pumped!\nImagine you muster up the courage to crawl out of your nerd hole and ask the captain of the cheerleading team to go to prom with you. Wonder of wonders, she says “yes”! That’s how I felt.\nWith my wife looking over my shoulder, I cracked it open.\nThen imagine you look that cheerleader in the eye and the realization crawls down your spine that her “yes” was laden with sarcasm you missed the first time around. She would never in a million years go to prom with you.\nSomehow, despite my meticulous measuring and scrupulous adherence to CreateSpace’s guidelines, my layout was bad. The text was too small. The top margin too short. Worst of all, the inner margin was too narrow, making it hard to read text near the spine.\nMerde.\nOK, Let’s Do it All Again\nAs you surely realize by now, changing any of the metrics of the book is a huge undertaking. Sure, you can just edit the master and all of the pages update. But that in turn affects how the text wraps, which then totally undoes all of my careful fitting of blocks of stuff onto different pages. That grueling two-month period where I laid out each page? Out the window now.\nI went back to the drawing board. I cracked open the master. I started re-measuring things. Part of the problem was that (unsurprisingly) I’d over-constrained myself. In addition to needing decent margins, a good-sized sidebar, and the right line height, I also wanted measurements that were relatively round numbers. A column width of 1.35728261\" is no fun to work with.\nIn the process of rounding some of those measurements to the nearest nice round number, I’d strayed away from actual good metrics. After bumping up the text size a bit, I spent days trying to come up with a column width, gutter size, and line height that would fit within the page margins and be easy to read.\nEventually, I found a way out: decimal inches. Most of my print work has used… shall we say… imperial measurements? Things like 16pt or 3/16\". In other words, usually some power of two fraction of an inch. But that’s not the only option. You can go French revolution and actually do things like 1.3\". InDesign won’t bat an eye at it.\nAfter a bunch of monkeying around, I found a new grid. Instead of a vertical grid where prose is every three grid lines and code is every two, I bumped the fraction to ¾. This opened up the code and asides a bit relative to the text. I brought down the top margin and gave myself more than enough breathing room near the spine.\nAll that was left to do was update all of the pages. By this point, I was angry and fired up. I was so close to thinking the book was done and I just wanted it to be over. I burned through those pages, working on them practically every waking moment. This time, I got the whole three-hundred-something pages done in a week:\n\n  Fortunately, years playing Pokemon have given me fantastic grinding skills.\n\n\nI uploaded a new PDF, crossed my fingers and waited for the new proof to arrive. When it did… God what a sigh of relief. It looked fine. Totally readable. Hallelujah.\nThat readability was great because it made it much easier for me to notice all the dumb mistakes I’d made in my hurried re-layout. Somehow, I’d managed to break all of the cross references, and sprinkle typos through much of the code. I did another proof-reading pass on the actual proof:\nEvery note is a mistake.\n\n\nI fixed those, and uploaded it again. And… that’s it. I know there are still mistakes lurking in there, and thinking about them kills me. But, at some point, the value of getting the damn thing in people’s hands outweighs the value of trying to keep making it better.\nKicking it Out the Door\nThe print edition was done, and I made a slew of final changes to the eBook versions—mainly getting the cover in and working. Finally, only three things were left to do:\nRedo the front page of the site to mention the new formats.\n\n\nUpload everything to the various market places and put them on sale.\n\n\nWrite this blog post.\n\n\n\nIf you’re reading this, it looks like I got those done too! You can see for youself:\nThe new site.\n\n\nThe print version on Amazon.\n\n\nThe Kindle version.\n\n\nThe eBook at Smashwords.\n\n\n\niBooks should be coming soon but Apple is busy manually reviewing erotica submissions so it may be a few weeks and I was too impatient to wait for that.\nThis whole production ended up taking six months. It was a ton of work, but I don’t regret doing it. For better or worse, I can now hold this book and know that it’s mine. From cover to cover, every word, picture, and bit of ink was up to me. I had a ton of help from my copy editor and from every kind reader who sent a bug report or pull request, and the book is immensely better thanks to their input. But, ultimately, the decisions were all mine.\nWhat I’m feeling now is a curious mixture of relief, gratitude, and trepidation. Relief that it’s done and I actually pulled off completing a large project. Immense gratitude to everyone who encouraged me to keep going. I know I wouldn’t have finished without that.\nBut, finally, trepidation. People—you—have been really supportive of the book, which is truly the best feeling in the world. But there’s a big difference between saying you like the book and spending cold hard cash on it. I’ve never written this for the money, but the number of copies it sells will, in some ways, legitimize it in my mind. And that’s entirely outside of my control now.\nI feel like I’m walking on stage, alone, squinting through the footlights to see if there’s anyone in the audience.","guid":"http://journal.stuffwithstuff.com/2014/11/03/bringing-my-web-book-to-print-and-ebook","isoDate":"2014-11-03T08:00:00.000Z","timestamp":"11/3/2014"}],"feedUrl":"http://journal.stuffwithstuff.com/rss.xml","paginationLinks":{"self":"http://journal.stuffwithstuff.com/rss.xml"},"title":"journal.stuffwithstuff.com","description":"Programming, languages, compilers, games, etc.","pubDate":"Thu, 29 Jul 2021 07:20:34 -0700","link":"http://journal.stuffwithstuff.com/","language":"en-us","lastBuildDate":"Thu, 29 Jul 2021 07:20:34 -0700","feed":"http://journal.stuffwithstuff.com/rss.xml"},{"items":[{"title":"Haxe Roundup 595","link":"https://blog.skialbainn.com/post/661839819657412608","pubDate":"Thu, 09 Sep 2021 10:27:15 +0100","content":"<a href=\"https://haxe.io/roundups/595/\">Haxe Roundup 595</a>","contentSnippet":"Haxe Roundup 595","guid":"https://blog.skialbainn.com/post/661839819657412608","isoDate":"2021-09-09T09:27:15.000Z","timestamp":"9/9/2021"},{"title":"Haxe Roundup 594","link":"https://blog.skialbainn.com/post/661207026479906817","pubDate":"Thu, 02 Sep 2021 10:49:17 +0100","content":"<a href=\"https://haxe.io/roundups/594/\">Haxe Roundup 594</a>","contentSnippet":"Haxe Roundup 594","guid":"https://blog.skialbainn.com/post/661207026479906817","isoDate":"2021-09-02T09:49:17.000Z","timestamp":"9/2/2021"},{"title":"Haxe Roundup 593","link":"https://blog.skialbainn.com/post/660574867540869120","pubDate":"Thu, 26 Aug 2021 11:21:23 +0100","content":"<a href=\"https://haxe.io/roundups/593/\">Haxe Roundup 593</a>","contentSnippet":"Haxe Roundup 593","guid":"https://blog.skialbainn.com/post/660574867540869120","isoDate":"2021-08-26T10:21:23.000Z","timestamp":"8/26/2021"},{"title":"Haxe Roundup 592","link":"https://blog.skialbainn.com/post/659939342086733824","pubDate":"Thu, 19 Aug 2021 10:59:59 +0100","content":"<a href=\"https://haxe.io/roundups/592/\">Haxe Roundup 592</a>","contentSnippet":"Haxe Roundup 592","guid":"https://blog.skialbainn.com/post/659939342086733824","isoDate":"2021-08-19T09:59:59.000Z","timestamp":"8/19/2021"},{"title":"Haxe Roundup 591","link":"https://blog.skialbainn.com/post/659307498733453312","pubDate":"Thu, 12 Aug 2021 11:37:06 +0100","content":"<a href=\"https://haxe.io/roundups/591/\">Haxe Roundup 591</a>","contentSnippet":"Haxe Roundup 591","guid":"https://blog.skialbainn.com/post/659307498733453312","isoDate":"2021-08-12T10:37:06.000Z","timestamp":"8/12/2021"},{"title":"Haxe Roundup 590","link":"https://blog.skialbainn.com/post/658668768836321280","pubDate":"Thu, 05 Aug 2021 10:24:46 +0100","content":"<a href=\"https://haxe.io/roundups/590/\">Haxe Roundup 590</a>","contentSnippet":"Haxe Roundup 590","guid":"https://blog.skialbainn.com/post/658668768836321280","isoDate":"2021-08-05T09:24:46.000Z","timestamp":"8/5/2021"},{"title":"Haxe Roundup 589","link":"https://blog.skialbainn.com/post/658036243710558208","pubDate":"Thu, 29 Jul 2021 10:51:02 +0100","content":"<a href=\"https://haxe.io/roundups/589/\">Haxe Roundup 589</a>","contentSnippet":"Haxe Roundup 589","guid":"https://blog.skialbainn.com/post/658036243710558208","isoDate":"2021-07-29T09:51:02.000Z","timestamp":"7/29/2021"},{"title":"Haxe Roundup 588","link":"https://blog.skialbainn.com/post/657401491194347520","pubDate":"Thu, 22 Jul 2021 10:41:56 +0100","content":"<a href=\"https://haxe.io/roundups/588/\">Haxe Roundup 588</a>","contentSnippet":"Haxe Roundup 588","guid":"https://blog.skialbainn.com/post/657401491194347520","isoDate":"2021-07-22T09:41:56.000Z","timestamp":"7/22/2021"},{"title":"Haxe Roundup 587","link":"https://blog.skialbainn.com/post/656766295342268416","pubDate":"Thu, 15 Jul 2021 10:25:45 +0100","content":"<a href=\"https://haxe.io/roundups/587/\">Haxe Roundup 587</a>","contentSnippet":"Haxe Roundup 587","guid":"https://blog.skialbainn.com/post/656766295342268416","isoDate":"2021-07-15T09:25:45.000Z","timestamp":"7/15/2021"},{"title":"Haxe Roundup 586","link":"https://blog.skialbainn.com/post/656133384154873856","pubDate":"Thu, 08 Jul 2021 10:45:55 +0100","content":"<a href=\"https://haxe.io/roundups/586/\">Haxe Roundup 586</a>","contentSnippet":"Haxe Roundup 586","guid":"https://blog.skialbainn.com/post/656133384154873856","isoDate":"2021-07-08T09:45:55.000Z","timestamp":"7/8/2021"},{"title":"Haxe Roundup 585","link":"https://blog.skialbainn.com/post/655496870430392320","pubDate":"Thu, 01 Jul 2021 10:08:47 +0100","content":"<a href=\"https://haxe.io/roundups/585/\">Haxe Roundup 585</a>","contentSnippet":"Haxe Roundup 585","guid":"https://blog.skialbainn.com/post/655496870430392320","isoDate":"2021-07-01T09:08:47.000Z","timestamp":"7/1/2021"},{"title":"Haxe Roundup 584","link":"https://blog.skialbainn.com/post/654865325939113984","pubDate":"Thu, 24 Jun 2021 10:50:40 +0100","content":"<a href=\"https://haxe.io/roundups/584/\">Haxe Roundup 584</a>","contentSnippet":"Haxe Roundup 584","guid":"https://blog.skialbainn.com/post/654865325939113984","isoDate":"2021-06-24T09:50:40.000Z","timestamp":"6/24/2021"},{"title":"Haxe Roundup 583","link":"https://blog.skialbainn.com/post/654231044907745280","pubDate":"Thu, 17 Jun 2021 10:49:02 +0100","content":"<a href=\"https://haxe.io/roundups/583/\">Haxe Roundup 583</a>","contentSnippet":"Haxe Roundup 583","guid":"https://blog.skialbainn.com/post/654231044907745280","isoDate":"2021-06-17T09:49:02.000Z","timestamp":"6/17/2021"},{"title":"Haxe Roundup 582","link":"https://blog.skialbainn.com/post/653596530559860736","pubDate":"Thu, 10 Jun 2021 10:43:43 +0100","content":"<a href=\"https://haxe.io/roundups/582/\">Haxe Roundup 582</a>","contentSnippet":"Haxe Roundup 582","guid":"https://blog.skialbainn.com/post/653596530559860736","isoDate":"2021-06-10T09:43:43.000Z","timestamp":"6/10/2021"},{"title":"Haxe Roundup 581","link":"https://blog.skialbainn.com/post/652965041793105920","pubDate":"Thu, 03 Jun 2021 11:26:28 +0100","content":"<a href=\"https://haxe.io/roundups/581/\">Haxe Roundup 581</a>","contentSnippet":"Haxe Roundup 581","guid":"https://blog.skialbainn.com/post/652965041793105920","isoDate":"2021-06-03T10:26:28.000Z","timestamp":"6/3/2021"},{"title":"Haxe Roundup 580","link":"https://blog.skialbainn.com/post/652330015031197696","pubDate":"Thu, 27 May 2021 11:12:59 +0100","content":"<a href=\"https://haxe.io/roundups/580/\">Haxe Roundup 580</a>","contentSnippet":"Haxe Roundup 580","guid":"https://blog.skialbainn.com/post/652330015031197696","isoDate":"2021-05-27T10:12:59.000Z","timestamp":"5/27/2021"},{"title":"Haxe Roundup 579","link":"https://blog.skialbainn.com/post/651694575775350784","pubDate":"Thu, 20 May 2021 10:52:57 +0100","content":"<a href=\"https://haxe.io/roundups/579/\">Haxe Roundup 579</a>","contentSnippet":"Haxe Roundup 579","guid":"https://blog.skialbainn.com/post/651694575775350784","isoDate":"2021-05-20T09:52:57.000Z","timestamp":"5/20/2021"},{"title":"Haxe Roundup 578","link":"https://blog.skialbainn.com/post/651060395714510848","pubDate":"Thu, 13 May 2021 10:52:56 +0100","content":"<a href=\"https://haxe.io/roundups/578/\">Haxe Roundup 578</a>","contentSnippet":"Haxe Roundup 578","guid":"https://blog.skialbainn.com/post/651060395714510848","isoDate":"2021-05-13T09:52:56.000Z","timestamp":"5/13/2021"},{"title":"Haxe Roundup 577","link":"https://blog.skialbainn.com/post/650428139269439488","pubDate":"Thu, 06 May 2021 11:23:29 +0100","content":"<a href=\"https://haxe.io/roundups/577/\">Haxe Roundup 577</a>","contentSnippet":"Haxe Roundup 577","guid":"https://blog.skialbainn.com/post/650428139269439488","isoDate":"2021-05-06T10:23:29.000Z","timestamp":"5/6/2021"},{"title":"Haxe Roundup 576","link":"https://blog.skialbainn.com/post/649793217969225728","pubDate":"Thu, 29 Apr 2021 11:11:41 +0100","content":"<a href=\"https://haxe.io/roundups/576/\">Haxe Roundup 576</a>","contentSnippet":"Haxe Roundup 576","guid":"https://blog.skialbainn.com/post/649793217969225728","isoDate":"2021-04-29T10:11:41.000Z","timestamp":"4/29/2021"}],"title":"Skial Bainn","description":"That Haxe Roundup guy","generator":"Tumblr (3.0; @skialbainn)","link":"https://blog.skialbainn.com/","feed":"https://blog.skialbainn.com/rss"}],"videogames":[{"items":[{"title":"Looks like there's a new version of GOG GALAXY Steam integration coming (self.gog)","link":"https://www.reddit.com/r/gog/comments/pkezit/looks_like_theres_a_new_version_of_gog_galaxy/","pubDate":"Wed, 08 Sep 2021 17:23:55 +0000","comments":"https://www.reddit.com/r/gog/comments/pkezit/looks_like_theres_a_new_version_of_gog_galaxy/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pkezit/looks_like_theres_a_new_version_of_gog_galaxy/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>Just noticed while going through Friends of Galaxy github I noticed that there's a new discussion thread about a new version of Steam Integration. </p>\n\n<p>I actually I'm pretty stoked that the community is not dead and unofficial plugins are getting some love :)</p>\n\n<p><a href=\"https://github.com/FriendsOfGalaxy/galaxy-integration-steam/discussions/131\">https://github.com/FriendsOfGalaxy/galaxy-integration-steam/discussions/131</a></p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nJust noticed while going through Friends of Galaxy github I noticed that there's a new discussion thread about a new version of Steam Integration. \nI actually I'm pretty stoked that the community is not dead and unofficial plugins are getting some love :)\nhttps://github.com/FriendsOfGalaxy/galaxy-integration-steam/discussions/131","guid":"https://www.reddit.com/r/gog/comments/pkezit/looks_like_theres_a_new_version_of_gog_galaxy/","isoDate":"2021-09-08T17:23:55.000Z","timestamp":"9/8/2021"},{"title":"6 classic Star Trek games ready to beam up new players and fans alike (gog.com)","link":"https://www.gog.com/news/6_classic_star_trek_games_ready_to_beam_up_new_players_and_fans_alike","pubDate":"Wed, 08 Sep 2021 12:09:48 +0000","comments":"https://www.reddit.com/r/gog/comments/pk97sa/6_classic_star_trek_games_ready_to_beam_up_new/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pk97sa/6_classic_star_trek_games_ready_to_beam_up_new/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/gog/comments/pk97sa/6_classic_star_trek_games_ready_to_beam_up_new/","isoDate":"2021-09-08T12:09:48.000Z","timestamp":"9/8/2021"},{"title":"What are the advantages/disadvantages when buying a game from GOG instead of steam? (self.gog)","link":"https://www.reddit.com/r/gog/comments/pj60gg/what_are_the_advantagesdisadvantages_when_buying/","pubDate":"Mon, 06 Sep 2021 19:01:09 +0000","comments":"https://www.reddit.com/r/gog/comments/pj60gg/what_are_the_advantagesdisadvantages_when_buying/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pj60gg/what_are_the_advantagesdisadvantages_when_buying/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>so I was going to buy no mans sky on GOG instead of steam, so I was wondering if there are any differences when buying from GOG compared to steam? (i.e can't mod GOG games, GOG games don't have crossplay, just something like that.)</p>\n\n<p>edit: thanks to everyone who responded! my question has been answered</p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nso I was going to buy no mans sky on GOG instead of steam, so I was wondering if there are any differences when buying from GOG compared to steam? (i.e can't mod GOG games, GOG games don't have crossplay, just something like that.)\nedit: thanks to everyone who responded! my question has been answered","guid":"https://www.reddit.com/r/gog/comments/pj60gg/what_are_the_advantagesdisadvantages_when_buying/","isoDate":"2021-09-06T19:01:09.000Z","timestamp":"9/6/2021"},{"title":"Hi folks, just started using Gog.com and this keeps happening when I'm on Galaxy 2.0, DLC appears in the small boxes you see then it expands when I hover over. I assume this isnt normal, any fixes? (i.redd.it)","link":"https://i.redd.it/vt2xuy4oerl71.jpg","pubDate":"Sun, 05 Sep 2021 22:17:52 +0000","comments":"https://www.reddit.com/r/gog/comments/pimm80/hi_folks_just_started_using_gogcom_and_this_keeps/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pimm80/hi_folks_just_started_using_gogcom_and_this_keeps/'>Post permalink</a> </p><p><a href='https://i.redd.it/vt2xuy4oerl71.jpg'><img src='https://i.redd.it/vt2xuy4oerl71.jpg'></img></a></p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/gog/comments/pimm80/hi_folks_just_started_using_gogcom_and_this_keeps/","isoDate":"2021-09-05T22:17:52.000Z","timestamp":"9/5/2021"},{"title":"Galaxy achievements have not worked in 4+ years. (self.gog)","link":"https://www.reddit.com/r/gog/comments/pi0632/galaxy_achievements_have_not_worked_in_4_years/","pubDate":"Sat, 04 Sep 2021 21:34:06 +0000","comments":"https://www.reddit.com/r/gog/comments/pi0632/galaxy_achievements_have_not_worked_in_4_years/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pi0632/galaxy_achievements_have_not_worked_in_4_years/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>The first game I played through Galaxy with achievements was Tyranny in 2017.  That was with the old version 1.0 of Galaxy.  It is the only game that achievements have ever worked.</p>\n\n<p>About a year later I picked up Dead Cells and noticed achievements weren't working.  At first I thought it was just happening with Dead Cells, but then other games that had Galaxy achievements didn't work in it either.</p>\n\n<p>I contacted GOG support, they had me uninstall Galaxy, delete leftover files and re-install, reboot while doing a head stand with one eye closed, etc and nothing worked.  I sent them some log files and they said they would send them to the the dev team for investigation, and I never heard back from them.</p>\n\n<p>I got accepted to the Galaxy 2.0 beta, I tried Dead Cells again because it has some achievements that are quick and easy to get, but achievements still weren't working for me in Galaxy 2.0.  I contacted support again, referencing my old support ticket.  Tried all suggestions, and again sent log files that they said they would send to the dev team for investigation and never heard from them again.</p>\n\n<p>That was 2 years ago.  I have since upgraded my PC and re-installed Windows, but Galaxy achievements still do not work.  I generally don't care about achievements, but I bothers me when stuff doesn't work.  A year ago, I decided to look into it again and sort of had a small breakthrough, but I never solved it.  I found a post on the GOG forums where someone said achievements didn't work for them until they enabled cloud saves.  I have always had cloud saves disabled, but decided to give it a try.</p>\n\n<p>When I enabled cloud saves, I got an error syncing the saves.  I managed to find one post with someone having the same problem, but no one replied.  Luckily months later this person fixed it and thankfully updated the post with the solution.  It turned out that the Windows process lsass.exe was being blocked by a firewall and preventing some kind of a certificate verification and caused cloud saves to not work.</p>\n\n<p>I have Windows 10 and have a 3rd party firewall blocking all non-essential processes to minimize telemetry and data collection.  I unblocked lsass.exe and it fixed the cloud saves, but not achievements.  I tinkered around with it some, going as far as disabling the 3rd party firewall, but nothing worked and I gave up.</p>\n\n<p>Since achievements don't work, I only use Galaxy for new games that get updates often, but other than that I pretty much only use Galaxy to download offline installers.  For some reason, today I decided to give it another look.  I did a search and found some posts on the subreddit about achievements not working in The Witcher 3, but the solution to that didn't help me.</p>\n\n<p>I never thought about checking here to see if anyone else had the same problem, but unfortunately my searching didn't turn up anything except more posts about achievements not working.</p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nThe first game I played through Galaxy with achievements was Tyranny in 2017.  That was with the old version 1.0 of Galaxy.  It is the only game that achievements have ever worked.\nAbout a year later I picked up Dead Cells and noticed achievements weren't working.  At first I thought it was just happening with Dead Cells, but then other games that had Galaxy achievements didn't work in it either.\nI contacted GOG support, they had me uninstall Galaxy, delete leftover files and re-install, reboot while doing a head stand with one eye closed, etc and nothing worked.  I sent them some log files and they said they would send them to the the dev team for investigation, and I never heard back from them.\nI got accepted to the Galaxy 2.0 beta, I tried Dead Cells again because it has some achievements that are quick and easy to get, but achievements still weren't working for me in Galaxy 2.0.  I contacted support again, referencing my old support ticket.  Tried all suggestions, and again sent log files that they said they would send to the dev team for investigation and never heard from them again.\nThat was 2 years ago.  I have since upgraded my PC and re-installed Windows, but Galaxy achievements still do not work.  I generally don't care about achievements, but I bothers me when stuff doesn't work.  A year ago, I decided to look into it again and sort of had a small breakthrough, but I never solved it.  I found a post on the GOG forums where someone said achievements didn't work for them until they enabled cloud saves.  I have always had cloud saves disabled, but decided to give it a try.\nWhen I enabled cloud saves, I got an error syncing the saves.  I managed to find one post with someone having the same problem, but no one replied.  Luckily months later this person fixed it and thankfully updated the post with the solution.  It turned out that the Windows process lsass.exe was being blocked by a firewall and preventing some kind of a certificate verification and caused cloud saves to not work.\nI have Windows 10 and have a 3rd party firewall blocking all non-essential processes to minimize telemetry and data collection.  I unblocked lsass.exe and it fixed the cloud saves, but not achievements.  I tinkered around with it some, going as far as disabling the 3rd party firewall, but nothing worked and I gave up.\nSince achievements don't work, I only use Galaxy for new games that get updates often, but other than that I pretty much only use Galaxy to download offline installers.  For some reason, today I decided to give it another look.  I did a search and found some posts on the subreddit about achievements not working in The Witcher 3, but the solution to that didn't help me.\nI never thought about checking here to see if anyone else had the same problem, but unfortunately my searching didn't turn up anything except more posts about achievements not working.","guid":"https://www.reddit.com/r/gog/comments/pi0632/galaxy_achievements_have_not_worked_in_4_years/","isoDate":"2021-09-04T21:34:06.000Z","timestamp":"9/4/2021"},{"title":"GOG Store Stealth/Silent changes for 2021-08-28 through 2021-09-03 (self.gog)","link":"https://www.reddit.com/r/gog/comments/phnt0g/gog_store_stealthsilent_changes_for_20210828/","pubDate":"Sat, 04 Sep 2021 08:32:59 +0000","comments":"https://www.reddit.com/r/gog/comments/phnt0g/gog_store_stealthsilent_changes_for_20210828/","content":"<p><a href='https://www.reddit.com/r/gog/comments/phnt0g/gog_store_stealthsilent_changes_for_20210828/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>Explanation for these posts can be found in the original one: <a href=\"https://www.reddit.com/r/gog/comments/kkg559/gog_stealth_releases/\">https://www.reddit.com/r/gog/comments/kkg559/gog_stealth_releases/</a></p>\n\n<p>TL:DR - I have a weekly routine for checking the changes to the GOG store which didn't have a News article (as of the time of writing this post), and I'll be sharing the results here every Saturday morning.</p>\n\n<p>IMPORTANT NOTE: A lot of the new releases that don't have a News Article can actually be found <a href=\"https://www.gog.com/games?sort=date&amp;amp;page=1\">here</a>, and forum posts about delisted games can be tracked <a href=\"https://www.gog.com/forum/general/gog_news_and_staff_threads_2008\">here</a>, so there are places on the GOG site where this information can be found</p>\n\n<p>&amp;#x200B;</p>\n\n<p>REMOVED</p>\n\n<p><strong>Stranger Things 3: The Game</strong> - Reported already <a href=\"https://www.reddit.com/r/gog/comments/pej7ng/delisting_stranger_things_3_the_game/\">here</a></p>\n\n<p><strong>X3: Farnham's Legacy - Donation Pack</strong></p>\n\n<p><strong>Kraken Academy!! Demo</strong> - Game is still Coming soon</p>\n\n<p>&amp;#x200B;</p>\n\n<p>ADDED</p>\n\n<p><strong>Hundred Days - Grape Lab</strong> - <a href=\"https://www.gog.com/game/hundred_days_winemaking_simulator_grapelab\">Store Link</a> - FREE</p>\n\n<p><strong>Surviving Mars - Mars Lifestyle Radio</strong> - <a href=\"https://www.gog.com/game/surviving_mars_mars_lifestyle_radio\">Store Link</a> - Coming soon</p>\n\n<p><strong>Surviving Mars: Below and Beyond</strong> - <a href=\"https://www.gog.com/game/surviving_mars_below_and_beyond\">Store Link</a> - Coming soon</p>\n\n<p><strong>Star Dynasties</strong> - <a href=\"https://www.gog.com/game/star_dynasties\">Store Link</a> - Coming soon</p>\n\n<p>&amp;#x200B;</p>\n\n<p>As always, if you have some suggestions on how to make these posts more useful, let me know :)</p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nExplanation for these posts can be found in the original one: https://www.reddit.com/r/gog/comments/kkg559/gog_stealth_releases/\nTL:DR - I have a weekly routine for checking the changes to the GOG store which didn't have a News article (as of the time of writing this post), and I'll be sharing the results here every Saturday morning.\nIMPORTANT NOTE: A lot of the new releases that don't have a News Article can actually be found here, and forum posts about delisted games can be tracked here, so there are places on the GOG site where this information can be found\n&#x200B;\nREMOVED\nStranger Things 3: The Game - Reported already here\nX3: Farnham's Legacy - Donation Pack\nKraken Academy!! Demo - Game is still Coming soon\n&#x200B;\nADDED\nHundred Days - Grape Lab - Store Link - FREE\nSurviving Mars - Mars Lifestyle Radio - Store Link - Coming soon\nSurviving Mars: Below and Beyond - Store Link - Coming soon\nStar Dynasties - Store Link - Coming soon\n&#x200B;\nAs always, if you have some suggestions on how to make these posts more useful, let me know :)","guid":"https://www.reddit.com/r/gog/comments/phnt0g/gog_store_stealthsilent_changes_for_20210828/","isoDate":"2021-09-04T08:32:59.000Z","timestamp":"9/4/2021"},{"title":"Apparently GOG Galaxy is down again... maybe because of the Pathfinder: Wrath of the Righteous release? (i.redd.it)","link":"https://i.redd.it/xaq8zjmar4l71.png","pubDate":"Thu, 02 Sep 2021 18:06:57 +0000","comments":"https://www.reddit.com/r/gog/comments/pgn9ut/apparently_gog_galaxy_is_down_again_maybe_because/","content":"<p><a href='https://www.reddit.com/r/gog/comments/pgn9ut/apparently_gog_galaxy_is_down_again_maybe_because/'>Post permalink</a> </p><p><a href='https://i.redd.it/xaq8zjmar4l71.png'><img src='https://i.redd.it/xaq8zjmar4l71.png'></img></a></p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/gog/comments/pgn9ut/apparently_gog_galaxy_is_down_again_maybe_because/","isoDate":"2021-09-02T18:06:57.000Z","timestamp":"9/2/2021"},{"title":"GOG FAQ (Start here if you're new to GOG) (self.gog)","link":"https://www.reddit.com/r/gog/comments/n35z24/gog_faq_start_here_if_youre_new_to_gog/","pubDate":"Sun, 02 May 2021 13:02:34 +0000","comments":"https://www.reddit.com/r/gog/comments/n35z24/gog_faq_start_here_if_youre_new_to_gog/","content":"<p><a href='https://www.reddit.com/r/gog/comments/n35z24/gog_faq_start_here_if_youre_new_to_gog/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>This will remained pinned when we have no announcements as a resource for new GOG fans. It will be updated periodically as needed.</p>\n\n<p><strong>Last updated:</strong> May, 2, 2021</p>\n\n<p><strong>1 - What is GOG.com?</strong></p>\n\n<p>GOG is a online storefront that sells DRM Free PC games, similar to Steam. It is owned by CD Projekt, who also owns CD Projekt Red, developers of the Witcher series and Cyberpunk 2077. It began in 2008 as \"Good Old Games\" a service that sold old games that were fixed for modern systems, all DRM Free. In 2012 the \"Good Old Games\" branding was dropped, and rebranded to simply GOG.com, a service for old and new games.</p>\n\n<p><strong>2 - DRM Free? What is that?</strong></p>\n\n<p>DRM means Digital Rights Management. In general terms it is used to prevent unauthorized use or distribution of software after sale. In practice this has arguably been ineffective, and only impacts legal software owners. What DRM encompasses and what exactly DRM entails in highly debated, even in the DRM Free community.</p>\n\n<p>In regards to GOG, they generally see DRM as anything that prevents a single player game from being played offline or prevents a single player game from being copied, installed, or played. However, they do not seem to view online MP in the same aspect, and do require a client (ie <a href=\"https://www.gog.com/galaxy\">GOG Galaxy</a>) for online play in certain games. In once instance, they also sell a F2P online only multiplayer game (ie Gwent).</p>\n\n<p><strong>3 - GOG Galaxy? What is that?</strong></p>\n\n<p><a href=\"https://www.gog.com/galaxy\">GOG Galaxy</a> is a gaming client similar to Steam. It allows you organize your GOG gaming collection and gives you access to client features like auto-updating, achievements, and cloud saves. It also boast some notable features when compared to competing clients like the ability to completely disable all game updates and to rollback any patch to an older version.</p>\n\n<p>GOG Galaxy is optional for single player games and is not required if you just want to play a game offline. It is however, needed for online multiplayer in many games. In addition to Galaxy, all games on GOG come with an offline self contained installer that installs games similar to how games were installed from a game disk back before gaming clients existed. These installers can be downloaded via your library on the GOG.com website. To access them, click on the game card then under the big blue Galaxy installer, click the drop-down labeled <strong>Download Offline Backup Game Installers</strong>. They can also be downloaded via Galaxy's extra's section. More info on that can be found below.</p>\n\n<p><strong>4 - I have an issue with my game / galaxy or the GOG website, where can I get help?</strong></p>\n\n<p>First and foremost, for any issue you may be having with GOG and / or GOG Galaxy, reaching out the their <a href=\"https://support.gog.com/\">official support team</a> via email is the best course of action.</p>\n\n<p>If you have a GOG Galaxy bug that does not need immediate action, you can report the bug using the built in report function inside of Galaxy 2.0 under the gear icon. However, this method is not recommended for any Galaxy issues that are major or prevent Galaxy from being used. Contacting support with your <a href=\"https://support.gog.com/hc/en-us/articles/212807345-I-ve-encountered-a-bug-in-GOG-Galaxy-How-can-I-report-it-\">Galaxy logs</a> is a better method.</p>\n\n<p><strong>5 - I've heard that GOG games are harder to patch and / or that some games are missing patches on GOG... is this true?</strong></p>\n\n<p>In the past, it has been harder for a developer to update their games on GOG. This process was not a simple as it was on Steam. But recently, GOG has expanded their developer tools and created a new system, built on Galaxy, that allows developers to update as easily as they can on Steam. Updates can be pushed to Galaxy with a single script and will go live to every user immediately. There is even a developer portal that contains tools and documentation for developers. Once their game has been set up for the new system, developers are in complete control of the patching process.</p>\n\n<p>As far as games missing updates. There are some developers, who haven't updated their games. If a game isn't being updated it is entirely on the developers at this point. While this seems to be rare, and the amount of games is tiny when compared to GOG entire catalog, it does occur.</p>\n\n<p>However, one should note that games, especially older games, end up being sold broken on Steam too. So neither storefront is immune to bad developers. Instead of buying somewhere else, I recommend not rewarding those developers with your money. Just get a refund if possible.</p>\n\n<p><a href=\"https://www.gog.com/forum/general/gog_is_it_truly_more_difficult_for_developers_to_update_their_games_on_gog/page1/?staff=yes\">More info on GOG's patching system can be found here.</a></p>\n\n<p><strong>NOTICE</strong>: <a href=\"https://docs.google.com/spreadsheets/d/1zjwUN1mtJdCkgtTDRB2IoFp7PP41fraY-oFNY00fEkI/edit#gid=0\">View This Link For Games That May Be Missing Content (DLC, Mod Tools, Language Support, etc.) or Patches On GOG!</a></p>\n\n<p><strong>6 - I purchased a game it came with some extra goodies where can I find them?</strong></p>\n\n<p>When using the GOG Galaxy client go to the game's page and then click on \"Extras\" next to the play button. You will find a list of your extra goodies there. Downloaded goodies are located in the game's main directory folder (you can change the download location in the client settings, which can be accessed using the gear icon in the top left).</p>\n\n<p>If you want to download them trough the GOG.com website head to your game library select the game and at the right hand side you'll find the \"Extras\" section.</p>\n\n<p><strong>7 - I want a game on GOG, that isn't currently sold by GOG... what can I do?</strong></p>\n\n<p>Honestly, not much. You can submit a wish for the game on <a href=\"https://www.gog.com/wishlist\">GOG's wishlist</a> or vote for one if it is already there. The simple fact is, due to GOG's DRM Free requirement and smaller user-base, getting some games can be a challenge. There is also the legal issues surrounding old games that GOG may want to revive and sell. Reaching out to the publisher or developer of said game may help increase the chances of a release on GOG.</p>\n\n<p><strong>8 - How come a game isn't being sold on Linux or Mac, even though it is on Steam (or another service)?</strong></p>\n\n<p>There could be a variety of reasons why this is the case. It can range from needing a new contract to the port being done by a third party that also has to sign up with GOG, which sometimes they don't want to do. It's usually some kind of legal issue, but can also be due to other reasons like, for example, the Linux or Mac version not being up to GOG's quality assurance.</p>\n\n<p><strong>9 - Galaxy on Linux? When?</strong></p>\n\n<p>Sorry but all GOG has stated on the matter is that they will eventually create a Linux client, but as of now they are not actively working on it as it is currently not their foremost priority and that they have to put their limited resources to other upcoming features. Galaxy is being developed with cross-platform in mind.</p>\n\n<p><strong>10 - I want to learn more about GOG, where can I do that?</strong></p>\n\n<p>Nice idea. NoClip which produces crowdfunded video game documentaries, did a great video on how GOG goes about preserving games which can be viewed <a href=\"https://www.youtube.com/watch?v=ffngZOB1U2A\">here</a>. You can also find more info on GOG, via the GOG.com <a href=\"https://en.wikipedia.org/wiki/GOG.com\">Wikipedia page</a>.</p>\n\n<p><strong>11 - I am a software developer / web developer or have other relevant skills that would make me a good fit for GOG... are they hiring?</strong></p>\n\n<p>GOG is currently hiring for a number of positions. GOG requires all potential applicants to work in-house in Warsaw, Poland. If interested, check out <a href=\"https://www.gog.com/work\">GOG's work for us page</a>.</p>\n\n<p><strong>12 - I am a game developer and I want to get my game on GOG, how do I do that?</strong></p>\n\n<p>You can submit your game for GOG.com to review <a href=\"https://www.gog.com/indie\">here</a>. Once your game has been accepted and you have been set up with a developer account, you can access the developer portal <a href=\"https://devportal.gog.com/welcome\">here</a>.</p>\n\n<p><strong>13 - I am a game developer and I am interested in implementing the Galaxy API, were can I get more info?</strong></p>\n\n<p>Please see:  <a href=\"https://docs.gog.com/\">GOG Developer Docs</a></p>\n\n<p><strong>14 - When is the game coming on sale again?</strong></p>\n\n<p>Use <a href=\"http://isthereanydeal.com/\">http://isthereanydeal.com</a> and/or wishlist the game on GOG to be notified of future discounts.</p>\n\n<p><strong>15 - Is there a GOG discord server?</strong></p>\n\n<p>There is a large unofficial server located at: <a href=\"https://discord.gg/bT2HJ9k\">https://discord.gg/bT2HJ9k</a> that is used by <a href=\"/r/GOG\">/r/GOG</a> staff and some verified GOG staff alike. You can discuss pretty much anything about GOG or Galaxy here and get the latest GOG news.</p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nThis will remained pinned when we have no announcements as a resource for new GOG fans. It will be updated periodically as needed.\nLast updated: May, 2, 2021\n1 - What is GOG.com?\nGOG is a online storefront that sells DRM Free PC games, similar to Steam. It is owned by CD Projekt, who also owns CD Projekt Red, developers of the Witcher series and Cyberpunk 2077. It began in 2008 as \"Good Old Games\" a service that sold old games that were fixed for modern systems, all DRM Free. In 2012 the \"Good Old Games\" branding was dropped, and rebranded to simply GOG.com, a service for old and new games.\n2 - DRM Free? What is that?\nDRM means Digital Rights Management. In general terms it is used to prevent unauthorized use or distribution of software after sale. In practice this has arguably been ineffective, and only impacts legal software owners. What DRM encompasses and what exactly DRM entails in highly debated, even in the DRM Free community.\nIn regards to GOG, they generally see DRM as anything that prevents a single player game from being played offline or prevents a single player game from being copied, installed, or played. However, they do not seem to view online MP in the same aspect, and do require a client (ie GOG Galaxy) for online play in certain games. In once instance, they also sell a F2P online only multiplayer game (ie Gwent).\n3 - GOG Galaxy? What is that?\nGOG Galaxy is a gaming client similar to Steam. It allows you organize your GOG gaming collection and gives you access to client features like auto-updating, achievements, and cloud saves. It also boast some notable features when compared to competing clients like the ability to completely disable all game updates and to rollback any patch to an older version.\nGOG Galaxy is optional for single player games and is not required if you just want to play a game offline. It is however, needed for online multiplayer in many games. In addition to Galaxy, all games on GOG come with an offline self contained installer that installs games similar to how games were installed from a game disk back before gaming clients existed. These installers can be downloaded via your library on the GOG.com website. To access them, click on the game card then under the big blue Galaxy installer, click the drop-down labeled Download Offline Backup Game Installers. They can also be downloaded via Galaxy's extra's section. More info on that can be found below.\n4 - I have an issue with my game / galaxy or the GOG website, where can I get help?\nFirst and foremost, for any issue you may be having with GOG and / or GOG Galaxy, reaching out the their official support team via email is the best course of action.\nIf you have a GOG Galaxy bug that does not need immediate action, you can report the bug using the built in report function inside of Galaxy 2.0 under the gear icon. However, this method is not recommended for any Galaxy issues that are major or prevent Galaxy from being used. Contacting support with your Galaxy logs is a better method.\n5 - I've heard that GOG games are harder to patch and / or that some games are missing patches on GOG... is this true?\nIn the past, it has been harder for a developer to update their games on GOG. This process was not a simple as it was on Steam. But recently, GOG has expanded their developer tools and created a new system, built on Galaxy, that allows developers to update as easily as they can on Steam. Updates can be pushed to Galaxy with a single script and will go live to every user immediately. There is even a developer portal that contains tools and documentation for developers. Once their game has been set up for the new system, developers are in complete control of the patching process.\nAs far as games missing updates. There are some developers, who haven't updated their games. If a game isn't being updated it is entirely on the developers at this point. While this seems to be rare, and the amount of games is tiny when compared to GOG entire catalog, it does occur.\nHowever, one should note that games, especially older games, end up being sold broken on Steam too. So neither storefront is immune to bad developers. Instead of buying somewhere else, I recommend not rewarding those developers with your money. Just get a refund if possible.\nMore info on GOG's patching system can be found here.\nNOTICE: View This Link For Games That May Be Missing Content (DLC, Mod Tools, Language Support, etc.) or Patches On GOG!\n6 - I purchased a game it came with some extra goodies where can I find them?\nWhen using the GOG Galaxy client go to the game's page and then click on \"Extras\" next to the play button. You will find a list of your extra goodies there. Downloaded goodies are located in the game's main directory folder (you can change the download location in the client settings, which can be accessed using the gear icon in the top left).\nIf you want to download them trough the GOG.com website head to your game library select the game and at the right hand side you'll find the \"Extras\" section.\n7 - I want a game on GOG, that isn't currently sold by GOG... what can I do?\nHonestly, not much. You can submit a wish for the game on GOG's wishlist or vote for one if it is already there. The simple fact is, due to GOG's DRM Free requirement and smaller user-base, getting some games can be a challenge. There is also the legal issues surrounding old games that GOG may want to revive and sell. Reaching out to the publisher or developer of said game may help increase the chances of a release on GOG.\n8 - How come a game isn't being sold on Linux or Mac, even though it is on Steam (or another service)?\nThere could be a variety of reasons why this is the case. It can range from needing a new contract to the port being done by a third party that also has to sign up with GOG, which sometimes they don't want to do. It's usually some kind of legal issue, but can also be due to other reasons like, for example, the Linux or Mac version not being up to GOG's quality assurance.\n9 - Galaxy on Linux? When?\nSorry but all GOG has stated on the matter is that they will eventually create a Linux client, but as of now they are not actively working on it as it is currently not their foremost priority and that they have to put their limited resources to other upcoming features. Galaxy is being developed with cross-platform in mind.\n10 - I want to learn more about GOG, where can I do that?\nNice idea. NoClip which produces crowdfunded video game documentaries, did a great video on how GOG goes about preserving games which can be viewed here. You can also find more info on GOG, via the GOG.com Wikipedia page.\n11 - I am a software developer / web developer or have other relevant skills that would make me a good fit for GOG... are they hiring?\nGOG is currently hiring for a number of positions. GOG requires all potential applicants to work in-house in Warsaw, Poland. If interested, check out GOG's work for us page.\n12 - I am a game developer and I want to get my game on GOG, how do I do that?\nYou can submit your game for GOG.com to review here. Once your game has been accepted and you have been set up with a developer account, you can access the developer portal here.\n13 - I am a game developer and I am interested in implementing the Galaxy API, were can I get more info?\nPlease see:  GOG Developer Docs\n14 - When is the game coming on sale again?\nUse http://isthereanydeal.com and/or wishlist the game on GOG to be notified of future discounts.\n15 - Is there a GOG discord server?\nThere is a large unofficial server located at: https://discord.gg/bT2HJ9k that is used by /r/GOG staff and some verified GOG staff alike. You can discuss pretty much anything about GOG or Galaxy here and get the latest GOG news.","guid":"https://www.reddit.com/r/gog/comments/n35z24/gog_faq_start_here_if_youre_new_to_gog/","isoDate":"2021-05-02T13:02:34.000Z","timestamp":"5/2/2021"}],"feedUrl":"https://reddit-top-rss.herokuapp.com/?subreddit=gog&score=30&view=rss","image":{"url":"https://www.redditstatic.com/desktop2x/img/favicon/android-icon-192x192.png"},"paginationLinks":{"self":"https://reddit-top-rss.herokuapp.com/?subreddit=gog&score=30&view=rss"},"title":"/r/gog","description":"Hot posts in /r/gog at or above a score of 30","generator":"PHP DOMDocument","link":"https://www.reddit.com/r/gog","language":"en-us","lastBuildDate":"Sat, 11 Sep 2021 02:05:15 +0000","feed":"https://reddit-top-rss.herokuapp.com/?subreddit=gog&score=30&view=rss"},{"items":[{"title":"SAINTS ROW | SANTO ILESO NEWS - CHARACTERS, CUSTOMISATION & CO-OP (saintsrow.com)","link":"https://saintsrow.com/news/santo-ileso-news-sep-21","pubDate":"Fri, 10 Sep 2021 21:10:10 +0000","comments":"https://www.reddit.com/r/Games/comments/pltrbp/saints_row_santo_ileso_news_characters/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pltrbp/saints_row_santo_ileso_news_characters/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pltrbp/saints_row_santo_ileso_news_characters/","isoDate":"2021-09-10T21:10:10.000Z","timestamp":"9/10/2021"},{"title":"Downloads to community mods Team Fortress 2 Classic and Open Fortress have been disabled \"due to an arrangement with Valve\" (twitter.com)","link":"https://twitter.com/tf2classic/status/1436328611485818880","pubDate":"Fri, 10 Sep 2021 18:57:04 +0000","comments":"https://www.reddit.com/r/Games/comments/plr9r7/downloads_to_community_mods_team_fortress_2/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plr9r7/downloads_to_community_mods_team_fortress_2/'>Post permalink</a> </p><blockquote class=\"twitter-video\"><p lang=\"en\" dir=\"ltr\">Hi all. As of this post, downloads for TF2Classic are temporarily disabled due to an arrangement with Valve. This includes direct downloads to the mod through our website, Discord, and launcher.<br><br>This is only temporary for now. We&amp;#39;ll keep you posted for further information.</p>&amp;mdash; TF2Classic (@tf2classic) <a href=\"https://twitter.com/tf2classic/status/1436328611485818880?ref_src=twsrc%5Etfw\">September 10, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n","contentSnippet":"Post permalink \n\nHi all. As of this post, downloads for TF2Classic are temporarily disabled due to an arrangement with Valve. This includes direct downloads to the mod through our website, Discord, and launcher.\nThis is only temporary for now. We&#39;ll keep you posted for further information.\n&mdash; TF2Classic (@tf2classic) September 10, 2021","guid":"https://www.reddit.com/r/Games/comments/plr9r7/downloads_to_community_mods_team_fortress_2/","isoDate":"2021-09-10T18:57:04.000Z","timestamp":"9/10/2021"},{"title":"Lost in Random – Official Launch Trailer (youtube.com)","link":"https://www.youtube.com/watch?v=iJ4lJRjECBU","pubDate":"Fri, 10 Sep 2021 18:15:07 +0000","comments":"https://www.reddit.com/r/Games/comments/plqhao/lost_in_random_official_launch_trailer/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plqhao/lost_in_random_official_launch_trailer/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/iJ4lJRjECBU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plqhao/lost_in_random_official_launch_trailer/","isoDate":"2021-09-10T18:15:07.000Z","timestamp":"9/10/2021"},{"title":"Analogue Pocket Delayed to December 2021 (support.analogue.co)","link":"https://support.analogue.co/hc/en-us/articles/4408932900365","pubDate":"Fri, 10 Sep 2021 17:33:48 +0000","comments":"https://www.reddit.com/r/Games/comments/plpphg/analogue_pocket_delayed_to_december_2021/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plpphg/analogue_pocket_delayed_to_december_2021/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plpphg/analogue_pocket_delayed_to_december_2021/","isoDate":"2021-09-10T17:33:48.000Z","timestamp":"9/10/2021"},{"title":"SpongeBob SquarePants Showcase - Nickelodeon All-Star Brawl (youtu.be)","link":"https://youtu.be/wdw_kmjCEGk","pubDate":"Fri, 10 Sep 2021 17:23:21 +0000","comments":"https://www.reddit.com/r/Games/comments/plpidq/spongebob_squarepants_showcase_nickelodeon/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plpidq/spongebob_squarepants_showcase_nickelodeon/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/wdw_kmjCEGk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plpidq/spongebob_squarepants_showcase_nickelodeon/","isoDate":"2021-09-10T17:23:21.000Z","timestamp":"9/10/2021"},{"title":"Oldschool Runescapes Runelite HD Plugin to release on Monday (secure.runescape.com)","link":"https://secure.runescape.com/m=news/117scapes-hd-plugin---update?oldschool=1","pubDate":"Fri, 10 Sep 2021 17:01:05 +0000","comments":"https://www.reddit.com/r/Games/comments/plp2lh/oldschool_runescapes_runelite_hd_plugin_to/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plp2lh/oldschool_runescapes_runelite_hd_plugin_to/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plp2lh/oldschool_runescapes_runelite_hd_plugin_to/","isoDate":"2021-09-10T17:01:05.000Z","timestamp":"9/10/2021"},{"title":"Former Capcom and Street Fighter Producer wishes he could have stopped bad box art Mega Man from ever existing (eventhubs.com)","link":"https://www.eventhubs.com/news/2021/sep/09/box-art-mega-man/","pubDate":"Fri, 10 Sep 2021 16:07:50 +0000","comments":"https://www.reddit.com/r/Games/comments/plo227/former_capcom_and_street_fighter_producer_wishes/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plo227/former_capcom_and_street_fighter_producer_wishes/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plo227/former_capcom_and_street_fighter_producer_wishes/","isoDate":"2021-09-10T16:07:50.000Z","timestamp":"9/10/2021"},{"title":"Photography Simulator - Gameplay Trailer (youtu.be)","link":"https://youtu.be/3Kdev94u3pc","pubDate":"Fri, 10 Sep 2021 15:51:02 +0000","comments":"https://www.reddit.com/r/Games/comments/plnptk/photography_simulator_gameplay_trailer/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plnptk/photography_simulator_gameplay_trailer/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/3Kdev94u3pc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plnptk/photography_simulator_gameplay_trailer/","isoDate":"2021-09-10T15:51:02.000Z","timestamp":"9/10/2021"},{"title":"Epic vs Apple ruling revealed: Apple must allow App Store devs to redirect users to other payment systems (9to5mac.com)","link":"https://9to5mac.com/2021/09/10/epic-vs-apple-ruling-revealed-apple-must-allow-app-store-devs-to-redirect-users-to-other-payment-systems/","pubDate":"Fri, 10 Sep 2021 15:37:56 +0000","comments":"https://www.reddit.com/r/Games/comments/plnh1t/epic_vs_apple_ruling_revealed_apple_must_allow/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plnh1t/epic_vs_apple_ruling_revealed_apple_must_allow/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plnh1t/epic_vs_apple_ruling_revealed_apple_must_allow/","isoDate":"2021-09-10T15:37:56.000Z","timestamp":"9/10/2021"},{"title":"Vroom! - Obstacle Racing Gameplay Reveal Trailer (youtube.com)","link":"https://www.youtube.com/watch?v=2MeqPQCwNtU","pubDate":"Fri, 10 Sep 2021 15:37:11 +0000","comments":"https://www.reddit.com/r/Games/comments/plngiq/vroom_obstacle_racing_gameplay_reveal_trailer/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plngiq/vroom_obstacle_racing_gameplay_reveal_trailer/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2MeqPQCwNtU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plngiq/vroom_obstacle_racing_gameplay_reveal_trailer/","isoDate":"2021-09-10T15:37:11.000Z","timestamp":"9/10/2021"},{"title":"Tales of Arise shatters franchise record for the highest concurrent player count on Steam. 45,680 players so far, it's higher than all previous Tales games combined. (steamdb.info)","link":"https://steamdb.info/app/740130/graphs/","pubDate":"Fri, 10 Sep 2021 15:26:48 +0000","comments":"https://www.reddit.com/r/Games/comments/pln9b6/tales_of_arise_shatters_franchise_record_for_the/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pln9b6/tales_of_arise_shatters_franchise_record_for_the/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pln9b6/tales_of_arise_shatters_franchise_record_for_the/","isoDate":"2021-09-10T15:26:48.000Z","timestamp":"9/10/2021"},{"title":"WarioWare: Get It Together! - Launch Trailer - Nintendo Switch (youtu.be)","link":"https://youtu.be/Od0RTB_k73w","pubDate":"Fri, 10 Sep 2021 14:26:08 +0000","comments":"https://www.reddit.com/r/Games/comments/plm3wm/warioware_get_it_together_launch_trailer_nintendo/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plm3wm/warioware_get_it_together_launch_trailer_nintendo/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Od0RTB_k73w?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plm3wm/warioware_get_it_together_launch_trailer_nintendo/","isoDate":"2021-09-10T14:26:08.000Z","timestamp":"9/10/2021"},{"title":"Tales of ARISE - Launch Trailer (youtube.com)","link":"https://www.youtube.com/watch?v=2g3XPcVSX_A","pubDate":"Fri, 10 Sep 2021 14:04:38 +0000","comments":"https://www.reddit.com/r/Games/comments/pllpai/tales_of_arise_launch_trailer/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pllpai/tales_of_arise_launch_trailer/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/2g3XPcVSX_A?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pllpai/tales_of_arise_launch_trailer/","isoDate":"2021-09-10T14:04:38.000Z","timestamp":"9/10/2021"},{"title":"Xbox Series X/S can use standard SSDs in the expansion card slot, it’s claimed (videogameschronicle.com)","link":"https://www.videogameschronicle.com/news/xbox-series-x-s-can-use-standard-ssds-in-the-expansion-card-slot-its-claimed/","pubDate":"Fri, 10 Sep 2021 13:18:50 +0000","comments":"https://www.reddit.com/r/Games/comments/plkvzb/xbox_series_xs_can_use_standard_ssds_in_the/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plkvzb/xbox_series_xs_can_use_standard_ssds_in_the/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plkvzb/xbox_series_xs_can_use_standard_ssds_in_the/","isoDate":"2021-09-10T13:18:50.000Z","timestamp":"9/10/2021"},{"title":"Platinum says it’s ‘proud’ of Bayonetta 3 and ‘wants to show it’ (videogameschronicle.com)","link":"https://www.videogameschronicle.com/news/platinum-says-its-proud-of-bayonetta-3-and-wants-to-show-it/","pubDate":"Fri, 10 Sep 2021 13:09:09 +0000","comments":"https://www.reddit.com/r/Games/comments/plkpz0/platinum_says_its_proud_of_bayonetta_3_and_wants/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plkpz0/platinum_says_its_proud_of_bayonetta_3_and_wants/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/plkpz0/platinum_says_its_proud_of_bayonetta_3_and_wants/","isoDate":"2021-09-10T13:09:09.000Z","timestamp":"9/10/2021"},{"title":"Lost in Random - Review Thread (self.Games)","link":"https://www.reddit.com/r/Games/comments/plkby6/lost_in_random_review_thread/","pubDate":"Fri, 10 Sep 2021 12:46:33 +0000","comments":"https://www.reddit.com/r/Games/comments/plkby6/lost_in_random_review_thread/","content":"<p><a href='https://www.reddit.com/r/Games/comments/plkby6/lost_in_random_review_thread/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p><strong>Game Information</strong></p>\n\n<p><strong>Game Title:</strong> Lost in Random</p>\n\n<p><strong>Platforms:</strong></p>\n\n<ul>\n<li>PC (10th September 2021)</li>\n<li>Xbox One (10th September 2021)</li>\n<li>Xbox Series X|S (10th September 2021)</li>\n<li>PlayStation 4 (10th September 2021)</li>\n<li>PlayStation 5 (10th September 2021)</li>\n<li>Switch (10th September 2021)</li>\n</ul>\n\n<p><strong>Trailers:</strong></p>\n\n<ul>\n<li><a href=\"https://youtu.be/QdM8pFtjtcI\">Lost in Random Teaser Trailer // June 2020</a></li>\n<li><a href=\"https://youtu.be/FBM4wBbOgQk\">Lost in Random Story Trailer // June 2021</a></li>\n<li><a href=\"https://youtu.be/diilMn5gSAg\">Lost in Random Gameplay Trailer // July 2021</a></li>\n</ul>\n\n<p><strong>Developer:</strong> Zoink</p>\n\n<p><strong>Publisher:</strong> Electronic Arts (EA Originals)</p>\n\n<p><strong>Genre:</strong> Action</p>\n\n<p><strong>Review Aggregator</strong></p>\n\n<p><a href=\"https://opencritic.com/game/11918/lost-in-random\">OpenCritic - 78% Top Critic Average - 70% Critics Recommend</a></p>\n\n<p><strong>Critic Reviews</strong></p>\n\n<p><a href=\"https://www.ausgamers.com/games/lost-in-random/review/\">AusGamers</a> - 8/10</p>\n\n<blockquote>\n<p>Interesting combat aside, what resonates and exhilarates about Lost in Random is its story first and foremost. The adventure that Even embarks on is one to savour and one that lives up to the wonderful art direction and visual design. The characters, the dialogue, the discoveries, the animation, the voice acting, the music, the presentation -- it all comes together wonderfully. A game well worth taking a chance and rolling the dice on.</p>\n</blockquote>\n\n<p><a href=\"https://www.cgmagonline.com/review/lost-in-random-review/\">CGMagOnline</a> - 7.5/10</p>\n\n<blockquote>\n<p>Like a toss of the dice, Lost in Random can be truly inspired at times, and a little underwhelming at others.</p>\n</blockquote>\n\n<p><a href=\"https://comicbook.com/gaming/news/lost-in-random-review-a-charming-roll-of-the-dice-you-wont-forget/\">Comic Book</a> - 4/5</p>\n\n<blockquote>\n<p>Even with that gripe, Lost in Random just does so much right that it doesn't even really matter. I wouldn't trade my experience in the game for anything, and I'd be willing to get lost in the world of Random all-over gain. If you're on the fence, trust me, just roll the dice and jump on in, because you won't regret it.</p>\n</blockquote>\n\n<p><a href=\"https://www.destructoid.com/reviews/review-lost-in-random/\">Destructoid</a> - 8/10</p>\n\n<blockquote>\n<p>Aside from a couple of noticeable dips with less fleshed-out areas in the final act, Zoink held my attention for my entire 11-hour playthrough. That counts for a lot. If given the chance, I’d love to return to the world of Random in a possible sequel to Lost in Random that smooths over some of these first-game-in-a-new-series pitfalls.</p>\n</blockquote>\n\n<p><a href=\"https://www.gameinformer.com/review/lost-in-random/playing-its-cards-right\">Gameinformer</a> - 8.25/10</p>\n\n<blockquote>\n<p>This shadowy fairy tale ties together a thoughtful story, evocative art style, and clever combat system in one engaging experience. Lost in Random has a lot to offer at any time, but the game’s bizarre world and characteristic, spooky atmosphere make it an excellent pick for the Halloween season.</p>\n</blockquote>\n\n<p><a href=\"https://www.gamereactor.eu/lost-in-random-review/\">Gamerreactor</a> - 8/10</p>\n\n<blockquote>\n<p>Lost in Random is a pretty incredible indie game, as it's one of the most unique concepts I've ever experienced, and it's been handled in such a well-thought out and fluid manner. You never feel out of your depth in the game, and in fact it's so enthralling that you'll want to keep on playing. It's easy to look at the concept of Lost in Random and feel a little uncertain, as it's a game that looks at the industry and established genres we know and refuses to conform, but if you're willing to roll the dice and take a risk with what Zoink has created, you'll be in for a unique journey that doesn't disappoint.</p>\n</blockquote>\n\n<p><a href=\"https://geekculture.co/geek-review-lost-in-random/\">Geek Culture</a> - 8.6/10</p>\n\n<blockquote>\n<p>An exciting story of evens and odds, Lost in Random is the kind of action-adventure that is worth experiencing no matter who you are.</p>\n</blockquote>\n\n<p><a href=\"https://www.gfinityesports.com/reviews/lost-in-random/\">Gfinity</a> - 4/5</p>\n\n<blockquote>\n<p>Lost in Random is easily one of the more unique games I’ve played recently. Offering an entertaining fusion of deck-builders and real-time combat, Zoink’s done well in realising their vision. Thanks to chance-based combat, lack of enemy variety and some long-winded dialogue with NPCs, it's not perfect, but ultimately, the positives outweigh these points. With some strong combat customisation, a captivating story and excellent art style, Lost in Random comes highly recommended.</p>\n</blockquote>\n\n<p><a href=\"https://www.godisageek.com/reviews/lost-in-random-review/\">God Is A Geek</a> - 8/10</p>\n\n<blockquote>\n<p>Despite some clunky movement, Lost in Random features smart combat and a world filled with wonder, mystery, and excitement.</p>\n</blockquote>\n\n<p><a href=\"https://www.pushsquare.com/reviews/ps5/lost_in_random\">Pushsquare</a> - 8/10</p>\n\n<blockquote>\n<p>Lost in Random is set in a masterfully crafted world which tells a gothic fairy tale-like story that has plenty of warmth despite its dark hue. With beautiful writing and a touching story, it does a great job at making you really care about what happens to Even, as well as everyone she meets. It also has a truly unique battle system that offers loads of fun in your quest to create a perfect deck. This is a delight to play from beginning to end.</p>\n</blockquote>\n\n<p><a href=\"https://www.radiotimes.com/technology/gaming/lost-in-random-review-humour-heart/amp/\">Radio Times</a> - 4/5</p>\n\n<blockquote>\n<p>This is a game full of surprises and enough twists to the gameplay along the way to keep it feeling fresh throughout. Things do have a habit of getting repetitive on occasion but not enough to impact the overall experience too much. The main takeaway for us is how much we want to revisit this world and to see it expand. There is so much potential for this universe and we hope we get to see it. Lost in Random may be random, but it's also an extremely fun game.</p>\n</blockquote>\n\n<p><a href=\"https://www.rockpapershotgun.com/lost-in-random-review\">Rock Paper Shotgun</a> - Unscored</p>\n\n<blockquote>\n<p>Lost In Random gets lots of things right, including that Dicey is now with us. But for an adventure game with such a wacky setting, it somehow doesn't get playful enough - or really even random enough - to elevate itself from a solid time to a rip-roaring one.</p>\n</blockquote>\n\n<p><a href=\"https://screenrant.com/lost-in-random-game-review/#:%7E:text=Lost%20In%20Random%20Review%3A%20A%20Distinct%20Blend%20Of,in%20video%20games%20is%20an%20oft-derided%20gameplay%20element.\">Screenrant</a> - 4/5</p>\n\n<blockquote>\n<p>While not flawless, Lost in Random's impressively weird art style and unique approach to its combat give it a distinct feeling all its own.</p>\n</blockquote>\n\n<p><a href=\"https://www.shacknews.com/article/126578/lost-in-random-review-burton-esque-dice-adventures?amphtml=1\">Shacknews</a>- 7/10</p>\n\n<blockquote>\n<p>Ultimately, I think what Lost in Random reminds me of most is American McGee’s early Alice games, but less brutal and more whimsical. It’s got a similar form of macabre about its world and narrative, but it also has a similar limitation and technical tarnish that those games had. Even and Dicey’s Journey to save Odd and stop the Queen is well written and presented by the game’s action, music, and narrative, but it feels like there’s also varying degrees of jank just sitting in your periphery. Get past that, and I still feel this is a fairy-tale adventure that deserves a cover-to-cover read.</p>\n</blockquote>\n\n<p><a href=\"https://sirusgaming.com/2021/09/10/lost-in-random-review/\">Sirius Gaming</a> - 8/10</p>\n\n<blockquote>\n<p>Lost in Random has the potential of a modern classic in the making. More than the Tim Burton vibes or the uniqueness of the combat mechanics. There is a certain charm to its writing and the line delivery that’s hard to place, be the epic poetry battle with Mayor Royam or Seemore giving Even a pep talk worthy of a sports underdog movie. It’s one of those games that I would actually consider a sleeper hit. As such, I highly recommend for the story content first. The combat, a near second.</p>\n</blockquote>\n\n<p><a href=\"https://www.thegamer.com/lost-in-random-review/\">The Gamer</a> - Unscored</p>\n\n<blockquote>\n<p>Lost in Random is an okay 15-hour game, front-loaded with seven fantastic hours. It’s worth playing even if you don’t make it to the end, simply because there’s never been another game like it. Disney goths will delight in its charming blend of cute and macabre, and there are some legitimate thrills to be had with the combat system for strategy-brained players like myself. If it had continued to innovate with new battle mechanics and more cards to collect throughout the entire game, it would be an easy contender for game of the year for me. Unfortunately, it rests on its laurels too early, and the game as a whole suffers for it. I would be eager to return to Random were there ever a sequel, but I don’t think I’ll be revisiting Lost in Random again anytime soon.</p>\n</blockquote>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nGame Information\nGame Title: Lost in Random\nPlatforms:\nPC (10th September 2021)\nXbox One (10th September 2021)\nXbox Series X|S (10th September 2021)\nPlayStation 4 (10th September 2021)\nPlayStation 5 (10th September 2021)\nSwitch (10th September 2021)\nTrailers:\nLost in Random Teaser Trailer // June 2020\nLost in Random Story Trailer // June 2021\nLost in Random Gameplay Trailer // July 2021\nDeveloper: Zoink\nPublisher: Electronic Arts (EA Originals)\nGenre: Action\nReview Aggregator\nOpenCritic - 78% Top Critic Average - 70% Critics Recommend\nCritic Reviews\nAusGamers - 8/10\nInteresting combat aside, what resonates and exhilarates about Lost in Random is its story first and foremost. The adventure that Even embarks on is one to savour and one that lives up to the wonderful art direction and visual design. The characters, the dialogue, the discoveries, the animation, the voice acting, the music, the presentation -- it all comes together wonderfully. A game well worth taking a chance and rolling the dice on.\nCGMagOnline - 7.5/10\nLike a toss of the dice, Lost in Random can be truly inspired at times, and a little underwhelming at others.\nComic Book - 4/5\nEven with that gripe, Lost in Random just does so much right that it doesn't even really matter. I wouldn't trade my experience in the game for anything, and I'd be willing to get lost in the world of Random all-over gain. If you're on the fence, trust me, just roll the dice and jump on in, because you won't regret it.\nDestructoid - 8/10\nAside from a couple of noticeable dips with less fleshed-out areas in the final act, Zoink held my attention for my entire 11-hour playthrough. That counts for a lot. If given the chance, I’d love to return to the world of Random in a possible sequel to Lost in Random that smooths over some of these first-game-in-a-new-series pitfalls.\nGameinformer - 8.25/10\nThis shadowy fairy tale ties together a thoughtful story, evocative art style, and clever combat system in one engaging experience. Lost in Random has a lot to offer at any time, but the game’s bizarre world and characteristic, spooky atmosphere make it an excellent pick for the Halloween season.\nGamerreactor - 8/10\nLost in Random is a pretty incredible indie game, as it's one of the most unique concepts I've ever experienced, and it's been handled in such a well-thought out and fluid manner. You never feel out of your depth in the game, and in fact it's so enthralling that you'll want to keep on playing. It's easy to look at the concept of Lost in Random and feel a little uncertain, as it's a game that looks at the industry and established genres we know and refuses to conform, but if you're willing to roll the dice and take a risk with what Zoink has created, you'll be in for a unique journey that doesn't disappoint.\nGeek Culture - 8.6/10\nAn exciting story of evens and odds, Lost in Random is the kind of action-adventure that is worth experiencing no matter who you are.\nGfinity - 4/5\nLost in Random is easily one of the more unique games I’ve played recently. Offering an entertaining fusion of deck-builders and real-time combat, Zoink’s done well in realising their vision. Thanks to chance-based combat, lack of enemy variety and some long-winded dialogue with NPCs, it's not perfect, but ultimately, the positives outweigh these points. With some strong combat customisation, a captivating story and excellent art style, Lost in Random comes highly recommended.\nGod Is A Geek - 8/10\nDespite some clunky movement, Lost in Random features smart combat and a world filled with wonder, mystery, and excitement.\nPushsquare - 8/10\nLost in Random is set in a masterfully crafted world which tells a gothic fairy tale-like story that has plenty of warmth despite its dark hue. With beautiful writing and a touching story, it does a great job at making you really care about what happens to Even, as well as everyone she meets. It also has a truly unique battle system that offers loads of fun in your quest to create a perfect deck. This is a delight to play from beginning to end.\nRadio Times - 4/5\nThis is a game full of surprises and enough twists to the gameplay along the way to keep it feeling fresh throughout. Things do have a habit of getting repetitive on occasion but not enough to impact the overall experience too much. The main takeaway for us is how much we want to revisit this world and to see it expand. There is so much potential for this universe and we hope we get to see it. Lost in Random may be random, but it's also an extremely fun game.\nRock Paper Shotgun - Unscored\nLost In Random gets lots of things right, including that Dicey is now with us. But for an adventure game with such a wacky setting, it somehow doesn't get playful enough - or really even random enough - to elevate itself from a solid time to a rip-roaring one.\nScreenrant - 4/5\nWhile not flawless, Lost in Random's impressively weird art style and unique approach to its combat give it a distinct feeling all its own.\nShacknews- 7/10\nUltimately, I think what Lost in Random reminds me of most is American McGee’s early Alice games, but less brutal and more whimsical. It’s got a similar form of macabre about its world and narrative, but it also has a similar limitation and technical tarnish that those games had. Even and Dicey’s Journey to save Odd and stop the Queen is well written and presented by the game’s action, music, and narrative, but it feels like there’s also varying degrees of jank just sitting in your periphery. Get past that, and I still feel this is a fairy-tale adventure that deserves a cover-to-cover read.\nSirius Gaming - 8/10\nLost in Random has the potential of a modern classic in the making. More than the Tim Burton vibes or the uniqueness of the combat mechanics. There is a certain charm to its writing and the line delivery that’s hard to place, be the epic poetry battle with Mayor Royam or Seemore giving Even a pep talk worthy of a sports underdog movie. It’s one of those games that I would actually consider a sleeper hit. As such, I highly recommend for the story content first. The combat, a near second.\nThe Gamer - Unscored\nLost in Random is an okay 15-hour game, front-loaded with seven fantastic hours. It’s worth playing even if you don’t make it to the end, simply because there’s never been another game like it. Disney goths will delight in its charming blend of cute and macabre, and there are some legitimate thrills to be had with the combat system for strategy-brained players like myself. If it had continued to innovate with new battle mechanics and more cards to collect throughout the entire game, it would be an easy contender for game of the year for me. Unfortunately, it rests on its laurels too early, and the game as a whole suffers for it. I would be eager to return to Random were there ever a sequel, but I don’t think I’ll be revisiting Lost in Random again anytime soon.","guid":"https://www.reddit.com/r/Games/comments/plkby6/lost_in_random_review_thread/","isoDate":"2021-09-10T12:46:33.000Z","timestamp":"9/10/2021"},{"title":"Metroid Dread - Overview Trailer - Nintendo Switch (youtube.com)","link":"https://www.youtube.com/watch?v=AOvefm5U250","pubDate":"Fri, 10 Sep 2021 12:10:39 +0000","comments":"https://www.reddit.com/r/Games/comments/pljryz/metroid_dread_overview_trailer_nintendo_switch/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pljryz/metroid_dread_overview_trailer_nintendo_switch/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AOvefm5U250?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pljryz/metroid_dread_overview_trailer_nintendo_switch/","isoDate":"2021-09-10T12:10:39.000Z","timestamp":"9/10/2021"},{"title":"Daily /r/Games Discussion - Free Talk Friday - September 10, 2021 (self.Games)","link":"https://www.reddit.com/r/Games/comments/pli054/daily_rgames_discussion_free_talk_friday/","pubDate":"Fri, 10 Sep 2021 10:00:17 +0000","comments":"https://www.reddit.com/r/Games/comments/pli054/daily_rgames_discussion_free_talk_friday/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pli054/daily_rgames_discussion_free_talk_friday/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>It's F-F-Friday, the best day of the week where you can finally get home and play video games all weekend and also, talk about anything not-games in this thread. </p>\n\n<p>Just keep our rules in mind, especially Rule 2. This post is set to sort comments by 'new' on default. </p>\n\n<p><strong>Obligatory Advertisements</strong></p>\n\n<p><a href=\"/r/Games\">/r/Games</a> has a Discord server! Feel free to join us and chit-chat about games here: <a href=\"https://discord.gg/zRPaXTn\">https://discord.gg/zRPaXTn</a></p>\n\n<p><strong>Scheduled Discussion Posts</strong> </p>\n\n<p>WEEKLY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28What+have+you+been+playing%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">What Have You Been Playing?</a></p>\n\n<p>MONDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Thematic%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Thematic Monday</a></p>\n\n<p>WEDNESDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Suggest%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Suggest Me A Game</a></p>\n\n<p>FRIDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Friday%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Free Talk Friday</a></p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nIt's F-F-Friday, the best day of the week where you can finally get home and play video games all weekend and also, talk about anything not-games in this thread. \nJust keep our rules in mind, especially Rule 2. This post is set to sort comments by 'new' on default. \nObligatory Advertisements\n/r/Games has a Discord server! Feel free to join us and chit-chat about games here: https://discord.gg/zRPaXTn\nScheduled Discussion Posts \nWEEKLY: What Have You Been Playing?\nMONDAY: Thematic Monday\nWEDNESDAY: Suggest Me A Game\nFRIDAY: Free Talk Friday","guid":"https://www.reddit.com/r/Games/comments/pli054/daily_rgames_discussion_free_talk_friday/","isoDate":"2021-09-10T10:00:17.000Z","timestamp":"9/10/2021"},{"title":"Star Wars: Knights of the Old Republic Remake is coming to PC as well (twitter.com)","link":"https://twitter.com/LucasfilmGames/status/1436066933032439824","pubDate":"Thu, 09 Sep 2021 21:13:10 +0000","comments":"https://www.reddit.com/r/Games/comments/pl6sfr/star_wars_knights_of_the_old_republic_remake_is/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl6sfr/star_wars_knights_of_the_old_republic_remake_is/'>Post permalink</a> </p><blockquote class=\"twitter-video\"><p lang=\"en\" dir=\"ltr\">A legendary story remade for a new generation of players is coming to PlayStation 5 and PC. <a href=\"https://t.co/JdeFhyMG9W\">https://t.co/JdeFhyMG9W</a></p>&amp;mdash; Lucasfilm Games (@LucasfilmGames) <a href=\"https://twitter.com/LucasfilmGames/status/1436066933032439824?ref_src=twsrc%5Etfw\">September 9, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n","contentSnippet":"Post permalink \n\nA legendary story remade for a new generation of players is coming to PlayStation 5 and PC. https://t.co/JdeFhyMG9W\n&mdash; Lucasfilm Games (@LucasfilmGames) September 9, 2021","guid":"https://www.reddit.com/r/Games/comments/pl6sfr/star_wars_knights_of_the_old_republic_remake_is/","isoDate":"2021-09-09T21:13:10.000Z","timestamp":"9/9/2021"},{"title":"God of War: Ragnarok – Gameplay Trailer | PlayStation Showcase 2021 (youtube.com)","link":"https://www.youtube.com/watch?v=TXukPnO9IdY","pubDate":"Thu, 09 Sep 2021 20:57:12 +0000","comments":"https://www.reddit.com/r/Games/comments/pl6h5g/god_of_war_ragnarok_gameplay_trailer_playstation/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl6h5g/god_of_war_ragnarok_gameplay_trailer_playstation/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/TXukPnO9IdY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl6h5g/god_of_war_ragnarok_gameplay_trailer_playstation/","isoDate":"2021-09-09T20:57:12.000Z","timestamp":"9/9/2021"},{"title":"First look at God of War Ragnarök (blog.playstation.com)","link":"https://blog.playstation.com/2021/09/09/first-look-at-god-of-war-ragnarok/","pubDate":"Thu, 09 Sep 2021 20:51:20 +0000","comments":"https://www.reddit.com/r/Games/comments/pl6d9y/first_look_at_god_of_war_ragnarök/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl6d9y/first_look_at_god_of_war_ragnarök/'>Post permalink</a> </p>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl6d9y/first_look_at_god_of_war_ragnarök/","isoDate":"2021-09-09T20:51:20.000Z","timestamp":"9/9/2021"},{"title":"Marvel's Wolverine - Reveal Trailer | PlayStation Showcase 2021 (youtube.com)","link":"https://www.youtube.com/watch?v=AF_f8kl8lJQ&ab_channel=IGN","pubDate":"Thu, 09 Sep 2021 20:41:29 +0000","comments":"https://www.reddit.com/r/Games/comments/pl66mr/marvels_wolverine_reveal_trailer_playstation/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl66mr/marvels_wolverine_reveal_trailer_playstation/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AF_f8kl8lJQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl66mr/marvels_wolverine_reveal_trailer_playstation/","isoDate":"2021-09-09T20:41:29.000Z","timestamp":"9/9/2021"},{"title":"Marvel's Spider-Man 2 - PlayStation Showcase 2021 Trailer | PS5 (youtube.com)","link":"https://www.youtube.com/watch?v=qIQ3xNqkVC4&feature=youtube_video_deck","pubDate":"Thu, 09 Sep 2021 20:40:12 +0000","comments":"https://www.reddit.com/r/Games/comments/pl65pp/marvels_spiderman_2_playstation_showcase_2021/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl65pp/marvels_spiderman_2_playstation_showcase_2021/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/qIQ3xNqkVC4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl65pp/marvels_spiderman_2_playstation_showcase_2021/","isoDate":"2021-09-09T20:40:12.000Z","timestamp":"9/9/2021"},{"title":"Uncharted: Legacy of Thieves Collection - PlayStation Showcase 2021 Trailer | PS5 (youtube.com)","link":"https://www.youtube.com/watch?v=IfrfJn_-24g","pubDate":"Thu, 09 Sep 2021 20:34:11 +0000","comments":"https://www.reddit.com/r/Games/comments/pl61hc/uncharted_legacy_of_thieves_collection/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl61hc/uncharted_legacy_of_thieves_collection/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/IfrfJn_-24g?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl61hc/uncharted_legacy_of_thieves_collection/","isoDate":"2021-09-09T20:34:11.000Z","timestamp":"9/9/2021"},{"title":"Forspoken - PlayStation Showcase 2021 | PS5 (youtube.com)","link":"https://www.youtube.com/watch?v=AdZUrXCqUck","pubDate":"Thu, 09 Sep 2021 20:16:36 +0000","comments":"https://www.reddit.com/r/Games/comments/pl5p2u/forspoken_playstation_showcase_2021_ps5/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl5p2u/forspoken_playstation_showcase_2021_ps5/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AdZUrXCqUck?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl5p2u/forspoken_playstation_showcase_2021_ps5/","isoDate":"2021-09-09T20:16:36.000Z","timestamp":"9/9/2021"},{"title":"Star Wars: Knights of the Old Republic Remake - PlayStation Showcase 2021 Trailer | PS5 (youtube.com)","link":"https://www.youtube.com/watch?v=lL-RfE-ioJ8","pubDate":"Thu, 09 Sep 2021 20:07:15 +0000","comments":"https://www.reddit.com/r/Games/comments/pl5in2/star_wars_knights_of_the_old_republic_remake/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pl5in2/star_wars_knights_of_the_old_republic_remake/'>Post permalink</a> </p><iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/lL-RfE-ioJ8?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","contentSnippet":"Post permalink","guid":"https://www.reddit.com/r/Games/comments/pl5in2/star_wars_knights_of_the_old_republic_remake/","isoDate":"2021-09-09T20:07:15.000Z","timestamp":"9/9/2021"},{"title":"Weekly /r/Games Discussion - What have you been playing, and what are your thoughts? - September 05, 2021 (self.Games)","link":"https://www.reddit.com/r/Games/comments/pi9ofw/weekly_rgames_discussion_what_have_you_been/","pubDate":"Sun, 05 Sep 2021 09:00:12 +0000","comments":"https://www.reddit.com/r/Games/comments/pi9ofw/weekly_rgames_discussion_what_have_you_been/","content":"<p><a href='https://www.reddit.com/r/Games/comments/pi9ofw/weekly_rgames_discussion_what_have_you_been/'>Post permalink</a> </p><!-- SC_OFF --><div class=\"md\"><p>Use this thread to discuss whatever game you've been playing lately: old or new, AAA or indie, on any platform between Atari and XBox. Please don't just list off the games you're playing in your comment. Elaborate with your thoughts on the games and make it easier for other users to find what game you're talking about by putting the title in <strong>bold</strong>. </p>\n\n<p>Also, please make sure to use spoiler tags if you're revealing anything about a game's plot that may significantly impact another player's experience who has not played the game yet, no matter how retro or recent the game is. You can find instructions on how to do so in the subreddit sidebar. </p>\n\n<p>This thread is set to sort comments by 'new' on default. </p>\n\n<p><strong>Obligatory Advertisements</strong></p>\n\n<p>For a subreddit devoted to this type of discussion during the rest of the week, please check out <a href=\"/r/WhatAreYouPlaying\">/r/WhatAreYouPlaying</a>. </p>\n\n<p><a href=\"/r/Games\">/r/Games</a> has a Discord server! Feel free to join us and chit-chat about games here: <a href=\"https://discord.gg/zRPaXTn\">https://discord.gg/zRPaXTn</a></p>\n\n<p><strong>Scheduled Discussion Posts</strong> </p>\n\n<p>WEEKLY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28What+have+you+been+playing%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">What Have You Been Playing?</a></p>\n\n<p>MONDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Thematic%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Thematic Monday</a></p>\n\n<p>WEDNESDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Suggest%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Suggest Me A Game</a></p>\n\n<p>FRIDAY: <a href=\"https://www.reddit.com/r/Games/search?q=author%3AAutoModerator+AND+title%3A%28Friday%29&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all\">Free Talk Friday</a></p>\n</div><!-- SC_ON -->","contentSnippet":"Post permalink \n\nUse this thread to discuss whatever game you've been playing lately: old or new, AAA or indie, on any platform between Atari and XBox. Please don't just list off the games you're playing in your comment. Elaborate with your thoughts on the games and make it easier for other users to find what game you're talking about by putting the title in bold. \nAlso, please make sure to use spoiler tags if you're revealing anything about a game's plot that may significantly impact another player's experience who has not played the game yet, no matter how retro or recent the game is. You can find instructions on how to do so in the subreddit sidebar. \nThis thread is set to sort comments by 'new' on default. \nObligatory Advertisements\nFor a subreddit devoted to this type of discussion during the rest of the week, please check out /r/WhatAreYouPlaying. \n/r/Games has a Discord server! Feel free to join us and chit-chat about games here: https://discord.gg/zRPaXTn\nScheduled Discussion Posts \nWEEKLY: What Have You Been Playing?\nMONDAY: Thematic Monday\nWEDNESDAY: Suggest Me A Game\nFRIDAY: Free Talk Friday","guid":"https://www.reddit.com/r/Games/comments/pi9ofw/weekly_rgames_discussion_what_have_you_been/","isoDate":"2021-09-05T09:00:12.000Z","timestamp":"9/5/2021"}],"feedUrl":"https://reddit-top-rss.herokuapp.com/?subreddit=games&score=30&view=rss","image":{"url":"https://www.redditstatic.com/desktop2x/img/favicon/android-icon-192x192.png"},"paginationLinks":{"self":"https://reddit-top-rss.herokuapp.com/?subreddit=games&score=30&view=rss"},"title":"/r/games","description":"Hot posts in /r/games at or above a score of 30","generator":"PHP DOMDocument","link":"https://www.reddit.com/r/games","language":"en-us","lastBuildDate":"Sat, 11 Sep 2021 01:59:59 +0000","feed":"https://reddit-top-rss.herokuapp.com/?subreddit=games&score=30&view=rss"}]}